[2025-12-10 16:57:34,854 INFO train.py line 136 4140988] => Loading config ...
[2025-12-10 16:57:34,854 INFO train.py line 138 4140988] Save path: /home/shsi/outputs/on_sbatch/small_drop47_density
[2025-12-10 16:57:35,368 INFO train.py line 139 4140988] Config:
weight = None
resume = False
evaluate = False
test_only = False
seed = 38416291
save_path = '/home/shsi/outputs/on_sbatch/small_drop47_density'
num_worker = 16
batch_size = 1
batch_size_val = None
batch_size_test = None
epoch = 200
eval_epoch = 10
clip_grad = 3.0
sync_bn = False
enable_amp = True
amp_dtype = 'bfloat16'
empty_cache = False
empty_cache_per_epoch = True
find_unused_parameters = False
enable_wandb = False
wandb_project = 'pointcept'
wandb_key = '8e059ab5df68865b71cfae546e75a48702a68d65'
mix_prob = 0
param_dicts = [
    dict(keyword='enc0.block0.', lr=0.00035451752478610026),
    dict(keyword='enc0.block1.', lr=0.00039390836087344473),
    dict(keyword='enc0.block2.', lr=0.00043767595652604966),
    dict(keyword='enc1.block0.', lr=0.0004863066183622774),
    dict(keyword='enc1.block1.', lr=0.0005403406870691972),
    dict(keyword='enc1.block2.', lr=0.0006003785411879967),
    dict(keyword='enc2.block0.', lr=0.000667087267986663),
    dict(keyword='enc2.block1.', lr=0.0007412080755407367),
    dict(keyword='enc2.block2.', lr=0.0008235645283785963),
    dict(keyword='enc3.block0.', lr=0.0009150716981984404),
    dict(keyword='enc3.block1.', lr=0.0010167463313316004),
    dict(keyword='enc3.block2.', lr=0.0011297181459240004),
    dict(keyword='enc3.block3.', lr=0.0012552423843600004),
    dict(keyword='enc3.block4.', lr=0.0013947137604000005),
    dict(keyword='enc3.block5.', lr=0.0015496819560000003),
    dict(keyword='enc3.block6.', lr=0.0017218688400000004),
    dict(keyword='enc3.block7.', lr=0.0019131876000000004),
    dict(keyword='enc3.block8.', lr=0.002125764),
    dict(keyword='enc3.block9.', lr=0.00236196),
    dict(keyword='enc3.block10.', lr=0.0026244000000000003),
    dict(keyword='enc3.block11.', lr=0.0029160000000000006),
    dict(keyword='enc4.block0.', lr=0.0032400000000000003),
    dict(keyword='enc4.block1.', lr=0.0036000000000000003),
    dict(keyword='enc4.block2.', lr=0.004)
]
hooks = [
    dict(type='CheckpointLoader'),
    dict(type='ModelHook'),
    dict(type='WeightDecaySchedular', base_value=0.04, final_value=0.2),
    dict(type='IterationTimer', warmup_iter=2),
    dict(type='InformationWriter'),
    dict(type='CheckpointSaver', save_freq=5)
]
train = dict(type='DefaultTrainer')
test = dict(type='SemSegTester', verbose=True)
num_points_per_step = 65536
grid_size = 0.1
dataset_type = 'NavarraDataset'
data_root = '/home/shsi/datasets/Point_Cloud/navarra17'
model = dict(
    type='Sonata-v1m1_density_ssl',
    backbone=dict(
        type='PT-v3m2',
        in_channels=6,
        order=('z', 'z-trans', 'hilbert', 'hilbert-trans'),
        stride=(2, 2, 2, 2),
        enc_depths=(3, 3, 3, 12, 3),
        enc_channels=(48, 96, 192, 384, 512),
        enc_num_head=(3, 6, 12, 24, 32),
        enc_patch_size=(1024, 1024, 1024, 1024, 1024),
        mlp_ratio=4,
        qkv_bias=True,
        qk_scale=None,
        attn_drop=0.0,
        proj_drop=0.0,
        drop_path=0.3,
        shuffle_orders=True,
        pre_norm=True,
        enable_rpe=False,
        enable_flash=True,
        upcast_attention=False,
        upcast_softmax=False,
        traceable=True,
        enc_mode=True,
        mask_token=True),
    teacher_custom=dict(attn_drop=0.0, proj_drop=0.0, drop_path=0.0),
    head_in_channels=1088,
    head_hidden_channels=4096,
    head_embed_channels=256,
    head_num_prototypes=4096,
    num_global_view=2,
    num_local_view=4,
    mask_size_start=0.4,
    mask_size_base=1.2,
    mask_size_warmup_ratio=0.05,
    mask_ratio_start=0.3,
    mask_ratio_base=0.7,
    mask_ratio_warmup_ratio=0.05,
    mask_jitter=0.01,
    teacher_temp_start=0.04,
    teacher_temp_base=0.07,
    teacher_temp_warmup_ratio=0.05,
    student_temp=0.1,
    density_loss_weight=0.01,
    mask_loss_weight=0.25,
    roll_mask_loss_weight=0.25,
    unmask_loss_weight=0.5,
    momentum_base=0.994,
    momentum_final=1,
    match_max_k=8,
    match_max_r=0.32,
    up_cast_level=2)
base_lr = 0.004
lr_decay = 0.9
base_wd = 0.04
final_wd = 0.2
optimizer = dict(type='AdamW', lr=0.004, weight_decay=0.04)
scheduler = dict(
    type='OneCycleLR',
    max_lr=[
        0.004, 0.00035451752478610026, 0.00039390836087344473,
        0.00043767595652604966, 0.0004863066183622774, 0.0005403406870691972,
        0.0006003785411879967, 0.000667087267986663, 0.0007412080755407367,
        0.0008235645283785963, 0.0009150716981984404, 0.0010167463313316004,
        0.0011297181459240004, 0.0012552423843600004, 0.0013947137604000005,
        0.0015496819560000003, 0.0017218688400000004, 0.0019131876000000004,
        0.002125764, 0.00236196, 0.0026244000000000003, 0.0029160000000000006,
        0.0032400000000000003, 0.0036000000000000003, 0.004
    ],
    pct_start=0.05,
    anneal_strategy='cos',
    div_factor=10.0,
    final_div_factor=1000.0)
transform = [
    dict(type='GridSample', grid_size=0.1, hash_type='fnv', mode='train'),
    dict(type='Copy', keys_dict=dict(coord='origin_coord')),
    dict(
        type='MultiViewGeneratorDesnitySSL',
        global_view_scale=(0.4, 1.0),
        local_view_scale=(0.1, 0.4),
        enable_density_simulation=True,
        student_drop_rate=(0.4, 0.7),
        view_keys=('coord', 'origin_coord', 'color'),
        global_view_num=2,
        local_view_num=4,
        global_shared_transform=[
            dict(
                type='RandomColorJitter',
                brightness=0.4,
                contrast=0.4,
                saturation=0.2,
                hue=0.02,
                p=0.8),
            dict(type='ChromaticTranslation', p=0.95, ratio=0.05)
        ],
        global_transform=[
            dict(type='CenterShift', apply_z=True),
            dict(type='RandomScale', scale=[0.8, 1.2]),
            dict(
                type='RandomRotate',
                angle=[-0.1, 0.1],
                axis='z',
                center=[0, 0, 0],
                p=0.8),
            dict(
                type='RandomRotate',
                angle=[-0.015625, 0.015625],
                axis='x',
                p=0.8),
            dict(
                type='RandomRotate',
                angle=[-0.015625, 0.015625],
                axis='y',
                p=0.8),
            dict(type='RandomFlip', p=0.5),
            dict(type='RandomJitter', sigma=0.05, clip=0.5)
        ],
        local_transform=[
            dict(type='CenterShift', apply_z=True),
            dict(type='RandomScale', scale=[0.8, 1.2]),
            dict(
                type='RandomRotate',
                angle=[-0.1, 0.1],
                axis='z',
                center=[0, 0, 0],
                p=0.8),
            dict(
                type='RandomRotate',
                angle=[-0.015625, 0.015625],
                axis='x',
                p=0.8),
            dict(
                type='RandomRotate',
                angle=[-0.015625, 0.015625],
                axis='y',
                p=0.8),
            dict(type='RandomFlip', p=0.5),
            dict(type='RandomJitter', sigma=0.05, clip=0.5),
            dict(
                type='RandomColorJitter',
                brightness=0.4,
                contrast=0.4,
                saturation=0.2,
                hue=0.02,
                p=0.8),
            dict(type='ChromaticTranslation', p=0.95, ratio=0.05)
        ],
        max_size=65536),
    dict(type='ToTensor'),
    dict(type='Update', keys_dict=dict(grid_size=0.1)),
    dict(
        type='Collect',
        keys=('global_origin_coord', 'global_coord', 'global_color',
              'global_offset', 'local_origin_coord', 'local_coord',
              'local_color', 'local_offset', 'grid_size', 'name',
              'sparse_coord', 'sparse_color', 'sparse_offset'),
        offset_keys_dict=dict(),
        global_feat_keys=('global_coord', 'global_color'),
        local_feat_keys=('local_coord', 'local_color'),
        sparse_feat_keys=('sparse_coord', 'sparse_color'))
]
data = dict(
    train=dict(
        type='NavarraDataset',
        split=('train', 'val'),
        data_root='/home/shsi/datasets/Point_Cloud/navarra17',
        transform=[
            dict(
                type='GridSample',
                grid_size=0.1,
                hash_type='fnv',
                mode='train'),
            dict(type='Copy', keys_dict=dict(coord='origin_coord')),
            dict(
                type='MultiViewGeneratorDesnitySSL',
                global_view_scale=(0.4, 1.0),
                local_view_scale=(0.1, 0.4),
                enable_density_simulation=True,
                student_drop_rate=(0.4, 0.7),
                view_keys=('coord', 'origin_coord', 'color'),
                global_view_num=2,
                local_view_num=4,
                global_shared_transform=[
                    dict(
                        type='RandomColorJitter',
                        brightness=0.4,
                        contrast=0.4,
                        saturation=0.2,
                        hue=0.02,
                        p=0.8),
                    dict(type='ChromaticTranslation', p=0.95, ratio=0.05)
                ],
                global_transform=[
                    dict(type='CenterShift', apply_z=True),
                    dict(type='RandomScale', scale=[0.8, 1.2]),
                    dict(
                        type='RandomRotate',
                        angle=[-0.1, 0.1],
                        axis='z',
                        center=[0, 0, 0],
                        p=0.8),
                    dict(
                        type='RandomRotate',
                        angle=[-0.015625, 0.015625],
                        axis='x',
                        p=0.8),
                    dict(
                        type='RandomRotate',
                        angle=[-0.015625, 0.015625],
                        axis='y',
                        p=0.8),
                    dict(type='RandomFlip', p=0.5),
                    dict(type='RandomJitter', sigma=0.05, clip=0.5)
                ],
                local_transform=[
                    dict(type='CenterShift', apply_z=True),
                    dict(type='RandomScale', scale=[0.8, 1.2]),
                    dict(
                        type='RandomRotate',
                        angle=[-0.1, 0.1],
                        axis='z',
                        center=[0, 0, 0],
                        p=0.8),
                    dict(
                        type='RandomRotate',
                        angle=[-0.015625, 0.015625],
                        axis='x',
                        p=0.8),
                    dict(
                        type='RandomRotate',
                        angle=[-0.015625, 0.015625],
                        axis='y',
                        p=0.8),
                    dict(type='RandomFlip', p=0.5),
                    dict(type='RandomJitter', sigma=0.05, clip=0.5),
                    dict(
                        type='RandomColorJitter',
                        brightness=0.4,
                        contrast=0.4,
                        saturation=0.2,
                        hue=0.02,
                        p=0.8),
                    dict(type='ChromaticTranslation', p=0.95, ratio=0.05)
                ],
                max_size=65536),
            dict(type='ToTensor'),
            dict(type='Update', keys_dict=dict(grid_size=0.1)),
            dict(
                type='Collect',
                keys=('global_origin_coord', 'global_coord', 'global_color',
                      'global_offset', 'local_origin_coord', 'local_coord',
                      'local_color', 'local_offset', 'grid_size', 'name',
                      'sparse_coord', 'sparse_color', 'sparse_offset'),
                offset_keys_dict=dict(),
                global_feat_keys=('global_coord', 'global_color'),
                local_feat_keys=('local_coord', 'local_color'),
                sparse_feat_keys=('sparse_coord', 'sparse_color'))
        ],
        test_mode=False,
        loop=20))
num_worker_per_gpu = 16
batch_size_per_gpu = 1
batch_size_val_per_gpu = 1
batch_size_test_per_gpu = 1

[2025-12-10 16:57:35,369 INFO train.py line 140 4140988] => Building model ...
[2025-12-10 16:57:37,260 INFO train.py line 241 4140988] Num params: 121577136
[2025-12-10 16:57:37,514 INFO train.py line 142 4140988] => Building writer ...
[2025-12-10 16:57:37,519 INFO train.py line 251 4140988] Tensorboard writer logging dir: /home/shsi/outputs/on_sbatch/small_drop47_density
[2025-12-10 16:57:37,519 INFO train.py line 144 4140988] => Building train dataset & dataloader ...
[2025-12-10 16:57:37,542 INFO defaults.py line 70 4140988] Totally 370 x 20 samples in processed ('train', 'val') set.
[2025-12-10 16:57:37,543 INFO train.py line 146 4140988] => Building val dataset & dataloader ...
[2025-12-10 16:57:37,543 INFO train.py line 148 4140988] => Building optimize, scheduler, scaler(amp) ...
[2025-12-10 16:57:37,552 INFO optimizer.py line 56 4140988] Params Group 1 - lr: 0.004; Params: ['student.backbone.embedding.mask_token', 'student.backbone.embedding.stem.linear.weight', 'student.backbone.embedding.stem.linear.bias', 'student.backbone.embedding.stem.norm.weight', 'student.backbone.embedding.stem.norm.bias', 'student.backbone.enc.enc1.down.proj.weight', 'student.backbone.enc.enc1.down.proj.bias', 'student.backbone.enc.enc1.down.norm.0.weight', 'student.backbone.enc.enc1.down.norm.0.bias', 'student.backbone.enc.enc2.down.proj.weight', 'student.backbone.enc.enc2.down.proj.bias', 'student.backbone.enc.enc2.down.norm.0.weight', 'student.backbone.enc.enc2.down.norm.0.bias', 'student.backbone.enc.enc3.down.proj.weight', 'student.backbone.enc.enc3.down.proj.bias', 'student.backbone.enc.enc3.down.norm.0.weight', 'student.backbone.enc.enc3.down.norm.0.bias', 'student.backbone.enc.enc4.down.proj.weight', 'student.backbone.enc.enc4.down.proj.bias', 'student.backbone.enc.enc4.down.norm.0.weight', 'student.backbone.enc.enc4.down.norm.0.bias', 'student.mask_head.mlp.0.weight', 'student.mask_head.mlp.0.bias', 'student.mask_head.mlp.2.weight', 'student.mask_head.mlp.2.bias', 'student.mask_head.prototype.parametrizations.weight.original0', 'student.mask_head.prototype.parametrizations.weight.original1', 'student.unmask_head.mlp.0.weight', 'student.unmask_head.mlp.0.bias', 'student.unmask_head.mlp.2.weight', 'student.unmask_head.mlp.2.bias', 'student.unmask_head.prototype.parametrizations.weight.original0', 'student.unmask_head.prototype.parametrizations.weight.original1', 'teacher.backbone.embedding.mask_token', 'teacher.backbone.embedding.stem.linear.weight', 'teacher.backbone.embedding.stem.linear.bias', 'teacher.backbone.embedding.stem.norm.weight', 'teacher.backbone.embedding.stem.norm.bias', 'teacher.backbone.enc.enc1.down.proj.weight', 'teacher.backbone.enc.enc1.down.proj.bias', 'teacher.backbone.enc.enc1.down.norm.0.weight', 'teacher.backbone.enc.enc1.down.norm.0.bias', 'teacher.backbone.enc.enc2.down.proj.weight', 'teacher.backbone.enc.enc2.down.proj.bias', 'teacher.backbone.enc.enc2.down.norm.0.weight', 'teacher.backbone.enc.enc2.down.norm.0.bias', 'teacher.backbone.enc.enc3.down.proj.weight', 'teacher.backbone.enc.enc3.down.proj.bias', 'teacher.backbone.enc.enc3.down.norm.0.weight', 'teacher.backbone.enc.enc3.down.norm.0.bias', 'teacher.backbone.enc.enc4.down.proj.weight', 'teacher.backbone.enc.enc4.down.proj.bias', 'teacher.backbone.enc.enc4.down.norm.0.weight', 'teacher.backbone.enc.enc4.down.norm.0.bias', 'teacher.mask_head.mlp.0.weight', 'teacher.mask_head.mlp.0.bias', 'teacher.mask_head.mlp.2.weight', 'teacher.mask_head.mlp.2.bias', 'teacher.mask_head.prototype.parametrizations.weight.original0', 'teacher.mask_head.prototype.parametrizations.weight.original1', 'teacher.unmask_head.mlp.0.weight', 'teacher.unmask_head.mlp.0.bias', 'teacher.unmask_head.mlp.2.weight', 'teacher.unmask_head.mlp.2.bias', 'teacher.unmask_head.prototype.parametrizations.weight.original0', 'teacher.unmask_head.prototype.parametrizations.weight.original1'].
[2025-12-10 16:57:37,552 INFO optimizer.py line 56 4140988] Params Group 2 - lr: 0.00035451752478610026; Params: ['student.backbone.enc.enc0.block0.cpe.0.weight', 'student.backbone.enc.enc0.block0.cpe.0.bias', 'student.backbone.enc.enc0.block0.cpe.1.weight', 'student.backbone.enc.enc0.block0.cpe.1.bias', 'student.backbone.enc.enc0.block0.cpe.2.weight', 'student.backbone.enc.enc0.block0.cpe.2.bias', 'student.backbone.enc.enc0.block0.norm1.0.weight', 'student.backbone.enc.enc0.block0.norm1.0.bias', 'student.backbone.enc.enc0.block0.attn.qkv.weight', 'student.backbone.enc.enc0.block0.attn.qkv.bias', 'student.backbone.enc.enc0.block0.attn.proj.weight', 'student.backbone.enc.enc0.block0.attn.proj.bias', 'student.backbone.enc.enc0.block0.norm2.0.weight', 'student.backbone.enc.enc0.block0.norm2.0.bias', 'student.backbone.enc.enc0.block0.mlp.0.fc1.weight', 'student.backbone.enc.enc0.block0.mlp.0.fc1.bias', 'student.backbone.enc.enc0.block0.mlp.0.fc2.weight', 'student.backbone.enc.enc0.block0.mlp.0.fc2.bias', 'teacher.backbone.enc.enc0.block0.cpe.0.weight', 'teacher.backbone.enc.enc0.block0.cpe.0.bias', 'teacher.backbone.enc.enc0.block0.cpe.1.weight', 'teacher.backbone.enc.enc0.block0.cpe.1.bias', 'teacher.backbone.enc.enc0.block0.cpe.2.weight', 'teacher.backbone.enc.enc0.block0.cpe.2.bias', 'teacher.backbone.enc.enc0.block0.norm1.0.weight', 'teacher.backbone.enc.enc0.block0.norm1.0.bias', 'teacher.backbone.enc.enc0.block0.attn.qkv.weight', 'teacher.backbone.enc.enc0.block0.attn.qkv.bias', 'teacher.backbone.enc.enc0.block0.attn.proj.weight', 'teacher.backbone.enc.enc0.block0.attn.proj.bias', 'teacher.backbone.enc.enc0.block0.norm2.0.weight', 'teacher.backbone.enc.enc0.block0.norm2.0.bias', 'teacher.backbone.enc.enc0.block0.mlp.0.fc1.weight', 'teacher.backbone.enc.enc0.block0.mlp.0.fc1.bias', 'teacher.backbone.enc.enc0.block0.mlp.0.fc2.weight', 'teacher.backbone.enc.enc0.block0.mlp.0.fc2.bias'].
[2025-12-10 16:57:37,552 INFO optimizer.py line 56 4140988] Params Group 3 - lr: 0.00039390836087344473; Params: ['student.backbone.enc.enc0.block1.cpe.0.weight', 'student.backbone.enc.enc0.block1.cpe.0.bias', 'student.backbone.enc.enc0.block1.cpe.1.weight', 'student.backbone.enc.enc0.block1.cpe.1.bias', 'student.backbone.enc.enc0.block1.cpe.2.weight', 'student.backbone.enc.enc0.block1.cpe.2.bias', 'student.backbone.enc.enc0.block1.norm1.0.weight', 'student.backbone.enc.enc0.block1.norm1.0.bias', 'student.backbone.enc.enc0.block1.attn.qkv.weight', 'student.backbone.enc.enc0.block1.attn.qkv.bias', 'student.backbone.enc.enc0.block1.attn.proj.weight', 'student.backbone.enc.enc0.block1.attn.proj.bias', 'student.backbone.enc.enc0.block1.norm2.0.weight', 'student.backbone.enc.enc0.block1.norm2.0.bias', 'student.backbone.enc.enc0.block1.mlp.0.fc1.weight', 'student.backbone.enc.enc0.block1.mlp.0.fc1.bias', 'student.backbone.enc.enc0.block1.mlp.0.fc2.weight', 'student.backbone.enc.enc0.block1.mlp.0.fc2.bias', 'teacher.backbone.enc.enc0.block1.cpe.0.weight', 'teacher.backbone.enc.enc0.block1.cpe.0.bias', 'teacher.backbone.enc.enc0.block1.cpe.1.weight', 'teacher.backbone.enc.enc0.block1.cpe.1.bias', 'teacher.backbone.enc.enc0.block1.cpe.2.weight', 'teacher.backbone.enc.enc0.block1.cpe.2.bias', 'teacher.backbone.enc.enc0.block1.norm1.0.weight', 'teacher.backbone.enc.enc0.block1.norm1.0.bias', 'teacher.backbone.enc.enc0.block1.attn.qkv.weight', 'teacher.backbone.enc.enc0.block1.attn.qkv.bias', 'teacher.backbone.enc.enc0.block1.attn.proj.weight', 'teacher.backbone.enc.enc0.block1.attn.proj.bias', 'teacher.backbone.enc.enc0.block1.norm2.0.weight', 'teacher.backbone.enc.enc0.block1.norm2.0.bias', 'teacher.backbone.enc.enc0.block1.mlp.0.fc1.weight', 'teacher.backbone.enc.enc0.block1.mlp.0.fc1.bias', 'teacher.backbone.enc.enc0.block1.mlp.0.fc2.weight', 'teacher.backbone.enc.enc0.block1.mlp.0.fc2.bias'].
[2025-12-10 16:57:37,552 INFO optimizer.py line 56 4140988] Params Group 4 - lr: 0.00043767595652604966; Params: ['student.backbone.enc.enc0.block2.cpe.0.weight', 'student.backbone.enc.enc0.block2.cpe.0.bias', 'student.backbone.enc.enc0.block2.cpe.1.weight', 'student.backbone.enc.enc0.block2.cpe.1.bias', 'student.backbone.enc.enc0.block2.cpe.2.weight', 'student.backbone.enc.enc0.block2.cpe.2.bias', 'student.backbone.enc.enc0.block2.norm1.0.weight', 'student.backbone.enc.enc0.block2.norm1.0.bias', 'student.backbone.enc.enc0.block2.attn.qkv.weight', 'student.backbone.enc.enc0.block2.attn.qkv.bias', 'student.backbone.enc.enc0.block2.attn.proj.weight', 'student.backbone.enc.enc0.block2.attn.proj.bias', 'student.backbone.enc.enc0.block2.norm2.0.weight', 'student.backbone.enc.enc0.block2.norm2.0.bias', 'student.backbone.enc.enc0.block2.mlp.0.fc1.weight', 'student.backbone.enc.enc0.block2.mlp.0.fc1.bias', 'student.backbone.enc.enc0.block2.mlp.0.fc2.weight', 'student.backbone.enc.enc0.block2.mlp.0.fc2.bias', 'teacher.backbone.enc.enc0.block2.cpe.0.weight', 'teacher.backbone.enc.enc0.block2.cpe.0.bias', 'teacher.backbone.enc.enc0.block2.cpe.1.weight', 'teacher.backbone.enc.enc0.block2.cpe.1.bias', 'teacher.backbone.enc.enc0.block2.cpe.2.weight', 'teacher.backbone.enc.enc0.block2.cpe.2.bias', 'teacher.backbone.enc.enc0.block2.norm1.0.weight', 'teacher.backbone.enc.enc0.block2.norm1.0.bias', 'teacher.backbone.enc.enc0.block2.attn.qkv.weight', 'teacher.backbone.enc.enc0.block2.attn.qkv.bias', 'teacher.backbone.enc.enc0.block2.attn.proj.weight', 'teacher.backbone.enc.enc0.block2.attn.proj.bias', 'teacher.backbone.enc.enc0.block2.norm2.0.weight', 'teacher.backbone.enc.enc0.block2.norm2.0.bias', 'teacher.backbone.enc.enc0.block2.mlp.0.fc1.weight', 'teacher.backbone.enc.enc0.block2.mlp.0.fc1.bias', 'teacher.backbone.enc.enc0.block2.mlp.0.fc2.weight', 'teacher.backbone.enc.enc0.block2.mlp.0.fc2.bias'].
[2025-12-10 16:57:37,552 INFO optimizer.py line 56 4140988] Params Group 5 - lr: 0.0004863066183622774; Params: ['student.backbone.enc.enc1.block0.cpe.0.weight', 'student.backbone.enc.enc1.block0.cpe.0.bias', 'student.backbone.enc.enc1.block0.cpe.1.weight', 'student.backbone.enc.enc1.block0.cpe.1.bias', 'student.backbone.enc.enc1.block0.cpe.2.weight', 'student.backbone.enc.enc1.block0.cpe.2.bias', 'student.backbone.enc.enc1.block0.norm1.0.weight', 'student.backbone.enc.enc1.block0.norm1.0.bias', 'student.backbone.enc.enc1.block0.attn.qkv.weight', 'student.backbone.enc.enc1.block0.attn.qkv.bias', 'student.backbone.enc.enc1.block0.attn.proj.weight', 'student.backbone.enc.enc1.block0.attn.proj.bias', 'student.backbone.enc.enc1.block0.norm2.0.weight', 'student.backbone.enc.enc1.block0.norm2.0.bias', 'student.backbone.enc.enc1.block0.mlp.0.fc1.weight', 'student.backbone.enc.enc1.block0.mlp.0.fc1.bias', 'student.backbone.enc.enc1.block0.mlp.0.fc2.weight', 'student.backbone.enc.enc1.block0.mlp.0.fc2.bias', 'teacher.backbone.enc.enc1.block0.cpe.0.weight', 'teacher.backbone.enc.enc1.block0.cpe.0.bias', 'teacher.backbone.enc.enc1.block0.cpe.1.weight', 'teacher.backbone.enc.enc1.block0.cpe.1.bias', 'teacher.backbone.enc.enc1.block0.cpe.2.weight', 'teacher.backbone.enc.enc1.block0.cpe.2.bias', 'teacher.backbone.enc.enc1.block0.norm1.0.weight', 'teacher.backbone.enc.enc1.block0.norm1.0.bias', 'teacher.backbone.enc.enc1.block0.attn.qkv.weight', 'teacher.backbone.enc.enc1.block0.attn.qkv.bias', 'teacher.backbone.enc.enc1.block0.attn.proj.weight', 'teacher.backbone.enc.enc1.block0.attn.proj.bias', 'teacher.backbone.enc.enc1.block0.norm2.0.weight', 'teacher.backbone.enc.enc1.block0.norm2.0.bias', 'teacher.backbone.enc.enc1.block0.mlp.0.fc1.weight', 'teacher.backbone.enc.enc1.block0.mlp.0.fc1.bias', 'teacher.backbone.enc.enc1.block0.mlp.0.fc2.weight', 'teacher.backbone.enc.enc1.block0.mlp.0.fc2.bias'].
[2025-12-10 16:57:37,552 INFO optimizer.py line 56 4140988] Params Group 6 - lr: 0.0005403406870691972; Params: ['student.backbone.enc.enc1.block1.cpe.0.weight', 'student.backbone.enc.enc1.block1.cpe.0.bias', 'student.backbone.enc.enc1.block1.cpe.1.weight', 'student.backbone.enc.enc1.block1.cpe.1.bias', 'student.backbone.enc.enc1.block1.cpe.2.weight', 'student.backbone.enc.enc1.block1.cpe.2.bias', 'student.backbone.enc.enc1.block1.norm1.0.weight', 'student.backbone.enc.enc1.block1.norm1.0.bias', 'student.backbone.enc.enc1.block1.attn.qkv.weight', 'student.backbone.enc.enc1.block1.attn.qkv.bias', 'student.backbone.enc.enc1.block1.attn.proj.weight', 'student.backbone.enc.enc1.block1.attn.proj.bias', 'student.backbone.enc.enc1.block1.norm2.0.weight', 'student.backbone.enc.enc1.block1.norm2.0.bias', 'student.backbone.enc.enc1.block1.mlp.0.fc1.weight', 'student.backbone.enc.enc1.block1.mlp.0.fc1.bias', 'student.backbone.enc.enc1.block1.mlp.0.fc2.weight', 'student.backbone.enc.enc1.block1.mlp.0.fc2.bias', 'teacher.backbone.enc.enc1.block1.cpe.0.weight', 'teacher.backbone.enc.enc1.block1.cpe.0.bias', 'teacher.backbone.enc.enc1.block1.cpe.1.weight', 'teacher.backbone.enc.enc1.block1.cpe.1.bias', 'teacher.backbone.enc.enc1.block1.cpe.2.weight', 'teacher.backbone.enc.enc1.block1.cpe.2.bias', 'teacher.backbone.enc.enc1.block1.norm1.0.weight', 'teacher.backbone.enc.enc1.block1.norm1.0.bias', 'teacher.backbone.enc.enc1.block1.attn.qkv.weight', 'teacher.backbone.enc.enc1.block1.attn.qkv.bias', 'teacher.backbone.enc.enc1.block1.attn.proj.weight', 'teacher.backbone.enc.enc1.block1.attn.proj.bias', 'teacher.backbone.enc.enc1.block1.norm2.0.weight', 'teacher.backbone.enc.enc1.block1.norm2.0.bias', 'teacher.backbone.enc.enc1.block1.mlp.0.fc1.weight', 'teacher.backbone.enc.enc1.block1.mlp.0.fc1.bias', 'teacher.backbone.enc.enc1.block1.mlp.0.fc2.weight', 'teacher.backbone.enc.enc1.block1.mlp.0.fc2.bias'].
[2025-12-10 16:57:37,552 INFO optimizer.py line 56 4140988] Params Group 7 - lr: 0.0006003785411879967; Params: ['student.backbone.enc.enc1.block2.cpe.0.weight', 'student.backbone.enc.enc1.block2.cpe.0.bias', 'student.backbone.enc.enc1.block2.cpe.1.weight', 'student.backbone.enc.enc1.block2.cpe.1.bias', 'student.backbone.enc.enc1.block2.cpe.2.weight', 'student.backbone.enc.enc1.block2.cpe.2.bias', 'student.backbone.enc.enc1.block2.norm1.0.weight', 'student.backbone.enc.enc1.block2.norm1.0.bias', 'student.backbone.enc.enc1.block2.attn.qkv.weight', 'student.backbone.enc.enc1.block2.attn.qkv.bias', 'student.backbone.enc.enc1.block2.attn.proj.weight', 'student.backbone.enc.enc1.block2.attn.proj.bias', 'student.backbone.enc.enc1.block2.norm2.0.weight', 'student.backbone.enc.enc1.block2.norm2.0.bias', 'student.backbone.enc.enc1.block2.mlp.0.fc1.weight', 'student.backbone.enc.enc1.block2.mlp.0.fc1.bias', 'student.backbone.enc.enc1.block2.mlp.0.fc2.weight', 'student.backbone.enc.enc1.block2.mlp.0.fc2.bias', 'teacher.backbone.enc.enc1.block2.cpe.0.weight', 'teacher.backbone.enc.enc1.block2.cpe.0.bias', 'teacher.backbone.enc.enc1.block2.cpe.1.weight', 'teacher.backbone.enc.enc1.block2.cpe.1.bias', 'teacher.backbone.enc.enc1.block2.cpe.2.weight', 'teacher.backbone.enc.enc1.block2.cpe.2.bias', 'teacher.backbone.enc.enc1.block2.norm1.0.weight', 'teacher.backbone.enc.enc1.block2.norm1.0.bias', 'teacher.backbone.enc.enc1.block2.attn.qkv.weight', 'teacher.backbone.enc.enc1.block2.attn.qkv.bias', 'teacher.backbone.enc.enc1.block2.attn.proj.weight', 'teacher.backbone.enc.enc1.block2.attn.proj.bias', 'teacher.backbone.enc.enc1.block2.norm2.0.weight', 'teacher.backbone.enc.enc1.block2.norm2.0.bias', 'teacher.backbone.enc.enc1.block2.mlp.0.fc1.weight', 'teacher.backbone.enc.enc1.block2.mlp.0.fc1.bias', 'teacher.backbone.enc.enc1.block2.mlp.0.fc2.weight', 'teacher.backbone.enc.enc1.block2.mlp.0.fc2.bias'].
[2025-12-10 16:57:37,552 INFO optimizer.py line 56 4140988] Params Group 8 - lr: 0.000667087267986663; Params: ['student.backbone.enc.enc2.block0.cpe.0.weight', 'student.backbone.enc.enc2.block0.cpe.0.bias', 'student.backbone.enc.enc2.block0.cpe.1.weight', 'student.backbone.enc.enc2.block0.cpe.1.bias', 'student.backbone.enc.enc2.block0.cpe.2.weight', 'student.backbone.enc.enc2.block0.cpe.2.bias', 'student.backbone.enc.enc2.block0.norm1.0.weight', 'student.backbone.enc.enc2.block0.norm1.0.bias', 'student.backbone.enc.enc2.block0.attn.qkv.weight', 'student.backbone.enc.enc2.block0.attn.qkv.bias', 'student.backbone.enc.enc2.block0.attn.proj.weight', 'student.backbone.enc.enc2.block0.attn.proj.bias', 'student.backbone.enc.enc2.block0.norm2.0.weight', 'student.backbone.enc.enc2.block0.norm2.0.bias', 'student.backbone.enc.enc2.block0.mlp.0.fc1.weight', 'student.backbone.enc.enc2.block0.mlp.0.fc1.bias', 'student.backbone.enc.enc2.block0.mlp.0.fc2.weight', 'student.backbone.enc.enc2.block0.mlp.0.fc2.bias', 'teacher.backbone.enc.enc2.block0.cpe.0.weight', 'teacher.backbone.enc.enc2.block0.cpe.0.bias', 'teacher.backbone.enc.enc2.block0.cpe.1.weight', 'teacher.backbone.enc.enc2.block0.cpe.1.bias', 'teacher.backbone.enc.enc2.block0.cpe.2.weight', 'teacher.backbone.enc.enc2.block0.cpe.2.bias', 'teacher.backbone.enc.enc2.block0.norm1.0.weight', 'teacher.backbone.enc.enc2.block0.norm1.0.bias', 'teacher.backbone.enc.enc2.block0.attn.qkv.weight', 'teacher.backbone.enc.enc2.block0.attn.qkv.bias', 'teacher.backbone.enc.enc2.block0.attn.proj.weight', 'teacher.backbone.enc.enc2.block0.attn.proj.bias', 'teacher.backbone.enc.enc2.block0.norm2.0.weight', 'teacher.backbone.enc.enc2.block0.norm2.0.bias', 'teacher.backbone.enc.enc2.block0.mlp.0.fc1.weight', 'teacher.backbone.enc.enc2.block0.mlp.0.fc1.bias', 'teacher.backbone.enc.enc2.block0.mlp.0.fc2.weight', 'teacher.backbone.enc.enc2.block0.mlp.0.fc2.bias'].
[2025-12-10 16:57:37,552 INFO optimizer.py line 56 4140988] Params Group 9 - lr: 0.0007412080755407367; Params: ['student.backbone.enc.enc2.block1.cpe.0.weight', 'student.backbone.enc.enc2.block1.cpe.0.bias', 'student.backbone.enc.enc2.block1.cpe.1.weight', 'student.backbone.enc.enc2.block1.cpe.1.bias', 'student.backbone.enc.enc2.block1.cpe.2.weight', 'student.backbone.enc.enc2.block1.cpe.2.bias', 'student.backbone.enc.enc2.block1.norm1.0.weight', 'student.backbone.enc.enc2.block1.norm1.0.bias', 'student.backbone.enc.enc2.block1.attn.qkv.weight', 'student.backbone.enc.enc2.block1.attn.qkv.bias', 'student.backbone.enc.enc2.block1.attn.proj.weight', 'student.backbone.enc.enc2.block1.attn.proj.bias', 'student.backbone.enc.enc2.block1.norm2.0.weight', 'student.backbone.enc.enc2.block1.norm2.0.bias', 'student.backbone.enc.enc2.block1.mlp.0.fc1.weight', 'student.backbone.enc.enc2.block1.mlp.0.fc1.bias', 'student.backbone.enc.enc2.block1.mlp.0.fc2.weight', 'student.backbone.enc.enc2.block1.mlp.0.fc2.bias', 'teacher.backbone.enc.enc2.block1.cpe.0.weight', 'teacher.backbone.enc.enc2.block1.cpe.0.bias', 'teacher.backbone.enc.enc2.block1.cpe.1.weight', 'teacher.backbone.enc.enc2.block1.cpe.1.bias', 'teacher.backbone.enc.enc2.block1.cpe.2.weight', 'teacher.backbone.enc.enc2.block1.cpe.2.bias', 'teacher.backbone.enc.enc2.block1.norm1.0.weight', 'teacher.backbone.enc.enc2.block1.norm1.0.bias', 'teacher.backbone.enc.enc2.block1.attn.qkv.weight', 'teacher.backbone.enc.enc2.block1.attn.qkv.bias', 'teacher.backbone.enc.enc2.block1.attn.proj.weight', 'teacher.backbone.enc.enc2.block1.attn.proj.bias', 'teacher.backbone.enc.enc2.block1.norm2.0.weight', 'teacher.backbone.enc.enc2.block1.norm2.0.bias', 'teacher.backbone.enc.enc2.block1.mlp.0.fc1.weight', 'teacher.backbone.enc.enc2.block1.mlp.0.fc1.bias', 'teacher.backbone.enc.enc2.block1.mlp.0.fc2.weight', 'teacher.backbone.enc.enc2.block1.mlp.0.fc2.bias'].
[2025-12-10 16:57:37,552 INFO optimizer.py line 56 4140988] Params Group 10 - lr: 0.0008235645283785963; Params: ['student.backbone.enc.enc2.block2.cpe.0.weight', 'student.backbone.enc.enc2.block2.cpe.0.bias', 'student.backbone.enc.enc2.block2.cpe.1.weight', 'student.backbone.enc.enc2.block2.cpe.1.bias', 'student.backbone.enc.enc2.block2.cpe.2.weight', 'student.backbone.enc.enc2.block2.cpe.2.bias', 'student.backbone.enc.enc2.block2.norm1.0.weight', 'student.backbone.enc.enc2.block2.norm1.0.bias', 'student.backbone.enc.enc2.block2.attn.qkv.weight', 'student.backbone.enc.enc2.block2.attn.qkv.bias', 'student.backbone.enc.enc2.block2.attn.proj.weight', 'student.backbone.enc.enc2.block2.attn.proj.bias', 'student.backbone.enc.enc2.block2.norm2.0.weight', 'student.backbone.enc.enc2.block2.norm2.0.bias', 'student.backbone.enc.enc2.block2.mlp.0.fc1.weight', 'student.backbone.enc.enc2.block2.mlp.0.fc1.bias', 'student.backbone.enc.enc2.block2.mlp.0.fc2.weight', 'student.backbone.enc.enc2.block2.mlp.0.fc2.bias', 'teacher.backbone.enc.enc2.block2.cpe.0.weight', 'teacher.backbone.enc.enc2.block2.cpe.0.bias', 'teacher.backbone.enc.enc2.block2.cpe.1.weight', 'teacher.backbone.enc.enc2.block2.cpe.1.bias', 'teacher.backbone.enc.enc2.block2.cpe.2.weight', 'teacher.backbone.enc.enc2.block2.cpe.2.bias', 'teacher.backbone.enc.enc2.block2.norm1.0.weight', 'teacher.backbone.enc.enc2.block2.norm1.0.bias', 'teacher.backbone.enc.enc2.block2.attn.qkv.weight', 'teacher.backbone.enc.enc2.block2.attn.qkv.bias', 'teacher.backbone.enc.enc2.block2.attn.proj.weight', 'teacher.backbone.enc.enc2.block2.attn.proj.bias', 'teacher.backbone.enc.enc2.block2.norm2.0.weight', 'teacher.backbone.enc.enc2.block2.norm2.0.bias', 'teacher.backbone.enc.enc2.block2.mlp.0.fc1.weight', 'teacher.backbone.enc.enc2.block2.mlp.0.fc1.bias', 'teacher.backbone.enc.enc2.block2.mlp.0.fc2.weight', 'teacher.backbone.enc.enc2.block2.mlp.0.fc2.bias'].
[2025-12-10 16:57:37,552 INFO optimizer.py line 56 4140988] Params Group 11 - lr: 0.0009150716981984404; Params: ['student.backbone.enc.enc3.block0.cpe.0.weight', 'student.backbone.enc.enc3.block0.cpe.0.bias', 'student.backbone.enc.enc3.block0.cpe.1.weight', 'student.backbone.enc.enc3.block0.cpe.1.bias', 'student.backbone.enc.enc3.block0.cpe.2.weight', 'student.backbone.enc.enc3.block0.cpe.2.bias', 'student.backbone.enc.enc3.block0.norm1.0.weight', 'student.backbone.enc.enc3.block0.norm1.0.bias', 'student.backbone.enc.enc3.block0.attn.qkv.weight', 'student.backbone.enc.enc3.block0.attn.qkv.bias', 'student.backbone.enc.enc3.block0.attn.proj.weight', 'student.backbone.enc.enc3.block0.attn.proj.bias', 'student.backbone.enc.enc3.block0.norm2.0.weight', 'student.backbone.enc.enc3.block0.norm2.0.bias', 'student.backbone.enc.enc3.block0.mlp.0.fc1.weight', 'student.backbone.enc.enc3.block0.mlp.0.fc1.bias', 'student.backbone.enc.enc3.block0.mlp.0.fc2.weight', 'student.backbone.enc.enc3.block0.mlp.0.fc2.bias', 'teacher.backbone.enc.enc3.block0.cpe.0.weight', 'teacher.backbone.enc.enc3.block0.cpe.0.bias', 'teacher.backbone.enc.enc3.block0.cpe.1.weight', 'teacher.backbone.enc.enc3.block0.cpe.1.bias', 'teacher.backbone.enc.enc3.block0.cpe.2.weight', 'teacher.backbone.enc.enc3.block0.cpe.2.bias', 'teacher.backbone.enc.enc3.block0.norm1.0.weight', 'teacher.backbone.enc.enc3.block0.norm1.0.bias', 'teacher.backbone.enc.enc3.block0.attn.qkv.weight', 'teacher.backbone.enc.enc3.block0.attn.qkv.bias', 'teacher.backbone.enc.enc3.block0.attn.proj.weight', 'teacher.backbone.enc.enc3.block0.attn.proj.bias', 'teacher.backbone.enc.enc3.block0.norm2.0.weight', 'teacher.backbone.enc.enc3.block0.norm2.0.bias', 'teacher.backbone.enc.enc3.block0.mlp.0.fc1.weight', 'teacher.backbone.enc.enc3.block0.mlp.0.fc1.bias', 'teacher.backbone.enc.enc3.block0.mlp.0.fc2.weight', 'teacher.backbone.enc.enc3.block0.mlp.0.fc2.bias'].
[2025-12-10 16:57:37,552 INFO optimizer.py line 56 4140988] Params Group 12 - lr: 0.0010167463313316004; Params: ['student.backbone.enc.enc3.block1.cpe.0.weight', 'student.backbone.enc.enc3.block1.cpe.0.bias', 'student.backbone.enc.enc3.block1.cpe.1.weight', 'student.backbone.enc.enc3.block1.cpe.1.bias', 'student.backbone.enc.enc3.block1.cpe.2.weight', 'student.backbone.enc.enc3.block1.cpe.2.bias', 'student.backbone.enc.enc3.block1.norm1.0.weight', 'student.backbone.enc.enc3.block1.norm1.0.bias', 'student.backbone.enc.enc3.block1.attn.qkv.weight', 'student.backbone.enc.enc3.block1.attn.qkv.bias', 'student.backbone.enc.enc3.block1.attn.proj.weight', 'student.backbone.enc.enc3.block1.attn.proj.bias', 'student.backbone.enc.enc3.block1.norm2.0.weight', 'student.backbone.enc.enc3.block1.norm2.0.bias', 'student.backbone.enc.enc3.block1.mlp.0.fc1.weight', 'student.backbone.enc.enc3.block1.mlp.0.fc1.bias', 'student.backbone.enc.enc3.block1.mlp.0.fc2.weight', 'student.backbone.enc.enc3.block1.mlp.0.fc2.bias', 'teacher.backbone.enc.enc3.block1.cpe.0.weight', 'teacher.backbone.enc.enc3.block1.cpe.0.bias', 'teacher.backbone.enc.enc3.block1.cpe.1.weight', 'teacher.backbone.enc.enc3.block1.cpe.1.bias', 'teacher.backbone.enc.enc3.block1.cpe.2.weight', 'teacher.backbone.enc.enc3.block1.cpe.2.bias', 'teacher.backbone.enc.enc3.block1.norm1.0.weight', 'teacher.backbone.enc.enc3.block1.norm1.0.bias', 'teacher.backbone.enc.enc3.block1.attn.qkv.weight', 'teacher.backbone.enc.enc3.block1.attn.qkv.bias', 'teacher.backbone.enc.enc3.block1.attn.proj.weight', 'teacher.backbone.enc.enc3.block1.attn.proj.bias', 'teacher.backbone.enc.enc3.block1.norm2.0.weight', 'teacher.backbone.enc.enc3.block1.norm2.0.bias', 'teacher.backbone.enc.enc3.block1.mlp.0.fc1.weight', 'teacher.backbone.enc.enc3.block1.mlp.0.fc1.bias', 'teacher.backbone.enc.enc3.block1.mlp.0.fc2.weight', 'teacher.backbone.enc.enc3.block1.mlp.0.fc2.bias'].
[2025-12-10 16:57:37,552 INFO optimizer.py line 56 4140988] Params Group 13 - lr: 0.0011297181459240004; Params: ['student.backbone.enc.enc3.block2.cpe.0.weight', 'student.backbone.enc.enc3.block2.cpe.0.bias', 'student.backbone.enc.enc3.block2.cpe.1.weight', 'student.backbone.enc.enc3.block2.cpe.1.bias', 'student.backbone.enc.enc3.block2.cpe.2.weight', 'student.backbone.enc.enc3.block2.cpe.2.bias', 'student.backbone.enc.enc3.block2.norm1.0.weight', 'student.backbone.enc.enc3.block2.norm1.0.bias', 'student.backbone.enc.enc3.block2.attn.qkv.weight', 'student.backbone.enc.enc3.block2.attn.qkv.bias', 'student.backbone.enc.enc3.block2.attn.proj.weight', 'student.backbone.enc.enc3.block2.attn.proj.bias', 'student.backbone.enc.enc3.block2.norm2.0.weight', 'student.backbone.enc.enc3.block2.norm2.0.bias', 'student.backbone.enc.enc3.block2.mlp.0.fc1.weight', 'student.backbone.enc.enc3.block2.mlp.0.fc1.bias', 'student.backbone.enc.enc3.block2.mlp.0.fc2.weight', 'student.backbone.enc.enc3.block2.mlp.0.fc2.bias', 'teacher.backbone.enc.enc3.block2.cpe.0.weight', 'teacher.backbone.enc.enc3.block2.cpe.0.bias', 'teacher.backbone.enc.enc3.block2.cpe.1.weight', 'teacher.backbone.enc.enc3.block2.cpe.1.bias', 'teacher.backbone.enc.enc3.block2.cpe.2.weight', 'teacher.backbone.enc.enc3.block2.cpe.2.bias', 'teacher.backbone.enc.enc3.block2.norm1.0.weight', 'teacher.backbone.enc.enc3.block2.norm1.0.bias', 'teacher.backbone.enc.enc3.block2.attn.qkv.weight', 'teacher.backbone.enc.enc3.block2.attn.qkv.bias', 'teacher.backbone.enc.enc3.block2.attn.proj.weight', 'teacher.backbone.enc.enc3.block2.attn.proj.bias', 'teacher.backbone.enc.enc3.block2.norm2.0.weight', 'teacher.backbone.enc.enc3.block2.norm2.0.bias', 'teacher.backbone.enc.enc3.block2.mlp.0.fc1.weight', 'teacher.backbone.enc.enc3.block2.mlp.0.fc1.bias', 'teacher.backbone.enc.enc3.block2.mlp.0.fc2.weight', 'teacher.backbone.enc.enc3.block2.mlp.0.fc2.bias'].
[2025-12-10 16:57:37,552 INFO optimizer.py line 56 4140988] Params Group 14 - lr: 0.0012552423843600004; Params: ['student.backbone.enc.enc3.block3.cpe.0.weight', 'student.backbone.enc.enc3.block3.cpe.0.bias', 'student.backbone.enc.enc3.block3.cpe.1.weight', 'student.backbone.enc.enc3.block3.cpe.1.bias', 'student.backbone.enc.enc3.block3.cpe.2.weight', 'student.backbone.enc.enc3.block3.cpe.2.bias', 'student.backbone.enc.enc3.block3.norm1.0.weight', 'student.backbone.enc.enc3.block3.norm1.0.bias', 'student.backbone.enc.enc3.block3.attn.qkv.weight', 'student.backbone.enc.enc3.block3.attn.qkv.bias', 'student.backbone.enc.enc3.block3.attn.proj.weight', 'student.backbone.enc.enc3.block3.attn.proj.bias', 'student.backbone.enc.enc3.block3.norm2.0.weight', 'student.backbone.enc.enc3.block3.norm2.0.bias', 'student.backbone.enc.enc3.block3.mlp.0.fc1.weight', 'student.backbone.enc.enc3.block3.mlp.0.fc1.bias', 'student.backbone.enc.enc3.block3.mlp.0.fc2.weight', 'student.backbone.enc.enc3.block3.mlp.0.fc2.bias', 'teacher.backbone.enc.enc3.block3.cpe.0.weight', 'teacher.backbone.enc.enc3.block3.cpe.0.bias', 'teacher.backbone.enc.enc3.block3.cpe.1.weight', 'teacher.backbone.enc.enc3.block3.cpe.1.bias', 'teacher.backbone.enc.enc3.block3.cpe.2.weight', 'teacher.backbone.enc.enc3.block3.cpe.2.bias', 'teacher.backbone.enc.enc3.block3.norm1.0.weight', 'teacher.backbone.enc.enc3.block3.norm1.0.bias', 'teacher.backbone.enc.enc3.block3.attn.qkv.weight', 'teacher.backbone.enc.enc3.block3.attn.qkv.bias', 'teacher.backbone.enc.enc3.block3.attn.proj.weight', 'teacher.backbone.enc.enc3.block3.attn.proj.bias', 'teacher.backbone.enc.enc3.block3.norm2.0.weight', 'teacher.backbone.enc.enc3.block3.norm2.0.bias', 'teacher.backbone.enc.enc3.block3.mlp.0.fc1.weight', 'teacher.backbone.enc.enc3.block3.mlp.0.fc1.bias', 'teacher.backbone.enc.enc3.block3.mlp.0.fc2.weight', 'teacher.backbone.enc.enc3.block3.mlp.0.fc2.bias'].
[2025-12-10 16:57:37,552 INFO optimizer.py line 56 4140988] Params Group 15 - lr: 0.0013947137604000005; Params: ['student.backbone.enc.enc3.block4.cpe.0.weight', 'student.backbone.enc.enc3.block4.cpe.0.bias', 'student.backbone.enc.enc3.block4.cpe.1.weight', 'student.backbone.enc.enc3.block4.cpe.1.bias', 'student.backbone.enc.enc3.block4.cpe.2.weight', 'student.backbone.enc.enc3.block4.cpe.2.bias', 'student.backbone.enc.enc3.block4.norm1.0.weight', 'student.backbone.enc.enc3.block4.norm1.0.bias', 'student.backbone.enc.enc3.block4.attn.qkv.weight', 'student.backbone.enc.enc3.block4.attn.qkv.bias', 'student.backbone.enc.enc3.block4.attn.proj.weight', 'student.backbone.enc.enc3.block4.attn.proj.bias', 'student.backbone.enc.enc3.block4.norm2.0.weight', 'student.backbone.enc.enc3.block4.norm2.0.bias', 'student.backbone.enc.enc3.block4.mlp.0.fc1.weight', 'student.backbone.enc.enc3.block4.mlp.0.fc1.bias', 'student.backbone.enc.enc3.block4.mlp.0.fc2.weight', 'student.backbone.enc.enc3.block4.mlp.0.fc2.bias', 'teacher.backbone.enc.enc3.block4.cpe.0.weight', 'teacher.backbone.enc.enc3.block4.cpe.0.bias', 'teacher.backbone.enc.enc3.block4.cpe.1.weight', 'teacher.backbone.enc.enc3.block4.cpe.1.bias', 'teacher.backbone.enc.enc3.block4.cpe.2.weight', 'teacher.backbone.enc.enc3.block4.cpe.2.bias', 'teacher.backbone.enc.enc3.block4.norm1.0.weight', 'teacher.backbone.enc.enc3.block4.norm1.0.bias', 'teacher.backbone.enc.enc3.block4.attn.qkv.weight', 'teacher.backbone.enc.enc3.block4.attn.qkv.bias', 'teacher.backbone.enc.enc3.block4.attn.proj.weight', 'teacher.backbone.enc.enc3.block4.attn.proj.bias', 'teacher.backbone.enc.enc3.block4.norm2.0.weight', 'teacher.backbone.enc.enc3.block4.norm2.0.bias', 'teacher.backbone.enc.enc3.block4.mlp.0.fc1.weight', 'teacher.backbone.enc.enc3.block4.mlp.0.fc1.bias', 'teacher.backbone.enc.enc3.block4.mlp.0.fc2.weight', 'teacher.backbone.enc.enc3.block4.mlp.0.fc2.bias'].
[2025-12-10 16:57:37,552 INFO optimizer.py line 56 4140988] Params Group 16 - lr: 0.0015496819560000003; Params: ['student.backbone.enc.enc3.block5.cpe.0.weight', 'student.backbone.enc.enc3.block5.cpe.0.bias', 'student.backbone.enc.enc3.block5.cpe.1.weight', 'student.backbone.enc.enc3.block5.cpe.1.bias', 'student.backbone.enc.enc3.block5.cpe.2.weight', 'student.backbone.enc.enc3.block5.cpe.2.bias', 'student.backbone.enc.enc3.block5.norm1.0.weight', 'student.backbone.enc.enc3.block5.norm1.0.bias', 'student.backbone.enc.enc3.block5.attn.qkv.weight', 'student.backbone.enc.enc3.block5.attn.qkv.bias', 'student.backbone.enc.enc3.block5.attn.proj.weight', 'student.backbone.enc.enc3.block5.attn.proj.bias', 'student.backbone.enc.enc3.block5.norm2.0.weight', 'student.backbone.enc.enc3.block5.norm2.0.bias', 'student.backbone.enc.enc3.block5.mlp.0.fc1.weight', 'student.backbone.enc.enc3.block5.mlp.0.fc1.bias', 'student.backbone.enc.enc3.block5.mlp.0.fc2.weight', 'student.backbone.enc.enc3.block5.mlp.0.fc2.bias', 'teacher.backbone.enc.enc3.block5.cpe.0.weight', 'teacher.backbone.enc.enc3.block5.cpe.0.bias', 'teacher.backbone.enc.enc3.block5.cpe.1.weight', 'teacher.backbone.enc.enc3.block5.cpe.1.bias', 'teacher.backbone.enc.enc3.block5.cpe.2.weight', 'teacher.backbone.enc.enc3.block5.cpe.2.bias', 'teacher.backbone.enc.enc3.block5.norm1.0.weight', 'teacher.backbone.enc.enc3.block5.norm1.0.bias', 'teacher.backbone.enc.enc3.block5.attn.qkv.weight', 'teacher.backbone.enc.enc3.block5.attn.qkv.bias', 'teacher.backbone.enc.enc3.block5.attn.proj.weight', 'teacher.backbone.enc.enc3.block5.attn.proj.bias', 'teacher.backbone.enc.enc3.block5.norm2.0.weight', 'teacher.backbone.enc.enc3.block5.norm2.0.bias', 'teacher.backbone.enc.enc3.block5.mlp.0.fc1.weight', 'teacher.backbone.enc.enc3.block5.mlp.0.fc1.bias', 'teacher.backbone.enc.enc3.block5.mlp.0.fc2.weight', 'teacher.backbone.enc.enc3.block5.mlp.0.fc2.bias'].
[2025-12-10 16:57:37,552 INFO optimizer.py line 56 4140988] Params Group 17 - lr: 0.0017218688400000004; Params: ['student.backbone.enc.enc3.block6.cpe.0.weight', 'student.backbone.enc.enc3.block6.cpe.0.bias', 'student.backbone.enc.enc3.block6.cpe.1.weight', 'student.backbone.enc.enc3.block6.cpe.1.bias', 'student.backbone.enc.enc3.block6.cpe.2.weight', 'student.backbone.enc.enc3.block6.cpe.2.bias', 'student.backbone.enc.enc3.block6.norm1.0.weight', 'student.backbone.enc.enc3.block6.norm1.0.bias', 'student.backbone.enc.enc3.block6.attn.qkv.weight', 'student.backbone.enc.enc3.block6.attn.qkv.bias', 'student.backbone.enc.enc3.block6.attn.proj.weight', 'student.backbone.enc.enc3.block6.attn.proj.bias', 'student.backbone.enc.enc3.block6.norm2.0.weight', 'student.backbone.enc.enc3.block6.norm2.0.bias', 'student.backbone.enc.enc3.block6.mlp.0.fc1.weight', 'student.backbone.enc.enc3.block6.mlp.0.fc1.bias', 'student.backbone.enc.enc3.block6.mlp.0.fc2.weight', 'student.backbone.enc.enc3.block6.mlp.0.fc2.bias', 'teacher.backbone.enc.enc3.block6.cpe.0.weight', 'teacher.backbone.enc.enc3.block6.cpe.0.bias', 'teacher.backbone.enc.enc3.block6.cpe.1.weight', 'teacher.backbone.enc.enc3.block6.cpe.1.bias', 'teacher.backbone.enc.enc3.block6.cpe.2.weight', 'teacher.backbone.enc.enc3.block6.cpe.2.bias', 'teacher.backbone.enc.enc3.block6.norm1.0.weight', 'teacher.backbone.enc.enc3.block6.norm1.0.bias', 'teacher.backbone.enc.enc3.block6.attn.qkv.weight', 'teacher.backbone.enc.enc3.block6.attn.qkv.bias', 'teacher.backbone.enc.enc3.block6.attn.proj.weight', 'teacher.backbone.enc.enc3.block6.attn.proj.bias', 'teacher.backbone.enc.enc3.block6.norm2.0.weight', 'teacher.backbone.enc.enc3.block6.norm2.0.bias', 'teacher.backbone.enc.enc3.block6.mlp.0.fc1.weight', 'teacher.backbone.enc.enc3.block6.mlp.0.fc1.bias', 'teacher.backbone.enc.enc3.block6.mlp.0.fc2.weight', 'teacher.backbone.enc.enc3.block6.mlp.0.fc2.bias'].
[2025-12-10 16:57:37,552 INFO optimizer.py line 56 4140988] Params Group 18 - lr: 0.0019131876000000004; Params: ['student.backbone.enc.enc3.block7.cpe.0.weight', 'student.backbone.enc.enc3.block7.cpe.0.bias', 'student.backbone.enc.enc3.block7.cpe.1.weight', 'student.backbone.enc.enc3.block7.cpe.1.bias', 'student.backbone.enc.enc3.block7.cpe.2.weight', 'student.backbone.enc.enc3.block7.cpe.2.bias', 'student.backbone.enc.enc3.block7.norm1.0.weight', 'student.backbone.enc.enc3.block7.norm1.0.bias', 'student.backbone.enc.enc3.block7.attn.qkv.weight', 'student.backbone.enc.enc3.block7.attn.qkv.bias', 'student.backbone.enc.enc3.block7.attn.proj.weight', 'student.backbone.enc.enc3.block7.attn.proj.bias', 'student.backbone.enc.enc3.block7.norm2.0.weight', 'student.backbone.enc.enc3.block7.norm2.0.bias', 'student.backbone.enc.enc3.block7.mlp.0.fc1.weight', 'student.backbone.enc.enc3.block7.mlp.0.fc1.bias', 'student.backbone.enc.enc3.block7.mlp.0.fc2.weight', 'student.backbone.enc.enc3.block7.mlp.0.fc2.bias', 'teacher.backbone.enc.enc3.block7.cpe.0.weight', 'teacher.backbone.enc.enc3.block7.cpe.0.bias', 'teacher.backbone.enc.enc3.block7.cpe.1.weight', 'teacher.backbone.enc.enc3.block7.cpe.1.bias', 'teacher.backbone.enc.enc3.block7.cpe.2.weight', 'teacher.backbone.enc.enc3.block7.cpe.2.bias', 'teacher.backbone.enc.enc3.block7.norm1.0.weight', 'teacher.backbone.enc.enc3.block7.norm1.0.bias', 'teacher.backbone.enc.enc3.block7.attn.qkv.weight', 'teacher.backbone.enc.enc3.block7.attn.qkv.bias', 'teacher.backbone.enc.enc3.block7.attn.proj.weight', 'teacher.backbone.enc.enc3.block7.attn.proj.bias', 'teacher.backbone.enc.enc3.block7.norm2.0.weight', 'teacher.backbone.enc.enc3.block7.norm2.0.bias', 'teacher.backbone.enc.enc3.block7.mlp.0.fc1.weight', 'teacher.backbone.enc.enc3.block7.mlp.0.fc1.bias', 'teacher.backbone.enc.enc3.block7.mlp.0.fc2.weight', 'teacher.backbone.enc.enc3.block7.mlp.0.fc2.bias'].
[2025-12-10 16:57:37,552 INFO optimizer.py line 56 4140988] Params Group 19 - lr: 0.002125764; Params: ['student.backbone.enc.enc3.block8.cpe.0.weight', 'student.backbone.enc.enc3.block8.cpe.0.bias', 'student.backbone.enc.enc3.block8.cpe.1.weight', 'student.backbone.enc.enc3.block8.cpe.1.bias', 'student.backbone.enc.enc3.block8.cpe.2.weight', 'student.backbone.enc.enc3.block8.cpe.2.bias', 'student.backbone.enc.enc3.block8.norm1.0.weight', 'student.backbone.enc.enc3.block8.norm1.0.bias', 'student.backbone.enc.enc3.block8.attn.qkv.weight', 'student.backbone.enc.enc3.block8.attn.qkv.bias', 'student.backbone.enc.enc3.block8.attn.proj.weight', 'student.backbone.enc.enc3.block8.attn.proj.bias', 'student.backbone.enc.enc3.block8.norm2.0.weight', 'student.backbone.enc.enc3.block8.norm2.0.bias', 'student.backbone.enc.enc3.block8.mlp.0.fc1.weight', 'student.backbone.enc.enc3.block8.mlp.0.fc1.bias', 'student.backbone.enc.enc3.block8.mlp.0.fc2.weight', 'student.backbone.enc.enc3.block8.mlp.0.fc2.bias', 'teacher.backbone.enc.enc3.block8.cpe.0.weight', 'teacher.backbone.enc.enc3.block8.cpe.0.bias', 'teacher.backbone.enc.enc3.block8.cpe.1.weight', 'teacher.backbone.enc.enc3.block8.cpe.1.bias', 'teacher.backbone.enc.enc3.block8.cpe.2.weight', 'teacher.backbone.enc.enc3.block8.cpe.2.bias', 'teacher.backbone.enc.enc3.block8.norm1.0.weight', 'teacher.backbone.enc.enc3.block8.norm1.0.bias', 'teacher.backbone.enc.enc3.block8.attn.qkv.weight', 'teacher.backbone.enc.enc3.block8.attn.qkv.bias', 'teacher.backbone.enc.enc3.block8.attn.proj.weight', 'teacher.backbone.enc.enc3.block8.attn.proj.bias', 'teacher.backbone.enc.enc3.block8.norm2.0.weight', 'teacher.backbone.enc.enc3.block8.norm2.0.bias', 'teacher.backbone.enc.enc3.block8.mlp.0.fc1.weight', 'teacher.backbone.enc.enc3.block8.mlp.0.fc1.bias', 'teacher.backbone.enc.enc3.block8.mlp.0.fc2.weight', 'teacher.backbone.enc.enc3.block8.mlp.0.fc2.bias'].
[2025-12-10 16:57:37,552 INFO optimizer.py line 56 4140988] Params Group 20 - lr: 0.00236196; Params: ['student.backbone.enc.enc3.block9.cpe.0.weight', 'student.backbone.enc.enc3.block9.cpe.0.bias', 'student.backbone.enc.enc3.block9.cpe.1.weight', 'student.backbone.enc.enc3.block9.cpe.1.bias', 'student.backbone.enc.enc3.block9.cpe.2.weight', 'student.backbone.enc.enc3.block9.cpe.2.bias', 'student.backbone.enc.enc3.block9.norm1.0.weight', 'student.backbone.enc.enc3.block9.norm1.0.bias', 'student.backbone.enc.enc3.block9.attn.qkv.weight', 'student.backbone.enc.enc3.block9.attn.qkv.bias', 'student.backbone.enc.enc3.block9.attn.proj.weight', 'student.backbone.enc.enc3.block9.attn.proj.bias', 'student.backbone.enc.enc3.block9.norm2.0.weight', 'student.backbone.enc.enc3.block9.norm2.0.bias', 'student.backbone.enc.enc3.block9.mlp.0.fc1.weight', 'student.backbone.enc.enc3.block9.mlp.0.fc1.bias', 'student.backbone.enc.enc3.block9.mlp.0.fc2.weight', 'student.backbone.enc.enc3.block9.mlp.0.fc2.bias', 'teacher.backbone.enc.enc3.block9.cpe.0.weight', 'teacher.backbone.enc.enc3.block9.cpe.0.bias', 'teacher.backbone.enc.enc3.block9.cpe.1.weight', 'teacher.backbone.enc.enc3.block9.cpe.1.bias', 'teacher.backbone.enc.enc3.block9.cpe.2.weight', 'teacher.backbone.enc.enc3.block9.cpe.2.bias', 'teacher.backbone.enc.enc3.block9.norm1.0.weight', 'teacher.backbone.enc.enc3.block9.norm1.0.bias', 'teacher.backbone.enc.enc3.block9.attn.qkv.weight', 'teacher.backbone.enc.enc3.block9.attn.qkv.bias', 'teacher.backbone.enc.enc3.block9.attn.proj.weight', 'teacher.backbone.enc.enc3.block9.attn.proj.bias', 'teacher.backbone.enc.enc3.block9.norm2.0.weight', 'teacher.backbone.enc.enc3.block9.norm2.0.bias', 'teacher.backbone.enc.enc3.block9.mlp.0.fc1.weight', 'teacher.backbone.enc.enc3.block9.mlp.0.fc1.bias', 'teacher.backbone.enc.enc3.block9.mlp.0.fc2.weight', 'teacher.backbone.enc.enc3.block9.mlp.0.fc2.bias'].
[2025-12-10 16:57:37,552 INFO optimizer.py line 56 4140988] Params Group 21 - lr: 0.0026244000000000003; Params: ['student.backbone.enc.enc3.block10.cpe.0.weight', 'student.backbone.enc.enc3.block10.cpe.0.bias', 'student.backbone.enc.enc3.block10.cpe.1.weight', 'student.backbone.enc.enc3.block10.cpe.1.bias', 'student.backbone.enc.enc3.block10.cpe.2.weight', 'student.backbone.enc.enc3.block10.cpe.2.bias', 'student.backbone.enc.enc3.block10.norm1.0.weight', 'student.backbone.enc.enc3.block10.norm1.0.bias', 'student.backbone.enc.enc3.block10.attn.qkv.weight', 'student.backbone.enc.enc3.block10.attn.qkv.bias', 'student.backbone.enc.enc3.block10.attn.proj.weight', 'student.backbone.enc.enc3.block10.attn.proj.bias', 'student.backbone.enc.enc3.block10.norm2.0.weight', 'student.backbone.enc.enc3.block10.norm2.0.bias', 'student.backbone.enc.enc3.block10.mlp.0.fc1.weight', 'student.backbone.enc.enc3.block10.mlp.0.fc1.bias', 'student.backbone.enc.enc3.block10.mlp.0.fc2.weight', 'student.backbone.enc.enc3.block10.mlp.0.fc2.bias', 'teacher.backbone.enc.enc3.block10.cpe.0.weight', 'teacher.backbone.enc.enc3.block10.cpe.0.bias', 'teacher.backbone.enc.enc3.block10.cpe.1.weight', 'teacher.backbone.enc.enc3.block10.cpe.1.bias', 'teacher.backbone.enc.enc3.block10.cpe.2.weight', 'teacher.backbone.enc.enc3.block10.cpe.2.bias', 'teacher.backbone.enc.enc3.block10.norm1.0.weight', 'teacher.backbone.enc.enc3.block10.norm1.0.bias', 'teacher.backbone.enc.enc3.block10.attn.qkv.weight', 'teacher.backbone.enc.enc3.block10.attn.qkv.bias', 'teacher.backbone.enc.enc3.block10.attn.proj.weight', 'teacher.backbone.enc.enc3.block10.attn.proj.bias', 'teacher.backbone.enc.enc3.block10.norm2.0.weight', 'teacher.backbone.enc.enc3.block10.norm2.0.bias', 'teacher.backbone.enc.enc3.block10.mlp.0.fc1.weight', 'teacher.backbone.enc.enc3.block10.mlp.0.fc1.bias', 'teacher.backbone.enc.enc3.block10.mlp.0.fc2.weight', 'teacher.backbone.enc.enc3.block10.mlp.0.fc2.bias'].
[2025-12-10 16:57:37,552 INFO optimizer.py line 56 4140988] Params Group 22 - lr: 0.0029160000000000006; Params: ['student.backbone.enc.enc3.block11.cpe.0.weight', 'student.backbone.enc.enc3.block11.cpe.0.bias', 'student.backbone.enc.enc3.block11.cpe.1.weight', 'student.backbone.enc.enc3.block11.cpe.1.bias', 'student.backbone.enc.enc3.block11.cpe.2.weight', 'student.backbone.enc.enc3.block11.cpe.2.bias', 'student.backbone.enc.enc3.block11.norm1.0.weight', 'student.backbone.enc.enc3.block11.norm1.0.bias', 'student.backbone.enc.enc3.block11.attn.qkv.weight', 'student.backbone.enc.enc3.block11.attn.qkv.bias', 'student.backbone.enc.enc3.block11.attn.proj.weight', 'student.backbone.enc.enc3.block11.attn.proj.bias', 'student.backbone.enc.enc3.block11.norm2.0.weight', 'student.backbone.enc.enc3.block11.norm2.0.bias', 'student.backbone.enc.enc3.block11.mlp.0.fc1.weight', 'student.backbone.enc.enc3.block11.mlp.0.fc1.bias', 'student.backbone.enc.enc3.block11.mlp.0.fc2.weight', 'student.backbone.enc.enc3.block11.mlp.0.fc2.bias', 'teacher.backbone.enc.enc3.block11.cpe.0.weight', 'teacher.backbone.enc.enc3.block11.cpe.0.bias', 'teacher.backbone.enc.enc3.block11.cpe.1.weight', 'teacher.backbone.enc.enc3.block11.cpe.1.bias', 'teacher.backbone.enc.enc3.block11.cpe.2.weight', 'teacher.backbone.enc.enc3.block11.cpe.2.bias', 'teacher.backbone.enc.enc3.block11.norm1.0.weight', 'teacher.backbone.enc.enc3.block11.norm1.0.bias', 'teacher.backbone.enc.enc3.block11.attn.qkv.weight', 'teacher.backbone.enc.enc3.block11.attn.qkv.bias', 'teacher.backbone.enc.enc3.block11.attn.proj.weight', 'teacher.backbone.enc.enc3.block11.attn.proj.bias', 'teacher.backbone.enc.enc3.block11.norm2.0.weight', 'teacher.backbone.enc.enc3.block11.norm2.0.bias', 'teacher.backbone.enc.enc3.block11.mlp.0.fc1.weight', 'teacher.backbone.enc.enc3.block11.mlp.0.fc1.bias', 'teacher.backbone.enc.enc3.block11.mlp.0.fc2.weight', 'teacher.backbone.enc.enc3.block11.mlp.0.fc2.bias'].
[2025-12-10 16:57:37,552 INFO optimizer.py line 56 4140988] Params Group 23 - lr: 0.0032400000000000003; Params: ['student.backbone.enc.enc4.block0.cpe.0.weight', 'student.backbone.enc.enc4.block0.cpe.0.bias', 'student.backbone.enc.enc4.block0.cpe.1.weight', 'student.backbone.enc.enc4.block0.cpe.1.bias', 'student.backbone.enc.enc4.block0.cpe.2.weight', 'student.backbone.enc.enc4.block0.cpe.2.bias', 'student.backbone.enc.enc4.block0.norm1.0.weight', 'student.backbone.enc.enc4.block0.norm1.0.bias', 'student.backbone.enc.enc4.block0.attn.qkv.weight', 'student.backbone.enc.enc4.block0.attn.qkv.bias', 'student.backbone.enc.enc4.block0.attn.proj.weight', 'student.backbone.enc.enc4.block0.attn.proj.bias', 'student.backbone.enc.enc4.block0.norm2.0.weight', 'student.backbone.enc.enc4.block0.norm2.0.bias', 'student.backbone.enc.enc4.block0.mlp.0.fc1.weight', 'student.backbone.enc.enc4.block0.mlp.0.fc1.bias', 'student.backbone.enc.enc4.block0.mlp.0.fc2.weight', 'student.backbone.enc.enc4.block0.mlp.0.fc2.bias', 'teacher.backbone.enc.enc4.block0.cpe.0.weight', 'teacher.backbone.enc.enc4.block0.cpe.0.bias', 'teacher.backbone.enc.enc4.block0.cpe.1.weight', 'teacher.backbone.enc.enc4.block0.cpe.1.bias', 'teacher.backbone.enc.enc4.block0.cpe.2.weight', 'teacher.backbone.enc.enc4.block0.cpe.2.bias', 'teacher.backbone.enc.enc4.block0.norm1.0.weight', 'teacher.backbone.enc.enc4.block0.norm1.0.bias', 'teacher.backbone.enc.enc4.block0.attn.qkv.weight', 'teacher.backbone.enc.enc4.block0.attn.qkv.bias', 'teacher.backbone.enc.enc4.block0.attn.proj.weight', 'teacher.backbone.enc.enc4.block0.attn.proj.bias', 'teacher.backbone.enc.enc4.block0.norm2.0.weight', 'teacher.backbone.enc.enc4.block0.norm2.0.bias', 'teacher.backbone.enc.enc4.block0.mlp.0.fc1.weight', 'teacher.backbone.enc.enc4.block0.mlp.0.fc1.bias', 'teacher.backbone.enc.enc4.block0.mlp.0.fc2.weight', 'teacher.backbone.enc.enc4.block0.mlp.0.fc2.bias'].
[2025-12-10 16:57:37,552 INFO optimizer.py line 56 4140988] Params Group 24 - lr: 0.0036000000000000003; Params: ['student.backbone.enc.enc4.block1.cpe.0.weight', 'student.backbone.enc.enc4.block1.cpe.0.bias', 'student.backbone.enc.enc4.block1.cpe.1.weight', 'student.backbone.enc.enc4.block1.cpe.1.bias', 'student.backbone.enc.enc4.block1.cpe.2.weight', 'student.backbone.enc.enc4.block1.cpe.2.bias', 'student.backbone.enc.enc4.block1.norm1.0.weight', 'student.backbone.enc.enc4.block1.norm1.0.bias', 'student.backbone.enc.enc4.block1.attn.qkv.weight', 'student.backbone.enc.enc4.block1.attn.qkv.bias', 'student.backbone.enc.enc4.block1.attn.proj.weight', 'student.backbone.enc.enc4.block1.attn.proj.bias', 'student.backbone.enc.enc4.block1.norm2.0.weight', 'student.backbone.enc.enc4.block1.norm2.0.bias', 'student.backbone.enc.enc4.block1.mlp.0.fc1.weight', 'student.backbone.enc.enc4.block1.mlp.0.fc1.bias', 'student.backbone.enc.enc4.block1.mlp.0.fc2.weight', 'student.backbone.enc.enc4.block1.mlp.0.fc2.bias', 'teacher.backbone.enc.enc4.block1.cpe.0.weight', 'teacher.backbone.enc.enc4.block1.cpe.0.bias', 'teacher.backbone.enc.enc4.block1.cpe.1.weight', 'teacher.backbone.enc.enc4.block1.cpe.1.bias', 'teacher.backbone.enc.enc4.block1.cpe.2.weight', 'teacher.backbone.enc.enc4.block1.cpe.2.bias', 'teacher.backbone.enc.enc4.block1.norm1.0.weight', 'teacher.backbone.enc.enc4.block1.norm1.0.bias', 'teacher.backbone.enc.enc4.block1.attn.qkv.weight', 'teacher.backbone.enc.enc4.block1.attn.qkv.bias', 'teacher.backbone.enc.enc4.block1.attn.proj.weight', 'teacher.backbone.enc.enc4.block1.attn.proj.bias', 'teacher.backbone.enc.enc4.block1.norm2.0.weight', 'teacher.backbone.enc.enc4.block1.norm2.0.bias', 'teacher.backbone.enc.enc4.block1.mlp.0.fc1.weight', 'teacher.backbone.enc.enc4.block1.mlp.0.fc1.bias', 'teacher.backbone.enc.enc4.block1.mlp.0.fc2.weight', 'teacher.backbone.enc.enc4.block1.mlp.0.fc2.bias'].
[2025-12-10 16:57:37,552 INFO optimizer.py line 56 4140988] Params Group 25 - lr: 0.004; Params: ['student.backbone.enc.enc4.block2.cpe.0.weight', 'student.backbone.enc.enc4.block2.cpe.0.bias', 'student.backbone.enc.enc4.block2.cpe.1.weight', 'student.backbone.enc.enc4.block2.cpe.1.bias', 'student.backbone.enc.enc4.block2.cpe.2.weight', 'student.backbone.enc.enc4.block2.cpe.2.bias', 'student.backbone.enc.enc4.block2.norm1.0.weight', 'student.backbone.enc.enc4.block2.norm1.0.bias', 'student.backbone.enc.enc4.block2.attn.qkv.weight', 'student.backbone.enc.enc4.block2.attn.qkv.bias', 'student.backbone.enc.enc4.block2.attn.proj.weight', 'student.backbone.enc.enc4.block2.attn.proj.bias', 'student.backbone.enc.enc4.block2.norm2.0.weight', 'student.backbone.enc.enc4.block2.norm2.0.bias', 'student.backbone.enc.enc4.block2.mlp.0.fc1.weight', 'student.backbone.enc.enc4.block2.mlp.0.fc1.bias', 'student.backbone.enc.enc4.block2.mlp.0.fc2.weight', 'student.backbone.enc.enc4.block2.mlp.0.fc2.bias', 'teacher.backbone.enc.enc4.block2.cpe.0.weight', 'teacher.backbone.enc.enc4.block2.cpe.0.bias', 'teacher.backbone.enc.enc4.block2.cpe.1.weight', 'teacher.backbone.enc.enc4.block2.cpe.1.bias', 'teacher.backbone.enc.enc4.block2.cpe.2.weight', 'teacher.backbone.enc.enc4.block2.cpe.2.bias', 'teacher.backbone.enc.enc4.block2.norm1.0.weight', 'teacher.backbone.enc.enc4.block2.norm1.0.bias', 'teacher.backbone.enc.enc4.block2.attn.qkv.weight', 'teacher.backbone.enc.enc4.block2.attn.qkv.bias', 'teacher.backbone.enc.enc4.block2.attn.proj.weight', 'teacher.backbone.enc.enc4.block2.attn.proj.bias', 'teacher.backbone.enc.enc4.block2.norm2.0.weight', 'teacher.backbone.enc.enc4.block2.norm2.0.bias', 'teacher.backbone.enc.enc4.block2.mlp.0.fc1.weight', 'teacher.backbone.enc.enc4.block2.mlp.0.fc1.bias', 'teacher.backbone.enc.enc4.block2.mlp.0.fc2.weight', 'teacher.backbone.enc.enc4.block2.mlp.0.fc2.bias'].
[2025-12-10 16:57:37,554 INFO train.py line 152 4140988] => Building hooks ...
[2025-12-10 16:57:37,554 INFO misc.py line 237 4140988] => Loading checkpoint & weight ...
[2025-12-10 16:57:37,554 INFO misc.py line 274 4140988] No weight found at: None
[2025-12-10 16:57:37,577 INFO train.py line 159 4140988] >>>>>>>>>>>>>>>> Start Training >>>>>>>>>>>>>>>>
[2025-12-10 16:57:45,843 INFO misc.py line 117 4140988] Train: [1/10][1/7400] Data 1.127 (1.127) Batch 7.866 (7.866) Remain 161:40:56 loss: 8.4772 mask_loss: 8.1827 roll_mask_loss: 8.4509 density_loss: 8.4307 unmask_loss: 8.4690 Lr: 0.00040
[2025-12-10 16:57:46,695 INFO misc.py line 117 4140988] Train: [1/10][2/7400] Data 0.003 (0.003) Batch 0.850 (0.850) Remain 17:27:57 loss: 8.4811 mask_loss: 8.1445 roll_mask_loss: 8.4924 density_loss: 8.4321 unmask_loss: 8.4751 Lr: 0.00040
[2025-12-10 16:57:47,423 INFO misc.py line 117 4140988] Train: [1/10][3/7400] Data 0.004 (0.004) Batch 0.729 (0.729) Remain 14:59:13 loss: 8.5072 mask_loss: 8.2294 roll_mask_loss: 8.4987 density_loss: 8.4167 unmask_loss: 8.4821 Lr: 0.00040
[2025-12-10 16:57:48,059 INFO misc.py line 117 4140988] Train: [1/10][4/7400] Data 0.003 (0.003) Batch 0.636 (0.636) Remain 13:04:07 loss: 8.5152 mask_loss: 8.3254 roll_mask_loss: 8.4751 density_loss: 8.4933 unmask_loss: 8.4604 Lr: 0.00040
[2025-12-10 16:57:48,728 INFO misc.py line 117 4140988] Train: [1/10][5/7400] Data 0.003 (0.003) Batch 0.669 (0.653) Remain 13:24:47 loss: 8.4675 mask_loss: 8.2740 roll_mask_loss: 8.4439 density_loss: 8.4367 unmask_loss: 8.4073 Lr: 0.00040
[2025-12-10 16:57:49,429 INFO misc.py line 117 4140988] Train: [1/10][6/7400] Data 0.004 (0.004) Batch 0.701 (0.669) Remain 13:44:28 loss: 8.4694 mask_loss: 8.2862 roll_mask_loss: 8.4294 density_loss: 8.4341 unmask_loss: 8.4123 Lr: 0.00040
[2025-12-10 16:57:50,228 INFO misc.py line 117 4140988] Train: [1/10][7/7400] Data 0.004 (0.004) Batch 0.799 (0.701) Remain 14:24:49 loss: 8.4606 mask_loss: 8.2459 roll_mask_loss: 8.3951 density_loss: 8.4224 unmask_loss: 8.4323 Lr: 0.00040
[2025-12-10 16:57:50,744 INFO misc.py line 117 4140988] Train: [1/10][8/7400] Data 0.004 (0.004) Batch 0.516 (0.664) Remain 13:39:05 loss: 8.4210 mask_loss: 8.2504 roll_mask_loss: 8.3817 density_loss: 8.3820 unmask_loss: 8.3582 Lr: 0.00040
[2025-12-10 16:57:51,279 INFO misc.py line 117 4140988] Train: [1/10][9/7400] Data 0.003 (0.004) Batch 0.534 (0.643) Remain 13:12:23 loss: 8.4452 mask_loss: 8.2371 roll_mask_loss: 8.4263 density_loss: 8.4236 unmask_loss: 8.3903 Lr: 0.00040
[2025-12-10 16:57:52,053 INFO misc.py line 117 4140988] Train: [1/10][10/7400] Data 0.004 (0.004) Batch 0.775 (0.661) Remain 13:35:38 loss: 8.4061 mask_loss: 8.2041 roll_mask_loss: 8.3802 density_loss: 8.4168 unmask_loss: 8.3516 Lr: 0.00040
[2025-12-10 16:57:52,700 INFO misc.py line 117 4140988] Train: [1/10][11/7400] Data 0.003 (0.004) Batch 0.647 (0.660) Remain 13:33:22 loss: 8.3939 mask_loss: 8.2121 roll_mask_loss: 8.3598 density_loss: 8.3769 unmask_loss: 8.3342 Lr: 0.00040
[2025-12-10 16:57:53,232 INFO misc.py line 117 4140988] Train: [1/10][12/7400] Data 0.004 (0.004) Batch 0.532 (0.645) Remain 13:15:51 loss: 8.4057 mask_loss: 8.2241 roll_mask_loss: 8.3506 density_loss: 8.3690 unmask_loss: 8.3567 Lr: 0.00040
[2025-12-10 16:57:53,865 INFO misc.py line 117 4140988] Train: [1/10][13/7400] Data 0.004 (0.004) Batch 0.633 (0.644) Remain 13:14:21 loss: 8.3784 mask_loss: 8.2048 roll_mask_loss: 8.3215 density_loss: 8.3886 unmask_loss: 8.3258 Lr: 0.00040
[2025-12-10 16:57:54,466 INFO misc.py line 117 4140988] Train: [1/10][14/7400] Data 0.004 (0.004) Batch 0.601 (0.640) Remain 13:09:28 loss: 8.3716 mask_loss: 8.1996 roll_mask_loss: 8.3339 density_loss: 8.3433 unmask_loss: 8.3095 Lr: 0.00040
[2025-12-10 16:57:54,987 INFO misc.py line 117 4140988] Train: [1/10][15/7400] Data 0.003 (0.004) Batch 0.521 (0.630) Remain 12:57:11 loss: 8.3852 mask_loss: 8.2128 roll_mask_loss: 8.3524 density_loss: 8.3368 unmask_loss: 8.3211 Lr: 0.00040
[2025-12-10 16:57:55,661 INFO misc.py line 117 4140988] Train: [1/10][16/7400] Data 0.005 (0.004) Batch 0.674 (0.634) Remain 13:01:20 loss: 8.3353 mask_loss: 8.1786 roll_mask_loss: 8.2770 density_loss: 8.3017 unmask_loss: 8.2768 Lr: 0.00040
[2025-12-10 16:57:56,002 INFO misc.py line 117 4140988] Train: [1/10][17/7400] Data 0.004 (0.004) Batch 0.341 (0.613) Remain 12:35:33 loss: 8.3616 mask_loss: 8.2036 roll_mask_loss: 8.3273 density_loss: 8.3671 unmask_loss: 8.2904 Lr: 0.00040
[2025-12-10 16:57:56,287 INFO misc.py line 117 4140988] Train: [1/10][18/7400] Data 0.004 (0.004) Batch 0.285 (0.591) Remain 12:08:36 loss: 8.4317 mask_loss: 8.3006 roll_mask_loss: 8.4200 density_loss: 8.3295 unmask_loss: 8.3366 Lr: 0.00040
[2025-12-10 16:57:56,649 INFO misc.py line 117 4140988] Train: [1/10][19/7400] Data 0.004 (0.004) Batch 0.362 (0.577) Remain 11:50:58 loss: 8.3527 mask_loss: 8.1953 roll_mask_loss: 8.3066 density_loss: 8.3088 unmask_loss: 8.2882 Lr: 0.00040
[2025-12-10 16:57:57,316 INFO misc.py line 117 4140988] Train: [1/10][20/7400] Data 0.004 (0.004) Batch 0.666 (0.582) Remain 11:57:28 loss: 8.3570 mask_loss: 8.1960 roll_mask_loss: 8.3203 density_loss: 8.3190 unmask_loss: 8.2894 Lr: 0.00040
[2025-12-10 16:57:58,152 INFO misc.py line 117 4140988] Train: [1/10][21/7400] Data 0.005 (0.004) Batch 0.836 (0.596) Remain 12:14:52 loss: 8.4033 mask_loss: 8.2350 roll_mask_loss: 8.3440 density_loss: 8.3277 unmask_loss: 8.3506 Lr: 0.00040
[2025-12-10 16:57:58,875 INFO misc.py line 117 4140988] Train: [1/10][22/7400] Data 0.004 (0.004) Batch 0.723 (0.603) Remain 12:23:06 loss: 8.3534 mask_loss: 8.1903 roll_mask_loss: 8.2906 density_loss: 8.3303 unmask_loss: 8.2997 Lr: 0.00040
[2025-12-10 16:57:59,614 INFO misc.py line 117 4140988] Train: [1/10][23/7400] Data 0.004 (0.004) Batch 0.740 (0.610) Remain 12:31:32 loss: 8.3554 mask_loss: 8.1955 roll_mask_loss: 8.2971 density_loss: 8.3448 unmask_loss: 8.2975 Lr: 0.00040
[2025-12-10 16:58:00,215 INFO misc.py line 117 4140988] Train: [1/10][24/7400] Data 0.003 (0.004) Batch 0.602 (0.609) Remain 12:31:03 loss: 8.3973 mask_loss: 8.2461 roll_mask_loss: 8.3242 density_loss: 8.3649 unmask_loss: 8.3422 Lr: 0.00040
[2025-12-10 16:58:00,669 INFO misc.py line 117 4140988] Train: [1/10][25/7400] Data 0.003 (0.004) Batch 0.454 (0.602) Remain 12:22:21 loss: 8.3981 mask_loss: 8.2464 roll_mask_loss: 8.3470 density_loss: 8.3404 unmask_loss: 8.3328 Lr: 0.00040
[2025-12-10 16:58:01,241 INFO misc.py line 117 4140988] Train: [1/10][26/7400] Data 0.003 (0.004) Batch 0.571 (0.601) Remain 12:20:41 loss: 8.3605 mask_loss: 8.2118 roll_mask_loss: 8.2893 density_loss: 8.3478 unmask_loss: 8.3034 Lr: 0.00040
[2025-12-10 16:58:01,886 INFO misc.py line 117 4140988] Train: [1/10][27/7400] Data 0.004 (0.004) Batch 0.645 (0.603) Remain 12:22:57 loss: 8.3454 mask_loss: 8.1773 roll_mask_loss: 8.3023 density_loss: 8.3405 unmask_loss: 8.2843 Lr: 0.00040
[2025-12-10 16:58:02,580 INFO misc.py line 117 4140988] Train: [1/10][28/7400] Data 0.004 (0.004) Batch 0.694 (0.606) Remain 12:27:25 loss: 8.3608 mask_loss: 8.1782 roll_mask_loss: 8.3206 density_loss: 8.3155 unmask_loss: 8.3059 Lr: 0.00040
[2025-12-10 16:58:03,223 INFO misc.py line 117 4140988] Train: [1/10][29/7400] Data 0.004 (0.004) Batch 0.643 (0.608) Remain 12:29:09 loss: 8.3683 mask_loss: 8.1486 roll_mask_loss: 8.3741 density_loss: 8.3772 unmask_loss: 8.3077 Lr: 0.00040
[2025-12-10 16:58:03,809 INFO misc.py line 117 4140988] Train: [1/10][30/7400] Data 0.004 (0.004) Batch 0.586 (0.607) Remain 12:28:09 loss: 8.3952 mask_loss: 8.2098 roll_mask_loss: 8.3743 density_loss: 8.3419 unmask_loss: 8.3315 Lr: 0.00040
[2025-12-10 16:58:04,448 INFO misc.py line 117 4140988] Train: [1/10][31/7400] Data 0.004 (0.004) Batch 0.640 (0.608) Remain 12:29:35 loss: 8.3359 mask_loss: 8.1417 roll_mask_loss: 8.3209 density_loss: 8.3116 unmask_loss: 8.2744 Lr: 0.00040
[2025-12-10 16:58:05,225 INFO misc.py line 117 4140988] Train: [1/10][32/7400] Data 0.004 (0.004) Batch 0.778 (0.614) Remain 12:36:47 loss: 8.3801 mask_loss: 8.1526 roll_mask_loss: 8.4079 density_loss: 8.3799 unmask_loss: 8.3124 Lr: 0.00040
[2025-12-10 16:58:05,831 INFO misc.py line 117 4140988] Train: [1/10][33/7400] Data 0.003 (0.004) Batch 0.605 (0.614) Remain 12:36:25 loss: 8.3239 mask_loss: 8.1434 roll_mask_loss: 8.2733 density_loss: 8.3253 unmask_loss: 8.2730 Lr: 0.00040
[2025-12-10 16:58:06,534 INFO misc.py line 117 4140988] Train: [1/10][34/7400] Data 0.004 (0.004) Batch 0.703 (0.616) Remain 12:39:56 loss: 8.3077 mask_loss: 8.1360 roll_mask_loss: 8.2467 density_loss: 8.2798 unmask_loss: 8.2584 Lr: 0.00040
[2025-12-10 16:58:07,265 INFO misc.py line 117 4140988] Train: [1/10][35/7400] Data 0.004 (0.004) Batch 0.732 (0.620) Remain 12:44:22 loss: 8.2996 mask_loss: 8.1250 roll_mask_loss: 8.2493 density_loss: 8.2901 unmask_loss: 8.2463 Lr: 0.00040
[2025-12-10 16:58:07,860 INFO misc.py line 117 4140988] Train: [1/10][36/7400] Data 0.004 (0.004) Batch 0.595 (0.619) Remain 12:43:25 loss: 8.3058 mask_loss: 8.1279 roll_mask_loss: 8.2521 density_loss: 8.4264 unmask_loss: 8.2531 Lr: 0.00040
[2025-12-10 16:58:08,370 INFO misc.py line 117 4140988] Train: [1/10][37/7400] Data 0.004 (0.004) Batch 0.510 (0.616) Remain 12:39:26 loss: 8.2833 mask_loss: 8.1060 roll_mask_loss: 8.2028 density_loss: 8.3104 unmask_loss: 8.2460 Lr: 0.00040
[2025-12-10 16:58:08,983 INFO misc.py line 117 4140988] Train: [1/10][38/7400] Data 0.004 (0.004) Batch 0.612 (0.616) Remain 12:39:18 loss: 8.3069 mask_loss: 8.1136 roll_mask_loss: 8.2707 density_loss: 8.3113 unmask_loss: 8.2555 Lr: 0.00040
[2025-12-10 16:58:09,536 INFO misc.py line 117 4140988] Train: [1/10][39/7400] Data 0.004 (0.004) Batch 0.554 (0.614) Remain 12:37:09 loss: 8.2756 mask_loss: 8.0914 roll_mask_loss: 8.2267 density_loss: 8.2260 unmask_loss: 8.2277 Lr: 0.00040
[2025-12-10 16:58:10,016 INFO misc.py line 117 4140988] Train: [1/10][40/7400] Data 0.004 (0.004) Batch 0.480 (0.611) Remain 12:32:40 loss: 8.4224 mask_loss: 8.2372 roll_mask_loss: 8.4061 density_loss: 8.3831 unmask_loss: 8.3554 Lr: 0.00040
[2025-12-10 16:58:10,603 INFO misc.py line 117 4140988] Train: [1/10][41/7400] Data 0.004 (0.004) Batch 0.588 (0.610) Remain 12:31:54 loss: 8.2605 mask_loss: 8.0570 roll_mask_loss: 8.2326 density_loss: 8.3347 unmask_loss: 8.2095 Lr: 0.00040
[2025-12-10 16:58:11,163 INFO misc.py line 117 4140988] Train: [1/10][42/7400] Data 0.004 (0.004) Batch 0.560 (0.609) Remain 12:30:19 loss: 8.3020 mask_loss: 8.1086 roll_mask_loss: 8.2680 density_loss: 8.3417 unmask_loss: 8.2488 Lr: 0.00040
[2025-12-10 16:58:11,974 INFO misc.py line 117 4140988] Train: [1/10][43/7400] Data 0.003 (0.004) Batch 0.812 (0.614) Remain 12:36:34 loss: 8.2560 mask_loss: 8.0427 roll_mask_loss: 8.2182 density_loss: 8.2706 unmask_loss: 8.2162 Lr: 0.00040
[2025-12-10 16:58:12,549 INFO misc.py line 117 4140988] Train: [1/10][44/7400] Data 0.003 (0.004) Batch 0.575 (0.613) Remain 12:35:23 loss: 8.3547 mask_loss: 8.0798 roll_mask_loss: 8.3313 density_loss: 8.4083 unmask_loss: 8.3358 Lr: 0.00040
[2025-12-10 16:58:13,228 INFO misc.py line 117 4140988] Train: [1/10][45/7400] Data 0.003 (0.004) Batch 0.678 (0.614) Remain 12:37:17 loss: 8.2382 mask_loss: 8.0270 roll_mask_loss: 8.2213 density_loss: 8.2753 unmask_loss: 8.1868 Lr: 0.00040
[2025-12-10 16:58:13,935 INFO misc.py line 117 4140988] Train: [1/10][46/7400] Data 0.004 (0.004) Batch 0.707 (0.617) Remain 12:39:56 loss: 8.2545 mask_loss: 8.0344 roll_mask_loss: 8.2456 density_loss: 8.3018 unmask_loss: 8.2029 Lr: 0.00040
[2025-12-10 16:58:14,658 INFO misc.py line 117 4140988] Train: [1/10][47/7400] Data 0.003 (0.004) Batch 0.723 (0.619) Remain 12:42:54 loss: 8.2682 mask_loss: 8.0159 roll_mask_loss: 8.2758 density_loss: 8.3415 unmask_loss: 8.2237 Lr: 0.00040
[2025-12-10 16:58:15,010 INFO misc.py line 117 4140988] Train: [1/10][48/7400] Data 0.004 (0.004) Batch 0.353 (0.613) Remain 12:35:35 loss: 8.3493 mask_loss: 8.0697 roll_mask_loss: 8.3866 density_loss: 8.4355 unmask_loss: 8.3018 Lr: 0.00040
[2025-12-10 16:58:15,606 INFO misc.py line 117 4140988] Train: [1/10][49/7400] Data 0.003 (0.004) Batch 0.596 (0.613) Remain 12:35:07 loss: 8.2314 mask_loss: 8.0194 roll_mask_loss: 8.2203 density_loss: 8.2863 unmask_loss: 8.1773 Lr: 0.00040
[2025-12-10 16:58:16,232 INFO misc.py line 117 4140988] Train: [1/10][50/7400] Data 0.004 (0.004) Batch 0.626 (0.613) Remain 12:35:27 loss: 8.4054 mask_loss: 8.1635 roll_mask_loss: 8.3869 density_loss: 8.4003 unmask_loss: 8.3676 Lr: 0.00040
[2025-12-10 16:58:16,749 INFO misc.py line 117 4140988] Train: [1/10][51/7400] Data 0.004 (0.004) Batch 0.517 (0.611) Remain 12:32:59 loss: 8.2708 mask_loss: 8.0367 roll_mask_loss: 8.3522 density_loss: 8.3493 unmask_loss: 8.1801 Lr: 0.00040
[2025-12-10 16:58:17,370 INFO misc.py line 117 4140988] Train: [1/10][52/7400] Data 0.004 (0.004) Batch 0.620 (0.611) Remain 12:33:12 loss: 8.3307 mask_loss: 8.0642 roll_mask_loss: 8.3690 density_loss: 8.4164 unmask_loss: 8.2766 Lr: 0.00040
[2025-12-10 16:58:18,007 INFO misc.py line 117 4140988] Train: [1/10][53/7400] Data 0.004 (0.004) Batch 0.637 (0.612) Remain 12:33:50 loss: 8.2405 mask_loss: 8.0521 roll_mask_loss: 8.2303 density_loss: 8.2866 unmask_loss: 8.1741 Lr: 0.00040
[2025-12-10 16:58:18,656 INFO misc.py line 117 4140988] Train: [1/10][54/7400] Data 0.004 (0.004) Batch 0.649 (0.612) Remain 12:34:44 loss: 8.3462 mask_loss: 8.0716 roll_mask_loss: 8.3636 density_loss: 8.4245 unmask_loss: 8.3063 Lr: 0.00040
[2025-12-10 16:58:19,327 INFO misc.py line 117 4140988] Train: [1/10][55/7400] Data 0.004 (0.004) Batch 0.671 (0.614) Remain 12:36:07 loss: 8.2639 mask_loss: 8.0359 roll_mask_loss: 8.2229 density_loss: 8.2636 unmask_loss: 8.2332 Lr: 0.00040
[2025-12-10 16:58:20,004 INFO misc.py line 117 4140988] Train: [1/10][56/7400] Data 0.004 (0.004) Batch 0.678 (0.615) Remain 12:37:36 loss: 8.1924 mask_loss: 8.0163 roll_mask_loss: 8.1539 density_loss: 8.2281 unmask_loss: 8.1351 Lr: 0.00040
[2025-12-10 16:58:20,565 INFO misc.py line 117 4140988] Train: [1/10][57/7400] Data 0.003 (0.004) Batch 0.560 (0.614) Remain 12:36:21 loss: 8.2321 mask_loss: 7.9977 roll_mask_loss: 8.2390 density_loss: 8.3447 unmask_loss: 8.1790 Lr: 0.00040
[2025-12-10 16:58:21,140 INFO misc.py line 117 4140988] Train: [1/10][58/7400] Data 0.004 (0.004) Batch 0.575 (0.613) Remain 12:35:27 loss: 8.1994 mask_loss: 7.9920 roll_mask_loss: 8.1917 density_loss: 8.2956 unmask_loss: 8.1410 Lr: 0.00040
[2025-12-10 16:58:21,808 INFO misc.py line 117 4140988] Train: [1/10][59/7400] Data 0.004 (0.004) Batch 0.667 (0.614) Remain 12:36:38 loss: 8.3205 mask_loss: 8.0302 roll_mask_loss: 8.2286 density_loss: 8.2770 unmask_loss: 8.3460 Lr: 0.00040
[2025-12-10 16:58:22,595 INFO misc.py line 117 4140988] Train: [1/10][60/7400] Data 0.005 (0.004) Batch 0.788 (0.617) Remain 12:40:24 loss: 8.2044 mask_loss: 7.9805 roll_mask_loss: 8.1687 density_loss: 8.3518 unmask_loss: 8.1672 Lr: 0.00040
[2025-12-10 16:58:23,137 INFO misc.py line 117 4140988] Train: [1/10][61/7400] Data 0.005 (0.004) Batch 0.541 (0.616) Remain 12:38:46 loss: 8.4282 mask_loss: 8.1532 roll_mask_loss: 8.4730 density_loss: 8.4097 unmask_loss: 8.3751 Lr: 0.00040
[2025-12-10 16:58:23,772 INFO misc.py line 117 4140988] Train: [1/10][62/7400] Data 0.006 (0.004) Batch 0.636 (0.616) Remain 12:39:11 loss: 8.4140 mask_loss: 8.1305 roll_mask_loss: 8.4219 density_loss: 8.4306 unmask_loss: 8.3833 Lr: 0.00040
[2025-12-10 16:58:24,588 INFO misc.py line 117 4140988] Train: [1/10][63/7400] Data 0.005 (0.004) Batch 0.817 (0.619) Remain 12:43:17 loss: 8.3397 mask_loss: 8.0424 roll_mask_loss: 8.3025 density_loss: 8.3266 unmask_loss: 8.3405 Lr: 0.00040
[2025-12-10 16:58:25,154 INFO misc.py line 117 4140988] Train: [1/10][64/7400] Data 0.004 (0.004) Batch 0.566 (0.619) Remain 12:42:11 loss: 8.3068 mask_loss: 8.0792 roll_mask_loss: 8.3026 density_loss: 8.3699 unmask_loss: 8.2553 Lr: 0.00040
[2025-12-10 16:58:25,845 INFO misc.py line 117 4140988] Train: [1/10][65/7400] Data 0.004 (0.004) Batch 0.692 (0.620) Remain 12:43:38 loss: 8.2678 mask_loss: 8.0203 roll_mask_loss: 8.2222 density_loss: 8.3245 unmask_loss: 8.2478 Lr: 0.00040
[2025-12-10 16:58:26,553 INFO misc.py line 117 4140988] Train: [1/10][66/7400] Data 0.004 (0.004) Batch 0.708 (0.621) Remain 12:45:21 loss: 8.2251 mask_loss: 8.0069 roll_mask_loss: 8.2307 density_loss: 8.3435 unmask_loss: 8.1646 Lr: 0.00040
[2025-12-10 16:58:27,254 INFO misc.py line 117 4140988] Train: [1/10][67/7400] Data 0.003 (0.004) Batch 0.701 (0.622) Remain 12:46:53 loss: 8.2120 mask_loss: 7.9746 roll_mask_loss: 8.1796 density_loss: 8.3174 unmask_loss: 8.1805 Lr: 0.00040
[2025-12-10 16:58:27,726 INFO misc.py line 117 4140988] Train: [1/10][68/7400] Data 0.003 (0.004) Batch 0.472 (0.620) Remain 12:44:01 loss: 8.1930 mask_loss: 7.9887 roll_mask_loss: 8.1096 density_loss: 8.2462 unmask_loss: 8.1719 Lr: 0.00040
[2025-12-10 16:58:28,234 INFO misc.py line 117 4140988] Train: [1/10][69/7400] Data 0.003 (0.004) Batch 0.507 (0.618) Remain 12:41:54 loss: 8.2969 mask_loss: 8.0845 roll_mask_loss: 8.3061 density_loss: 8.3843 unmask_loss: 8.2308 Lr: 0.00040
[2025-12-10 16:58:28,853 INFO misc.py line 117 4140988] Train: [1/10][70/7400] Data 0.004 (0.004) Batch 0.618 (0.618) Remain 12:41:54 loss: 8.2301 mask_loss: 7.9951 roll_mask_loss: 8.1937 density_loss: 8.3217 unmask_loss: 8.1994 Lr: 0.00040
[2025-12-10 16:58:29,376 INFO misc.py line 117 4140988] Train: [1/10][71/7400] Data 0.004 (0.004) Batch 0.523 (0.617) Remain 12:40:10 loss: 8.3790 mask_loss: 8.1497 roll_mask_loss: 8.3837 density_loss: 8.4124 unmask_loss: 8.3230 Lr: 0.00040
[2025-12-10 16:58:29,880 INFO misc.py line 117 4140988] Train: [1/10][72/7400] Data 0.004 (0.004) Batch 0.504 (0.615) Remain 12:38:08 loss: 8.2394 mask_loss: 8.0214 roll_mask_loss: 8.3155 density_loss: 8.3684 unmask_loss: 8.1431 Lr: 0.00040
[2025-12-10 16:58:30,636 INFO misc.py line 117 4140988] Train: [1/10][73/7400] Data 0.004 (0.004) Batch 0.757 (0.617) Remain 12:40:37 loss: 8.2044 mask_loss: 7.9884 roll_mask_loss: 8.1884 density_loss: 8.3575 unmask_loss: 8.1532 Lr: 0.00040
[2025-12-10 16:58:31,139 INFO misc.py line 117 4140988] Train: [1/10][74/7400] Data 0.004 (0.004) Batch 0.503 (0.616) Remain 12:38:37 loss: 8.2089 mask_loss: 7.9938 roll_mask_loss: 8.1452 density_loss: 8.4200 unmask_loss: 8.1799 Lr: 0.00040
[2025-12-10 16:58:31,529 INFO misc.py line 117 4140988] Train: [1/10][75/7400] Data 0.003 (0.004) Batch 0.390 (0.613) Remain 12:34:45 loss: 8.2279 mask_loss: 8.0138 roll_mask_loss: 8.1815 density_loss: 8.4100 unmask_loss: 8.1900 Lr: 0.00040
[2025-12-10 16:58:32,119 INFO misc.py line 117 4140988] Train: [1/10][76/7400] Data 0.004 (0.004) Batch 0.590 (0.612) Remain 12:34:21 loss: 8.2245 mask_loss: 7.9946 roll_mask_loss: 8.1918 density_loss: 8.3994 unmask_loss: 8.1878 Lr: 0.00040
[2025-12-10 16:58:32,755 INFO misc.py line 117 4140988] Train: [1/10][77/7400] Data 0.004 (0.004) Batch 0.635 (0.613) Remain 12:34:43 loss: 8.2055 mask_loss: 7.9735 roll_mask_loss: 8.2238 density_loss: 8.3308 unmask_loss: 8.1457 Lr: 0.00040
[2025-12-10 16:58:33,287 INFO misc.py line 117 4140988] Train: [1/10][78/7400] Data 0.004 (0.004) Batch 0.533 (0.612) Remain 12:33:24 loss: 8.2564 mask_loss: 7.9767 roll_mask_loss: 8.2604 density_loss: 8.1904 unmask_loss: 8.2304 Lr: 0.00040
[2025-12-10 16:58:33,759 INFO misc.py line 117 4140988] Train: [1/10][79/7400] Data 0.004 (0.004) Batch 0.472 (0.610) Remain 12:31:08 loss: 8.4436 mask_loss: 8.2524 roll_mask_loss: 8.4122 density_loss: 8.3782 unmask_loss: 8.3874 Lr: 0.00040
[2025-12-10 16:58:34,150 INFO misc.py line 117 4140988] Train: [1/10][80/7400] Data 0.004 (0.004) Batch 0.391 (0.607) Remain 12:27:37 loss: 8.2111 mask_loss: 7.9962 roll_mask_loss: 8.1728 density_loss: 8.2746 unmask_loss: 8.1722 Lr: 0.00040
[2025-12-10 16:58:34,740 INFO misc.py line 117 4140988] Train: [1/10][81/7400] Data 0.003 (0.004) Batch 0.590 (0.607) Remain 12:27:20 loss: 8.2123 mask_loss: 7.9539 roll_mask_loss: 8.2095 density_loss: 8.4278 unmask_loss: 8.1744 Lr: 0.00040
[2025-12-10 16:58:35,446 INFO misc.py line 117 4140988] Train: [1/10][82/7400] Data 0.004 (0.004) Batch 0.706 (0.608) Remain 12:28:52 loss: 8.1943 mask_loss: 7.9619 roll_mask_loss: 8.1624 density_loss: 8.3710 unmask_loss: 8.1590 Lr: 0.00040
[2025-12-10 16:58:36,189 INFO misc.py line 117 4140988] Train: [1/10][83/7400] Data 0.004 (0.004) Batch 0.743 (0.610) Remain 12:30:57 loss: 8.2040 mask_loss: 7.9764 roll_mask_loss: 8.1901 density_loss: 8.3752 unmask_loss: 8.1573 Lr: 0.00040
[2025-12-10 16:58:36,750 INFO misc.py line 117 4140988] Train: [1/10][84/7400] Data 0.004 (0.004) Batch 0.561 (0.609) Remain 12:30:12 loss: 8.3864 mask_loss: 8.1024 roll_mask_loss: 8.4185 density_loss: 8.4495 unmask_loss: 8.3434 Lr: 0.00040
[2025-12-10 16:58:37,451 INFO misc.py line 117 4140988] Train: [1/10][85/7400] Data 0.004 (0.004) Batch 0.702 (0.610) Remain 12:31:35 loss: 8.2752 mask_loss: 8.0626 roll_mask_loss: 8.2983 density_loss: 8.3825 unmask_loss: 8.2023 Lr: 0.00040
[2025-12-10 16:58:38,020 INFO misc.py line 117 4140988] Train: [1/10][86/7400] Data 0.004 (0.004) Batch 0.568 (0.610) Remain 12:30:57 loss: 8.1984 mask_loss: 7.9910 roll_mask_loss: 8.1616 density_loss: 8.2731 unmask_loss: 8.1550 Lr: 0.00040
[2025-12-10 16:58:38,680 INFO misc.py line 117 4140988] Train: [1/10][87/7400] Data 0.004 (0.004) Batch 0.660 (0.610) Remain 12:31:41 loss: 8.1684 mask_loss: 7.9569 roll_mask_loss: 8.1125 density_loss: 8.2264 unmask_loss: 8.1375 Lr: 0.00040
[2025-12-10 16:58:39,372 INFO misc.py line 117 4140988] Train: [1/10][88/7400] Data 0.004 (0.004) Batch 0.693 (0.611) Remain 12:32:52 loss: 8.1824 mask_loss: 7.9258 roll_mask_loss: 8.1753 density_loss: 8.3311 unmask_loss: 8.1477 Lr: 0.00040
[2025-12-10 16:58:39,939 INFO misc.py line 117 4140988] Train: [1/10][89/7400] Data 0.003 (0.004) Batch 0.567 (0.611) Remain 12:32:13 loss: 8.1590 mask_loss: 7.9236 roll_mask_loss: 8.1096 density_loss: 8.1700 unmask_loss: 8.1380 Lr: 0.00040
[2025-12-10 16:58:40,627 INFO misc.py line 117 4140988] Train: [1/10][90/7400] Data 0.003 (0.004) Batch 0.689 (0.612) Remain 12:33:19 loss: 8.3406 mask_loss: 8.0451 roll_mask_loss: 8.2660 density_loss: 8.3729 unmask_loss: 8.3582 Lr: 0.00041
[2025-12-10 16:58:41,360 INFO misc.py line 117 4140988] Train: [1/10][91/7400] Data 0.003 (0.004) Batch 0.731 (0.613) Remain 12:34:59 loss: 8.1763 mask_loss: 7.9441 roll_mask_loss: 8.1400 density_loss: 8.3620 unmask_loss: 8.1434 Lr: 0.00041
[2025-12-10 16:58:41,995 INFO misc.py line 117 4140988] Train: [1/10][92/7400] Data 0.005 (0.004) Batch 0.636 (0.613) Remain 12:35:17 loss: 8.1590 mask_loss: 7.9122 roll_mask_loss: 8.1214 density_loss: 8.4784 unmask_loss: 8.1316 Lr: 0.00041
[2025-12-10 16:58:42,610 INFO misc.py line 117 4140988] Train: [1/10][93/7400] Data 0.004 (0.004) Batch 0.615 (0.613) Remain 12:35:18 loss: 8.2202 mask_loss: 7.9505 roll_mask_loss: 8.2643 density_loss: 8.3873 unmask_loss: 8.1653 Lr: 0.00041
[2025-12-10 16:58:43,202 INFO misc.py line 117 4140988] Train: [1/10][94/7400] Data 0.004 (0.004) Batch 0.592 (0.613) Remain 12:35:00 loss: 8.1669 mask_loss: 7.9497 roll_mask_loss: 8.1573 density_loss: 8.1964 unmask_loss: 8.1164 Lr: 0.00041
[2025-12-10 16:58:43,991 INFO misc.py line 117 4140988] Train: [1/10][95/7400] Data 0.004 (0.004) Batch 0.790 (0.615) Remain 12:37:21 loss: 8.1461 mask_loss: 7.9254 roll_mask_loss: 8.0875 density_loss: 8.2277 unmask_loss: 8.1212 Lr: 0.00041
[2025-12-10 16:58:44,502 INFO misc.py line 117 4140988] Train: [1/10][96/7400] Data 0.003 (0.004) Batch 0.512 (0.614) Remain 12:35:58 loss: 8.1908 mask_loss: 7.9417 roll_mask_loss: 8.1682 density_loss: 8.4935 unmask_loss: 8.1567 Lr: 0.00041
[2025-12-10 16:58:44,828 INFO misc.py line 117 4140988] Train: [1/10][97/7400] Data 0.003 (0.004) Batch 0.326 (0.611) Remain 12:32:12 loss: 8.2045 mask_loss: 7.9270 roll_mask_loss: 8.2429 density_loss: 8.4663 unmask_loss: 8.1547 Lr: 0.00041
[2025-12-10 16:58:45,384 INFO misc.py line 117 4140988] Train: [1/10][98/7400] Data 0.003 (0.004) Batch 0.556 (0.610) Remain 12:31:29 loss: 8.1948 mask_loss: 7.9174 roll_mask_loss: 8.1713 density_loss: 8.4638 unmask_loss: 8.1759 Lr: 0.00041
[2025-12-10 16:58:46,258 INFO misc.py line 117 4140988] Train: [1/10][99/7400] Data 0.003 (0.004) Batch 0.874 (0.613) Remain 12:34:51 loss: 8.1459 mask_loss: 7.8867 roll_mask_loss: 8.1703 density_loss: 8.3611 unmask_loss: 8.0960 Lr: 0.00041
[2025-12-10 16:58:46,553 INFO misc.py line 117 4140988] Train: [1/10][100/7400] Data 0.003 (0.004) Batch 0.295 (0.610) Remain 12:30:48 loss: 8.4602 mask_loss: 8.3082 roll_mask_loss: 8.5025 density_loss: 8.4343 unmask_loss: 8.3463 Lr: 0.00041
[2025-12-10 16:58:47,251 INFO misc.py line 117 4140988] Train: [1/10][101/7400] Data 0.003 (0.004) Batch 0.697 (0.610) Remain 12:31:54 loss: 8.1481 mask_loss: 7.9164 roll_mask_loss: 8.0639 density_loss: 8.3940 unmask_loss: 8.1381 Lr: 0.00041
[2025-12-10 16:58:47,866 INFO misc.py line 117 4140988] Train: [1/10][102/7400] Data 0.004 (0.004) Batch 0.614 (0.611) Remain 12:31:56 loss: 8.1392 mask_loss: 7.9158 roll_mask_loss: 8.0602 density_loss: 8.3028 unmask_loss: 8.1243 Lr: 0.00041
[2025-12-10 16:58:48,400 INFO misc.py line 117 4140988] Train: [1/10][103/7400] Data 0.006 (0.004) Batch 0.535 (0.610) Remain 12:30:59 loss: 8.2077 mask_loss: 7.9711 roll_mask_loss: 8.1881 density_loss: 8.3462 unmask_loss: 8.1689 Lr: 0.00041
[2025-12-10 16:58:48,949 INFO misc.py line 117 4140988] Train: [1/10][104/7400] Data 0.003 (0.004) Batch 0.550 (0.609) Remain 12:30:15 loss: 8.2236 mask_loss: 7.9630 roll_mask_loss: 8.2102 density_loss: 8.4897 unmask_loss: 8.1908 Lr: 0.00041
[2025-12-10 16:58:49,347 INFO misc.py line 117 4140988] Train: [1/10][105/7400] Data 0.003 (0.004) Batch 0.397 (0.607) Remain 12:27:41 loss: 8.2221 mask_loss: 7.9760 roll_mask_loss: 8.1621 density_loss: 8.3520 unmask_loss: 8.2081 Lr: 0.00041
[2025-12-10 16:58:49,714 INFO misc.py line 117 4140988] Train: [1/10][106/7400] Data 0.003 (0.004) Batch 0.367 (0.605) Remain 12:24:48 loss: 8.1546 mask_loss: 7.9202 roll_mask_loss: 8.1305 density_loss: 8.2822 unmask_loss: 8.1182 Lr: 0.00041
[2025-12-10 16:58:50,206 INFO misc.py line 117 4140988] Train: [1/10][107/7400] Data 0.003 (0.004) Batch 0.492 (0.604) Remain 12:23:27 loss: 8.4639 mask_loss: 8.2359 roll_mask_loss: 8.4642 density_loss: 8.4441 unmask_loss: 8.4089 Lr: 0.00041
[2025-12-10 16:58:50,781 INFO misc.py line 117 4140988] Train: [1/10][108/7400] Data 0.004 (0.004) Batch 0.575 (0.603) Remain 12:23:06 loss: 8.3143 mask_loss: 8.0037 roll_mask_loss: 8.3051 density_loss: 8.4385 unmask_loss: 8.3054 Lr: 0.00041
[2025-12-10 16:58:51,260 INFO misc.py line 117 4140988] Train: [1/10][109/7400] Data 0.003 (0.004) Batch 0.479 (0.602) Remain 12:21:39 loss: 8.2666 mask_loss: 8.0465 roll_mask_loss: 8.2845 density_loss: 8.3405 unmask_loss: 8.2009 Lr: 0.00041
[2025-12-10 16:58:51,835 INFO misc.py line 117 4140988] Train: [1/10][110/7400] Data 0.004 (0.004) Batch 0.575 (0.602) Remain 12:21:20 loss: 8.1666 mask_loss: 7.9849 roll_mask_loss: 8.1092 density_loss: 8.1609 unmask_loss: 8.1229 Lr: 0.00041
[2025-12-10 16:58:52,668 INFO misc.py line 117 4140988] Train: [1/10][111/7400] Data 0.004 (0.004) Batch 0.832 (0.604) Remain 12:23:57 loss: 8.2408 mask_loss: 8.0068 roll_mask_loss: 8.2269 density_loss: 8.4171 unmask_loss: 8.1964 Lr: 0.00041
[2025-12-10 16:58:53,325 INFO misc.py line 117 4140988] Train: [1/10][112/7400] Data 0.004 (0.004) Batch 0.657 (0.605) Remain 12:24:32 loss: 8.1711 mask_loss: 7.9682 roll_mask_loss: 8.1223 density_loss: 8.2844 unmask_loss: 8.1314 Lr: 0.00041
[2025-12-10 16:58:53,995 INFO misc.py line 117 4140988] Train: [1/10][113/7400] Data 0.004 (0.004) Batch 0.670 (0.605) Remain 12:25:15 loss: 8.3123 mask_loss: 8.0800 roll_mask_loss: 8.2970 density_loss: 8.4025 unmask_loss: 8.2680 Lr: 0.00041
[2025-12-10 16:58:54,718 INFO misc.py line 117 4140988] Train: [1/10][114/7400] Data 0.004 (0.004) Batch 0.723 (0.606) Remain 12:26:33 loss: 8.1431 mask_loss: 7.9306 roll_mask_loss: 8.0639 density_loss: 8.3392 unmask_loss: 8.1222 Lr: 0.00041
[2025-12-10 16:58:55,298 INFO misc.py line 117 4140988] Train: [1/10][115/7400] Data 0.004 (0.004) Batch 0.580 (0.606) Remain 12:26:15 loss: 8.2579 mask_loss: 8.0495 roll_mask_loss: 8.2581 density_loss: 8.4650 unmask_loss: 8.1927 Lr: 0.00041
[2025-12-10 16:58:55,951 INFO misc.py line 117 4140988] Train: [1/10][116/7400] Data 0.004 (0.004) Batch 0.654 (0.606) Remain 12:26:46 loss: 8.1689 mask_loss: 7.9191 roll_mask_loss: 8.1182 density_loss: 8.3407 unmask_loss: 8.1523 Lr: 0.00041
[2025-12-10 16:58:56,468 INFO misc.py line 117 4140988] Train: [1/10][117/7400] Data 0.004 (0.004) Batch 0.516 (0.606) Remain 12:25:47 loss: 8.3825 mask_loss: 8.1401 roll_mask_loss: 8.3704 density_loss: 8.4207 unmask_loss: 8.3413 Lr: 0.00041
[2025-12-10 16:58:57,169 INFO misc.py line 117 4140988] Train: [1/10][118/7400] Data 0.004 (0.004) Batch 0.701 (0.606) Remain 12:26:48 loss: 8.1817 mask_loss: 8.0011 roll_mask_loss: 8.1659 density_loss: 8.2416 unmask_loss: 8.1151 Lr: 0.00041
[2025-12-10 16:58:57,744 INFO misc.py line 117 4140988] Train: [1/10][119/7400] Data 0.004 (0.004) Batch 0.575 (0.606) Remain 12:26:27 loss: 8.3120 mask_loss: 8.0511 roll_mask_loss: 8.3757 density_loss: 8.3811 unmask_loss: 8.2430 Lr: 0.00041
[2025-12-10 16:58:58,264 INFO misc.py line 117 4140988] Train: [1/10][120/7400] Data 0.004 (0.004) Batch 0.520 (0.605) Remain 12:25:32 loss: 8.1606 mask_loss: 7.9175 roll_mask_loss: 8.0974 density_loss: 8.3538 unmask_loss: 8.1466 Lr: 0.00041
[2025-12-10 16:58:58,898 INFO misc.py line 117 4140988] Train: [1/10][121/7400] Data 0.004 (0.004) Batch 0.634 (0.606) Remain 12:25:49 loss: 8.1891 mask_loss: 7.9371 roll_mask_loss: 8.1758 density_loss: 8.3460 unmask_loss: 8.1549 Lr: 0.00041
[2025-12-10 16:58:59,471 INFO misc.py line 117 4140988] Train: [1/10][122/7400] Data 0.004 (0.004) Batch 0.573 (0.605) Remain 12:25:29 loss: 8.1760 mask_loss: 7.9170 roll_mask_loss: 8.2016 density_loss: 8.2821 unmask_loss: 8.1271 Lr: 0.00041
[2025-12-10 16:59:00,062 INFO misc.py line 117 4140988] Train: [1/10][123/7400] Data 0.003 (0.004) Batch 0.590 (0.605) Remain 12:25:19 loss: 8.1337 mask_loss: 7.9259 roll_mask_loss: 8.0565 density_loss: 8.3062 unmask_loss: 8.1101 Lr: 0.00041
[2025-12-10 16:59:00,542 INFO misc.py line 117 4140988] Train: [1/10][124/7400] Data 0.004 (0.004) Batch 0.480 (0.604) Remain 12:24:02 loss: 8.2871 mask_loss: 7.9399 roll_mask_loss: 8.3502 density_loss: 8.2508 unmask_loss: 8.2641 Lr: 0.00041
[2025-12-10 16:59:01,237 INFO misc.py line 117 4140988] Train: [1/10][125/7400] Data 0.004 (0.004) Batch 0.694 (0.605) Remain 12:24:56 loss: 8.1387 mask_loss: 7.8905 roll_mask_loss: 8.0865 density_loss: 8.4428 unmask_loss: 8.1200 Lr: 0.00041
[2025-12-10 16:59:01,941 INFO misc.py line 117 4140988] Train: [1/10][126/7400] Data 0.005 (0.004) Batch 0.704 (0.606) Remain 12:25:55 loss: 8.0944 mask_loss: 7.8667 roll_mask_loss: 7.9966 density_loss: 8.1442 unmask_loss: 8.0943 Lr: 0.00041
[2025-12-10 16:59:02,482 INFO misc.py line 117 4140988] Train: [1/10][127/7400] Data 0.004 (0.004) Batch 0.542 (0.605) Remain 12:25:16 loss: 8.3975 mask_loss: 8.0488 roll_mask_loss: 8.4871 density_loss: 8.2925 unmask_loss: 8.3612 Lr: 0.00041
[2025-12-10 16:59:03,018 INFO misc.py line 117 4140988] Train: [1/10][128/7400] Data 0.003 (0.004) Batch 0.536 (0.605) Remain 12:24:34 loss: 8.2430 mask_loss: 7.9886 roll_mask_loss: 8.3601 density_loss: 8.4638 unmask_loss: 8.1425 Lr: 0.00041
[2025-12-10 16:59:03,389 INFO misc.py line 117 4140988] Train: [1/10][129/7400] Data 0.003 (0.004) Batch 0.371 (0.603) Remain 12:22:17 loss: 8.1975 mask_loss: 7.9512 roll_mask_loss: 8.1987 density_loss: 8.3913 unmask_loss: 8.1523 Lr: 0.00041
[2025-12-10 16:59:03,988 INFO misc.py line 117 4140988] Train: [1/10][130/7400] Data 0.003 (0.004) Batch 0.599 (0.603) Remain 12:22:14 loss: 8.1502 mask_loss: 7.9065 roll_mask_loss: 8.1507 density_loss: 8.4387 unmask_loss: 8.1030 Lr: 0.00041
[2025-12-10 16:59:04,600 INFO misc.py line 117 4140988] Train: [1/10][131/7400] Data 0.004 (0.004) Batch 0.611 (0.603) Remain 12:22:18 loss: 8.2446 mask_loss: 7.9786 roll_mask_loss: 8.2443 density_loss: 8.1769 unmask_loss: 8.2141 Lr: 0.00041
[2025-12-10 16:59:05,263 INFO misc.py line 117 4140988] Train: [1/10][132/7400] Data 0.004 (0.004) Batch 0.663 (0.603) Remain 12:22:52 loss: 8.1250 mask_loss: 7.9169 roll_mask_loss: 8.0842 density_loss: 8.3332 unmask_loss: 8.0829 Lr: 0.00041
[2025-12-10 16:59:05,564 INFO misc.py line 117 4140988] Train: [1/10][133/7400] Data 0.004 (0.004) Batch 0.301 (0.601) Remain 12:20:00 loss: 8.3524 mask_loss: 8.1721 roll_mask_loss: 8.4632 density_loss: 8.2398 unmask_loss: 8.2223 Lr: 0.00041
[2025-12-10 16:59:06,358 INFO misc.py line 117 4140988] Train: [1/10][134/7400] Data 0.004 (0.004) Batch 0.793 (0.603) Remain 12:21:47 loss: 8.2367 mask_loss: 7.9244 roll_mask_loss: 8.1657 density_loss: 8.4470 unmask_loss: 8.2594 Lr: 0.00041
[2025-12-10 16:59:06,962 INFO misc.py line 117 4140988] Train: [1/10][135/7400] Data 0.005 (0.004) Batch 0.605 (0.603) Remain 12:21:48 loss: 8.1610 mask_loss: 7.9193 roll_mask_loss: 8.0826 density_loss: 8.2178 unmask_loss: 8.1568 Lr: 0.00041
[2025-12-10 16:59:07,604 INFO misc.py line 117 4140988] Train: [1/10][136/7400] Data 0.004 (0.004) Batch 0.642 (0.603) Remain 12:22:09 loss: 8.0883 mask_loss: 7.8433 roll_mask_loss: 8.0426 density_loss: 8.4055 unmask_loss: 8.0656 Lr: 0.00041
[2025-12-10 16:59:08,235 INFO misc.py line 117 4140988] Train: [1/10][137/7400] Data 0.003 (0.004) Batch 0.630 (0.603) Remain 12:22:23 loss: 8.1737 mask_loss: 7.9109 roll_mask_loss: 8.2286 density_loss: 8.4232 unmask_loss: 8.1091 Lr: 0.00041
[2025-12-10 16:59:08,815 INFO misc.py line 117 4140988] Train: [1/10][138/7400] Data 0.006 (0.004) Batch 0.581 (0.603) Remain 12:22:11 loss: 8.1053 mask_loss: 7.8665 roll_mask_loss: 8.0776 density_loss: 8.2315 unmask_loss: 8.0740 Lr: 0.00041
[2025-12-10 16:59:09,803 INFO misc.py line 117 4140988] Train: [1/10][139/7400] Data 0.004 (0.004) Batch 0.989 (0.606) Remain 12:25:40 loss: 8.2197 mask_loss: 7.9143 roll_mask_loss: 8.2205 density_loss: 8.2791 unmask_loss: 8.2064 Lr: 0.00041
[2025-12-10 16:59:10,365 INFO misc.py line 117 4140988] Train: [1/10][140/7400] Data 0.003 (0.004) Batch 0.561 (0.605) Remain 12:25:15 loss: 8.2867 mask_loss: 7.9953 roll_mask_loss: 8.2349 density_loss: 8.2581 unmask_loss: 8.2932 Lr: 0.00041
[2025-12-10 16:59:11,002 INFO misc.py line 117 4140988] Train: [1/10][141/7400] Data 0.003 (0.004) Batch 0.637 (0.606) Remain 12:25:32 loss: 8.1189 mask_loss: 7.8888 roll_mask_loss: 8.0619 density_loss: 8.2572 unmask_loss: 8.0973 Lr: 0.00041
[2025-12-10 16:59:11,705 INFO misc.py line 117 4140988] Train: [1/10][142/7400] Data 0.004 (0.004) Batch 0.703 (0.606) Remain 12:26:23 loss: 8.2056 mask_loss: 7.9529 roll_mask_loss: 8.1428 density_loss: 8.4851 unmask_loss: 8.1937 Lr: 0.00041
[2025-12-10 16:59:12,283 INFO misc.py line 117 4140988] Train: [1/10][143/7400] Data 0.003 (0.004) Batch 0.579 (0.606) Remain 12:26:08 loss: 8.2828 mask_loss: 7.9924 roll_mask_loss: 8.2721 density_loss: 8.3809 unmask_loss: 8.2657 Lr: 0.00041
[2025-12-10 16:59:12,903 INFO misc.py line 117 4140988] Train: [1/10][144/7400] Data 0.003 (0.004) Batch 0.620 (0.606) Remain 12:26:14 loss: 8.0884 mask_loss: 7.8555 roll_mask_loss: 8.0348 density_loss: 8.4004 unmask_loss: 8.0637 Lr: 0.00041
[2025-12-10 16:59:13,606 INFO misc.py line 117 4140988] Train: [1/10][145/7400] Data 0.003 (0.004) Batch 0.702 (0.607) Remain 12:27:04 loss: 8.3153 mask_loss: 7.9769 roll_mask_loss: 8.3266 density_loss: 8.3308 unmask_loss: 8.3122 Lr: 0.00041
[2025-12-10 16:59:14,559 INFO misc.py line 117 4140988] Train: [1/10][146/7400] Data 0.004 (0.004) Batch 0.952 (0.609) Remain 12:30:02 loss: 8.1712 mask_loss: 7.8850 roll_mask_loss: 8.1174 density_loss: 8.3695 unmask_loss: 8.1737 Lr: 0.00041
[2025-12-10 16:59:15,141 INFO misc.py line 117 4140988] Train: [1/10][147/7400] Data 0.004 (0.004) Batch 0.581 (0.609) Remain 12:29:46 loss: 8.1300 mask_loss: 7.8593 roll_mask_loss: 8.1269 density_loss: 8.4699 unmask_loss: 8.0975 Lr: 0.00041
[2025-12-10 16:59:15,947 INFO misc.py line 117 4140988] Train: [1/10][148/7400] Data 0.005 (0.004) Batch 0.808 (0.611) Remain 12:31:27 loss: 8.0667 mask_loss: 7.8422 roll_mask_loss: 7.9851 density_loss: 8.2713 unmask_loss: 8.0543 Lr: 0.00041
[2025-12-10 16:59:16,613 INFO misc.py line 117 4140988] Train: [1/10][149/7400] Data 0.003 (0.004) Batch 0.665 (0.611) Remain 12:31:54 loss: 8.1052 mask_loss: 7.8279 roll_mask_loss: 8.0868 density_loss: 8.3004 unmask_loss: 8.0871 Lr: 0.00041
[2025-12-10 16:59:17,135 INFO misc.py line 117 4140988] Train: [1/10][150/7400] Data 0.003 (0.004) Batch 0.522 (0.610) Remain 12:31:09 loss: 8.2335 mask_loss: 7.9833 roll_mask_loss: 8.2201 density_loss: 8.3485 unmask_loss: 8.1983 Lr: 0.00041
[2025-12-10 16:59:17,733 INFO misc.py line 117 4140988] Train: [1/10][151/7400] Data 0.004 (0.004) Batch 0.598 (0.610) Remain 12:31:02 loss: 8.0654 mask_loss: 7.8618 roll_mask_loss: 8.0134 density_loss: 8.2630 unmask_loss: 8.0280 Lr: 0.00041
[2025-12-10 16:59:18,395 INFO misc.py line 117 4140988] Train: [1/10][152/7400] Data 0.004 (0.004) Batch 0.662 (0.611) Remain 12:31:27 loss: 8.0864 mask_loss: 7.8291 roll_mask_loss: 8.0377 density_loss: 8.3235 unmask_loss: 8.0729 Lr: 0.00041
[2025-12-10 16:59:18,728 INFO misc.py line 117 4140988] Train: [1/10][153/7400] Data 0.004 (0.004) Batch 0.334 (0.609) Remain 12:29:10 loss: 8.2223 mask_loss: 7.9342 roll_mask_loss: 8.0537 density_loss: 8.4523 unmask_loss: 8.2815 Lr: 0.00041
[2025-12-10 16:59:19,508 INFO misc.py line 117 4140988] Train: [1/10][154/7400] Data 0.003 (0.004) Batch 0.779 (0.610) Remain 12:30:33 loss: 8.0623 mask_loss: 7.8115 roll_mask_loss: 8.0090 density_loss: 8.3754 unmask_loss: 8.0469 Lr: 0.00041
[2025-12-10 16:59:19,969 INFO misc.py line 117 4140988] Train: [1/10][155/7400] Data 0.004 (0.004) Batch 0.462 (0.609) Remain 12:29:20 loss: 8.4058 mask_loss: 8.1870 roll_mask_loss: 8.4085 density_loss: 8.4051 unmask_loss: 8.3458 Lr: 0.00042
[2025-12-10 16:59:20,571 INFO misc.py line 117 4140988] Train: [1/10][156/7400] Data 0.003 (0.004) Batch 0.602 (0.609) Remain 12:29:17 loss: 8.4200 mask_loss: 8.1072 roll_mask_loss: 8.4652 density_loss: 8.3977 unmask_loss: 8.3858 Lr: 0.00042
[2025-12-10 16:59:21,537 INFO misc.py line 117 4140988] Train: [1/10][157/7400] Data 0.003 (0.004) Batch 0.965 (0.611) Remain 12:32:07 loss: 8.0854 mask_loss: 7.8280 roll_mask_loss: 8.0169 density_loss: 8.2870 unmask_loss: 8.0825 Lr: 0.00042
[2025-12-10 16:59:22,087 INFO misc.py line 117 4140988] Train: [1/10][158/7400] Data 0.004 (0.004) Batch 0.550 (0.611) Remain 12:31:37 loss: 8.1480 mask_loss: 7.8989 roll_mask_loss: 8.1444 density_loss: 8.6365 unmask_loss: 8.1015 Lr: 0.00042
[2025-12-10 16:59:22,804 INFO misc.py line 117 4140988] Train: [1/10][159/7400] Data 0.004 (0.004) Batch 0.718 (0.611) Remain 12:32:27 loss: 8.0839 mask_loss: 7.8094 roll_mask_loss: 8.0195 density_loss: 8.2569 unmask_loss: 8.0883 Lr: 0.00042
[2025-12-10 16:59:23,435 INFO misc.py line 117 4140988] Train: [1/10][160/7400] Data 0.004 (0.004) Batch 0.631 (0.612) Remain 12:32:36 loss: 8.3839 mask_loss: 7.9758 roll_mask_loss: 8.5394 density_loss: 8.3836 unmask_loss: 8.3425 Lr: 0.00042
[2025-12-10 16:59:24,045 INFO misc.py line 117 4140988] Train: [1/10][161/7400] Data 0.004 (0.004) Batch 0.610 (0.612) Remain 12:32:34 loss: 8.1270 mask_loss: 7.8786 roll_mask_loss: 8.1262 density_loss: 8.3306 unmask_loss: 8.0850 Lr: 0.00042
[2025-12-10 16:59:24,599 INFO misc.py line 117 4140988] Train: [1/10][162/7400] Data 0.004 (0.004) Batch 0.554 (0.611) Remain 12:32:07 loss: 8.1137 mask_loss: 7.8079 roll_mask_loss: 8.0650 density_loss: 8.3945 unmask_loss: 8.1230 Lr: 0.00042
[2025-12-10 16:59:25,493 INFO misc.py line 117 4140988] Train: [1/10][163/7400] Data 0.004 (0.004) Batch 0.894 (0.613) Remain 12:34:17 loss: 8.1307 mask_loss: 7.8022 roll_mask_loss: 8.0990 density_loss: 8.2693 unmask_loss: 8.1455 Lr: 0.00042
[2025-12-10 16:59:26,088 INFO misc.py line 117 4140988] Train: [1/10][164/7400] Data 0.004 (0.004) Batch 0.595 (0.613) Remain 12:34:08 loss: 8.1215 mask_loss: 7.8093 roll_mask_loss: 8.1740 density_loss: 8.5533 unmask_loss: 8.0803 Lr: 0.00042
[2025-12-10 16:59:26,867 INFO misc.py line 117 4140988] Train: [1/10][165/7400] Data 0.003 (0.004) Batch 0.779 (0.614) Remain 12:35:23 loss: 8.0746 mask_loss: 7.7469 roll_mask_loss: 8.0598 density_loss: 8.2485 unmask_loss: 8.0809 Lr: 0.00042
[2025-12-10 16:59:27,615 INFO misc.py line 117 4140988] Train: [1/10][166/7400] Data 0.004 (0.004) Batch 0.748 (0.615) Remain 12:36:23 loss: 8.0622 mask_loss: 7.7765 roll_mask_loss: 8.0121 density_loss: 8.3309 unmask_loss: 8.0634 Lr: 0.00042
[2025-12-10 16:59:28,129 INFO misc.py line 117 4140988] Train: [1/10][167/7400] Data 0.004 (0.004) Batch 0.513 (0.614) Remain 12:35:37 loss: 8.1788 mask_loss: 7.9615 roll_mask_loss: 8.1671 density_loss: 8.2479 unmask_loss: 8.1283 Lr: 0.00042
[2025-12-10 16:59:28,649 INFO misc.py line 117 4140988] Train: [1/10][168/7400] Data 0.004 (0.004) Batch 0.520 (0.613) Remain 12:34:54 loss: 8.4256 mask_loss: 8.2266 roll_mask_loss: 8.4458 density_loss: 8.4274 unmask_loss: 8.3465 Lr: 0.00042
[2025-12-10 16:59:29,255 INFO misc.py line 117 4140988] Train: [1/10][169/7400] Data 0.004 (0.004) Batch 0.606 (0.613) Remain 12:34:51 loss: 8.0878 mask_loss: 7.7863 roll_mask_loss: 8.0632 density_loss: 8.4479 unmask_loss: 8.0818 Lr: 0.00042
[2025-12-10 16:59:29,874 INFO misc.py line 117 4140988] Train: [1/10][170/7400] Data 0.004 (0.004) Batch 0.620 (0.613) Remain 12:34:53 loss: 8.0688 mask_loss: 7.8193 roll_mask_loss: 8.0249 density_loss: 8.1108 unmask_loss: 8.0533 Lr: 0.00042
[2025-12-10 16:59:30,561 INFO misc.py line 117 4140988] Train: [1/10][171/7400] Data 0.003 (0.004) Batch 0.687 (0.614) Remain 12:35:24 loss: 8.1651 mask_loss: 7.9062 roll_mask_loss: 8.1304 density_loss: 8.3719 unmask_loss: 8.1444 Lr: 0.00042
[2025-12-10 16:59:31,116 INFO misc.py line 117 4140988] Train: [1/10][172/7400] Data 0.003 (0.004) Batch 0.556 (0.614) Remain 12:34:58 loss: 8.3503 mask_loss: 8.1078 roll_mask_loss: 8.3782 density_loss: 8.4364 unmask_loss: 8.2888 Lr: 0.00042
[2025-12-10 16:59:31,902 INFO misc.py line 117 4140988] Train: [1/10][173/7400] Data 0.003 (0.004) Batch 0.785 (0.615) Remain 12:36:12 loss: 8.1395 mask_loss: 7.7602 roll_mask_loss: 8.3415 density_loss: 8.3509 unmask_loss: 8.0612 Lr: 0.00042
[2025-12-10 16:59:32,513 INFO misc.py line 117 4140988] Train: [1/10][174/7400] Data 0.004 (0.004) Batch 0.611 (0.615) Remain 12:36:10 loss: 8.3813 mask_loss: 8.0185 roll_mask_loss: 8.4335 density_loss: 8.3153 unmask_loss: 8.3703 Lr: 0.00042
[2025-12-10 16:59:32,980 INFO misc.py line 117 4140988] Train: [1/10][175/7400] Data 0.004 (0.004) Batch 0.467 (0.614) Remain 12:35:06 loss: 8.4119 mask_loss: 8.1498 roll_mask_loss: 8.4117 density_loss: 8.4187 unmask_loss: 8.3747 Lr: 0.00042
[2025-12-10 16:59:33,624 INFO misc.py line 117 4140988] Train: [1/10][176/7400] Data 0.004 (0.004) Batch 0.644 (0.614) Remain 12:35:18 loss: 8.0413 mask_loss: 7.7263 roll_mask_loss: 7.9751 density_loss: 8.2606 unmask_loss: 8.0666 Lr: 0.00042
[2025-12-10 16:59:34,281 INFO misc.py line 117 4140988] Train: [1/10][177/7400] Data 0.003 (0.004) Batch 0.657 (0.614) Remain 12:35:36 loss: 8.0715 mask_loss: 7.7603 roll_mask_loss: 8.0347 density_loss: 8.5737 unmask_loss: 8.0740 Lr: 0.00042
[2025-12-10 16:59:34,738 INFO misc.py line 117 4140988] Train: [1/10][178/7400] Data 0.003 (0.004) Batch 0.458 (0.613) Remain 12:34:29 loss: 8.1886 mask_loss: 7.9326 roll_mask_loss: 8.2209 density_loss: 8.5785 unmask_loss: 8.1289 Lr: 0.00042
[2025-12-10 16:59:35,417 INFO misc.py line 117 4140988] Train: [1/10][179/7400] Data 0.003 (0.004) Batch 0.679 (0.614) Remain 12:34:56 loss: 8.1083 mask_loss: 7.8020 roll_mask_loss: 8.0835 density_loss: 8.3935 unmask_loss: 8.1061 Lr: 0.00042
[2025-12-10 16:59:36,085 INFO misc.py line 117 4140988] Train: [1/10][180/7400] Data 0.003 (0.004) Batch 0.669 (0.614) Remain 12:35:19 loss: 8.1100 mask_loss: 7.8568 roll_mask_loss: 8.1289 density_loss: 8.2985 unmask_loss: 8.0613 Lr: 0.00042
[2025-12-10 16:59:36,855 INFO misc.py line 117 4140988] Train: [1/10][181/7400] Data 0.003 (0.004) Batch 0.770 (0.615) Remain 12:36:23 loss: 8.1363 mask_loss: 7.7595 roll_mask_loss: 8.0381 density_loss: 8.3369 unmask_loss: 8.2071 Lr: 0.00042
[2025-12-10 16:59:37,415 INFO misc.py line 117 4140988] Train: [1/10][182/7400] Data 0.003 (0.004) Batch 0.560 (0.614) Remain 12:35:59 loss: 8.1713 mask_loss: 7.8943 roll_mask_loss: 8.1308 density_loss: 8.3479 unmask_loss: 8.1632 Lr: 0.00042
[2025-12-10 16:59:38,051 INFO misc.py line 117 4140988] Train: [1/10][183/7400] Data 0.004 (0.004) Batch 0.636 (0.615) Remain 12:36:08 loss: 8.1121 mask_loss: 7.7621 roll_mask_loss: 8.0284 density_loss: 8.2754 unmask_loss: 8.1634 Lr: 0.00042
[2025-12-10 16:59:38,460 INFO misc.py line 117 4140988] Train: [1/10][184/7400] Data 0.003 (0.004) Batch 0.409 (0.613) Remain 12:34:43 loss: 8.2326 mask_loss: 7.9899 roll_mask_loss: 8.2072 density_loss: 8.6115 unmask_loss: 8.1945 Lr: 0.00042
[2025-12-10 16:59:39,014 INFO misc.py line 117 4140988] Train: [1/10][185/7400] Data 0.003 (0.004) Batch 0.553 (0.613) Remain 12:34:18 loss: 8.0537 mask_loss: 7.8077 roll_mask_loss: 7.9921 density_loss: 8.2299 unmask_loss: 8.0428 Lr: 0.00042
[2025-12-10 16:59:39,539 INFO misc.py line 117 4140988] Train: [1/10][186/7400] Data 0.004 (0.004) Batch 0.525 (0.613) Remain 12:33:42 loss: 8.0938 mask_loss: 7.8213 roll_mask_loss: 8.0923 density_loss: 8.3435 unmask_loss: 8.0640 Lr: 0.00042
[2025-12-10 16:59:40,090 INFO misc.py line 117 4140988] Train: [1/10][187/7400] Data 0.004 (0.004) Batch 0.551 (0.612) Remain 12:33:16 loss: 8.1634 mask_loss: 7.8019 roll_mask_loss: 8.1593 density_loss: 8.2178 unmask_loss: 8.1819 Lr: 0.00042
[2025-12-10 16:59:40,705 INFO misc.py line 117 4140988] Train: [1/10][188/7400] Data 0.004 (0.004) Batch 0.616 (0.612) Remain 12:33:17 loss: 8.0090 mask_loss: 7.7446 roll_mask_loss: 7.9476 density_loss: 8.1367 unmask_loss: 8.0093 Lr: 0.00042
[2025-12-10 16:59:41,241 INFO misc.py line 117 4140988] Train: [1/10][189/7400] Data 0.004 (0.004) Batch 0.536 (0.612) Remain 12:32:46 loss: 8.1058 mask_loss: 7.7050 roll_mask_loss: 8.0404 density_loss: 8.4272 unmask_loss: 8.1704 Lr: 0.00042
[2025-12-10 16:59:41,992 INFO misc.py line 117 4140988] Train: [1/10][190/7400] Data 0.003 (0.004) Batch 0.751 (0.613) Remain 12:33:40 loss: 7.9973 mask_loss: 7.6846 roll_mask_loss: 7.9377 density_loss: 8.2665 unmask_loss: 8.0182 Lr: 0.00042
[2025-12-10 16:59:42,530 INFO misc.py line 117 4140988] Train: [1/10][191/7400] Data 0.004 (0.004) Batch 0.538 (0.612) Remain 12:33:10 loss: 8.2000 mask_loss: 7.9367 roll_mask_loss: 8.2507 density_loss: 8.2362 unmask_loss: 8.1415 Lr: 0.00042
[2025-12-10 16:59:43,376 INFO misc.py line 117 4140988] Train: [1/10][192/7400] Data 0.004 (0.004) Batch 0.846 (0.614) Remain 12:34:41 loss: 8.1024 mask_loss: 7.7128 roll_mask_loss: 8.0732 density_loss: 8.5335 unmask_loss: 8.1410 Lr: 0.00042
[2025-12-10 16:59:44,143 INFO misc.py line 117 4140988] Train: [1/10][193/7400] Data 0.004 (0.004) Batch 0.768 (0.614) Remain 12:35:40 loss: 8.0087 mask_loss: 7.7001 roll_mask_loss: 7.9256 density_loss: 8.3556 unmask_loss: 8.0375 Lr: 0.00042
[2025-12-10 16:59:44,498 INFO misc.py line 117 4140988] Train: [1/10][194/7400] Data 0.003 (0.004) Batch 0.355 (0.613) Remain 12:34:00 loss: 8.2217 mask_loss: 7.9765 roll_mask_loss: 8.1452 density_loss: 8.3546 unmask_loss: 8.2154 Lr: 0.00042
[2025-12-10 16:59:45,094 INFO misc.py line 117 4140988] Train: [1/10][195/7400] Data 0.003 (0.004) Batch 0.595 (0.613) Remain 12:33:52 loss: 8.0913 mask_loss: 7.7796 roll_mask_loss: 7.9805 density_loss: 8.6476 unmask_loss: 8.1297 Lr: 0.00042
[2025-12-10 16:59:45,748 INFO misc.py line 117 4140988] Train: [1/10][196/7400] Data 0.004 (0.004) Batch 0.654 (0.613) Remain 12:34:07 loss: 8.3140 mask_loss: 8.0229 roll_mask_loss: 8.2938 density_loss: 8.4107 unmask_loss: 8.3013 Lr: 0.00042
[2025-12-10 16:59:46,464 INFO misc.py line 117 4140988] Train: [1/10][197/7400] Data 0.003 (0.004) Batch 0.715 (0.614) Remain 12:34:46 loss: 8.0216 mask_loss: 7.6708 roll_mask_loss: 7.9312 density_loss: 8.4634 unmask_loss: 8.0728 Lr: 0.00042
[2025-12-10 16:59:47,106 INFO misc.py line 117 4140988] Train: [1/10][198/7400] Data 0.004 (0.004) Batch 0.642 (0.614) Remain 12:34:56 loss: 8.0363 mask_loss: 7.7427 roll_mask_loss: 8.0073 density_loss: 8.5396 unmask_loss: 8.0269 Lr: 0.00042
[2025-12-10 16:59:47,762 INFO misc.py line 117 4140988] Train: [1/10][199/7400] Data 0.004 (0.004) Batch 0.657 (0.614) Remain 12:35:11 loss: 8.0235 mask_loss: 7.7836 roll_mask_loss: 7.9832 density_loss: 8.3990 unmask_loss: 7.9956 Lr: 0.00043
[2025-12-10 16:59:48,385 INFO misc.py line 117 4140988] Train: [1/10][200/7400] Data 0.004 (0.004) Batch 0.623 (0.614) Remain 12:35:14 loss: 8.0015 mask_loss: 7.7386 roll_mask_loss: 7.9455 density_loss: 8.1468 unmask_loss: 7.9980 Lr: 0.00043
[2025-12-10 16:59:48,970 INFO misc.py line 117 4140988] Train: [1/10][201/7400] Data 0.003 (0.004) Batch 0.584 (0.614) Remain 12:35:03 loss: 8.2437 mask_loss: 7.9498 roll_mask_loss: 8.2127 density_loss: 8.4980 unmask_loss: 8.2361 Lr: 0.00043
[2025-12-10 16:59:49,686 INFO misc.py line 117 4140988] Train: [1/10][202/7400] Data 0.003 (0.004) Batch 0.716 (0.614) Remain 12:35:40 loss: 8.0548 mask_loss: 7.7152 roll_mask_loss: 8.0339 density_loss: 8.4310 unmask_loss: 8.0664 Lr: 0.00043
[2025-12-10 16:59:49,991 INFO misc.py line 117 4140988] Train: [1/10][203/7400] Data 0.004 (0.004) Batch 0.305 (0.613) Remain 12:33:45 loss: 8.1966 mask_loss: 7.8630 roll_mask_loss: 8.1239 density_loss: 8.1866 unmask_loss: 8.2360 Lr: 0.00043
[2025-12-10 16:59:50,575 INFO misc.py line 117 4140988] Train: [1/10][204/7400] Data 0.004 (0.004) Batch 0.585 (0.613) Remain 12:33:34 loss: 8.1643 mask_loss: 7.8434 roll_mask_loss: 8.2258 density_loss: 8.2980 unmask_loss: 8.1280 Lr: 0.00043
[2025-12-10 16:59:51,123 INFO misc.py line 117 4140988] Train: [1/10][205/7400] Data 0.004 (0.004) Batch 0.548 (0.612) Remain 12:33:10 loss: 8.4319 mask_loss: 8.1392 roll_mask_loss: 8.4193 density_loss: 8.4072 unmask_loss: 8.4165 Lr: 0.00043
[2025-12-10 16:59:51,690 INFO misc.py line 117 4140988] Train: [1/10][206/7400] Data 0.004 (0.004) Batch 0.567 (0.612) Remain 12:32:53 loss: 8.0625 mask_loss: 7.6906 roll_mask_loss: 8.0715 density_loss: 8.4363 unmask_loss: 8.0752 Lr: 0.00043
[2025-12-10 16:59:52,253 INFO misc.py line 117 4140988] Train: [1/10][207/7400] Data 0.004 (0.004) Batch 0.563 (0.612) Remain 12:32:34 loss: 8.1719 mask_loss: 7.8722 roll_mask_loss: 8.2029 density_loss: 8.4270 unmask_loss: 8.1377 Lr: 0.00043
[2025-12-10 16:59:52,848 INFO misc.py line 117 4140988] Train: [1/10][208/7400] Data 0.003 (0.004) Batch 0.595 (0.612) Remain 12:32:27 loss: 8.2746 mask_loss: 7.9789 roll_mask_loss: 8.2661 density_loss: 8.4391 unmask_loss: 8.2580 Lr: 0.00043
[2025-12-10 16:59:53,463 INFO misc.py line 117 4140988] Train: [1/10][209/7400] Data 0.003 (0.004) Batch 0.614 (0.612) Remain 12:32:28 loss: 8.0176 mask_loss: 7.7706 roll_mask_loss: 7.9698 density_loss: 8.1638 unmask_loss: 8.0018 Lr: 0.00043
[2025-12-10 16:59:54,064 INFO misc.py line 117 4140988] Train: [1/10][210/7400] Data 0.004 (0.004) Batch 0.602 (0.612) Remain 12:32:24 loss: 8.2026 mask_loss: 7.8874 roll_mask_loss: 8.2646 density_loss: 8.2093 unmask_loss: 8.1651 Lr: 0.00043
[2025-12-10 16:59:54,651 INFO misc.py line 117 4140988] Train: [1/10][211/7400] Data 0.004 (0.004) Batch 0.587 (0.612) Remain 12:32:14 loss: 8.1025 mask_loss: 7.7881 roll_mask_loss: 8.0532 density_loss: 8.3687 unmask_loss: 8.1170 Lr: 0.00043
[2025-12-10 16:59:55,251 INFO misc.py line 117 4140988] Train: [1/10][212/7400] Data 0.003 (0.004) Batch 0.601 (0.612) Remain 12:32:10 loss: 8.0188 mask_loss: 7.7411 roll_mask_loss: 7.9625 density_loss: 8.1409 unmask_loss: 8.0230 Lr: 0.00043
[2025-12-10 16:59:55,841 INFO misc.py line 117 4140988] Train: [1/10][213/7400] Data 0.003 (0.004) Batch 0.589 (0.612) Remain 12:32:01 loss: 7.9882 mask_loss: 7.6562 roll_mask_loss: 7.8776 density_loss: 8.3738 unmask_loss: 8.0420 Lr: 0.00043
[2025-12-10 16:59:56,394 INFO misc.py line 117 4140988] Train: [1/10][214/7400] Data 0.004 (0.004) Batch 0.555 (0.611) Remain 12:31:40 loss: 8.2139 mask_loss: 7.7399 roll_mask_loss: 8.1627 density_loss: 8.3137 unmask_loss: 8.3103 Lr: 0.00043
[2025-12-10 16:59:56,849 INFO misc.py line 117 4140988] Train: [1/10][215/7400] Data 0.003 (0.004) Batch 0.455 (0.611) Remain 12:30:45 loss: 8.3478 mask_loss: 8.1038 roll_mask_loss: 8.3463 density_loss: 8.4175 unmask_loss: 8.3023 Lr: 0.00043
[2025-12-10 16:59:57,387 INFO misc.py line 117 4140988] Train: [1/10][216/7400] Data 0.003 (0.004) Batch 0.538 (0.610) Remain 12:30:19 loss: 8.0690 mask_loss: 7.6669 roll_mask_loss: 8.1291 density_loss: 8.3850 unmask_loss: 8.0724 Lr: 0.00043
[2025-12-10 16:59:57,977 INFO misc.py line 117 4140988] Train: [1/10][217/7400] Data 0.003 (0.004) Batch 0.590 (0.610) Remain 12:30:12 loss: 8.1566 mask_loss: 7.8896 roll_mask_loss: 8.1146 density_loss: 8.4644 unmask_loss: 8.1417 Lr: 0.00043
[2025-12-10 16:59:58,589 INFO misc.py line 117 4140988] Train: [1/10][218/7400] Data 0.003 (0.004) Batch 0.612 (0.610) Remain 12:30:12 loss: 7.9773 mask_loss: 7.6266 roll_mask_loss: 7.9157 density_loss: 8.2876 unmask_loss: 8.0176 Lr: 0.00043
[2025-12-10 16:59:59,190 INFO misc.py line 117 4140988] Train: [1/10][219/7400] Data 0.003 (0.004) Batch 0.601 (0.610) Remain 12:30:08 loss: 7.9673 mask_loss: 7.6167 roll_mask_loss: 7.9320 density_loss: 8.3983 unmask_loss: 7.9923 Lr: 0.00043
[2025-12-10 17:00:00,058 INFO misc.py line 117 4140988] Train: [1/10][220/7400] Data 0.004 (0.004) Batch 0.868 (0.611) Remain 12:31:35 loss: 8.1511 mask_loss: 7.6639 roll_mask_loss: 8.2164 density_loss: 8.3286 unmask_loss: 8.1954 Lr: 0.00043
[2025-12-10 17:00:00,595 INFO misc.py line 117 4140988] Train: [1/10][221/7400] Data 0.004 (0.004) Batch 0.537 (0.611) Remain 12:31:09 loss: 8.2850 mask_loss: 7.9171 roll_mask_loss: 8.7120 density_loss: 8.5361 unmask_loss: 8.0847 Lr: 0.00043
[2025-12-10 17:00:01,195 INFO misc.py line 117 4140988] Train: [1/10][222/7400] Data 0.004 (0.004) Batch 0.601 (0.611) Remain 12:31:05 loss: 8.1422 mask_loss: 7.8182 roll_mask_loss: 8.2176 density_loss: 8.5817 unmask_loss: 8.0949 Lr: 0.00043
[2025-12-10 17:00:01,523 INFO misc.py line 117 4140988] Train: [1/10][223/7400] Data 0.004 (0.004) Batch 0.327 (0.610) Remain 12:29:30 loss: 7.9821 mask_loss: 7.6325 roll_mask_loss: 7.9882 density_loss: 8.4534 unmask_loss: 7.9848 Lr: 0.00043
[2025-12-10 17:00:02,125 INFO misc.py line 117 4140988] Train: [1/10][224/7400] Data 0.004 (0.004) Batch 0.603 (0.610) Remain 12:29:27 loss: 7.9408 mask_loss: 7.6420 roll_mask_loss: 7.8401 density_loss: 8.3511 unmask_loss: 7.9736 Lr: 0.00043
[2025-12-10 17:00:03,054 INFO misc.py line 117 4140988] Train: [1/10][225/7400] Data 0.003 (0.004) Batch 0.929 (0.611) Remain 12:31:12 loss: 7.9445 mask_loss: 7.5926 roll_mask_loss: 7.8895 density_loss: 8.3264 unmask_loss: 7.9815 Lr: 0.00043
[2025-12-10 17:00:03,628 INFO misc.py line 117 4140988] Train: [1/10][226/7400] Data 0.003 (0.004) Batch 0.575 (0.611) Remain 12:31:00 loss: 7.9715 mask_loss: 7.6869 roll_mask_loss: 7.9452 density_loss: 8.3499 unmask_loss: 7.9599 Lr: 0.00043
[2025-12-10 17:00:04,171 INFO misc.py line 117 4140988] Train: [1/10][227/7400] Data 0.003 (0.004) Batch 0.544 (0.610) Remain 12:30:37 loss: 7.9860 mask_loss: 7.6664 roll_mask_loss: 7.9091 density_loss: 8.4628 unmask_loss: 8.0150 Lr: 0.00043
[2025-12-10 17:00:04,909 INFO misc.py line 117 4140988] Train: [1/10][228/7400] Data 0.003 (0.004) Batch 0.738 (0.611) Remain 12:31:18 loss: 8.0533 mask_loss: 7.7316 roll_mask_loss: 7.9974 density_loss: 8.2636 unmask_loss: 8.0768 Lr: 0.00043
[2025-12-10 17:00:05,689 INFO misc.py line 117 4140988] Train: [1/10][229/7400] Data 0.003 (0.004) Batch 0.779 (0.612) Remain 12:32:12 loss: 7.9356 mask_loss: 7.6449 roll_mask_loss: 7.8463 density_loss: 8.0471 unmask_loss: 7.9647 Lr: 0.00043
[2025-12-10 17:00:06,311 INFO misc.py line 117 4140988] Train: [1/10][230/7400] Data 0.004 (0.004) Batch 0.622 (0.612) Remain 12:32:15 loss: 7.9015 mask_loss: 7.5838 roll_mask_loss: 7.8355 density_loss: 8.6493 unmask_loss: 7.9205 Lr: 0.00043
[2025-12-10 17:00:06,814 INFO misc.py line 117 4140988] Train: [1/10][231/7400] Data 0.004 (0.004) Batch 0.503 (0.611) Remain 12:31:39 loss: 8.1893 mask_loss: 7.8099 roll_mask_loss: 8.2091 density_loss: 8.2315 unmask_loss: 8.2045 Lr: 0.00043
[2025-12-10 17:00:07,409 INFO misc.py line 117 4140988] Train: [1/10][232/7400] Data 0.004 (0.004) Batch 0.594 (0.611) Remain 12:31:33 loss: 8.1443 mask_loss: 7.8821 roll_mask_loss: 8.1695 density_loss: 8.3313 unmask_loss: 8.0963 Lr: 0.00043
[2025-12-10 17:00:07,945 INFO misc.py line 117 4140988] Train: [1/10][233/7400] Data 0.004 (0.004) Batch 0.536 (0.611) Remain 12:31:08 loss: 8.1736 mask_loss: 7.8145 roll_mask_loss: 8.1270 density_loss: 8.4314 unmask_loss: 8.2077 Lr: 0.00043
[2025-12-10 17:00:08,809 INFO misc.py line 117 4140988] Train: [1/10][234/7400] Data 0.004 (0.004) Batch 0.864 (0.612) Remain 12:32:29 loss: 8.1987 mask_loss: 7.8021 roll_mask_loss: 8.1740 density_loss: 8.6808 unmask_loss: 8.2357 Lr: 0.00043
[2025-12-10 17:00:09,349 INFO misc.py line 117 4140988] Train: [1/10][235/7400] Data 0.003 (0.004) Batch 0.539 (0.612) Remain 12:32:05 loss: 8.1788 mask_loss: 7.8186 roll_mask_loss: 8.1346 density_loss: 8.3111 unmask_loss: 8.2147 Lr: 0.00044
[2025-12-10 17:00:09,892 INFO misc.py line 117 4140988] Train: [1/10][236/7400] Data 0.004 (0.004) Batch 0.543 (0.611) Remain 12:31:43 loss: 8.4462 mask_loss: 8.1715 roll_mask_loss: 8.4142 density_loss: 8.3925 unmask_loss: 8.4317 Lr: 0.00044
[2025-12-10 17:00:10,594 INFO misc.py line 117 4140988] Train: [1/10][237/7400] Data 0.004 (0.004) Batch 0.703 (0.612) Remain 12:32:11 loss: 7.8962 mask_loss: 7.6061 roll_mask_loss: 7.7992 density_loss: 8.0662 unmask_loss: 7.9284 Lr: 0.00044
[2025-12-10 17:00:11,057 INFO misc.py line 117 4140988] Train: [1/10][238/7400] Data 0.003 (0.004) Batch 0.463 (0.611) Remain 12:31:23 loss: 8.1717 mask_loss: 7.8999 roll_mask_loss: 8.2514 density_loss: 8.3993 unmask_loss: 8.0997 Lr: 0.00044
[2025-12-10 17:00:11,618 INFO misc.py line 117 4140988] Train: [1/10][239/7400] Data 0.003 (0.004) Batch 0.561 (0.611) Remain 12:31:07 loss: 8.4343 mask_loss: 8.1992 roll_mask_loss: 8.4153 density_loss: 8.3980 unmask_loss: 8.3935 Lr: 0.00044
[2025-12-10 17:00:12,243 INFO misc.py line 117 4140988] Train: [1/10][240/7400] Data 0.003 (0.004) Batch 0.625 (0.611) Remain 12:31:11 loss: 7.9828 mask_loss: 7.6976 roll_mask_loss: 7.9305 density_loss: 8.5625 unmask_loss: 7.9802 Lr: 0.00044
[2025-12-10 17:00:12,859 INFO misc.py line 117 4140988] Train: [1/10][241/7400] Data 0.003 (0.004) Batch 0.614 (0.611) Remain 12:31:11 loss: 7.9052 mask_loss: 7.5521 roll_mask_loss: 7.8730 density_loss: 8.3720 unmask_loss: 7.9304 Lr: 0.00044
[2025-12-10 17:00:13,428 INFO misc.py line 117 4140988] Train: [1/10][242/7400] Data 0.005 (0.004) Batch 0.570 (0.611) Remain 12:30:58 loss: 7.9352 mask_loss: 7.6446 roll_mask_loss: 7.8529 density_loss: 8.2604 unmask_loss: 7.9565 Lr: 0.00044
[2025-12-10 17:00:14,063 INFO misc.py line 117 4140988] Train: [1/10][243/7400] Data 0.004 (0.004) Batch 0.634 (0.611) Remain 12:31:05 loss: 7.9752 mask_loss: 7.5849 roll_mask_loss: 7.9123 density_loss: 8.4595 unmask_loss: 8.0327 Lr: 0.00044
[2025-12-10 17:00:14,572 INFO misc.py line 117 4140988] Train: [1/10][244/7400] Data 0.004 (0.004) Batch 0.510 (0.611) Remain 12:30:33 loss: 8.3621 mask_loss: 7.8546 roll_mask_loss: 8.4643 density_loss: 8.7028 unmask_loss: 8.3907 Lr: 0.00044
[2025-12-10 17:00:15,220 INFO misc.py line 117 4140988] Train: [1/10][245/7400] Data 0.004 (0.004) Batch 0.648 (0.611) Remain 12:30:44 loss: 7.9799 mask_loss: 7.6604 roll_mask_loss: 7.9270 density_loss: 8.6218 unmask_loss: 7.9937 Lr: 0.00044
[2025-12-10 17:00:15,989 INFO misc.py line 117 4140988] Train: [1/10][246/7400] Data 0.004 (0.004) Batch 0.769 (0.611) Remain 12:31:31 loss: 7.9008 mask_loss: 7.5974 roll_mask_loss: 7.8417 density_loss: 8.2138 unmask_loss: 7.9178 Lr: 0.00044
[2025-12-10 17:00:16,586 INFO misc.py line 117 4140988] Train: [1/10][247/7400] Data 0.004 (0.004) Batch 0.597 (0.611) Remain 12:31:26 loss: 7.9423 mask_loss: 7.5373 roll_mask_loss: 7.8698 density_loss: 8.4371 unmask_loss: 8.0124 Lr: 0.00044
[2025-12-10 17:00:17,204 INFO misc.py line 117 4140988] Train: [1/10][248/7400] Data 0.004 (0.004) Batch 0.618 (0.611) Remain 12:31:28 loss: 7.9542 mask_loss: 7.6338 roll_mask_loss: 7.8367 density_loss: 8.1953 unmask_loss: 8.0092 Lr: 0.00044
[2025-12-10 17:00:17,512 INFO misc.py line 117 4140988] Train: [1/10][249/7400] Data 0.004 (0.004) Batch 0.309 (0.610) Remain 12:29:56 loss: 8.4353 mask_loss: 8.1969 roll_mask_loss: 8.4995 density_loss: 8.3993 unmask_loss: 8.3545 Lr: 0.00044
[2025-12-10 17:00:18,277 INFO misc.py line 117 4140988] Train: [1/10][250/7400] Data 0.004 (0.004) Batch 0.765 (0.611) Remain 12:30:42 loss: 7.8759 mask_loss: 7.5032 roll_mask_loss: 7.7778 density_loss: 8.3319 unmask_loss: 7.9446 Lr: 0.00044
[2025-12-10 17:00:19,089 INFO misc.py line 117 4140988] Train: [1/10][251/7400] Data 0.004 (0.004) Batch 0.812 (0.612) Remain 12:31:41 loss: 7.9035 mask_loss: 7.5286 roll_mask_loss: 7.8457 density_loss: 8.4995 unmask_loss: 7.9498 Lr: 0.00044
[2025-12-10 17:00:19,747 INFO misc.py line 117 4140988] Train: [1/10][252/7400] Data 0.004 (0.004) Batch 0.659 (0.612) Remain 12:31:54 loss: 8.1044 mask_loss: 7.7486 roll_mask_loss: 8.0599 density_loss: 8.3685 unmask_loss: 8.1372 Lr: 0.00044
[2025-12-10 17:00:20,271 INFO misc.py line 117 4140988] Train: [1/10][253/7400] Data 0.004 (0.004) Batch 0.524 (0.611) Remain 12:31:28 loss: 8.0249 mask_loss: 7.6604 roll_mask_loss: 7.9689 density_loss: 8.6023 unmask_loss: 8.0630 Lr: 0.00044
[2025-12-10 17:00:20,872 INFO misc.py line 117 4140988] Train: [1/10][254/7400] Data 0.004 (0.004) Batch 0.601 (0.611) Remain 12:31:24 loss: 8.0872 mask_loss: 7.6920 roll_mask_loss: 8.0585 density_loss: 8.5824 unmask_loss: 8.1274 Lr: 0.00044
[2025-12-10 17:00:21,490 INFO misc.py line 117 4140988] Train: [1/10][255/7400] Data 0.004 (0.004) Batch 0.618 (0.611) Remain 12:31:25 loss: 8.2297 mask_loss: 7.8994 roll_mask_loss: 8.2016 density_loss: 8.3753 unmask_loss: 8.2414 Lr: 0.00044
[2025-12-10 17:00:22,171 INFO misc.py line 117 4140988] Train: [1/10][256/7400] Data 0.004 (0.004) Batch 0.681 (0.612) Remain 12:31:45 loss: 8.0363 mask_loss: 7.6589 roll_mask_loss: 8.0054 density_loss: 8.7159 unmask_loss: 8.0661 Lr: 0.00044
[2025-12-10 17:00:22,783 INFO misc.py line 117 4140988] Train: [1/10][257/7400] Data 0.004 (0.004) Batch 0.612 (0.612) Remain 12:31:44 loss: 7.9769 mask_loss: 7.6238 roll_mask_loss: 7.8802 density_loss: 8.5222 unmask_loss: 8.0314 Lr: 0.00044
[2025-12-10 17:00:23,352 INFO misc.py line 117 4140988] Train: [1/10][258/7400] Data 0.004 (0.004) Batch 0.569 (0.611) Remain 12:31:32 loss: 8.2087 mask_loss: 7.9079 roll_mask_loss: 8.1748 density_loss: 8.4158 unmask_loss: 8.2076 Lr: 0.00044
[2025-12-10 17:00:23,794 INFO misc.py line 117 4140988] Train: [1/10][259/7400] Data 0.004 (0.004) Batch 0.442 (0.611) Remain 12:30:42 loss: 8.0335 mask_loss: 7.6890 roll_mask_loss: 7.9717 density_loss: 8.1228 unmask_loss: 8.0741 Lr: 0.00044
[2025-12-10 17:00:24,382 INFO misc.py line 117 4140988] Train: [1/10][260/7400] Data 0.003 (0.004) Batch 0.589 (0.611) Remain 12:30:35 loss: 8.0644 mask_loss: 7.7778 roll_mask_loss: 8.1194 density_loss: 8.4842 unmask_loss: 8.0105 Lr: 0.00044
[2025-12-10 17:00:25,051 INFO misc.py line 117 4140988] Train: [1/10][261/7400] Data 0.003 (0.004) Batch 0.668 (0.611) Remain 12:30:51 loss: 7.9231 mask_loss: 7.6028 roll_mask_loss: 7.8837 density_loss: 8.5704 unmask_loss: 7.9314 Lr: 0.00044
[2025-12-10 17:00:25,582 INFO misc.py line 117 4140988] Train: [1/10][262/7400] Data 0.004 (0.004) Batch 0.532 (0.611) Remain 12:30:28 loss: 8.3194 mask_loss: 8.0201 roll_mask_loss: 8.3368 density_loss: 8.4627 unmask_loss: 8.2911 Lr: 0.00044
[2025-12-10 17:00:26,343 INFO misc.py line 117 4140988] Train: [1/10][263/7400] Data 0.004 (0.004) Batch 0.761 (0.611) Remain 12:31:10 loss: 7.9471 mask_loss: 7.5943 roll_mask_loss: 7.9271 density_loss: 8.5471 unmask_loss: 7.9627 Lr: 0.00044
[2025-12-10 17:00:27,022 INFO misc.py line 117 4140988] Train: [1/10][264/7400] Data 0.004 (0.004) Batch 0.678 (0.611) Remain 12:31:28 loss: 8.3617 mask_loss: 7.8099 roll_mask_loss: 8.5776 density_loss: 8.1945 unmask_loss: 8.3658 Lr: 0.00044
[2025-12-10 17:00:27,507 INFO misc.py line 117 4140988] Train: [1/10][265/7400] Data 0.004 (0.004) Batch 0.486 (0.611) Remain 12:30:52 loss: 7.9423 mask_loss: 7.6537 roll_mask_loss: 7.8327 density_loss: 8.5436 unmask_loss: 7.9705 Lr: 0.00044
[2025-12-10 17:00:28,219 INFO misc.py line 117 4140988] Train: [1/10][266/7400] Data 0.004 (0.004) Batch 0.711 (0.611) Remain 12:31:20 loss: 7.9273 mask_loss: 7.5498 roll_mask_loss: 7.8705 density_loss: 8.5229 unmask_loss: 7.9739 Lr: 0.00045
[2025-12-10 17:00:28,916 INFO misc.py line 117 4140988] Train: [1/10][267/7400] Data 0.004 (0.004) Batch 0.697 (0.612) Remain 12:31:43 loss: 8.0084 mask_loss: 7.6414 roll_mask_loss: 8.1905 density_loss: 8.5202 unmask_loss: 7.9305 Lr: 0.00045
[2025-12-10 17:00:29,620 INFO misc.py line 117 4140988] Train: [1/10][268/7400] Data 0.004 (0.004) Batch 0.704 (0.612) Remain 12:32:08 loss: 7.8963 mask_loss: 7.5823 roll_mask_loss: 7.8111 density_loss: 8.1845 unmask_loss: 7.9322 Lr: 0.00045
[2025-12-10 17:00:30,334 INFO misc.py line 117 4140988] Train: [1/10][269/7400] Data 0.004 (0.004) Batch 0.715 (0.612) Remain 12:32:36 loss: 7.9387 mask_loss: 7.5893 roll_mask_loss: 7.8513 density_loss: 8.2833 unmask_loss: 7.9914 Lr: 0.00045
[2025-12-10 17:00:31,093 INFO misc.py line 117 4140988] Train: [1/10][270/7400] Data 0.004 (0.004) Batch 0.758 (0.613) Remain 12:33:15 loss: 7.9178 mask_loss: 7.6107 roll_mask_loss: 7.8474 density_loss: 8.3855 unmask_loss: 7.9388 Lr: 0.00045
[2025-12-10 17:00:31,777 INFO misc.py line 117 4140988] Train: [1/10][271/7400] Data 0.004 (0.004) Batch 0.684 (0.613) Remain 12:33:35 loss: 7.9818 mask_loss: 7.6709 roll_mask_loss: 7.9314 density_loss: 8.4768 unmask_loss: 7.9928 Lr: 0.00045
[2025-12-10 17:00:32,455 INFO misc.py line 117 4140988] Train: [1/10][272/7400] Data 0.003 (0.004) Batch 0.679 (0.614) Remain 12:33:52 loss: 8.0209 mask_loss: 7.4946 roll_mask_loss: 8.3112 density_loss: 8.5848 unmask_loss: 7.9672 Lr: 0.00045
[2025-12-10 17:00:33,107 INFO misc.py line 117 4140988] Train: [1/10][273/7400] Data 0.003 (0.004) Batch 0.651 (0.614) Remain 12:34:02 loss: 7.8911 mask_loss: 7.4745 roll_mask_loss: 7.9429 density_loss: 8.4484 unmask_loss: 7.9045 Lr: 0.00045
[2025-12-10 17:00:33,872 INFO misc.py line 117 4140988] Train: [1/10][274/7400] Data 0.004 (0.004) Batch 0.765 (0.614) Remain 12:34:42 loss: 7.8467 mask_loss: 7.4663 roll_mask_loss: 7.7253 density_loss: 8.6153 unmask_loss: 7.9254 Lr: 0.00045
[2025-12-10 17:00:34,401 INFO misc.py line 117 4140988] Train: [1/10][275/7400] Data 0.003 (0.004) Batch 0.529 (0.614) Remain 12:34:18 loss: 8.4933 mask_loss: 8.2184 roll_mask_loss: 8.4744 density_loss: 8.4975 unmask_loss: 8.4703 Lr: 0.00045
[2025-12-10 17:00:34,956 INFO misc.py line 117 4140988] Train: [1/10][276/7400] Data 0.003 (0.004) Batch 0.555 (0.614) Remain 12:34:02 loss: 8.4056 mask_loss: 8.1399 roll_mask_loss: 8.4060 density_loss: 8.4722 unmask_loss: 8.3689 Lr: 0.00045
[2025-12-10 17:00:35,754 INFO misc.py line 117 4140988] Train: [1/10][277/7400] Data 0.003 (0.004) Batch 0.797 (0.614) Remain 12:34:51 loss: 7.9349 mask_loss: 7.5880 roll_mask_loss: 7.9244 density_loss: 8.2587 unmask_loss: 7.9483 Lr: 0.00045
[2025-12-10 17:00:36,421 INFO misc.py line 117 4140988] Train: [1/10][278/7400] Data 0.004 (0.004) Batch 0.668 (0.615) Remain 12:35:04 loss: 8.0022 mask_loss: 7.5483 roll_mask_loss: 8.1182 density_loss: 8.3663 unmask_loss: 8.0037 Lr: 0.00045
[2025-12-10 17:00:36,983 INFO misc.py line 117 4140988] Train: [1/10][279/7400] Data 0.004 (0.004) Batch 0.562 (0.614) Remain 12:34:50 loss: 8.1427 mask_loss: 7.6858 roll_mask_loss: 8.2333 density_loss: 8.4116 unmask_loss: 8.1576 Lr: 0.00045
[2025-12-10 17:00:37,570 INFO misc.py line 117 4140988] Train: [1/10][280/7400] Data 0.004 (0.004) Batch 0.587 (0.614) Remain 12:34:42 loss: 7.9427 mask_loss: 7.5104 roll_mask_loss: 7.9033 density_loss: 8.6988 unmask_loss: 8.0047 Lr: 0.00045
[2025-12-10 17:00:38,093 INFO misc.py line 117 4140988] Train: [1/10][281/7400] Data 0.004 (0.004) Batch 0.523 (0.614) Remain 12:34:17 loss: 8.0096 mask_loss: 7.6096 roll_mask_loss: 8.1172 density_loss: 8.2051 unmask_loss: 7.9917 Lr: 0.00045
[2025-12-10 17:00:38,806 INFO misc.py line 117 4140988] Train: [1/10][282/7400] Data 0.004 (0.004) Batch 0.714 (0.614) Remain 12:34:43 loss: 8.0029 mask_loss: 7.5922 roll_mask_loss: 7.8745 density_loss: 8.3063 unmask_loss: 8.1064 Lr: 0.00045
[2025-12-10 17:00:39,283 INFO misc.py line 117 4140988] Train: [1/10][283/7400] Data 0.003 (0.004) Batch 0.477 (0.614) Remain 12:34:06 loss: 7.9535 mask_loss: 7.6242 roll_mask_loss: 7.9865 density_loss: 8.4343 unmask_loss: 7.9330 Lr: 0.00045
[2025-12-10 17:00:39,944 INFO misc.py line 117 4140988] Train: [1/10][284/7400] Data 0.004 (0.004) Batch 0.660 (0.614) Remain 12:34:17 loss: 7.8507 mask_loss: 7.4538 roll_mask_loss: 7.8072 density_loss: 8.5126 unmask_loss: 7.9006 Lr: 0.00045
[2025-12-10 17:00:40,679 INFO misc.py line 117 4140988] Train: [1/10][285/7400] Data 0.005 (0.004) Batch 0.736 (0.614) Remain 12:34:49 loss: 7.8347 mask_loss: 7.4494 roll_mask_loss: 7.7887 density_loss: 8.3630 unmask_loss: 7.8831 Lr: 0.00045
[2025-12-10 17:00:41,222 INFO misc.py line 117 4140988] Train: [1/10][286/7400] Data 0.004 (0.004) Batch 0.542 (0.614) Remain 12:34:29 loss: 8.0742 mask_loss: 7.8075 roll_mask_loss: 7.9855 density_loss: 8.3300 unmask_loss: 8.0852 Lr: 0.00045
[2025-12-10 17:00:41,833 INFO misc.py line 117 4140988] Train: [1/10][287/7400] Data 0.004 (0.004) Batch 0.611 (0.614) Remain 12:34:28 loss: 7.9097 mask_loss: 7.5167 roll_mask_loss: 7.8942 density_loss: 8.6136 unmask_loss: 7.9417 Lr: 0.00045
[2025-12-10 17:00:42,546 INFO misc.py line 117 4140988] Train: [1/10][288/7400] Data 0.004 (0.004) Batch 0.713 (0.614) Remain 12:34:53 loss: 7.8351 mask_loss: 7.4807 roll_mask_loss: 7.7233 density_loss: 8.2080 unmask_loss: 7.9040 Lr: 0.00045
[2025-12-10 17:00:43,157 INFO misc.py line 117 4140988] Train: [1/10][289/7400] Data 0.004 (0.004) Batch 0.612 (0.614) Remain 12:34:52 loss: 7.8686 mask_loss: 7.5304 roll_mask_loss: 7.8476 density_loss: 8.5844 unmask_loss: 7.8764 Lr: 0.00045
[2025-12-10 17:00:43,737 INFO misc.py line 117 4140988] Train: [1/10][290/7400] Data 0.003 (0.004) Batch 0.581 (0.614) Remain 12:34:42 loss: 8.0026 mask_loss: 7.6437 roll_mask_loss: 7.9746 density_loss: 8.3403 unmask_loss: 8.0293 Lr: 0.00045
[2025-12-10 17:00:44,258 INFO misc.py line 117 4140988] Train: [1/10][291/7400] Data 0.003 (0.004) Batch 0.520 (0.614) Remain 12:34:18 loss: 8.4316 mask_loss: 8.2131 roll_mask_loss: 8.3940 density_loss: 8.3907 unmask_loss: 8.3918 Lr: 0.00045
[2025-12-10 17:00:44,947 INFO misc.py line 117 4140988] Train: [1/10][292/7400] Data 0.003 (0.004) Batch 0.689 (0.614) Remain 12:34:36 loss: 8.0152 mask_loss: 7.6205 roll_mask_loss: 7.9531 density_loss: 8.3413 unmask_loss: 8.0768 Lr: 0.00045
[2025-12-10 17:00:45,467 INFO misc.py line 117 4140988] Train: [1/10][293/7400] Data 0.003 (0.004) Batch 0.519 (0.614) Remain 12:34:11 loss: 7.8602 mask_loss: 7.4540 roll_mask_loss: 7.7833 density_loss: 8.7324 unmask_loss: 7.9271 Lr: 0.00045
[2025-12-10 17:00:46,113 INFO misc.py line 117 4140988] Train: [1/10][294/7400] Data 0.004 (0.004) Batch 0.646 (0.614) Remain 12:34:19 loss: 8.2584 mask_loss: 7.9332 roll_mask_loss: 8.4110 density_loss: 8.4914 unmask_loss: 8.1750 Lr: 0.00046
[2025-12-10 17:00:46,763 INFO misc.py line 117 4140988] Train: [1/10][295/7400] Data 0.005 (0.004) Batch 0.650 (0.614) Remain 12:34:27 loss: 7.8088 mask_loss: 7.5048 roll_mask_loss: 7.6977 density_loss: 8.2323 unmask_loss: 7.8517 Lr: 0.00046
[2025-12-10 17:00:47,059 INFO misc.py line 117 4140988] Train: [1/10][296/7400] Data 0.004 (0.004) Batch 0.296 (0.613) Remain 12:33:07 loss: 8.2917 mask_loss: 7.7250 roll_mask_loss: 8.0458 density_loss: 8.1947 unmask_loss: 8.5340 Lr: 0.00046
[2025-12-10 17:00:47,573 INFO misc.py line 117 4140988] Train: [1/10][297/7400] Data 0.004 (0.004) Batch 0.513 (0.613) Remain 12:32:41 loss: 8.3478 mask_loss: 8.0775 roll_mask_loss: 8.4578 density_loss: 8.4086 unmask_loss: 8.2598 Lr: 0.00046
[2025-12-10 17:00:48,103 INFO misc.py line 117 4140988] Train: [1/10][298/7400] Data 0.004 (0.004) Batch 0.530 (0.612) Remain 12:32:20 loss: 7.9188 mask_loss: 7.4649 roll_mask_loss: 7.9443 density_loss: 8.4910 unmask_loss: 7.9631 Lr: 0.00046
[2025-12-10 17:00:48,637 INFO misc.py line 117 4140988] Train: [1/10][299/7400] Data 0.004 (0.004) Batch 0.534 (0.612) Remain 12:32:00 loss: 7.8531 mask_loss: 7.4634 roll_mask_loss: 7.8529 density_loss: 8.5840 unmask_loss: 7.8763 Lr: 0.00046
[2025-12-10 17:00:49,360 INFO misc.py line 117 4140988] Train: [1/10][300/7400] Data 0.004 (0.004) Batch 0.724 (0.613) Remain 12:32:27 loss: 7.8177 mask_loss: 7.4391 roll_mask_loss: 7.7451 density_loss: 8.4151 unmask_loss: 7.8750 Lr: 0.00046
[2025-12-10 17:00:49,902 INFO misc.py line 117 4140988] Train: [1/10][301/7400] Data 0.004 (0.004) Batch 0.541 (0.612) Remain 12:32:09 loss: 7.8583 mask_loss: 7.4160 roll_mask_loss: 7.8488 density_loss: 8.6822 unmask_loss: 7.9106 Lr: 0.00046
[2025-12-10 17:00:50,463 INFO misc.py line 117 4140988] Train: [1/10][302/7400] Data 0.004 (0.004) Batch 0.562 (0.612) Remain 12:31:55 loss: 8.1176 mask_loss: 7.6047 roll_mask_loss: 8.3102 density_loss: 8.3441 unmask_loss: 8.1109 Lr: 0.00046
[2025-12-10 17:00:51,220 INFO misc.py line 117 4140988] Train: [1/10][303/7400] Data 0.003 (0.004) Batch 0.757 (0.613) Remain 12:32:30 loss: 7.8073 mask_loss: 7.3923 roll_mask_loss: 7.6720 density_loss: 8.3864 unmask_loss: 7.9148 Lr: 0.00046
[2025-12-10 17:00:51,895 INFO misc.py line 117 4140988] Train: [1/10][304/7400] Data 0.004 (0.004) Batch 0.675 (0.613) Remain 12:32:45 loss: 8.0510 mask_loss: 7.6915 roll_mask_loss: 8.2272 density_loss: 8.4657 unmask_loss: 7.9733 Lr: 0.00046
[2025-12-10 17:00:52,538 INFO misc.py line 117 4140988] Train: [1/10][305/7400] Data 0.004 (0.004) Batch 0.642 (0.613) Remain 12:32:52 loss: 7.7826 mask_loss: 7.4592 roll_mask_loss: 7.6719 density_loss: 8.5467 unmask_loss: 7.8288 Lr: 0.00046
[2025-12-10 17:00:52,843 INFO misc.py line 117 4140988] Train: [1/10][306/7400] Data 0.004 (0.004) Batch 0.306 (0.612) Remain 12:31:36 loss: 8.4213 mask_loss: 8.2727 roll_mask_loss: 8.3513 density_loss: 8.3427 unmask_loss: 8.3638 Lr: 0.00046
[2025-12-10 17:00:53,554 INFO misc.py line 117 4140988] Train: [1/10][307/7400] Data 0.004 (0.004) Batch 0.711 (0.612) Remain 12:32:00 loss: 7.9442 mask_loss: 7.5670 roll_mask_loss: 7.8932 density_loss: 8.3823 unmask_loss: 7.9907 Lr: 0.00046
[2025-12-10 17:00:54,157 INFO misc.py line 117 4140988] Train: [1/10][308/7400] Data 0.004 (0.004) Batch 0.603 (0.612) Remain 12:31:57 loss: 7.9157 mask_loss: 7.4355 roll_mask_loss: 7.8685 density_loss: 8.4032 unmask_loss: 8.0113 Lr: 0.00046
[2025-12-10 17:00:54,861 INFO misc.py line 117 4140988] Train: [1/10][309/7400] Data 0.004 (0.004) Batch 0.704 (0.613) Remain 12:32:18 loss: 7.8451 mask_loss: 7.4246 roll_mask_loss: 7.8395 density_loss: 8.5266 unmask_loss: 7.8876 Lr: 0.00046
[2025-12-10 17:00:55,462 INFO misc.py line 117 4140988] Train: [1/10][310/7400] Data 0.004 (0.004) Batch 0.601 (0.613) Remain 12:32:15 loss: 7.8354 mask_loss: 7.4836 roll_mask_loss: 7.7005 density_loss: 8.5231 unmask_loss: 7.9084 Lr: 0.00046
[2025-12-10 17:00:56,156 INFO misc.py line 117 4140988] Train: [1/10][311/7400] Data 0.003 (0.004) Batch 0.693 (0.613) Remain 12:32:34 loss: 7.8127 mask_loss: 7.4123 roll_mask_loss: 7.8044 density_loss: 8.3613 unmask_loss: 7.8499 Lr: 0.00046
[2025-12-10 17:00:56,785 INFO misc.py line 117 4140988] Train: [1/10][312/7400] Data 0.005 (0.004) Batch 0.630 (0.613) Remain 12:32:37 loss: 7.8062 mask_loss: 7.3876 roll_mask_loss: 7.7249 density_loss: 8.5435 unmask_loss: 7.8853 Lr: 0.00046
[2025-12-10 17:00:57,620 INFO misc.py line 117 4140988] Train: [1/10][313/7400] Data 0.004 (0.004) Batch 0.835 (0.614) Remain 12:33:29 loss: 8.0252 mask_loss: 7.4836 roll_mask_loss: 8.0662 density_loss: 8.5169 unmask_loss: 8.1052 Lr: 0.00046
[2025-12-10 17:00:58,267 INFO misc.py line 117 4140988] Train: [1/10][314/7400] Data 0.004 (0.004) Batch 0.647 (0.614) Remain 12:33:36 loss: 7.8295 mask_loss: 7.4181 roll_mask_loss: 7.7285 density_loss: 8.6402 unmask_loss: 7.9129 Lr: 0.00046
[2025-12-10 17:00:58,875 INFO misc.py line 117 4140988] Train: [1/10][315/7400] Data 0.004 (0.004) Batch 0.608 (0.614) Remain 12:33:34 loss: 7.9507 mask_loss: 7.6075 roll_mask_loss: 7.9338 density_loss: 8.0871 unmask_loss: 7.9691 Lr: 0.00046
[2025-12-10 17:00:59,604 INFO misc.py line 117 4140988] Train: [1/10][316/7400] Data 0.004 (0.004) Batch 0.729 (0.614) Remain 12:34:01 loss: 7.8937 mask_loss: 7.3937 roll_mask_loss: 7.9305 density_loss: 8.3950 unmask_loss: 7.9573 Lr: 0.00046
[2025-12-10 17:01:00,340 INFO misc.py line 117 4140988] Train: [1/10][317/7400] Data 0.004 (0.004) Batch 0.734 (0.614) Remain 12:34:29 loss: 7.8194 mask_loss: 7.3858 roll_mask_loss: 7.8074 density_loss: 8.6242 unmask_loss: 7.8696 Lr: 0.00046
[2025-12-10 17:01:00,938 INFO misc.py line 117 4140988] Train: [1/10][318/7400] Data 0.005 (0.004) Batch 0.600 (0.614) Remain 12:34:25 loss: 7.9563 mask_loss: 7.7243 roll_mask_loss: 8.0088 density_loss: 8.4707 unmask_loss: 7.8765 Lr: 0.00046
[2025-12-10 17:01:01,471 INFO misc.py line 117 4140988] Train: [1/10][319/7400] Data 0.004 (0.004) Batch 0.534 (0.614) Remain 12:34:05 loss: 8.0465 mask_loss: 7.6898 roll_mask_loss: 7.9862 density_loss: 8.9350 unmask_loss: 8.0763 Lr: 0.00046
[2025-12-10 17:01:02,130 INFO misc.py line 117 4140988] Train: [1/10][320/7400] Data 0.003 (0.004) Batch 0.658 (0.614) Remain 12:34:15 loss: 8.1418 mask_loss: 7.7583 roll_mask_loss: 8.4665 density_loss: 8.2278 unmask_loss: 8.0066 Lr: 0.00047
[2025-12-10 17:01:02,837 INFO misc.py line 117 4140988] Train: [1/10][321/7400] Data 0.004 (0.004) Batch 0.706 (0.615) Remain 12:34:36 loss: 7.8796 mask_loss: 7.4739 roll_mask_loss: 7.8522 density_loss: 8.9388 unmask_loss: 7.9174 Lr: 0.00047
[2025-12-10 17:01:03,359 INFO misc.py line 117 4140988] Train: [1/10][322/7400] Data 0.004 (0.004) Batch 0.522 (0.614) Remain 12:34:14 loss: 8.4872 mask_loss: 7.9312 roll_mask_loss: 8.6404 density_loss: 8.3680 unmask_loss: 8.5212 Lr: 0.00047
[2025-12-10 17:01:03,825 INFO misc.py line 117 4140988] Train: [1/10][323/7400] Data 0.004 (0.004) Batch 0.467 (0.614) Remain 12:33:39 loss: 8.3814 mask_loss: 8.1167 roll_mask_loss: 8.3421 density_loss: 8.3944 unmask_loss: 8.3654 Lr: 0.00047
[2025-12-10 17:01:04,372 INFO misc.py line 117 4140988] Train: [1/10][324/7400] Data 0.004 (0.004) Batch 0.546 (0.614) Remain 12:33:23 loss: 8.2822 mask_loss: 8.1395 roll_mask_loss: 8.1976 density_loss: 8.4834 unmask_loss: 8.2262 Lr: 0.00047
[2025-12-10 17:01:05,029 INFO misc.py line 117 4140988] Train: [1/10][325/7400] Data 0.004 (0.004) Batch 0.658 (0.614) Remain 12:33:33 loss: 7.9955 mask_loss: 7.6231 roll_mask_loss: 8.0684 density_loss: 8.5562 unmask_loss: 7.9741 Lr: 0.00047
[2025-12-10 17:01:05,701 INFO misc.py line 117 4140988] Train: [1/10][326/7400] Data 0.003 (0.004) Batch 0.671 (0.614) Remain 12:33:45 loss: 7.9070 mask_loss: 7.5712 roll_mask_loss: 7.8767 density_loss: 8.3896 unmask_loss: 7.9223 Lr: 0.00047
[2025-12-10 17:01:06,225 INFO misc.py line 117 4140988] Train: [1/10][327/7400] Data 0.004 (0.004) Batch 0.524 (0.614) Remain 12:33:24 loss: 7.9122 mask_loss: 7.5387 roll_mask_loss: 7.8412 density_loss: 8.1999 unmask_loss: 7.9704 Lr: 0.00047
[2025-12-10 17:01:06,818 INFO misc.py line 117 4140988] Train: [1/10][328/7400] Data 0.004 (0.004) Batch 0.594 (0.614) Remain 12:33:19 loss: 8.1567 mask_loss: 7.6906 roll_mask_loss: 8.2764 density_loss: 8.3082 unmask_loss: 8.1637 Lr: 0.00047
[2025-12-10 17:01:07,278 INFO misc.py line 117 4140988] Train: [1/10][329/7400] Data 0.003 (0.004) Batch 0.459 (0.613) Remain 12:32:43 loss: 8.2080 mask_loss: 7.8281 roll_mask_loss: 8.1479 density_loss: 8.5212 unmask_loss: 8.2575 Lr: 0.00047
[2025-12-10 17:01:08,007 INFO misc.py line 117 4140988] Train: [1/10][330/7400] Data 0.004 (0.004) Batch 0.730 (0.613) Remain 12:33:09 loss: 7.8082 mask_loss: 7.4457 roll_mask_loss: 7.7636 density_loss: 8.1452 unmask_loss: 7.8488 Lr: 0.00047
[2025-12-10 17:01:08,591 INFO misc.py line 117 4140988] Train: [1/10][331/7400] Data 0.003 (0.004) Batch 0.583 (0.613) Remain 12:33:02 loss: 8.0875 mask_loss: 7.7128 roll_mask_loss: 8.0054 density_loss: 8.7934 unmask_loss: 8.1400 Lr: 0.00047
[2025-12-10 17:01:09,273 INFO misc.py line 117 4140988] Train: [1/10][332/7400] Data 0.003 (0.004) Batch 0.682 (0.614) Remain 12:33:17 loss: 7.8127 mask_loss: 7.3828 roll_mask_loss: 7.7530 density_loss: 8.7713 unmask_loss: 7.8821 Lr: 0.00047
[2025-12-10 17:01:09,939 INFO misc.py line 117 4140988] Train: [1/10][333/7400] Data 0.003 (0.004) Batch 0.666 (0.614) Remain 12:33:28 loss: 7.7505 mask_loss: 7.3723 roll_mask_loss: 7.6631 density_loss: 8.1210 unmask_loss: 7.8209 Lr: 0.00047
[2025-12-10 17:01:10,650 INFO misc.py line 117 4140988] Train: [1/10][334/7400] Data 0.004 (0.004) Batch 0.712 (0.614) Remain 12:33:49 loss: 7.8985 mask_loss: 7.5409 roll_mask_loss: 7.8525 density_loss: 8.5072 unmask_loss: 7.9302 Lr: 0.00047
[2025-12-10 17:01:11,421 INFO misc.py line 117 4140988] Train: [1/10][335/7400] Data 0.003 (0.004) Batch 0.771 (0.614) Remain 12:34:23 loss: 7.9251 mask_loss: 7.4855 roll_mask_loss: 7.9550 density_loss: 8.3808 unmask_loss: 7.9623 Lr: 0.00047
[2025-12-10 17:01:12,183 INFO misc.py line 117 4140988] Train: [1/10][336/7400] Data 0.003 (0.004) Batch 0.762 (0.615) Remain 12:34:55 loss: 7.7908 mask_loss: 7.3448 roll_mask_loss: 7.7283 density_loss: 8.8367 unmask_loss: 7.8684 Lr: 0.00047
[2025-12-10 17:01:12,835 INFO misc.py line 117 4140988] Train: [1/10][337/7400] Data 0.003 (0.004) Batch 0.651 (0.615) Remain 12:35:02 loss: 7.8561 mask_loss: 7.5287 roll_mask_loss: 7.8008 density_loss: 8.2199 unmask_loss: 7.8831 Lr: 0.00047
[2025-12-10 17:01:13,555 INFO misc.py line 117 4140988] Train: [1/10][338/7400] Data 0.004 (0.004) Batch 0.720 (0.615) Remain 12:35:25 loss: 7.7158 mask_loss: 7.3218 roll_mask_loss: 7.6072 density_loss: 8.0155 unmask_loss: 7.8068 Lr: 0.00047
[2025-12-10 17:01:14,255 INFO misc.py line 117 4140988] Train: [1/10][339/7400] Data 0.004 (0.004) Batch 0.700 (0.616) Remain 12:35:43 loss: 8.0081 mask_loss: 7.5358 roll_mask_loss: 7.8669 density_loss: 8.7709 unmask_loss: 8.1394 Lr: 0.00047
[2025-12-10 17:01:14,818 INFO misc.py line 117 4140988] Train: [1/10][340/7400] Data 0.004 (0.004) Batch 0.563 (0.615) Remain 12:35:31 loss: 8.6497 mask_loss: 8.4234 roll_mask_loss: 8.6435 density_loss: 8.5994 unmask_loss: 8.5940 Lr: 0.00047
[2025-12-10 17:01:15,234 INFO misc.py line 117 4140988] Train: [1/10][341/7400] Data 0.004 (0.004) Batch 0.416 (0.615) Remain 12:34:47 loss: 8.1456 mask_loss: 7.6871 roll_mask_loss: 7.9201 density_loss: 8.7748 unmask_loss: 8.3122 Lr: 0.00047
[2025-12-10 17:01:16,029 INFO misc.py line 117 4140988] Train: [1/10][342/7400] Data 0.004 (0.004) Batch 0.795 (0.615) Remain 12:35:25 loss: 7.7537 mask_loss: 7.3719 roll_mask_loss: 7.6898 density_loss: 8.3821 unmask_loss: 7.8089 Lr: 0.00047
[2025-12-10 17:01:16,851 INFO misc.py line 117 4140988] Train: [1/10][343/7400] Data 0.004 (0.004) Batch 0.822 (0.616) Remain 12:36:09 loss: 7.8043 mask_loss: 7.3608 roll_mask_loss: 7.8012 density_loss: 8.5069 unmask_loss: 7.8575 Lr: 0.00047
[2025-12-10 17:01:17,649 INFO misc.py line 117 4140988] Train: [1/10][344/7400] Data 0.004 (0.004) Batch 0.798 (0.616) Remain 12:36:48 loss: 7.7737 mask_loss: 7.3371 roll_mask_loss: 7.7123 density_loss: 8.5727 unmask_loss: 7.8513 Lr: 0.00048
[2025-12-10 17:01:18,316 INFO misc.py line 117 4140988] Train: [1/10][345/7400] Data 0.004 (0.004) Batch 0.667 (0.617) Remain 12:36:58 loss: 7.8141 mask_loss: 7.3675 roll_mask_loss: 7.9212 density_loss: 8.1516 unmask_loss: 7.8208 Lr: 0.00048
[2025-12-10 17:01:18,763 INFO misc.py line 117 4140988] Train: [1/10][346/7400] Data 0.004 (0.004) Batch 0.448 (0.616) Remain 12:36:22 loss: 8.3056 mask_loss: 7.8962 roll_mask_loss: 8.2748 density_loss: 8.5012 unmask_loss: 8.3556 Lr: 0.00048
[2025-12-10 17:01:19,443 INFO misc.py line 117 4140988] Train: [1/10][347/7400] Data 0.003 (0.004) Batch 0.680 (0.616) Remain 12:36:34 loss: 8.0011 mask_loss: 7.5178 roll_mask_loss: 7.9175 density_loss: 8.6738 unmask_loss: 8.1110 Lr: 0.00048
[2025-12-10 17:01:20,158 INFO misc.py line 117 4140988] Train: [1/10][348/7400] Data 0.003 (0.004) Batch 0.715 (0.617) Remain 12:36:55 loss: 7.8083 mask_loss: 7.4235 roll_mask_loss: 7.7252 density_loss: 8.3443 unmask_loss: 7.8754 Lr: 0.00048
[2025-12-10 17:01:20,710 INFO misc.py line 117 4140988] Train: [1/10][349/7400] Data 0.003 (0.004) Batch 0.551 (0.616) Remain 12:36:41 loss: 8.4458 mask_loss: 8.2043 roll_mask_loss: 8.4228 density_loss: 8.3904 unmask_loss: 8.4103 Lr: 0.00048
[2025-12-10 17:01:21,400 INFO misc.py line 117 4140988] Train: [1/10][350/7400] Data 0.003 (0.004) Batch 0.690 (0.617) Remain 12:36:56 loss: 7.7990 mask_loss: 7.3393 roll_mask_loss: 7.7408 density_loss: 8.6431 unmask_loss: 7.8851 Lr: 0.00048
[2025-12-10 17:01:21,882 INFO misc.py line 117 4140988] Train: [1/10][351/7400] Data 0.003 (0.004) Batch 0.482 (0.616) Remain 12:36:27 loss: 7.9939 mask_loss: 7.6986 roll_mask_loss: 7.9288 density_loss: 8.0823 unmask_loss: 8.0125 Lr: 0.00048
[2025-12-10 17:01:22,720 INFO misc.py line 117 4140988] Train: [1/10][352/7400] Data 0.003 (0.004) Batch 0.838 (0.617) Remain 12:37:13 loss: 7.8096 mask_loss: 7.3883 roll_mask_loss: 7.7668 density_loss: 8.1980 unmask_loss: 7.8778 Lr: 0.00048
[2025-12-10 17:01:23,294 INFO misc.py line 117 4140988] Train: [1/10][353/7400] Data 0.003 (0.004) Batch 0.573 (0.617) Remain 12:37:03 loss: 8.0315 mask_loss: 7.7475 roll_mask_loss: 8.0384 density_loss: 8.4149 unmask_loss: 8.0018 Lr: 0.00048
[2025-12-10 17:01:24,011 INFO misc.py line 117 4140988] Train: [1/10][354/7400] Data 0.004 (0.004) Batch 0.718 (0.617) Remain 12:37:23 loss: 7.9965 mask_loss: 7.4733 roll_mask_loss: 8.0284 density_loss: 8.5867 unmask_loss: 8.0704 Lr: 0.00048
[2025-12-10 17:01:24,565 INFO misc.py line 117 4140988] Train: [1/10][355/7400] Data 0.004 (0.004) Batch 0.554 (0.617) Remain 12:37:10 loss: 7.7802 mask_loss: 7.4002 roll_mask_loss: 7.6310 density_loss: 8.3200 unmask_loss: 7.8783 Lr: 0.00048
[2025-12-10 17:01:25,376 INFO misc.py line 117 4140988] Train: [1/10][356/7400] Data 0.003 (0.004) Batch 0.810 (0.617) Remain 12:37:50 loss: 7.7535 mask_loss: 7.3193 roll_mask_loss: 7.6407 density_loss: 8.4694 unmask_loss: 7.8575 Lr: 0.00048
[2025-12-10 17:01:25,678 INFO misc.py line 117 4140988] Train: [1/10][357/7400] Data 0.003 (0.004) Batch 0.300 (0.617) Remain 12:36:43 loss: 8.0383 mask_loss: 7.7080 roll_mask_loss: 8.0091 density_loss: 8.0331 unmask_loss: 8.0575 Lr: 0.00048
[2025-12-10 17:01:26,139 INFO misc.py line 117 4140988] Train: [1/10][358/7400] Data 0.005 (0.004) Batch 0.463 (0.616) Remain 12:36:10 loss: 8.1189 mask_loss: 7.8707 roll_mask_loss: 8.1306 density_loss: 8.4007 unmask_loss: 8.0691 Lr: 0.00048
[2025-12-10 17:01:26,887 INFO misc.py line 117 4140988] Train: [1/10][359/7400] Data 0.004 (0.004) Batch 0.748 (0.616) Remain 12:36:37 loss: 7.9591 mask_loss: 7.5159 roll_mask_loss: 7.9918 density_loss: 8.3871 unmask_loss: 7.9965 Lr: 0.00048
[2025-12-10 17:01:27,364 INFO misc.py line 117 4140988] Train: [1/10][360/7400] Data 0.004 (0.004) Batch 0.477 (0.616) Remain 12:36:08 loss: 8.1888 mask_loss: 7.8742 roll_mask_loss: 8.2385 density_loss: 8.5216 unmask_loss: 8.1507 Lr: 0.00048
[2025-12-10 17:01:27,859 INFO misc.py line 117 4140988] Train: [1/10][361/7400] Data 0.004 (0.004) Batch 0.495 (0.616) Remain 12:35:42 loss: 7.8340 mask_loss: 7.5418 roll_mask_loss: 7.7536 density_loss: 8.0308 unmask_loss: 7.8597 Lr: 0.00048
[2025-12-10 17:01:28,365 INFO misc.py line 117 4140988] Train: [1/10][362/7400] Data 0.004 (0.004) Batch 0.506 (0.615) Remain 12:35:19 loss: 7.9200 mask_loss: 7.5429 roll_mask_loss: 7.9010 density_loss: 8.4908 unmask_loss: 7.9483 Lr: 0.00048
[2025-12-10 17:01:28,696 INFO misc.py line 117 4140988] Train: [1/10][363/7400] Data 0.003 (0.004) Batch 0.331 (0.615) Remain 12:34:20 loss: 7.9384 mask_loss: 7.3842 roll_mask_loss: 7.8575 density_loss: 8.7497 unmask_loss: 8.0809 Lr: 0.00048
[2025-12-10 17:01:29,301 INFO misc.py line 117 4140988] Train: [1/10][364/7400] Data 0.003 (0.004) Batch 0.605 (0.615) Remain 12:34:18 loss: 8.0362 mask_loss: 7.6183 roll_mask_loss: 8.0769 density_loss: 8.1837 unmask_loss: 8.0610 Lr: 0.00048
[2025-12-10 17:01:29,811 INFO misc.py line 117 4140988] Train: [1/10][365/7400] Data 0.003 (0.004) Batch 0.510 (0.614) Remain 12:33:56 loss: 8.4385 mask_loss: 8.1447 roll_mask_loss: 8.5375 density_loss: 8.4943 unmask_loss: 8.3661 Lr: 0.00048
[2025-12-10 17:01:30,435 INFO misc.py line 117 4140988] Train: [1/10][366/7400] Data 0.003 (0.004) Batch 0.624 (0.614) Remain 12:33:57 loss: 7.8709 mask_loss: 7.5052 roll_mask_loss: 7.8493 density_loss: 8.1559 unmask_loss: 7.9015 Lr: 0.00049
[2025-12-10 17:01:31,000 INFO misc.py line 117 4140988] Train: [1/10][367/7400] Data 0.003 (0.004) Batch 0.566 (0.614) Remain 12:33:47 loss: 7.8139 mask_loss: 7.4219 roll_mask_loss: 7.7042 density_loss: 8.5090 unmask_loss: 7.8945 Lr: 0.00049
[2025-12-10 17:01:31,794 INFO misc.py line 117 4140988] Train: [1/10][368/7400] Data 0.003 (0.004) Batch 0.794 (0.615) Remain 12:34:22 loss: 7.8108 mask_loss: 7.2689 roll_mask_loss: 7.7093 density_loss: 8.5016 unmask_loss: 7.9625 Lr: 0.00049
[2025-12-10 17:01:32,429 INFO misc.py line 117 4140988] Train: [1/10][369/7400] Data 0.003 (0.004) Batch 0.635 (0.615) Remain 12:34:26 loss: 7.8010 mask_loss: 7.3847 roll_mask_loss: 7.7596 density_loss: 8.4713 unmask_loss: 7.8605 Lr: 0.00049
[2025-12-10 17:01:32,984 INFO misc.py line 117 4140988] Train: [1/10][370/7400] Data 0.004 (0.004) Batch 0.556 (0.615) Remain 12:34:13 loss: 8.3629 mask_loss: 7.9660 roll_mask_loss: 8.4536 density_loss: 8.3980 unmask_loss: 8.3480 Lr: 0.00049
[2025-12-10 17:01:33,654 INFO misc.py line 117 4140988] Train: [1/10][371/7400] Data 0.003 (0.004) Batch 0.670 (0.615) Remain 12:34:23 loss: 7.7041 mask_loss: 7.2933 roll_mask_loss: 7.6143 density_loss: 8.0421 unmask_loss: 7.7937 Lr: 0.00049
[2025-12-10 17:01:34,351 INFO misc.py line 117 4140988] Train: [1/10][372/7400] Data 0.004 (0.004) Batch 0.697 (0.615) Remain 12:34:39 loss: 7.7928 mask_loss: 7.2980 roll_mask_loss: 7.7066 density_loss: 8.7521 unmask_loss: 7.9083 Lr: 0.00049
[2025-12-10 17:01:34,855 INFO misc.py line 117 4140988] Train: [1/10][373/7400] Data 0.003 (0.004) Batch 0.503 (0.615) Remain 12:34:16 loss: 7.8313 mask_loss: 7.4238 roll_mask_loss: 7.6961 density_loss: 8.6534 unmask_loss: 7.9295 Lr: 0.00049
[2025-12-10 17:01:35,496 INFO misc.py line 117 4140988] Train: [1/10][374/7400] Data 0.004 (0.004) Batch 0.641 (0.615) Remain 12:34:21 loss: 7.7533 mask_loss: 7.2630 roll_mask_loss: 7.7085 density_loss: 7.9933 unmask_loss: 7.8609 Lr: 0.00049
[2025-12-10 17:01:35,992 INFO misc.py line 117 4140988] Train: [1/10][375/7400] Data 0.004 (0.004) Batch 0.496 (0.614) Remain 12:33:57 loss: 8.0798 mask_loss: 7.7060 roll_mask_loss: 8.1356 density_loss: 8.6544 unmask_loss: 8.0657 Lr: 0.00049
[2025-12-10 17:01:36,641 INFO misc.py line 117 4140988] Train: [1/10][376/7400] Data 0.004 (0.004) Batch 0.649 (0.615) Remain 12:34:03 loss: 7.8392 mask_loss: 7.4519 roll_mask_loss: 7.8757 density_loss: 8.4792 unmask_loss: 7.8451 Lr: 0.00049
[2025-12-10 17:01:37,306 INFO misc.py line 117 4140988] Train: [1/10][377/7400] Data 0.004 (0.004) Batch 0.664 (0.615) Remain 12:34:12 loss: 7.8628 mask_loss: 7.4728 roll_mask_loss: 7.7781 density_loss: 8.8671 unmask_loss: 7.9229 Lr: 0.00049
[2025-12-10 17:01:37,951 INFO misc.py line 117 4140988] Train: [1/10][378/7400] Data 0.004 (0.004) Batch 0.645 (0.615) Remain 12:34:18 loss: 7.9077 mask_loss: 7.5794 roll_mask_loss: 7.9062 density_loss: 8.6155 unmask_loss: 7.9002 Lr: 0.00049
[2025-12-10 17:01:38,399 INFO misc.py line 117 4140988] Train: [1/10][379/7400] Data 0.004 (0.004) Batch 0.448 (0.614) Remain 12:33:44 loss: 7.8582 mask_loss: 7.4570 roll_mask_loss: 7.8113 density_loss: 8.4915 unmask_loss: 7.9124 Lr: 0.00049
[2025-12-10 17:01:39,089 INFO misc.py line 117 4140988] Train: [1/10][380/7400] Data 0.004 (0.004) Batch 0.690 (0.614) Remain 12:33:59 loss: 7.9080 mask_loss: 7.3727 roll_mask_loss: 7.8708 density_loss: 8.7545 unmask_loss: 8.0191 Lr: 0.00049
[2025-12-10 17:01:39,720 INFO misc.py line 117 4140988] Train: [1/10][381/7400] Data 0.004 (0.004) Batch 0.631 (0.615) Remain 12:34:01 loss: 8.0251 mask_loss: 7.6911 roll_mask_loss: 8.0324 density_loss: 8.6054 unmask_loss: 8.0163 Lr: 0.00049
[2025-12-10 17:01:40,544 INFO misc.py line 117 4140988] Train: [1/10][382/7400] Data 0.004 (0.004) Batch 0.824 (0.615) Remain 12:34:41 loss: 7.7177 mask_loss: 7.2200 roll_mask_loss: 7.6807 density_loss: 8.3858 unmask_loss: 7.8172 Lr: 0.00049
[2025-12-10 17:01:41,109 INFO misc.py line 117 4140988] Train: [1/10][383/7400] Data 0.004 (0.004) Batch 0.565 (0.615) Remain 12:34:31 loss: 7.9323 mask_loss: 7.5306 roll_mask_loss: 7.9446 density_loss: 8.3545 unmask_loss: 7.9600 Lr: 0.00049
[2025-12-10 17:01:41,733 INFO misc.py line 117 4140988] Train: [1/10][384/7400] Data 0.004 (0.004) Batch 0.624 (0.615) Remain 12:34:32 loss: 7.7534 mask_loss: 7.2752 roll_mask_loss: 7.6680 density_loss: 8.3107 unmask_loss: 7.8691 Lr: 0.00049
[2025-12-10 17:01:42,353 INFO misc.py line 117 4140988] Train: [1/10][385/7400] Data 0.004 (0.004) Batch 0.620 (0.615) Remain 12:34:33 loss: 7.9367 mask_loss: 7.5108 roll_mask_loss: 7.8696 density_loss: 8.5828 unmask_loss: 8.0116 Lr: 0.00049
[2025-12-10 17:01:42,965 INFO misc.py line 117 4140988] Train: [1/10][386/7400] Data 0.004 (0.004) Batch 0.612 (0.615) Remain 12:34:32 loss: 7.6773 mask_loss: 7.2867 roll_mask_loss: 7.5562 density_loss: 8.0477 unmask_loss: 7.7723 Lr: 0.00049
[2025-12-10 17:01:43,698 INFO misc.py line 117 4140988] Train: [1/10][387/7400] Data 0.003 (0.004) Batch 0.733 (0.615) Remain 12:34:53 loss: 7.7350 mask_loss: 7.2442 roll_mask_loss: 7.6221 density_loss: 8.5052 unmask_loss: 7.8667 Lr: 0.00050
[2025-12-10 17:01:44,255 INFO misc.py line 117 4140988] Train: [1/10][388/7400] Data 0.003 (0.004) Batch 0.557 (0.615) Remain 12:34:42 loss: 8.2407 mask_loss: 7.9329 roll_mask_loss: 8.2469 density_loss: 8.3443 unmask_loss: 8.2246 Lr: 0.00050
[2025-12-10 17:01:44,711 INFO misc.py line 117 4140988] Train: [1/10][389/7400] Data 0.003 (0.004) Batch 0.457 (0.615) Remain 12:34:11 loss: 8.1248 mask_loss: 7.6717 roll_mask_loss: 8.3095 density_loss: 8.4594 unmask_loss: 8.0898 Lr: 0.00050
[2025-12-10 17:01:45,122 INFO misc.py line 117 4140988] Train: [1/10][390/7400] Data 0.003 (0.004) Batch 0.410 (0.614) Remain 12:33:31 loss: 8.1132 mask_loss: 7.7869 roll_mask_loss: 8.0370 density_loss: 8.3699 unmask_loss: 8.1470 Lr: 0.00050
[2025-12-10 17:01:45,665 INFO misc.py line 117 4140988] Train: [1/10][391/7400] Data 0.004 (0.004) Batch 0.542 (0.614) Remain 12:33:17 loss: 8.0962 mask_loss: 7.6857 roll_mask_loss: 8.0865 density_loss: 8.6336 unmask_loss: 8.1336 Lr: 0.00050
[2025-12-10 17:01:46,275 INFO misc.py line 117 4140988] Train: [1/10][392/7400] Data 0.004 (0.004) Batch 0.611 (0.614) Remain 12:33:16 loss: 8.4463 mask_loss: 8.1847 roll_mask_loss: 8.3799 density_loss: 8.3820 unmask_loss: 8.4427 Lr: 0.00050
[2025-12-10 17:01:46,612 INFO misc.py line 117 4140988] Train: [1/10][393/7400] Data 0.003 (0.004) Batch 0.337 (0.613) Remain 12:32:23 loss: 7.8582 mask_loss: 7.3683 roll_mask_loss: 7.7636 density_loss: 8.5893 unmask_loss: 7.9787 Lr: 0.00050
[2025-12-10 17:01:47,175 INFO misc.py line 117 4140988] Train: [1/10][394/7400] Data 0.003 (0.004) Batch 0.563 (0.613) Remain 12:32:13 loss: 8.1319 mask_loss: 7.8994 roll_mask_loss: 8.1306 density_loss: 8.3484 unmask_loss: 8.0818 Lr: 0.00050
[2025-12-10 17:01:47,512 INFO misc.py line 117 4140988] Train: [1/10][395/7400] Data 0.003 (0.004) Batch 0.337 (0.612) Remain 12:31:21 loss: 8.0481 mask_loss: 7.6544 roll_mask_loss: 8.0327 density_loss: 8.4256 unmask_loss: 8.0841 Lr: 0.00050
[2025-12-10 17:01:48,316 INFO misc.py line 117 4140988] Train: [1/10][396/7400] Data 0.003 (0.004) Batch 0.802 (0.613) Remain 12:31:55 loss: 7.7969 mask_loss: 7.2187 roll_mask_loss: 7.7485 density_loss: 8.6778 unmask_loss: 7.9365 Lr: 0.00050
[2025-12-10 17:01:48,863 INFO misc.py line 117 4140988] Train: [1/10][397/7400] Data 0.004 (0.004) Batch 0.547 (0.613) Remain 12:31:43 loss: 7.9149 mask_loss: 7.4512 roll_mask_loss: 7.9799 density_loss: 8.1894 unmask_loss: 7.9505 Lr: 0.00050
[2025-12-10 17:01:49,169 INFO misc.py line 117 4140988] Train: [1/10][398/7400] Data 0.004 (0.004) Batch 0.305 (0.612) Remain 12:30:45 loss: 7.9461 mask_loss: 7.5200 roll_mask_loss: 7.7727 density_loss: 8.8389 unmask_loss: 8.0691 Lr: 0.00050
[2025-12-10 17:01:49,795 INFO misc.py line 117 4140988] Train: [1/10][399/7400] Data 0.004 (0.004) Batch 0.627 (0.612) Remain 12:30:47 loss: 7.8385 mask_loss: 7.4766 roll_mask_loss: 7.8541 density_loss: 8.0813 unmask_loss: 7.8500 Lr: 0.00050
[2025-12-10 17:01:50,507 INFO misc.py line 117 4140988] Train: [1/10][400/7400] Data 0.004 (0.004) Batch 0.712 (0.612) Remain 12:31:05 loss: 7.7805 mask_loss: 7.2178 roll_mask_loss: 7.7816 density_loss: 8.2300 unmask_loss: 7.8966 Lr: 0.00050
[2025-12-10 17:01:51,225 INFO misc.py line 117 4140988] Train: [1/10][401/7400] Data 0.003 (0.004) Batch 0.717 (0.613) Remain 12:31:24 loss: 7.7444 mask_loss: 7.4125 roll_mask_loss: 7.6658 density_loss: 8.4060 unmask_loss: 7.7815 Lr: 0.00050
[2025-12-10 17:01:51,852 INFO misc.py line 117 4140988] Train: [1/10][402/7400] Data 0.005 (0.004) Batch 0.627 (0.613) Remain 12:31:26 loss: 7.6957 mask_loss: 7.1750 roll_mask_loss: 7.5490 density_loss: 8.3242 unmask_loss: 7.8629 Lr: 0.00050
[2025-12-10 17:01:52,485 INFO misc.py line 117 4140988] Train: [1/10][403/7400] Data 0.004 (0.004) Batch 0.633 (0.613) Remain 12:31:29 loss: 7.7747 mask_loss: 7.3822 roll_mask_loss: 7.6637 density_loss: 8.2629 unmask_loss: 7.8613 Lr: 0.00050
[2025-12-10 17:01:53,090 INFO misc.py line 117 4140988] Train: [1/10][404/7400] Data 0.004 (0.004) Batch 0.606 (0.613) Remain 12:31:27 loss: 7.8783 mask_loss: 7.5029 roll_mask_loss: 7.8439 density_loss: 8.5468 unmask_loss: 7.9122 Lr: 0.00050
[2025-12-10 17:01:53,576 INFO misc.py line 117 4140988] Train: [1/10][405/7400] Data 0.003 (0.004) Batch 0.486 (0.612) Remain 12:31:03 loss: 8.4358 mask_loss: 8.0485 roll_mask_loss: 8.5739 density_loss: 8.4116 unmask_loss: 8.3922 Lr: 0.00050
[2025-12-10 17:01:54,119 INFO misc.py line 117 4140988] Train: [1/10][406/7400] Data 0.003 (0.004) Batch 0.542 (0.612) Remain 12:30:50 loss: 7.8422 mask_loss: 7.4473 roll_mask_loss: 7.8363 density_loss: 8.8540 unmask_loss: 7.8655 Lr: 0.00050
[2025-12-10 17:01:54,872 INFO misc.py line 117 4140988] Train: [1/10][407/7400] Data 0.004 (0.004) Batch 0.754 (0.612) Remain 12:31:15 loss: 7.7769 mask_loss: 7.3672 roll_mask_loss: 7.7222 density_loss: 8.1572 unmask_loss: 7.8459 Lr: 0.00051
[2025-12-10 17:01:55,627 INFO misc.py line 117 4140988] Train: [1/10][408/7400] Data 0.004 (0.004) Batch 0.755 (0.613) Remain 12:31:40 loss: 7.7823 mask_loss: 7.1976 roll_mask_loss: 7.6901 density_loss: 8.5324 unmask_loss: 7.9502 Lr: 0.00051
[2025-12-10 17:01:56,234 INFO misc.py line 117 4140988] Train: [1/10][409/7400] Data 0.003 (0.004) Batch 0.606 (0.613) Remain 12:31:38 loss: 7.9660 mask_loss: 7.5654 roll_mask_loss: 8.0326 density_loss: 8.6304 unmask_loss: 7.9603 Lr: 0.00051
[2025-12-10 17:01:56,963 INFO misc.py line 117 4140988] Train: [1/10][410/7400] Data 0.004 (0.004) Batch 0.729 (0.613) Remain 12:31:59 loss: 7.9615 mask_loss: 7.6055 roll_mask_loss: 8.0192 density_loss: 8.7914 unmask_loss: 7.9347 Lr: 0.00051
[2025-12-10 17:01:57,494 INFO misc.py line 117 4140988] Train: [1/10][411/7400] Data 0.004 (0.004) Batch 0.531 (0.613) Remain 12:31:43 loss: 7.7157 mask_loss: 7.2326 roll_mask_loss: 7.6990 density_loss: 8.8712 unmask_loss: 7.7882 Lr: 0.00051
[2025-12-10 17:01:58,082 INFO misc.py line 117 4140988] Train: [1/10][412/7400] Data 0.004 (0.004) Batch 0.589 (0.613) Remain 12:31:38 loss: 7.7508 mask_loss: 7.2951 roll_mask_loss: 7.5857 density_loss: 8.2949 unmask_loss: 7.8953 Lr: 0.00051
[2025-12-10 17:01:58,795 INFO misc.py line 117 4140988] Train: [1/10][413/7400] Data 0.004 (0.004) Batch 0.713 (0.613) Remain 12:31:56 loss: 7.6660 mask_loss: 7.1826 roll_mask_loss: 7.5574 density_loss: 8.2842 unmask_loss: 7.7963 Lr: 0.00051
[2025-12-10 17:01:59,302 INFO misc.py line 117 4140988] Train: [1/10][414/7400] Data 0.004 (0.004) Batch 0.507 (0.613) Remain 12:31:36 loss: 7.7045 mask_loss: 7.2836 roll_mask_loss: 7.6698 density_loss: 8.2551 unmask_loss: 7.7672 Lr: 0.00051
[2025-12-10 17:02:00,003 INFO misc.py line 117 4140988] Train: [1/10][415/7400] Data 0.004 (0.004) Batch 0.702 (0.613) Remain 12:31:51 loss: 7.7952 mask_loss: 7.3988 roll_mask_loss: 7.7280 density_loss: 8.3728 unmask_loss: 7.8595 Lr: 0.00051
[2025-12-10 17:02:00,369 INFO misc.py line 117 4140988] Train: [1/10][416/7400] Data 0.003 (0.004) Batch 0.366 (0.612) Remain 12:31:07 loss: 7.7318 mask_loss: 7.1026 roll_mask_loss: 7.6288 density_loss: 8.8712 unmask_loss: 7.9204 Lr: 0.00051
[2025-12-10 17:02:01,055 INFO misc.py line 117 4140988] Train: [1/10][417/7400] Data 0.003 (0.004) Batch 0.685 (0.613) Remain 12:31:19 loss: 7.6999 mask_loss: 7.2804 roll_mask_loss: 7.6029 density_loss: 8.1889 unmask_loss: 7.7944 Lr: 0.00051
[2025-12-10 17:02:01,649 INFO misc.py line 117 4140988] Train: [1/10][418/7400] Data 0.004 (0.004) Batch 0.593 (0.613) Remain 12:31:15 loss: 7.9050 mask_loss: 7.5469 roll_mask_loss: 7.8458 density_loss: 8.2784 unmask_loss: 7.9481 Lr: 0.00051
[2025-12-10 17:02:02,240 INFO misc.py line 117 4140988] Train: [1/10][419/7400] Data 0.004 (0.004) Batch 0.592 (0.613) Remain 12:31:11 loss: 7.7341 mask_loss: 7.3328 roll_mask_loss: 7.7059 density_loss: 8.8654 unmask_loss: 7.7715 Lr: 0.00051
[2025-12-10 17:02:02,938 INFO misc.py line 117 4140988] Train: [1/10][420/7400] Data 0.004 (0.004) Batch 0.697 (0.613) Remain 12:31:25 loss: 7.9724 mask_loss: 7.4128 roll_mask_loss: 8.1009 density_loss: 8.5566 unmask_loss: 8.0168 Lr: 0.00051
[2025-12-10 17:02:03,243 INFO misc.py line 117 4140988] Train: [1/10][421/7400] Data 0.004 (0.004) Batch 0.306 (0.612) Remain 12:30:30 loss: 8.4797 mask_loss: 8.2704 roll_mask_loss: 8.4360 density_loss: 8.3826 unmask_loss: 8.4385 Lr: 0.00051
[2025-12-10 17:02:03,935 INFO misc.py line 117 4140988] Train: [1/10][422/7400] Data 0.004 (0.004) Batch 0.691 (0.612) Remain 12:30:44 loss: 7.7169 mask_loss: 7.2844 roll_mask_loss: 7.7579 density_loss: 8.2205 unmask_loss: 7.7483 Lr: 0.00051
[2025-12-10 17:02:04,689 INFO misc.py line 117 4140988] Train: [1/10][423/7400] Data 0.004 (0.004) Batch 0.755 (0.613) Remain 12:31:08 loss: 7.8395 mask_loss: 7.2016 roll_mask_loss: 7.7501 density_loss: 8.6720 unmask_loss: 8.0298 Lr: 0.00051
[2025-12-10 17:02:05,433 INFO misc.py line 117 4140988] Train: [1/10][424/7400] Data 0.004 (0.004) Batch 0.743 (0.613) Remain 12:31:30 loss: 7.6783 mask_loss: 7.1240 roll_mask_loss: 7.6843 density_loss: 8.6993 unmask_loss: 7.7785 Lr: 0.00051
[2025-12-10 17:02:06,022 INFO misc.py line 117 4140988] Train: [1/10][425/7400] Data 0.004 (0.004) Batch 0.589 (0.613) Remain 12:31:26 loss: 8.0225 mask_loss: 7.6472 roll_mask_loss: 7.9576 density_loss: 8.6352 unmask_loss: 8.0699 Lr: 0.00051
[2025-12-10 17:02:06,675 INFO misc.py line 117 4140988] Train: [1/10][426/7400] Data 0.004 (0.004) Batch 0.653 (0.613) Remain 12:31:32 loss: 7.8212 mask_loss: 7.3747 roll_mask_loss: 7.6734 density_loss: 8.4653 unmask_loss: 7.9490 Lr: 0.00052
[2025-12-10 17:02:07,393 INFO misc.py line 117 4140988] Train: [1/10][427/7400] Data 0.004 (0.004) Batch 0.718 (0.613) Remain 12:31:50 loss: 7.8300 mask_loss: 7.2107 roll_mask_loss: 7.8879 density_loss: 8.6998 unmask_loss: 7.9367 Lr: 0.00052
[2025-12-10 17:02:07,686 INFO misc.py line 117 4140988] Train: [1/10][428/7400] Data 0.004 (0.004) Batch 0.293 (0.612) Remain 12:30:54 loss: 8.4334 mask_loss: 8.1691 roll_mask_loss: 8.4707 density_loss: 8.6642 unmask_loss: 8.3736 Lr: 0.00052
[2025-12-10 17:02:08,285 INFO misc.py line 117 4140988] Train: [1/10][429/7400] Data 0.004 (0.004) Batch 0.598 (0.612) Remain 12:30:51 loss: 7.7067 mask_loss: 7.3410 roll_mask_loss: 7.5826 density_loss: 8.4256 unmask_loss: 7.7830 Lr: 0.00052
[2025-12-10 17:02:08,956 INFO misc.py line 117 4140988] Train: [1/10][430/7400] Data 0.004 (0.004) Batch 0.672 (0.612) Remain 12:31:00 loss: 7.6842 mask_loss: 7.1110 roll_mask_loss: 7.6126 density_loss: 8.9513 unmask_loss: 7.8276 Lr: 0.00052
[2025-12-10 17:02:09,686 INFO misc.py line 117 4140988] Train: [1/10][431/7400] Data 0.004 (0.004) Batch 0.730 (0.613) Remain 12:31:20 loss: 7.6644 mask_loss: 7.1844 roll_mask_loss: 7.6718 density_loss: 8.2408 unmask_loss: 7.7358 Lr: 0.00052
[2025-12-10 17:02:09,976 INFO misc.py line 117 4140988] Train: [1/10][432/7400] Data 0.003 (0.004) Batch 0.290 (0.612) Remain 12:30:24 loss: 7.9759 mask_loss: 7.5602 roll_mask_loss: 7.8495 density_loss: 8.5747 unmask_loss: 8.0756 Lr: 0.00052
[2025-12-10 17:02:10,818 INFO misc.py line 117 4140988] Train: [1/10][433/7400] Data 0.003 (0.004) Batch 0.842 (0.613) Remain 12:31:03 loss: 7.5721 mask_loss: 7.0219 roll_mask_loss: 7.4631 density_loss: 8.7285 unmask_loss: 7.7272 Lr: 0.00052
[2025-12-10 17:02:11,452 INFO misc.py line 117 4140988] Train: [1/10][434/7400] Data 0.004 (0.004) Batch 0.634 (0.613) Remain 12:31:06 loss: 7.6396 mask_loss: 7.1651 roll_mask_loss: 7.5863 density_loss: 8.7875 unmask_loss: 7.7277 Lr: 0.00052
[2025-12-10 17:02:11,979 INFO misc.py line 117 4140988] Train: [1/10][435/7400] Data 0.004 (0.004) Batch 0.528 (0.612) Remain 12:30:50 loss: 7.9240 mask_loss: 7.4358 roll_mask_loss: 7.9047 density_loss: 8.7662 unmask_loss: 8.0024 Lr: 0.00052
[2025-12-10 17:02:12,289 INFO misc.py line 117 4140988] Train: [1/10][436/7400] Data 0.004 (0.004) Batch 0.310 (0.612) Remain 12:29:59 loss: 7.7125 mask_loss: 7.1051 roll_mask_loss: 7.6719 density_loss: 8.9053 unmask_loss: 7.8584 Lr: 0.00052
[2025-12-10 17:02:12,647 INFO misc.py line 117 4140988] Train: [1/10][437/7400] Data 0.004 (0.004) Batch 0.357 (0.611) Remain 12:29:15 loss: 8.0637 mask_loss: 7.6295 roll_mask_loss: 8.0248 density_loss: 8.7823 unmask_loss: 8.1246 Lr: 0.00052
[2025-12-10 17:02:13,207 INFO misc.py line 117 4140988] Train: [1/10][438/7400] Data 0.004 (0.004) Batch 0.560 (0.611) Remain 12:29:06 loss: 7.8050 mask_loss: 7.3652 roll_mask_loss: 7.7776 density_loss: 8.3877 unmask_loss: 7.8708 Lr: 0.00052
[2025-12-10 17:02:13,753 INFO misc.py line 117 4140988] Train: [1/10][439/7400] Data 0.004 (0.004) Batch 0.546 (0.611) Remain 12:28:54 loss: 8.2041 mask_loss: 7.7381 roll_mask_loss: 8.2463 density_loss: 8.4422 unmask_loss: 8.2471 Lr: 0.00052
[2025-12-10 17:02:14,461 INFO misc.py line 117 4140988] Train: [1/10][440/7400] Data 0.004 (0.004) Batch 0.708 (0.611) Remain 12:29:10 loss: 7.6488 mask_loss: 7.1371 roll_mask_loss: 7.5936 density_loss: 8.5533 unmask_loss: 7.7613 Lr: 0.00052
[2025-12-10 17:02:15,094 INFO misc.py line 117 4140988] Train: [1/10][441/7400] Data 0.004 (0.004) Batch 0.633 (0.611) Remain 12:29:13 loss: 7.6987 mask_loss: 7.1344 roll_mask_loss: 7.5809 density_loss: 8.5279 unmask_loss: 7.8692 Lr: 0.00052
[2025-12-10 17:02:15,774 INFO misc.py line 117 4140988] Train: [1/10][442/7400] Data 0.004 (0.004) Batch 0.680 (0.611) Remain 12:29:24 loss: 7.9177 mask_loss: 7.5449 roll_mask_loss: 7.9030 density_loss: 8.5863 unmask_loss: 7.9398 Lr: 0.00052
[2025-12-10 17:02:16,347 INFO misc.py line 117 4140988] Train: [1/10][443/7400] Data 0.004 (0.004) Batch 0.572 (0.611) Remain 12:29:17 loss: 8.4154 mask_loss: 8.2249 roll_mask_loss: 8.4174 density_loss: 8.3990 unmask_loss: 8.3417 Lr: 0.00052
[2025-12-10 17:02:16,949 INFO misc.py line 117 4140988] Train: [1/10][444/7400] Data 0.004 (0.004) Batch 0.603 (0.611) Remain 12:29:15 loss: 7.9832 mask_loss: 7.5676 roll_mask_loss: 8.0276 density_loss: 8.3316 unmask_loss: 8.0021 Lr: 0.00053
[2025-12-10 17:02:17,474 INFO misc.py line 117 4140988] Train: [1/10][445/7400] Data 0.003 (0.004) Batch 0.524 (0.611) Remain 12:29:00 loss: 7.7531 mask_loss: 7.3319 roll_mask_loss: 7.6321 density_loss: 8.1234 unmask_loss: 7.8618 Lr: 0.00053
[2025-12-10 17:02:18,078 INFO misc.py line 117 4140988] Train: [1/10][446/7400] Data 0.004 (0.004) Batch 0.604 (0.611) Remain 12:28:58 loss: 8.0514 mask_loss: 7.6520 roll_mask_loss: 8.0374 density_loss: 8.3851 unmask_loss: 8.0903 Lr: 0.00053
[2025-12-10 17:02:18,806 INFO misc.py line 117 4140988] Train: [1/10][447/7400] Data 0.004 (0.004) Batch 0.728 (0.611) Remain 12:29:17 loss: 7.6867 mask_loss: 7.1477 roll_mask_loss: 7.6571 density_loss: 8.6301 unmask_loss: 7.7984 Lr: 0.00053
[2025-12-10 17:02:19,423 INFO misc.py line 117 4140988] Train: [1/10][448/7400] Data 0.004 (0.004) Batch 0.617 (0.611) Remain 12:29:17 loss: 7.6064 mask_loss: 7.0877 roll_mask_loss: 7.5170 density_loss: 8.4913 unmask_loss: 7.7406 Lr: 0.00053
[2025-12-10 17:02:20,034 INFO misc.py line 117 4140988] Train: [1/10][449/7400] Data 0.003 (0.004) Batch 0.612 (0.611) Remain 12:29:16 loss: 7.6199 mask_loss: 7.0721 roll_mask_loss: 7.6165 density_loss: 8.7737 unmask_loss: 7.7200 Lr: 0.00053
[2025-12-10 17:02:20,753 INFO misc.py line 117 4140988] Train: [1/10][450/7400] Data 0.003 (0.004) Batch 0.718 (0.611) Remain 12:29:33 loss: 7.5867 mask_loss: 7.1038 roll_mask_loss: 7.4502 density_loss: 8.9187 unmask_loss: 7.7181 Lr: 0.00053
[2025-12-10 17:02:21,371 INFO misc.py line 117 4140988] Train: [1/10][451/7400] Data 0.003 (0.004) Batch 0.618 (0.611) Remain 12:29:34 loss: 8.0799 mask_loss: 7.2191 roll_mask_loss: 8.6553 density_loss: 8.5888 unmask_loss: 8.0507 Lr: 0.00053
[2025-12-10 17:02:21,891 INFO misc.py line 117 4140988] Train: [1/10][452/7400] Data 0.003 (0.004) Batch 0.521 (0.611) Remain 12:29:18 loss: 8.1924 mask_loss: 7.8779 roll_mask_loss: 8.1670 density_loss: 8.6888 unmask_loss: 8.1886 Lr: 0.00053
[2025-12-10 17:02:22,488 INFO misc.py line 117 4140988] Train: [1/10][453/7400] Data 0.003 (0.004) Batch 0.596 (0.611) Remain 12:29:15 loss: 8.5134 mask_loss: 8.2759 roll_mask_loss: 8.5605 density_loss: 8.5051 unmask_loss: 8.4385 Lr: 0.00053
[2025-12-10 17:02:23,153 INFO misc.py line 117 4140988] Train: [1/10][454/7400] Data 0.003 (0.004) Batch 0.665 (0.611) Remain 12:29:24 loss: 7.6018 mask_loss: 7.0926 roll_mask_loss: 7.4601 density_loss: 8.2619 unmask_loss: 7.7621 Lr: 0.00053
[2025-12-10 17:02:23,724 INFO misc.py line 117 4140988] Train: [1/10][455/7400] Data 0.004 (0.004) Batch 0.571 (0.611) Remain 12:29:16 loss: 7.8047 mask_loss: 7.3862 roll_mask_loss: 7.7573 density_loss: 8.9465 unmask_loss: 7.8587 Lr: 0.00053
[2025-12-10 17:02:24,490 INFO misc.py line 117 4140988] Train: [1/10][456/7400] Data 0.004 (0.004) Batch 0.766 (0.612) Remain 12:29:41 loss: 7.6484 mask_loss: 7.1757 roll_mask_loss: 7.6414 density_loss: 8.4938 unmask_loss: 7.7183 Lr: 0.00053
[2025-12-10 17:02:25,126 INFO misc.py line 117 4140988] Train: [1/10][457/7400] Data 0.004 (0.004) Batch 0.636 (0.612) Remain 12:29:44 loss: 7.7245 mask_loss: 7.3118 roll_mask_loss: 7.6627 density_loss: 9.0162 unmask_loss: 7.7814 Lr: 0.00053
[2025-12-10 17:02:25,816 INFO misc.py line 117 4140988] Train: [1/10][458/7400] Data 0.004 (0.004) Batch 0.691 (0.612) Remain 12:29:56 loss: 7.7749 mask_loss: 7.3862 roll_mask_loss: 7.7407 density_loss: 7.9876 unmask_loss: 7.8266 Lr: 0.00053
[2025-12-10 17:02:26,458 INFO misc.py line 117 4140988] Train: [1/10][459/7400] Data 0.003 (0.004) Batch 0.641 (0.612) Remain 12:30:00 loss: 7.9038 mask_loss: 7.5308 roll_mask_loss: 7.8563 density_loss: 8.4321 unmask_loss: 7.9454 Lr: 0.00053
[2025-12-10 17:02:27,048 INFO misc.py line 117 4140988] Train: [1/10][460/7400] Data 0.005 (0.004) Batch 0.591 (0.612) Remain 12:29:56 loss: 8.4049 mask_loss: 8.2395 roll_mask_loss: 8.3796 density_loss: 8.3704 unmask_loss: 8.3329 Lr: 0.00053
[2025-12-10 17:02:27,615 INFO misc.py line 117 4140988] Train: [1/10][461/7400] Data 0.004 (0.004) Batch 0.567 (0.612) Remain 12:29:48 loss: 8.3972 mask_loss: 8.0808 roll_mask_loss: 8.4018 density_loss: 8.3749 unmask_loss: 8.3856 Lr: 0.00054
[2025-12-10 17:02:28,220 INFO misc.py line 117 4140988] Train: [1/10][462/7400] Data 0.004 (0.004) Batch 0.605 (0.612) Remain 12:29:47 loss: 8.2403 mask_loss: 7.9686 roll_mask_loss: 8.2565 density_loss: 8.3950 unmask_loss: 8.2001 Lr: 0.00054
[2025-12-10 17:02:28,865 INFO misc.py line 117 4140988] Train: [1/10][463/7400] Data 0.003 (0.004) Batch 0.646 (0.612) Remain 12:29:52 loss: 7.5874 mask_loss: 7.0469 roll_mask_loss: 7.5015 density_loss: 8.3048 unmask_loss: 7.7346 Lr: 0.00054
[2025-12-10 17:02:29,306 INFO misc.py line 117 4140988] Train: [1/10][464/7400] Data 0.003 (0.004) Batch 0.441 (0.611) Remain 12:29:24 loss: 8.1036 mask_loss: 7.7629 roll_mask_loss: 8.1521 density_loss: 8.7411 unmask_loss: 8.0749 Lr: 0.00054
[2025-12-10 17:02:29,996 INFO misc.py line 117 4140988] Train: [1/10][465/7400] Data 0.003 (0.004) Batch 0.688 (0.612) Remain 12:29:35 loss: 7.6679 mask_loss: 7.2142 roll_mask_loss: 7.6177 density_loss: 8.5534 unmask_loss: 7.7489 Lr: 0.00054
[2025-12-10 17:02:30,573 INFO misc.py line 117 4140988] Train: [1/10][466/7400] Data 0.004 (0.004) Batch 0.577 (0.612) Remain 12:29:29 loss: 8.3571 mask_loss: 8.0807 roll_mask_loss: 8.3511 density_loss: 8.3682 unmask_loss: 8.3310 Lr: 0.00054
[2025-12-10 17:02:31,402 INFO misc.py line 117 4140988] Train: [1/10][467/7400] Data 0.003 (0.004) Batch 0.830 (0.612) Remain 12:30:03 loss: 7.6427 mask_loss: 7.2296 roll_mask_loss: 7.5522 density_loss: 8.3082 unmask_loss: 7.7283 Lr: 0.00054
[2025-12-10 17:02:32,027 INFO misc.py line 117 4140988] Train: [1/10][468/7400] Data 0.003 (0.004) Batch 0.626 (0.612) Remain 12:30:05 loss: 7.7752 mask_loss: 7.2867 roll_mask_loss: 7.8968 density_loss: 8.6031 unmask_loss: 7.7866 Lr: 0.00054
[2025-12-10 17:02:32,496 INFO misc.py line 117 4140988] Train: [1/10][469/7400] Data 0.003 (0.004) Batch 0.468 (0.612) Remain 12:29:42 loss: 8.0770 mask_loss: 7.7545 roll_mask_loss: 8.0444 density_loss: 8.5144 unmask_loss: 8.0843 Lr: 0.00054
[2025-12-10 17:02:33,109 INFO misc.py line 117 4140988] Train: [1/10][470/7400] Data 0.004 (0.004) Batch 0.613 (0.612) Remain 12:29:41 loss: 7.7454 mask_loss: 7.3192 roll_mask_loss: 7.7023 density_loss: 9.0259 unmask_loss: 7.7995 Lr: 0.00054
[2025-12-10 17:02:34,021 INFO misc.py line 117 4140988] Train: [1/10][471/7400] Data 0.004 (0.004) Batch 0.912 (0.612) Remain 12:30:28 loss: 7.6093 mask_loss: 6.9789 roll_mask_loss: 7.5675 density_loss: 8.4806 unmask_loss: 7.7758 Lr: 0.00054
[2025-12-10 17:02:34,781 INFO misc.py line 117 4140988] Train: [1/10][472/7400] Data 0.004 (0.004) Batch 0.760 (0.613) Remain 12:30:50 loss: 7.5522 mask_loss: 7.0259 roll_mask_loss: 7.3767 density_loss: 8.9485 unmask_loss: 7.7242 Lr: 0.00054
[2025-12-10 17:02:35,077 INFO misc.py line 117 4140988] Train: [1/10][473/7400] Data 0.004 (0.004) Batch 0.296 (0.612) Remain 12:30:00 loss: 8.0566 mask_loss: 7.2694 roll_mask_loss: 7.9388 density_loss: 8.5026 unmask_loss: 8.3391 Lr: 0.00054
[2025-12-10 17:02:35,654 INFO misc.py line 117 4140988] Train: [1/10][474/7400] Data 0.004 (0.004) Batch 0.577 (0.612) Remain 12:29:54 loss: 7.9991 mask_loss: 7.3024 roll_mask_loss: 8.0491 density_loss: 8.4620 unmask_loss: 8.1531 Lr: 0.00054
[2025-12-10 17:02:36,168 INFO misc.py line 117 4140988] Train: [1/10][475/7400] Data 0.004 (0.004) Batch 0.515 (0.612) Remain 12:29:38 loss: 8.3732 mask_loss: 7.8087 roll_mask_loss: 8.5897 density_loss: 8.5046 unmask_loss: 8.3771 Lr: 0.00054
[2025-12-10 17:02:36,737 INFO misc.py line 117 4140988] Train: [1/10][476/7400] Data 0.004 (0.004) Batch 0.568 (0.612) Remain 12:29:31 loss: 8.0663 mask_loss: 7.7489 roll_mask_loss: 7.9959 density_loss: 8.3833 unmask_loss: 8.0926 Lr: 0.00054
[2025-12-10 17:02:37,249 INFO misc.py line 117 4140988] Train: [1/10][477/7400] Data 0.004 (0.004) Batch 0.512 (0.611) Remain 12:29:15 loss: 7.9711 mask_loss: 7.4820 roll_mask_loss: 8.0058 density_loss: 8.2149 unmask_loss: 8.0339 Lr: 0.00054
[2025-12-10 17:02:37,947 INFO misc.py line 117 4140988] Train: [1/10][478/7400] Data 0.004 (0.004) Batch 0.699 (0.612) Remain 12:29:28 loss: 8.3950 mask_loss: 8.1812 roll_mask_loss: 8.4072 density_loss: 8.3941 unmask_loss: 8.3279 Lr: 0.00055
[2025-12-10 17:02:38,690 INFO misc.py line 117 4140988] Train: [1/10][479/7400] Data 0.004 (0.004) Batch 0.743 (0.612) Remain 12:29:47 loss: 7.7970 mask_loss: 7.3082 roll_mask_loss: 7.6943 density_loss: 8.5438 unmask_loss: 7.9219 Lr: 0.00055
[2025-12-10 17:02:39,328 INFO misc.py line 117 4140988] Train: [1/10][480/7400] Data 0.004 (0.004) Batch 0.637 (0.612) Remain 12:29:51 loss: 7.7354 mask_loss: 7.1758 roll_mask_loss: 7.6691 density_loss: 9.1675 unmask_loss: 7.8650 Lr: 0.00055
[2025-12-10 17:02:40,096 INFO misc.py line 117 4140988] Train: [1/10][481/7400] Data 0.004 (0.004) Batch 0.768 (0.612) Remain 12:30:14 loss: 7.6632 mask_loss: 7.1125 roll_mask_loss: 7.6292 density_loss: 9.0085 unmask_loss: 7.7754 Lr: 0.00055
[2025-12-10 17:02:40,623 INFO misc.py line 117 4140988] Train: [1/10][482/7400] Data 0.004 (0.004) Batch 0.527 (0.612) Remain 12:30:00 loss: 7.9986 mask_loss: 7.6581 roll_mask_loss: 7.9402 density_loss: 8.1649 unmask_loss: 8.0348 Lr: 0.00055
[2025-12-10 17:02:41,301 INFO misc.py line 117 4140988] Train: [1/10][483/7400] Data 0.003 (0.004) Batch 0.679 (0.612) Remain 12:30:10 loss: 7.7013 mask_loss: 7.1390 roll_mask_loss: 7.5993 density_loss: 8.4475 unmask_loss: 7.8645 Lr: 0.00055
[2025-12-10 17:02:42,038 INFO misc.py line 117 4140988] Train: [1/10][484/7400] Data 0.003 (0.004) Batch 0.737 (0.613) Remain 12:30:28 loss: 7.5729 mask_loss: 6.9790 roll_mask_loss: 7.4971 density_loss: 8.7361 unmask_loss: 7.7331 Lr: 0.00055
[2025-12-10 17:02:42,671 INFO misc.py line 117 4140988] Train: [1/10][485/7400] Data 0.003 (0.004) Batch 0.633 (0.613) Remain 12:30:31 loss: 7.6109 mask_loss: 7.0737 roll_mask_loss: 7.4681 density_loss: 9.1014 unmask_loss: 7.7688 Lr: 0.00055
[2025-12-10 17:02:43,466 INFO misc.py line 117 4140988] Train: [1/10][486/7400] Data 0.003 (0.004) Batch 0.795 (0.613) Remain 12:30:58 loss: 7.7991 mask_loss: 7.3725 roll_mask_loss: 7.7642 density_loss: 8.3763 unmask_loss: 7.8624 Lr: 0.00055
[2025-12-10 17:02:44,160 INFO misc.py line 117 4140988] Train: [1/10][487/7400] Data 0.003 (0.004) Batch 0.695 (0.613) Remain 12:31:10 loss: 7.8491 mask_loss: 7.4982 roll_mask_loss: 7.7943 density_loss: 8.1291 unmask_loss: 7.8894 Lr: 0.00055
[2025-12-10 17:02:44,635 INFO misc.py line 117 4140988] Train: [1/10][488/7400] Data 0.003 (0.004) Batch 0.475 (0.613) Remain 12:30:48 loss: 8.1001 mask_loss: 7.6542 roll_mask_loss: 8.3001 density_loss: 8.3826 unmask_loss: 8.0554 Lr: 0.00055
[2025-12-10 17:02:45,539 INFO misc.py line 117 4140988] Train: [1/10][489/7400] Data 0.003 (0.004) Batch 0.903 (0.613) Remain 12:31:32 loss: 7.5537 mask_loss: 7.0305 roll_mask_loss: 7.4264 density_loss: 8.6672 unmask_loss: 7.7056 Lr: 0.00055
[2025-12-10 17:02:45,994 INFO misc.py line 117 4140988] Train: [1/10][490/7400] Data 0.004 (0.004) Batch 0.455 (0.613) Remain 12:31:07 loss: 8.3958 mask_loss: 8.1869 roll_mask_loss: 8.4034 density_loss: 8.4105 unmask_loss: 8.3282 Lr: 0.00055
[2025-12-10 17:02:46,581 INFO misc.py line 117 4140988] Train: [1/10][491/7400] Data 0.004 (0.004) Batch 0.586 (0.613) Remain 12:31:02 loss: 7.6491 mask_loss: 7.1030 roll_mask_loss: 7.5573 density_loss: 8.9592 unmask_loss: 7.7888 Lr: 0.00055
[2025-12-10 17:02:47,431 INFO misc.py line 117 4140988] Train: [1/10][492/7400] Data 0.004 (0.004) Batch 0.850 (0.614) Remain 12:31:37 loss: 7.6337 mask_loss: 7.1497 roll_mask_loss: 7.5025 density_loss: 8.8416 unmask_loss: 7.7645 Lr: 0.00055
[2025-12-10 17:02:47,808 INFO misc.py line 117 4140988] Train: [1/10][493/7400] Data 0.004 (0.004) Batch 0.377 (0.613) Remain 12:31:01 loss: 7.6290 mask_loss: 7.1915 roll_mask_loss: 7.5188 density_loss: 7.7232 unmask_loss: 7.7484 Lr: 0.00055
[2025-12-10 17:02:48,140 INFO misc.py line 117 4140988] Train: [1/10][494/7400] Data 0.004 (0.004) Batch 0.332 (0.612) Remain 12:30:19 loss: 7.9996 mask_loss: 7.4743 roll_mask_loss: 7.9673 density_loss: 8.0655 unmask_loss: 8.1172 Lr: 0.00055
[2025-12-10 17:02:48,877 INFO misc.py line 117 4140988] Train: [1/10][495/7400] Data 0.004 (0.004) Batch 0.736 (0.613) Remain 12:30:37 loss: 7.5946 mask_loss: 7.0104 roll_mask_loss: 7.4810 density_loss: 8.7669 unmask_loss: 7.7682 Lr: 0.00056
[2025-12-10 17:02:49,595 INFO misc.py line 117 4140988] Train: [1/10][496/7400] Data 0.004 (0.004) Batch 0.719 (0.613) Remain 12:30:52 loss: 7.7606 mask_loss: 7.4207 roll_mask_loss: 7.6781 density_loss: 8.2621 unmask_loss: 7.8066 Lr: 0.00056
[2025-12-10 17:02:50,268 INFO misc.py line 117 4140988] Train: [1/10][497/7400] Data 0.004 (0.004) Batch 0.673 (0.613) Remain 12:31:00 loss: 7.5486 mask_loss: 7.0511 roll_mask_loss: 7.3433 density_loss: 8.8523 unmask_loss: 7.7230 Lr: 0.00056
[2025-12-10 17:02:50,964 INFO misc.py line 117 4140988] Train: [1/10][498/7400] Data 0.004 (0.004) Batch 0.696 (0.613) Remain 12:31:12 loss: 7.5434 mask_loss: 7.0642 roll_mask_loss: 7.3478 density_loss: 8.4179 unmask_loss: 7.7124 Lr: 0.00056
[2025-12-10 17:02:51,744 INFO misc.py line 117 4140988] Train: [1/10][499/7400] Data 0.003 (0.004) Batch 0.781 (0.614) Remain 12:31:36 loss: 7.7218 mask_loss: 7.3074 roll_mask_loss: 7.5970 density_loss: 8.5429 unmask_loss: 7.8205 Lr: 0.00056
[2025-12-10 17:02:52,089 INFO misc.py line 117 4140988] Train: [1/10][500/7400] Data 0.003 (0.004) Batch 0.345 (0.613) Remain 12:30:56 loss: 7.6527 mask_loss: 7.3529 roll_mask_loss: 7.5365 density_loss: 8.5784 unmask_loss: 7.6891 Lr: 0.00056
[2025-12-10 17:02:52,693 INFO misc.py line 117 4140988] Train: [1/10][501/7400] Data 0.003 (0.004) Batch 0.604 (0.613) Remain 12:30:54 loss: 8.1884 mask_loss: 7.7477 roll_mask_loss: 8.2059 density_loss: 8.3630 unmask_loss: 8.2327 Lr: 0.00056
[2025-12-10 17:02:53,358 INFO misc.py line 117 4140988] Train: [1/10][502/7400] Data 0.003 (0.004) Batch 0.665 (0.613) Remain 12:31:01 loss: 7.6007 mask_loss: 7.0886 roll_mask_loss: 7.5686 density_loss: 8.7881 unmask_loss: 7.6971 Lr: 0.00056
[2025-12-10 17:02:53,985 INFO misc.py line 117 4140988] Train: [1/10][503/7400] Data 0.004 (0.004) Batch 0.627 (0.613) Remain 12:31:02 loss: 8.1830 mask_loss: 7.5523 roll_mask_loss: 8.0508 density_loss: 8.5603 unmask_loss: 8.3931 Lr: 0.00056
[2025-12-10 17:02:54,683 INFO misc.py line 117 4140988] Train: [1/10][504/7400] Data 0.004 (0.004) Batch 0.699 (0.613) Remain 12:31:14 loss: 7.5783 mask_loss: 7.0749 roll_mask_loss: 7.4972 density_loss: 9.0206 unmask_loss: 7.6901 Lr: 0.00056
[2025-12-10 17:02:55,202 INFO misc.py line 117 4140988] Train: [1/10][505/7400] Data 0.004 (0.004) Batch 0.519 (0.613) Remain 12:31:00 loss: 7.7297 mask_loss: 7.2720 roll_mask_loss: 7.6048 density_loss: 8.5144 unmask_loss: 7.8508 Lr: 0.00056
[2025-12-10 17:02:55,810 INFO misc.py line 117 4140988] Train: [1/10][506/7400] Data 0.004 (0.004) Batch 0.607 (0.613) Remain 12:30:58 loss: 7.8598 mask_loss: 7.5438 roll_mask_loss: 8.0266 density_loss: 8.8472 unmask_loss: 7.7574 Lr: 0.00056
[2025-12-10 17:02:56,460 INFO misc.py line 117 4140988] Train: [1/10][507/7400] Data 0.004 (0.004) Batch 0.651 (0.613) Remain 12:31:03 loss: 7.8361 mask_loss: 7.4138 roll_mask_loss: 7.8049 density_loss: 8.2171 unmask_loss: 7.8985 Lr: 0.00056
[2025-12-10 17:02:57,107 INFO misc.py line 117 4140988] Train: [1/10][508/7400] Data 0.004 (0.004) Batch 0.647 (0.613) Remain 12:31:07 loss: 7.9308 mask_loss: 7.5632 roll_mask_loss: 8.0410 density_loss: 8.5639 unmask_loss: 7.8883 Lr: 0.00056
[2025-12-10 17:02:57,621 INFO misc.py line 117 4140988] Train: [1/10][509/7400] Data 0.004 (0.004) Batch 0.513 (0.613) Remain 12:30:52 loss: 7.8398 mask_loss: 7.5304 roll_mask_loss: 7.8170 density_loss: 8.0914 unmask_loss: 7.8440 Lr: 0.00056
[2025-12-10 17:02:58,329 INFO misc.py line 117 4140988] Train: [1/10][510/7400] Data 0.004 (0.004) Batch 0.708 (0.613) Remain 12:31:05 loss: 7.6735 mask_loss: 7.2799 roll_mask_loss: 7.6737 density_loss: 8.3345 unmask_loss: 7.7035 Lr: 0.00056
[2025-12-10 17:02:59,208 INFO misc.py line 117 4140988] Train: [1/10][511/7400] Data 0.004 (0.004) Batch 0.879 (0.614) Remain 12:31:43 loss: 7.5846 mask_loss: 7.0376 roll_mask_loss: 7.4449 density_loss: 8.4090 unmask_loss: 7.7597 Lr: 0.00057
[2025-12-10 17:02:59,733 INFO misc.py line 117 4140988] Train: [1/10][512/7400] Data 0.004 (0.004) Batch 0.524 (0.614) Remain 12:31:30 loss: 7.8987 mask_loss: 7.4955 roll_mask_loss: 7.7465 density_loss: 8.4264 unmask_loss: 8.0079 Lr: 0.00057
[2025-12-10 17:03:00,378 INFO misc.py line 117 4140988] Train: [1/10][513/7400] Data 0.004 (0.004) Batch 0.646 (0.614) Remain 12:31:34 loss: 7.6826 mask_loss: 7.0184 roll_mask_loss: 7.6440 density_loss: 8.3087 unmask_loss: 7.8679 Lr: 0.00057
[2025-12-10 17:03:01,102 INFO misc.py line 117 4140988] Train: [1/10][514/7400] Data 0.003 (0.004) Batch 0.723 (0.614) Remain 12:31:49 loss: 7.5150 mask_loss: 6.9542 roll_mask_loss: 7.4336 density_loss: 8.5723 unmask_loss: 7.6647 Lr: 0.00057
[2025-12-10 17:03:01,600 INFO misc.py line 117 4140988] Train: [1/10][515/7400] Data 0.005 (0.004) Batch 0.499 (0.614) Remain 12:31:32 loss: 8.4301 mask_loss: 8.2323 roll_mask_loss: 8.4120 density_loss: 8.3834 unmask_loss: 8.3704 Lr: 0.00057
[2025-12-10 17:03:02,182 INFO misc.py line 117 4140988] Train: [1/10][516/7400] Data 0.004 (0.004) Batch 0.582 (0.614) Remain 12:31:27 loss: 8.4288 mask_loss: 8.2470 roll_mask_loss: 8.4045 density_loss: 8.3639 unmask_loss: 8.3646 Lr: 0.00057
[2025-12-10 17:03:02,846 INFO misc.py line 117 4140988] Train: [1/10][517/7400] Data 0.003 (0.004) Batch 0.664 (0.614) Remain 12:31:33 loss: 7.7914 mask_loss: 7.4031 roll_mask_loss: 7.6815 density_loss: 8.5304 unmask_loss: 7.8699 Lr: 0.00057
[2025-12-10 17:03:03,280 INFO misc.py line 117 4140988] Train: [1/10][518/7400] Data 0.004 (0.004) Batch 0.434 (0.613) Remain 12:31:07 loss: 7.6000 mask_loss: 7.0770 roll_mask_loss: 7.4609 density_loss: 8.3761 unmask_loss: 7.7635 Lr: 0.00057
[2025-12-10 17:03:03,827 INFO misc.py line 117 4140988] Train: [1/10][519/7400] Data 0.004 (0.004) Batch 0.547 (0.613) Remain 12:30:57 loss: 7.6814 mask_loss: 7.0333 roll_mask_loss: 7.5484 density_loss: 8.5018 unmask_loss: 7.9020 Lr: 0.00057
[2025-12-10 17:03:04,317 INFO misc.py line 117 4140988] Train: [1/10][520/7400] Data 0.004 (0.004) Batch 0.490 (0.613) Remain 12:30:39 loss: 8.4226 mask_loss: 8.2210 roll_mask_loss: 8.3702 density_loss: 8.3799 unmask_loss: 8.3820 Lr: 0.00057
[2025-12-10 17:03:04,991 INFO misc.py line 117 4140988] Train: [1/10][521/7400] Data 0.004 (0.004) Batch 0.674 (0.613) Remain 12:30:47 loss: 7.4749 mask_loss: 6.9641 roll_mask_loss: 7.3585 density_loss: 8.0506 unmask_loss: 7.6275 Lr: 0.00057
[2025-12-10 17:03:05,525 INFO misc.py line 117 4140988] Train: [1/10][522/7400] Data 0.004 (0.004) Batch 0.534 (0.613) Remain 12:30:35 loss: 8.0183 mask_loss: 7.6656 roll_mask_loss: 7.9114 density_loss: 8.2081 unmask_loss: 8.0839 Lr: 0.00057
[2025-12-10 17:03:06,385 INFO misc.py line 117 4140988] Train: [1/10][523/7400] Data 0.004 (0.004) Batch 0.860 (0.613) Remain 12:31:09 loss: 7.5295 mask_loss: 6.8975 roll_mask_loss: 7.4507 density_loss: 8.6238 unmask_loss: 7.7125 Lr: 0.00057
[2025-12-10 17:03:06,910 INFO misc.py line 117 4140988] Train: [1/10][524/7400] Data 0.004 (0.004) Batch 0.526 (0.613) Remain 12:30:56 loss: 8.4208 mask_loss: 8.2504 roll_mask_loss: 8.4317 density_loss: 8.4338 unmask_loss: 8.3319 Lr: 0.00057
[2025-12-10 17:03:07,608 INFO misc.py line 117 4140988] Train: [1/10][525/7400] Data 0.004 (0.004) Batch 0.698 (0.613) Remain 12:31:08 loss: 7.5738 mask_loss: 7.0420 roll_mask_loss: 7.5623 density_loss: 8.9308 unmask_loss: 7.6668 Lr: 0.00057
[2025-12-10 17:03:08,228 INFO misc.py line 117 4140988] Train: [1/10][526/7400] Data 0.004 (0.004) Batch 0.620 (0.613) Remain 12:31:08 loss: 7.5889 mask_loss: 7.0021 roll_mask_loss: 7.5894 density_loss: 8.9097 unmask_loss: 7.7039 Lr: 0.00058
[2025-12-10 17:03:08,820 INFO misc.py line 117 4140988] Train: [1/10][527/7400] Data 0.004 (0.004) Batch 0.592 (0.613) Remain 12:31:04 loss: 7.9816 mask_loss: 7.3830 roll_mask_loss: 7.9717 density_loss: 8.6444 unmask_loss: 8.1130 Lr: 0.00058
[2025-12-10 17:03:09,534 INFO misc.py line 117 4140988] Train: [1/10][528/7400] Data 0.004 (0.004) Batch 0.714 (0.614) Remain 12:31:18 loss: 7.5201 mask_loss: 6.8829 roll_mask_loss: 7.3574 density_loss: 8.9628 unmask_loss: 7.7407 Lr: 0.00058
[2025-12-10 17:03:10,084 INFO misc.py line 117 4140988] Train: [1/10][529/7400] Data 0.004 (0.004) Batch 0.551 (0.613) Remain 12:31:08 loss: 8.0625 mask_loss: 7.8876 roll_mask_loss: 8.0545 density_loss: 8.3476 unmask_loss: 7.9870 Lr: 0.00058
[2025-12-10 17:03:10,627 INFO misc.py line 117 4140988] Train: [1/10][530/7400] Data 0.003 (0.004) Batch 0.543 (0.613) Remain 12:30:58 loss: 7.4191 mask_loss: 6.8862 roll_mask_loss: 7.2237 density_loss: 9.5074 unmask_loss: 7.5930 Lr: 0.00058
[2025-12-10 17:03:11,283 INFO misc.py line 117 4140988] Train: [1/10][531/7400] Data 0.003 (0.004) Batch 0.656 (0.613) Remain 12:31:03 loss: 8.4596 mask_loss: 8.0696 roll_mask_loss: 8.5138 density_loss: 8.2522 unmask_loss: 8.4624 Lr: 0.00058
[2025-12-10 17:03:11,858 INFO misc.py line 117 4140988] Train: [1/10][532/7400] Data 0.003 (0.004) Batch 0.575 (0.613) Remain 12:30:57 loss: 7.8283 mask_loss: 7.2509 roll_mask_loss: 7.8598 density_loss: 8.7186 unmask_loss: 7.9269 Lr: 0.00058
[2025-12-10 17:03:12,455 INFO misc.py line 117 4140988] Train: [1/10][533/7400] Data 0.003 (0.004) Batch 0.596 (0.613) Remain 12:30:54 loss: 7.5478 mask_loss: 7.0417 roll_mask_loss: 7.4193 density_loss: 8.0783 unmask_loss: 7.7035 Lr: 0.00058
[2025-12-10 17:03:13,063 INFO misc.py line 117 4140988] Train: [1/10][534/7400] Data 0.004 (0.004) Batch 0.608 (0.613) Remain 12:30:53 loss: 7.7492 mask_loss: 7.2421 roll_mask_loss: 7.6457 density_loss: 8.0945 unmask_loss: 7.8926 Lr: 0.00058
[2025-12-10 17:03:13,864 INFO misc.py line 117 4140988] Train: [1/10][535/7400] Data 0.004 (0.004) Batch 0.801 (0.614) Remain 12:31:18 loss: 7.5034 mask_loss: 6.9473 roll_mask_loss: 7.3663 density_loss: 8.7350 unmask_loss: 7.6753 Lr: 0.00058
[2025-12-10 17:03:14,440 INFO misc.py line 117 4140988] Train: [1/10][536/7400] Data 0.004 (0.004) Batch 0.577 (0.614) Remain 12:31:12 loss: 7.6579 mask_loss: 7.1891 roll_mask_loss: 7.7014 density_loss: 8.6573 unmask_loss: 7.6974 Lr: 0.00058
[2025-12-10 17:03:15,171 INFO misc.py line 117 4140988] Train: [1/10][537/7400] Data 0.004 (0.004) Batch 0.731 (0.614) Remain 12:31:28 loss: 7.7044 mask_loss: 6.9639 roll_mask_loss: 7.9769 density_loss: 8.2310 unmask_loss: 7.7737 Lr: 0.00058
[2025-12-10 17:03:15,801 INFO misc.py line 117 4140988] Train: [1/10][538/7400] Data 0.004 (0.004) Batch 0.630 (0.614) Remain 12:31:30 loss: 7.7659 mask_loss: 7.3347 roll_mask_loss: 7.8515 density_loss: 8.5008 unmask_loss: 7.7688 Lr: 0.00058
[2025-12-10 17:03:16,658 INFO misc.py line 117 4140988] Train: [1/10][539/7400] Data 0.004 (0.004) Batch 0.857 (0.614) Remain 12:32:02 loss: 7.4996 mask_loss: 6.9238 roll_mask_loss: 7.5021 density_loss: 8.7944 unmask_loss: 7.6104 Lr: 0.00058
[2025-12-10 17:03:17,235 INFO misc.py line 117 4140988] Train: [1/10][540/7400] Data 0.005 (0.004) Batch 0.577 (0.614) Remain 12:31:57 loss: 7.4581 mask_loss: 6.8727 roll_mask_loss: 7.2801 density_loss: 8.8174 unmask_loss: 7.6634 Lr: 0.00058
[2025-12-10 17:03:17,851 INFO misc.py line 117 4140988] Train: [1/10][541/7400] Data 0.004 (0.004) Batch 0.616 (0.614) Remain 12:31:56 loss: 7.7720 mask_loss: 7.3814 roll_mask_loss: 7.8600 density_loss: 8.7890 unmask_loss: 7.7476 Lr: 0.00059
[2025-12-10 17:03:18,385 INFO misc.py line 117 4140988] Train: [1/10][542/7400] Data 0.004 (0.004) Batch 0.534 (0.614) Remain 12:31:45 loss: 8.4152 mask_loss: 8.0905 roll_mask_loss: 8.3701 density_loss: 8.4310 unmask_loss: 8.4314 Lr: 0.00059
[2025-12-10 17:03:19,057 INFO misc.py line 117 4140988] Train: [1/10][543/7400] Data 0.004 (0.004) Batch 0.673 (0.614) Remain 12:31:52 loss: 7.6940 mask_loss: 7.1776 roll_mask_loss: 7.7105 density_loss: 8.4899 unmask_loss: 7.7742 Lr: 0.00059
[2025-12-10 17:03:20,005 INFO misc.py line 117 4140988] Train: [1/10][544/7400] Data 0.004 (0.004) Batch 0.948 (0.615) Remain 12:32:37 loss: 7.4647 mask_loss: 6.8208 roll_mask_loss: 7.3837 density_loss: 9.0716 unmask_loss: 7.6457 Lr: 0.00059
[2025-12-10 17:03:20,732 INFO misc.py line 117 4140988] Train: [1/10][545/7400] Data 0.003 (0.004) Batch 0.726 (0.615) Remain 12:32:51 loss: 7.5167 mask_loss: 6.8412 roll_mask_loss: 7.4018 density_loss: 8.3173 unmask_loss: 7.7456 Lr: 0.00059
[2025-12-10 17:03:21,335 INFO misc.py line 117 4140988] Train: [1/10][546/7400] Data 0.004 (0.004) Batch 0.603 (0.615) Remain 12:32:49 loss: 7.7067 mask_loss: 7.1185 roll_mask_loss: 7.6411 density_loss: 8.6560 unmask_loss: 7.8605 Lr: 0.00059
[2025-12-10 17:03:21,899 INFO misc.py line 117 4140988] Train: [1/10][547/7400] Data 0.003 (0.004) Batch 0.565 (0.615) Remain 12:32:42 loss: 8.2448 mask_loss: 7.9608 roll_mask_loss: 8.3305 density_loss: 8.5494 unmask_loss: 8.1729 Lr: 0.00059
[2025-12-10 17:03:22,584 INFO misc.py line 117 4140988] Train: [1/10][548/7400] Data 0.003 (0.004) Batch 0.685 (0.615) Remain 12:32:51 loss: 7.4552 mask_loss: 6.9074 roll_mask_loss: 7.3555 density_loss: 9.1580 unmask_loss: 7.5957 Lr: 0.00059
[2025-12-10 17:03:23,124 INFO misc.py line 117 4140988] Train: [1/10][549/7400] Data 0.003 (0.004) Batch 0.539 (0.615) Remain 12:32:40 loss: 7.7004 mask_loss: 7.1284 roll_mask_loss: 7.7561 density_loss: 8.7846 unmask_loss: 7.7828 Lr: 0.00059
[2025-12-10 17:03:23,818 INFO misc.py line 117 4140988] Train: [1/10][550/7400] Data 0.004 (0.004) Batch 0.694 (0.615) Remain 12:32:50 loss: 7.4635 mask_loss: 6.9694 roll_mask_loss: 7.3558 density_loss: 9.2253 unmask_loss: 7.5798 Lr: 0.00059
[2025-12-10 17:03:24,150 INFO misc.py line 117 4140988] Train: [1/10][551/7400] Data 0.003 (0.004) Batch 0.333 (0.614) Remain 12:32:11 loss: 7.5833 mask_loss: 7.0095 roll_mask_loss: 7.5325 density_loss: 8.5477 unmask_loss: 7.7246 Lr: 0.00059
[2025-12-10 17:03:24,726 INFO misc.py line 117 4140988] Train: [1/10][552/7400] Data 0.003 (0.004) Batch 0.576 (0.614) Remain 12:32:06 loss: 7.7642 mask_loss: 7.1371 roll_mask_loss: 7.6548 density_loss: 9.1083 unmask_loss: 7.9504 Lr: 0.00059
[2025-12-10 17:03:25,407 INFO misc.py line 117 4140988] Train: [1/10][553/7400] Data 0.003 (0.004) Batch 0.680 (0.615) Remain 12:32:14 loss: 7.6245 mask_loss: 7.1076 roll_mask_loss: 7.5102 density_loss: 8.8734 unmask_loss: 7.7627 Lr: 0.00059
[2025-12-10 17:03:25,905 INFO misc.py line 117 4140988] Train: [1/10][554/7400] Data 0.004 (0.004) Batch 0.495 (0.614) Remain 12:31:57 loss: 7.6632 mask_loss: 7.2302 roll_mask_loss: 7.6402 density_loss: 8.7486 unmask_loss: 7.7162 Lr: 0.00059
[2025-12-10 17:03:26,601 INFO misc.py line 117 4140988] Train: [1/10][555/7400] Data 0.006 (0.004) Batch 0.698 (0.614) Remain 12:32:08 loss: 7.4371 mask_loss: 6.8660 roll_mask_loss: 7.3340 density_loss: 8.7054 unmask_loss: 7.6002 Lr: 0.00059
[2025-12-10 17:03:27,362 INFO misc.py line 117 4140988] Train: [1/10][556/7400] Data 0.004 (0.004) Batch 0.761 (0.615) Remain 12:32:27 loss: 7.5002 mask_loss: 6.9156 roll_mask_loss: 7.4683 density_loss: 9.2815 unmask_loss: 7.6229 Lr: 0.00060
[2025-12-10 17:03:28,120 INFO misc.py line 117 4140988] Train: [1/10][557/7400] Data 0.004 (0.004) Batch 0.758 (0.615) Remain 12:32:45 loss: 7.5240 mask_loss: 6.9510 roll_mask_loss: 7.4177 density_loss: 9.1202 unmask_loss: 7.6812 Lr: 0.00060
[2025-12-10 17:03:28,915 INFO misc.py line 117 4140988] Train: [1/10][558/7400] Data 0.004 (0.004) Batch 0.795 (0.615) Remain 12:33:08 loss: 7.4929 mask_loss: 6.9241 roll_mask_loss: 7.5153 density_loss: 9.0194 unmask_loss: 7.5857 Lr: 0.00060
[2025-12-10 17:03:29,689 INFO misc.py line 117 4140988] Train: [1/10][559/7400] Data 0.004 (0.004) Batch 0.775 (0.616) Remain 12:33:29 loss: 7.5037 mask_loss: 6.9090 roll_mask_loss: 7.3462 density_loss: 8.8069 unmask_loss: 7.7036 Lr: 0.00060
[2025-12-10 17:03:30,340 INFO misc.py line 117 4140988] Train: [1/10][560/7400] Data 0.004 (0.004) Batch 0.651 (0.616) Remain 12:33:33 loss: 7.7923 mask_loss: 7.1755 roll_mask_loss: 7.9438 density_loss: 9.0318 unmask_loss: 7.8443 Lr: 0.00060
[2025-12-10 17:03:30,998 INFO misc.py line 117 4140988] Train: [1/10][561/7400] Data 0.004 (0.004) Batch 0.658 (0.616) Remain 12:33:38 loss: 7.5696 mask_loss: 7.0724 roll_mask_loss: 7.4428 density_loss: 8.4154 unmask_loss: 7.7134 Lr: 0.00060
[2025-12-10 17:03:31,652 INFO misc.py line 117 4140988] Train: [1/10][562/7400] Data 0.004 (0.004) Batch 0.654 (0.616) Remain 12:33:42 loss: 7.8785 mask_loss: 6.8135 roll_mask_loss: 8.1531 density_loss: 8.7478 unmask_loss: 8.0987 Lr: 0.00060
[2025-12-10 17:03:32,263 INFO misc.py line 117 4140988] Train: [1/10][563/7400] Data 0.004 (0.004) Batch 0.612 (0.616) Remain 12:33:41 loss: 8.4314 mask_loss: 8.2583 roll_mask_loss: 8.3641 density_loss: 8.3752 unmask_loss: 8.3840 Lr: 0.00060
[2025-12-10 17:03:32,891 INFO misc.py line 117 4140988] Train: [1/10][564/7400] Data 0.003 (0.004) Batch 0.628 (0.616) Remain 12:33:42 loss: 7.5539 mask_loss: 7.0396 roll_mask_loss: 7.5413 density_loss: 8.0536 unmask_loss: 7.6563 Lr: 0.00060
[2025-12-10 17:03:33,583 INFO misc.py line 117 4140988] Train: [1/10][565/7400] Data 0.003 (0.004) Batch 0.691 (0.616) Remain 12:33:51 loss: 7.6073 mask_loss: 6.7706 roll_mask_loss: 7.7520 density_loss: 8.6465 unmask_loss: 7.7803 Lr: 0.00060
[2025-12-10 17:03:34,176 INFO misc.py line 117 4140988] Train: [1/10][566/7400] Data 0.004 (0.004) Batch 0.593 (0.616) Remain 12:33:47 loss: 7.6293 mask_loss: 6.9720 roll_mask_loss: 7.6719 density_loss: 8.2552 unmask_loss: 7.7716 Lr: 0.00060
[2025-12-10 17:03:34,916 INFO misc.py line 117 4140988] Train: [1/10][567/7400] Data 0.004 (0.004) Batch 0.740 (0.616) Remain 12:34:03 loss: 7.5057 mask_loss: 6.8565 roll_mask_loss: 7.4531 density_loss: 9.1925 unmask_loss: 7.6728 Lr: 0.00060
[2025-12-10 17:03:35,260 INFO misc.py line 117 4140988] Train: [1/10][568/7400] Data 0.003 (0.004) Batch 0.344 (0.616) Remain 12:33:27 loss: 7.9946 mask_loss: 7.4758 roll_mask_loss: 8.0443 density_loss: 8.8127 unmask_loss: 8.0529 Lr: 0.00060
[2025-12-10 17:03:35,835 INFO misc.py line 117 4140988] Train: [1/10][569/7400] Data 0.003 (0.004) Batch 0.575 (0.616) Remain 12:33:21 loss: 8.1307 mask_loss: 7.7343 roll_mask_loss: 8.0116 density_loss: 8.4094 unmask_loss: 8.2203 Lr: 0.00060
[2025-12-10 17:03:36,374 INFO misc.py line 117 4140988] Train: [1/10][570/7400] Data 0.003 (0.004) Batch 0.539 (0.615) Remain 12:33:11 loss: 8.3894 mask_loss: 8.1933 roll_mask_loss: 8.3697 density_loss: 8.3549 unmask_loss: 8.3303 Lr: 0.00061
[2025-12-10 17:03:36,890 INFO misc.py line 117 4140988] Train: [1/10][571/7400] Data 0.003 (0.004) Batch 0.516 (0.615) Remain 12:32:57 loss: 7.5059 mask_loss: 6.9711 roll_mask_loss: 7.4122 density_loss: 8.6721 unmask_loss: 7.6468 Lr: 0.00061
[2025-12-10 17:03:37,651 INFO misc.py line 117 4140988] Train: [1/10][572/7400] Data 0.004 (0.004) Batch 0.761 (0.616) Remain 12:33:15 loss: 7.4763 mask_loss: 6.9692 roll_mask_loss: 7.3642 density_loss: 8.3171 unmask_loss: 7.6196 Lr: 0.00061
[2025-12-10 17:03:38,443 INFO misc.py line 117 4140988] Train: [1/10][573/7400] Data 0.004 (0.004) Batch 0.792 (0.616) Remain 12:33:37 loss: 7.5359 mask_loss: 6.8947 roll_mask_loss: 7.4370 density_loss: 8.6404 unmask_loss: 7.7332 Lr: 0.00061
[2025-12-10 17:03:39,285 INFO misc.py line 117 4140988] Train: [1/10][574/7400] Data 0.004 (0.004) Batch 0.843 (0.616) Remain 12:34:06 loss: 7.5590 mask_loss: 6.8541 roll_mask_loss: 7.5899 density_loss: 8.4922 unmask_loss: 7.7262 Lr: 0.00061
[2025-12-10 17:03:39,890 INFO misc.py line 117 4140988] Train: [1/10][575/7400] Data 0.004 (0.004) Batch 0.605 (0.616) Remain 12:34:04 loss: 8.0307 mask_loss: 7.6071 roll_mask_loss: 8.0304 density_loss: 8.3897 unmask_loss: 8.0748 Lr: 0.00061
[2025-12-10 17:03:40,401 INFO misc.py line 117 4140988] Train: [1/10][576/7400] Data 0.004 (0.004) Batch 0.511 (0.616) Remain 12:33:50 loss: 7.7998 mask_loss: 7.2714 roll_mask_loss: 7.7014 density_loss: 8.0591 unmask_loss: 7.9520 Lr: 0.00061
[2025-12-10 17:03:40,906 INFO misc.py line 117 4140988] Train: [1/10][577/7400] Data 0.004 (0.004) Batch 0.505 (0.616) Remain 12:33:35 loss: 8.0102 mask_loss: 7.5521 roll_mask_loss: 7.9284 density_loss: 8.4557 unmask_loss: 8.1110 Lr: 0.00061
[2025-12-10 17:03:41,564 INFO misc.py line 117 4140988] Train: [1/10][578/7400] Data 0.004 (0.004) Batch 0.658 (0.616) Remain 12:33:40 loss: 7.5235 mask_loss: 6.9228 roll_mask_loss: 7.4703 density_loss: 8.7659 unmask_loss: 7.6751 Lr: 0.00061
[2025-12-10 17:03:42,222 INFO misc.py line 117 4140988] Train: [1/10][579/7400] Data 0.004 (0.004) Batch 0.658 (0.616) Remain 12:33:45 loss: 7.5072 mask_loss: 7.0253 roll_mask_loss: 7.4151 density_loss: 7.8946 unmask_loss: 7.6362 Lr: 0.00061
[2025-12-10 17:03:42,504 INFO misc.py line 117 4140988] Train: [1/10][580/7400] Data 0.004 (0.004) Batch 0.283 (0.615) Remain 12:33:02 loss: 8.4142 mask_loss: 8.3067 roll_mask_loss: 8.3349 density_loss: 8.3305 unmask_loss: 8.3410 Lr: 0.00061
[2025-12-10 17:03:43,354 INFO misc.py line 117 4140988] Train: [1/10][581/7400] Data 0.004 (0.004) Batch 0.848 (0.616) Remain 12:33:30 loss: 7.4062 mask_loss: 6.7903 roll_mask_loss: 7.2710 density_loss: 8.7070 unmask_loss: 7.6076 Lr: 0.00061
[2025-12-10 17:03:43,913 INFO misc.py line 117 4140988] Train: [1/10][582/7400] Data 0.005 (0.004) Batch 0.560 (0.616) Remain 12:33:23 loss: 8.4162 mask_loss: 8.2290 roll_mask_loss: 8.3965 density_loss: 8.3832 unmask_loss: 8.3521 Lr: 0.00061
[2025-12-10 17:03:44,419 INFO misc.py line 117 4140988] Train: [1/10][583/7400] Data 0.004 (0.004) Batch 0.506 (0.616) Remain 12:33:08 loss: 7.7337 mask_loss: 7.2465 roll_mask_loss: 7.6974 density_loss: 8.6811 unmask_loss: 7.8218 Lr: 0.00061
[2025-12-10 17:03:45,075 INFO misc.py line 117 4140988] Train: [1/10][584/7400] Data 0.004 (0.004) Batch 0.657 (0.616) Remain 12:33:13 loss: 7.5001 mask_loss: 6.9794 roll_mask_loss: 7.3937 density_loss: 8.5246 unmask_loss: 7.6431 Lr: 0.00062
[2025-12-10 17:03:45,885 INFO misc.py line 117 4140988] Train: [1/10][585/7400] Data 0.003 (0.004) Batch 0.809 (0.616) Remain 12:33:37 loss: 7.6255 mask_loss: 6.9861 roll_mask_loss: 7.7420 density_loss: 8.8259 unmask_loss: 7.7104 Lr: 0.00062
[2025-12-10 17:03:46,457 INFO misc.py line 117 4140988] Train: [1/10][586/7400] Data 0.004 (0.004) Batch 0.572 (0.616) Remain 12:33:31 loss: 7.6919 mask_loss: 7.1352 roll_mask_loss: 7.6891 density_loss: 9.0447 unmask_loss: 7.7908 Lr: 0.00062
[2025-12-10 17:03:47,093 INFO misc.py line 117 4140988] Train: [1/10][587/7400] Data 0.004 (0.004) Batch 0.636 (0.616) Remain 12:33:32 loss: 7.8320 mask_loss: 7.4049 roll_mask_loss: 8.1769 density_loss: 8.5082 unmask_loss: 7.7029 Lr: 0.00062
[2025-12-10 17:03:47,951 INFO misc.py line 117 4140988] Train: [1/10][588/7400] Data 0.004 (0.004) Batch 0.858 (0.616) Remain 12:34:02 loss: 7.5072 mask_loss: 6.8551 roll_mask_loss: 7.3799 density_loss: 9.0115 unmask_loss: 7.7166 Lr: 0.00062
[2025-12-10 17:03:48,629 INFO misc.py line 117 4140988] Train: [1/10][589/7400] Data 0.004 (0.004) Batch 0.678 (0.616) Remain 12:34:09 loss: 7.4974 mask_loss: 6.9376 roll_mask_loss: 7.5136 density_loss: 8.1585 unmask_loss: 7.6061 Lr: 0.00062
[2025-12-10 17:03:49,525 INFO misc.py line 117 4140988] Train: [1/10][590/7400] Data 0.003 (0.004) Batch 0.896 (0.617) Remain 12:34:44 loss: 7.4567 mask_loss: 6.7360 roll_mask_loss: 7.3347 density_loss: 8.7816 unmask_loss: 7.7024 Lr: 0.00062
[2025-12-10 17:03:50,169 INFO misc.py line 117 4140988] Train: [1/10][591/7400] Data 0.003 (0.004) Batch 0.644 (0.617) Remain 12:34:47 loss: 7.8001 mask_loss: 7.2894 roll_mask_loss: 7.7576 density_loss: 8.2981 unmask_loss: 7.9107 Lr: 0.00062
[2025-12-10 17:03:50,964 INFO misc.py line 117 4140988] Train: [1/10][592/7400] Data 0.003 (0.004) Batch 0.795 (0.617) Remain 12:35:08 loss: 7.5191 mask_loss: 7.0046 roll_mask_loss: 7.4958 density_loss: 8.5590 unmask_loss: 7.6169 Lr: 0.00062
[2025-12-10 17:03:51,784 INFO misc.py line 117 4140988] Train: [1/10][593/7400] Data 0.003 (0.004) Batch 0.820 (0.618) Remain 12:35:33 loss: 7.4340 mask_loss: 6.7641 roll_mask_loss: 7.2964 density_loss: 8.2733 unmask_loss: 7.6722 Lr: 0.00062
[2025-12-10 17:03:52,507 INFO misc.py line 117 4140988] Train: [1/10][594/7400] Data 0.004 (0.004) Batch 0.723 (0.618) Remain 12:35:45 loss: 7.5699 mask_loss: 6.9978 roll_mask_loss: 7.4872 density_loss: 8.7334 unmask_loss: 7.7226 Lr: 0.00062
[2025-12-10 17:03:53,158 INFO misc.py line 117 4140988] Train: [1/10][595/7400] Data 0.003 (0.004) Batch 0.652 (0.618) Remain 12:35:49 loss: 7.4124 mask_loss: 6.9226 roll_mask_loss: 7.3044 density_loss: 8.1516 unmask_loss: 7.5482 Lr: 0.00062
[2025-12-10 17:03:53,912 INFO misc.py line 117 4140988] Train: [1/10][596/7400] Data 0.003 (0.004) Batch 0.754 (0.618) Remain 12:36:05 loss: 7.4890 mask_loss: 6.8765 roll_mask_loss: 7.5982 density_loss: 8.0798 unmask_loss: 7.5791 Lr: 0.00062
[2025-12-10 17:03:54,553 INFO misc.py line 117 4140988] Train: [1/10][597/7400] Data 0.003 (0.004) Batch 0.640 (0.618) Remain 12:36:07 loss: 7.4552 mask_loss: 6.7692 roll_mask_loss: 7.4479 density_loss: 8.6649 unmask_loss: 7.6286 Lr: 0.00062
[2025-12-10 17:03:55,266 INFO misc.py line 117 4140988] Train: [1/10][598/7400] Data 0.004 (0.004) Batch 0.713 (0.618) Remain 12:36:18 loss: 7.3405 mask_loss: 6.7504 roll_mask_loss: 7.2264 density_loss: 8.7490 unmask_loss: 7.5176 Lr: 0.00063
[2025-12-10 17:03:55,882 INFO misc.py line 117 4140988] Train: [1/10][599/7400] Data 0.004 (0.004) Batch 0.616 (0.618) Remain 12:36:17 loss: 8.4394 mask_loss: 8.2080 roll_mask_loss: 8.3781 density_loss: 8.3524 unmask_loss: 8.4186 Lr: 0.00063
[2025-12-10 17:03:56,571 INFO misc.py line 117 4140988] Train: [1/10][600/7400] Data 0.004 (0.004) Batch 0.689 (0.618) Remain 12:36:25 loss: 7.7849 mask_loss: 7.3151 roll_mask_loss: 7.8014 density_loss: 9.0033 unmask_loss: 7.8315 Lr: 0.00063
[2025-12-10 17:03:57,322 INFO misc.py line 117 4140988] Train: [1/10][601/7400] Data 0.004 (0.004) Batch 0.750 (0.619) Remain 12:36:41 loss: 7.4406 mask_loss: 6.8915 roll_mask_loss: 7.4035 density_loss: 9.3002 unmask_loss: 7.5478 Lr: 0.00063
[2025-12-10 17:03:57,877 INFO misc.py line 117 4140988] Train: [1/10][602/7400] Data 0.004 (0.004) Batch 0.556 (0.618) Remain 12:36:33 loss: 7.6235 mask_loss: 6.9933 roll_mask_loss: 7.7196 density_loss: 9.0771 unmask_loss: 7.7090 Lr: 0.00063
[2025-12-10 17:03:58,513 INFO misc.py line 117 4140988] Train: [1/10][603/7400] Data 0.004 (0.004) Batch 0.636 (0.618) Remain 12:36:34 loss: 7.6390 mask_loss: 7.1403 roll_mask_loss: 7.4240 density_loss: 8.8570 unmask_loss: 7.8187 Lr: 0.00063
[2025-12-10 17:03:59,347 INFO misc.py line 117 4140988] Train: [1/10][604/7400] Data 0.004 (0.004) Batch 0.834 (0.619) Remain 12:37:00 loss: 7.4069 mask_loss: 6.8055 roll_mask_loss: 7.2621 density_loss: 8.9511 unmask_loss: 7.6010 Lr: 0.00063
[2025-12-10 17:04:00,108 INFO misc.py line 117 4140988] Train: [1/10][605/7400] Data 0.004 (0.004) Batch 0.761 (0.619) Remain 12:37:17 loss: 7.5097 mask_loss: 6.9922 roll_mask_loss: 7.5295 density_loss: 8.4507 unmask_loss: 7.5895 Lr: 0.00063
[2025-12-10 17:04:00,900 INFO misc.py line 117 4140988] Train: [1/10][606/7400] Data 0.003 (0.004) Batch 0.792 (0.619) Remain 12:37:37 loss: 7.4116 mask_loss: 6.7969 roll_mask_loss: 7.2419 density_loss: 8.9470 unmask_loss: 7.6248 Lr: 0.00063
[2025-12-10 17:04:01,435 INFO misc.py line 117 4140988] Train: [1/10][607/7400] Data 0.004 (0.004) Batch 0.535 (0.619) Remain 12:37:26 loss: 7.6462 mask_loss: 6.9927 roll_mask_loss: 7.4975 density_loss: 8.3974 unmask_loss: 7.8793 Lr: 0.00063
[2025-12-10 17:04:02,034 INFO misc.py line 117 4140988] Train: [1/10][608/7400] Data 0.004 (0.004) Batch 0.599 (0.619) Remain 12:37:23 loss: 8.4018 mask_loss: 8.2293 roll_mask_loss: 8.3357 density_loss: 8.3602 unmask_loss: 8.3540 Lr: 0.00063
[2025-12-10 17:04:02,862 INFO misc.py line 117 4140988] Train: [1/10][609/7400] Data 0.004 (0.004) Batch 0.827 (0.620) Remain 12:37:48 loss: 7.4646 mask_loss: 6.9451 roll_mask_loss: 7.3693 density_loss: 7.9850 unmask_loss: 7.6123 Lr: 0.00063
[2025-12-10 17:04:03,359 INFO misc.py line 117 4140988] Train: [1/10][610/7400] Data 0.004 (0.004) Batch 0.497 (0.619) Remain 12:37:32 loss: 7.4309 mask_loss: 6.8310 roll_mask_loss: 7.3593 density_loss: 9.0422 unmask_loss: 7.5858 Lr: 0.00063
[2025-12-10 17:04:03,921 INFO misc.py line 117 4140988] Train: [1/10][611/7400] Data 0.004 (0.004) Batch 0.563 (0.619) Remain 12:37:25 loss: 7.8954 mask_loss: 7.4821 roll_mask_loss: 7.6606 density_loss: 8.3522 unmask_loss: 8.0524 Lr: 0.00064
[2025-12-10 17:04:04,521 INFO misc.py line 117 4140988] Train: [1/10][612/7400] Data 0.003 (0.004) Batch 0.600 (0.619) Remain 12:37:22 loss: 8.0877 mask_loss: 7.7696 roll_mask_loss: 8.7639 density_loss: 8.3310 unmask_loss: 7.7420 Lr: 0.00064
[2025-12-10 17:04:05,151 INFO misc.py line 117 4140988] Train: [1/10][613/7400] Data 0.003 (0.004) Batch 0.629 (0.619) Remain 12:37:22 loss: 7.5273 mask_loss: 6.9976 roll_mask_loss: 7.3925 density_loss: 7.9191 unmask_loss: 7.7011 Lr: 0.00064
[2025-12-10 17:04:05,957 INFO misc.py line 117 4140988] Train: [1/10][614/7400] Data 0.004 (0.004) Batch 0.806 (0.620) Remain 12:37:44 loss: 7.3818 mask_loss: 6.7865 roll_mask_loss: 7.3226 density_loss: 8.5607 unmask_loss: 7.5378 Lr: 0.00064
[2025-12-10 17:04:06,697 INFO misc.py line 117 4140988] Train: [1/10][615/7400] Data 0.004 (0.004) Batch 0.740 (0.620) Remain 12:37:58 loss: 7.4860 mask_loss: 6.9826 roll_mask_loss: 7.4710 density_loss: 8.1619 unmask_loss: 7.5819 Lr: 0.00064
[2025-12-10 17:04:07,270 INFO misc.py line 117 4140988] Train: [1/10][616/7400] Data 0.004 (0.004) Batch 0.574 (0.620) Remain 12:37:52 loss: 8.3981 mask_loss: 8.2076 roll_mask_loss: 8.3889 density_loss: 8.3535 unmask_loss: 8.3308 Lr: 0.00064
[2025-12-10 17:04:07,965 INFO misc.py line 117 4140988] Train: [1/10][617/7400] Data 0.003 (0.004) Batch 0.694 (0.620) Remain 12:38:00 loss: 7.8925 mask_loss: 7.2772 roll_mask_loss: 7.6594 density_loss: 8.7799 unmask_loss: 8.1410 Lr: 0.00064
[2025-12-10 17:04:08,354 INFO misc.py line 117 4140988] Train: [1/10][618/7400] Data 0.004 (0.004) Batch 0.389 (0.619) Remain 12:37:32 loss: 7.9195 mask_loss: 7.5410 roll_mask_loss: 7.8100 density_loss: 9.4635 unmask_loss: 7.9741 Lr: 0.00064
[2025-12-10 17:04:08,922 INFO misc.py line 117 4140988] Train: [1/10][619/7400] Data 0.004 (0.004) Batch 0.568 (0.619) Remain 12:37:25 loss: 8.3555 mask_loss: 8.0896 roll_mask_loss: 8.3654 density_loss: 8.4514 unmask_loss: 8.3143 Lr: 0.00064
[2025-12-10 17:04:09,209 INFO misc.py line 117 4140988] Train: [1/10][620/7400] Data 0.003 (0.004) Batch 0.288 (0.619) Remain 12:36:45 loss: 7.9369 mask_loss: 7.4074 roll_mask_loss: 7.8009 density_loss: 8.5882 unmask_loss: 8.0979 Lr: 0.00064
[2025-12-10 17:04:09,902 INFO misc.py line 117 4140988] Train: [1/10][621/7400] Data 0.003 (0.004) Batch 0.692 (0.619) Remain 12:36:53 loss: 7.5594 mask_loss: 7.0362 roll_mask_loss: 7.4400 density_loss: 8.5340 unmask_loss: 7.7100 Lr: 0.00064
[2025-12-10 17:04:10,544 INFO misc.py line 117 4140988] Train: [1/10][622/7400] Data 0.004 (0.004) Batch 0.642 (0.619) Remain 12:36:56 loss: 7.7173 mask_loss: 6.8424 roll_mask_loss: 7.9970 density_loss: 9.5992 unmask_loss: 7.8229 Lr: 0.00064
[2025-12-10 17:04:11,124 INFO misc.py line 117 4140988] Train: [1/10][623/7400] Data 0.004 (0.004) Batch 0.580 (0.619) Remain 12:36:50 loss: 7.5535 mask_loss: 7.0754 roll_mask_loss: 7.4471 density_loss: 8.6488 unmask_loss: 7.6728 Lr: 0.00064
[2025-12-10 17:04:11,745 INFO misc.py line 117 4140988] Train: [1/10][624/7400] Data 0.004 (0.004) Batch 0.621 (0.619) Remain 12:36:50 loss: 7.7092 mask_loss: 7.3045 roll_mask_loss: 7.5977 density_loss: 8.7749 unmask_loss: 7.7918 Lr: 0.00065
[2025-12-10 17:04:12,386 INFO misc.py line 117 4140988] Train: [1/10][625/7400] Data 0.003 (0.004) Batch 0.640 (0.619) Remain 12:36:52 loss: 7.5353 mask_loss: 6.9362 roll_mask_loss: 7.4062 density_loss: 8.2417 unmask_loss: 7.7345 Lr: 0.00065
[2025-12-10 17:04:13,060 INFO misc.py line 117 4140988] Train: [1/10][626/7400] Data 0.004 (0.004) Batch 0.674 (0.619) Remain 12:36:58 loss: 7.6159 mask_loss: 6.6516 roll_mask_loss: 7.5299 density_loss: 8.5324 unmask_loss: 7.9703 Lr: 0.00065
[2025-12-10 17:04:13,667 INFO misc.py line 117 4140988] Train: [1/10][627/7400] Data 0.004 (0.004) Batch 0.606 (0.619) Remain 12:36:56 loss: 8.0664 mask_loss: 7.5768 roll_mask_loss: 8.1844 density_loss: 8.2475 unmask_loss: 8.0871 Lr: 0.00065
[2025-12-10 17:04:14,359 INFO misc.py line 117 4140988] Train: [1/10][628/7400] Data 0.004 (0.004) Batch 0.692 (0.619) Remain 12:37:04 loss: 7.4905 mask_loss: 6.9185 roll_mask_loss: 7.5015 density_loss: 9.0291 unmask_loss: 7.5904 Lr: 0.00065
[2025-12-10 17:04:15,103 INFO misc.py line 117 4140988] Train: [1/10][629/7400] Data 0.004 (0.004) Batch 0.745 (0.619) Remain 12:37:18 loss: 7.5064 mask_loss: 6.7804 roll_mask_loss: 7.4533 density_loss: 8.7260 unmask_loss: 7.7215 Lr: 0.00065
[2025-12-10 17:04:15,712 INFO misc.py line 117 4140988] Train: [1/10][630/7400] Data 0.003 (0.004) Batch 0.608 (0.619) Remain 12:37:16 loss: 7.5541 mask_loss: 6.9324 roll_mask_loss: 7.5646 density_loss: 8.1994 unmask_loss: 7.6957 Lr: 0.00065
[2025-12-10 17:04:16,229 INFO misc.py line 117 4140988] Train: [1/10][631/7400] Data 0.004 (0.004) Batch 0.517 (0.619) Remain 12:37:03 loss: 7.6963 mask_loss: 7.2023 roll_mask_loss: 7.5023 density_loss: 8.9030 unmask_loss: 7.8624 Lr: 0.00065
[2025-12-10 17:04:16,553 INFO misc.py line 117 4140988] Train: [1/10][632/7400] Data 0.004 (0.004) Batch 0.324 (0.619) Remain 12:36:28 loss: 7.7447 mask_loss: 7.1826 roll_mask_loss: 7.6394 density_loss: 8.7468 unmask_loss: 7.9035 Lr: 0.00065
[2025-12-10 17:04:17,188 INFO misc.py line 117 4140988] Train: [1/10][633/7400] Data 0.004 (0.004) Batch 0.635 (0.619) Remain 12:36:30 loss: 7.4678 mask_loss: 6.8255 roll_mask_loss: 7.5145 density_loss: 8.9682 unmask_loss: 7.5863 Lr: 0.00065
[2025-12-10 17:04:17,806 INFO misc.py line 117 4140988] Train: [1/10][634/7400] Data 0.004 (0.004) Batch 0.618 (0.619) Remain 12:36:29 loss: 7.4240 mask_loss: 6.7664 roll_mask_loss: 7.3146 density_loss: 8.9318 unmask_loss: 7.6289 Lr: 0.00065
[2025-12-10 17:04:18,317 INFO misc.py line 117 4140988] Train: [1/10][635/7400] Data 0.004 (0.004) Batch 0.510 (0.619) Remain 12:36:16 loss: 8.2312 mask_loss: 7.7643 roll_mask_loss: 8.2778 density_loss: 8.7719 unmask_loss: 8.2660 Lr: 0.00065
[2025-12-10 17:04:18,939 INFO misc.py line 117 4140988] Train: [1/10][636/7400] Data 0.004 (0.004) Batch 0.623 (0.619) Remain 12:36:16 loss: 7.9245 mask_loss: 7.4451 roll_mask_loss: 7.9199 density_loss: 9.1974 unmask_loss: 7.9825 Lr: 0.00065
[2025-12-10 17:04:19,554 INFO misc.py line 117 4140988] Train: [1/10][637/7400] Data 0.004 (0.004) Batch 0.614 (0.619) Remain 12:36:15 loss: 7.6272 mask_loss: 7.1613 roll_mask_loss: 7.6400 density_loss: 8.6122 unmask_loss: 7.6815 Lr: 0.00066
[2025-12-10 17:04:20,230 INFO misc.py line 117 4140988] Train: [1/10][638/7400] Data 0.004 (0.004) Batch 0.676 (0.619) Remain 12:36:21 loss: 8.2276 mask_loss: 7.7310 roll_mask_loss: 8.2926 density_loss: 8.6904 unmask_loss: 8.2695 Lr: 0.00066
[2025-12-10 17:04:20,870 INFO misc.py line 117 4140988] Train: [1/10][639/7400] Data 0.004 (0.004) Batch 0.640 (0.619) Remain 12:36:23 loss: 7.4374 mask_loss: 6.8964 roll_mask_loss: 7.3311 density_loss: 8.6165 unmask_loss: 7.5888 Lr: 0.00066
[2025-12-10 17:04:21,349 INFO misc.py line 117 4140988] Train: [1/10][640/7400] Data 0.004 (0.004) Batch 0.479 (0.618) Remain 12:36:06 loss: 8.4373 mask_loss: 8.2970 roll_mask_loss: 8.3631 density_loss: 8.3767 unmask_loss: 8.3771 Lr: 0.00066
[2025-12-10 17:04:21,966 INFO misc.py line 117 4140988] Train: [1/10][641/7400] Data 0.004 (0.004) Batch 0.617 (0.618) Remain 12:36:05 loss: 7.3587 mask_loss: 6.6912 roll_mask_loss: 7.3850 density_loss: 8.8638 unmask_loss: 7.5021 Lr: 0.00066
[2025-12-10 17:04:22,489 INFO misc.py line 117 4140988] Train: [1/10][642/7400] Data 0.004 (0.004) Batch 0.524 (0.618) Remain 12:35:53 loss: 7.9794 mask_loss: 7.6268 roll_mask_loss: 8.0025 density_loss: 8.7039 unmask_loss: 7.9700 Lr: 0.00066
[2025-12-10 17:04:23,082 INFO misc.py line 117 4140988] Train: [1/10][643/7400] Data 0.003 (0.004) Batch 0.593 (0.618) Remain 12:35:50 loss: 7.6254 mask_loss: 6.7230 roll_mask_loss: 7.6022 density_loss: 9.4064 unmask_loss: 7.9001 Lr: 0.00066
[2025-12-10 17:04:23,926 INFO misc.py line 117 4140988] Train: [1/10][644/7400] Data 0.003 (0.004) Batch 0.844 (0.619) Remain 12:36:15 loss: 7.4368 mask_loss: 6.6018 roll_mask_loss: 7.3634 density_loss: 9.3705 unmask_loss: 7.7036 Lr: 0.00066
[2025-12-10 17:04:24,420 INFO misc.py line 117 4140988] Train: [1/10][645/7400] Data 0.003 (0.004) Batch 0.493 (0.618) Remain 12:36:00 loss: 8.1060 mask_loss: 7.7738 roll_mask_loss: 8.0005 density_loss: 8.3950 unmask_loss: 8.1569 Lr: 0.00066
[2025-12-10 17:04:24,976 INFO misc.py line 117 4140988] Train: [1/10][646/7400] Data 0.004 (0.004) Batch 0.556 (0.618) Remain 12:35:53 loss: 7.3364 mask_loss: 6.7043 roll_mask_loss: 7.1930 density_loss: 9.0608 unmask_loss: 7.5430 Lr: 0.00066
[2025-12-10 17:04:25,817 INFO misc.py line 117 4140988] Train: [1/10][647/7400] Data 0.004 (0.004) Batch 0.841 (0.619) Remain 12:36:17 loss: 7.3535 mask_loss: 6.7894 roll_mask_loss: 7.2622 density_loss: 8.4029 unmask_loss: 7.5131 Lr: 0.00066
[2025-12-10 17:04:26,555 INFO misc.py line 117 4140988] Train: [1/10][648/7400] Data 0.004 (0.004) Batch 0.738 (0.619) Remain 12:36:30 loss: 7.4400 mask_loss: 6.9368 roll_mask_loss: 7.3269 density_loss: 9.0343 unmask_loss: 7.5675 Lr: 0.00066
[2025-12-10 17:04:27,225 INFO misc.py line 117 4140988] Train: [1/10][649/7400] Data 0.004 (0.004) Batch 0.670 (0.619) Remain 12:36:35 loss: 7.4053 mask_loss: 6.8405 roll_mask_loss: 7.3119 density_loss: 8.3631 unmask_loss: 7.5672 Lr: 0.00066
[2025-12-10 17:04:27,854 INFO misc.py line 117 4140988] Train: [1/10][650/7400] Data 0.004 (0.004) Batch 0.629 (0.619) Remain 12:36:36 loss: 8.1152 mask_loss: 7.7118 roll_mask_loss: 8.0678 density_loss: 8.5700 unmask_loss: 8.1692 Lr: 0.00067
[2025-12-10 17:04:28,607 INFO misc.py line 117 4140988] Train: [1/10][651/7400] Data 0.004 (0.004) Batch 0.753 (0.619) Remain 12:36:51 loss: 7.3157 mask_loss: 6.6932 roll_mask_loss: 7.1770 density_loss: 8.4548 unmask_loss: 7.5272 Lr: 0.00067
[2025-12-10 17:04:29,361 INFO misc.py line 117 4140988] Train: [1/10][652/7400] Data 0.004 (0.004) Batch 0.755 (0.619) Remain 12:37:05 loss: 7.4436 mask_loss: 6.7708 roll_mask_loss: 7.3764 density_loss: 8.8168 unmask_loss: 7.6373 Lr: 0.00067
[2025-12-10 17:04:29,796 INFO misc.py line 117 4140988] Train: [1/10][653/7400] Data 0.003 (0.004) Batch 0.434 (0.619) Remain 12:36:44 loss: 8.4412 mask_loss: 8.2832 roll_mask_loss: 8.4450 density_loss: 8.4294 unmask_loss: 8.3497 Lr: 0.00067
[2025-12-10 17:04:30,126 INFO misc.py line 117 4140988] Train: [1/10][654/7400] Data 0.004 (0.004) Batch 0.330 (0.619) Remain 12:36:11 loss: 7.4963 mask_loss: 6.8028 roll_mask_loss: 7.5363 density_loss: 9.2121 unmask_loss: 7.6388 Lr: 0.00067
[2025-12-10 17:04:30,602 INFO misc.py line 117 4140988] Train: [1/10][655/7400] Data 0.004 (0.004) Batch 0.476 (0.618) Remain 12:35:54 loss: 7.4619 mask_loss: 6.8331 roll_mask_loss: 7.4004 density_loss: 8.3700 unmask_loss: 7.6396 Lr: 0.00067
[2025-12-10 17:04:30,910 INFO misc.py line 117 4140988] Train: [1/10][656/7400] Data 0.004 (0.004) Batch 0.309 (0.618) Remain 12:35:18 loss: 8.4138 mask_loss: 8.2976 roll_mask_loss: 8.3596 density_loss: 8.3575 unmask_loss: 8.3319 Lr: 0.00067
[2025-12-10 17:04:31,462 INFO misc.py line 117 4140988] Train: [1/10][657/7400] Data 0.004 (0.004) Batch 0.552 (0.618) Remain 12:35:10 loss: 7.6976 mask_loss: 7.2475 roll_mask_loss: 7.5468 density_loss: 8.5987 unmask_loss: 7.8260 Lr: 0.00067
[2025-12-10 17:04:32,042 INFO misc.py line 117 4140988] Train: [1/10][658/7400] Data 0.004 (0.004) Batch 0.580 (0.618) Remain 12:35:06 loss: 7.4713 mask_loss: 6.8948 roll_mask_loss: 7.3330 density_loss: 8.7940 unmask_loss: 7.6529 Lr: 0.00067
[2025-12-10 17:04:32,569 INFO misc.py line 117 4140988] Train: [1/10][659/7400] Data 0.004 (0.004) Batch 0.528 (0.618) Remain 12:34:55 loss: 8.1427 mask_loss: 7.4916 roll_mask_loss: 8.1808 density_loss: 8.7161 unmask_loss: 8.2748 Lr: 0.00067
[2025-12-10 17:04:33,155 INFO misc.py line 117 4140988] Train: [1/10][660/7400] Data 0.003 (0.004) Batch 0.586 (0.618) Remain 12:34:51 loss: 7.3913 mask_loss: 6.7822 roll_mask_loss: 7.2750 density_loss: 8.4497 unmask_loss: 7.5849 Lr: 0.00067
[2025-12-10 17:04:33,871 INFO misc.py line 117 4140988] Train: [1/10][661/7400] Data 0.003 (0.004) Batch 0.716 (0.618) Remain 12:35:01 loss: 7.4958 mask_loss: 6.6397 roll_mask_loss: 7.4125 density_loss: 9.4391 unmask_loss: 7.7768 Lr: 0.00067
[2025-12-10 17:04:34,743 INFO misc.py line 117 4140988] Train: [1/10][662/7400] Data 0.004 (0.004) Batch 0.872 (0.618) Remain 12:35:29 loss: 7.3240 mask_loss: 6.8168 roll_mask_loss: 7.2333 density_loss: 8.7898 unmask_loss: 7.4471 Lr: 0.00068
[2025-12-10 17:04:35,486 INFO misc.py line 117 4140988] Train: [1/10][663/7400] Data 0.004 (0.004) Batch 0.743 (0.618) Remain 12:35:42 loss: 7.4516 mask_loss: 6.8351 roll_mask_loss: 7.4127 density_loss: 8.4858 unmask_loss: 7.6096 Lr: 0.00068
[2025-12-10 17:04:35,940 INFO misc.py line 117 4140988] Train: [1/10][664/7400] Data 0.004 (0.004) Batch 0.453 (0.618) Remain 12:35:23 loss: 8.0707 mask_loss: 7.5777 roll_mask_loss: 8.1688 density_loss: 8.5205 unmask_loss: 8.0978 Lr: 0.00068
[2025-12-10 17:04:36,550 INFO misc.py line 117 4140988] Train: [1/10][665/7400] Data 0.003 (0.004) Batch 0.610 (0.618) Remain 12:35:22 loss: 7.9955 mask_loss: 7.5699 roll_mask_loss: 7.8907 density_loss: 8.6426 unmask_loss: 8.0879 Lr: 0.00068
[2025-12-10 17:04:37,186 INFO misc.py line 117 4140988] Train: [1/10][666/7400] Data 0.004 (0.004) Batch 0.637 (0.618) Remain 12:35:23 loss: 7.4863 mask_loss: 6.9366 roll_mask_loss: 7.4317 density_loss: 8.2700 unmask_loss: 7.6231 Lr: 0.00068
[2025-12-10 17:04:37,931 INFO misc.py line 117 4140988] Train: [1/10][667/7400] Data 0.003 (0.004) Batch 0.743 (0.618) Remain 12:35:36 loss: 7.4845 mask_loss: 6.8551 roll_mask_loss: 7.3641 density_loss: 8.5585 unmask_loss: 7.6882 Lr: 0.00068
[2025-12-10 17:04:38,545 INFO misc.py line 117 4140988] Train: [1/10][668/7400] Data 0.004 (0.004) Batch 0.614 (0.618) Remain 12:35:35 loss: 7.9575 mask_loss: 7.4187 roll_mask_loss: 7.9443 density_loss: 8.6301 unmask_loss: 8.0610 Lr: 0.00068
[2025-12-10 17:04:39,224 INFO misc.py line 117 4140988] Train: [1/10][669/7400] Data 0.004 (0.004) Batch 0.679 (0.618) Remain 12:35:41 loss: 7.5445 mask_loss: 7.0875 roll_mask_loss: 7.6541 density_loss: 8.8366 unmask_loss: 7.5416 Lr: 0.00068
[2025-12-10 17:04:39,850 INFO misc.py line 117 4140988] Train: [1/10][670/7400] Data 0.004 (0.004) Batch 0.626 (0.618) Remain 12:35:42 loss: 7.8922 mask_loss: 7.2617 roll_mask_loss: 7.8508 density_loss: 8.3910 unmask_loss: 8.0603 Lr: 0.00068
[2025-12-10 17:04:40,551 INFO misc.py line 117 4140988] Train: [1/10][671/7400] Data 0.004 (0.004) Batch 0.701 (0.618) Remain 12:35:50 loss: 7.4255 mask_loss: 6.6700 roll_mask_loss: 7.4422 density_loss: 9.5188 unmask_loss: 7.6046 Lr: 0.00068
[2025-12-10 17:04:41,378 INFO misc.py line 117 4140988] Train: [1/10][672/7400] Data 0.004 (0.004) Batch 0.827 (0.619) Remain 12:36:12 loss: 7.4664 mask_loss: 6.6046 roll_mask_loss: 7.4007 density_loss: 9.3120 unmask_loss: 7.7440 Lr: 0.00068
[2025-12-10 17:04:41,906 INFO misc.py line 117 4140988] Train: [1/10][673/7400] Data 0.003 (0.004) Batch 0.528 (0.619) Remain 12:36:02 loss: 8.4571 mask_loss: 8.2931 roll_mask_loss: 8.4177 density_loss: 8.4252 unmask_loss: 8.3904 Lr: 0.00068
[2025-12-10 17:04:42,503 INFO misc.py line 117 4140988] Train: [1/10][674/7400] Data 0.004 (0.004) Batch 0.597 (0.619) Remain 12:35:59 loss: 7.3613 mask_loss: 6.7658 roll_mask_loss: 7.1113 density_loss: 9.0168 unmask_loss: 7.6037 Lr: 0.00069
[2025-12-10 17:04:43,012 INFO misc.py line 117 4140988] Train: [1/10][675/7400] Data 0.004 (0.004) Batch 0.509 (0.618) Remain 12:35:46 loss: 8.0150 mask_loss: 7.6599 roll_mask_loss: 8.0172 density_loss: 8.5726 unmask_loss: 8.0200 Lr: 0.00069
[2025-12-10 17:04:43,592 INFO misc.py line 117 4140988] Train: [1/10][676/7400] Data 0.003 (0.004) Batch 0.581 (0.618) Remain 12:35:41 loss: 8.0520 mask_loss: 7.2100 roll_mask_loss: 8.5990 density_loss: 8.5986 unmask_loss: 8.0275 Lr: 0.00069
[2025-12-10 17:04:44,194 INFO misc.py line 117 4140988] Train: [1/10][677/7400] Data 0.003 (0.004) Batch 0.601 (0.618) Remain 12:35:39 loss: 7.3956 mask_loss: 6.7857 roll_mask_loss: 7.2596 density_loss: 9.2985 unmask_loss: 7.5826 Lr: 0.00069
[2025-12-10 17:04:44,831 INFO misc.py line 117 4140988] Train: [1/10][678/7400] Data 0.004 (0.004) Batch 0.638 (0.618) Remain 12:35:40 loss: 8.0381 mask_loss: 7.7583 roll_mask_loss: 7.9152 density_loss: 8.6758 unmask_loss: 8.0659 Lr: 0.00069
[2025-12-10 17:04:45,385 INFO misc.py line 117 4140988] Train: [1/10][679/7400] Data 0.003 (0.004) Batch 0.554 (0.618) Remain 12:35:33 loss: 7.5372 mask_loss: 6.9558 roll_mask_loss: 7.4257 density_loss: 8.3838 unmask_loss: 7.7160 Lr: 0.00069
[2025-12-10 17:04:46,173 INFO misc.py line 117 4140988] Train: [1/10][680/7400] Data 0.003 (0.004) Batch 0.788 (0.619) Remain 12:35:51 loss: 7.3468 mask_loss: 6.7754 roll_mask_loss: 7.2024 density_loss: 8.8759 unmask_loss: 7.5272 Lr: 0.00069
[2025-12-10 17:04:46,871 INFO misc.py line 117 4140988] Train: [1/10][681/7400] Data 0.003 (0.004) Batch 0.697 (0.619) Remain 12:35:58 loss: 7.5484 mask_loss: 6.5860 roll_mask_loss: 8.1297 density_loss: 8.9717 unmask_loss: 7.5595 Lr: 0.00069
[2025-12-10 17:04:47,638 INFO misc.py line 117 4140988] Train: [1/10][682/7400] Data 0.004 (0.004) Batch 0.767 (0.619) Remain 12:36:14 loss: 7.5476 mask_loss: 6.5889 roll_mask_loss: 7.4635 density_loss: 9.4478 unmask_loss: 7.8801 Lr: 0.00069
[2025-12-10 17:04:48,236 INFO misc.py line 117 4140988] Train: [1/10][683/7400] Data 0.004 (0.004) Batch 0.598 (0.619) Remain 12:36:11 loss: 7.4491 mask_loss: 6.8279 roll_mask_loss: 7.4003 density_loss: 8.8082 unmask_loss: 7.6078 Lr: 0.00069
[2025-12-10 17:04:48,879 INFO misc.py line 117 4140988] Train: [1/10][684/7400] Data 0.004 (0.004) Batch 0.643 (0.619) Remain 12:36:13 loss: 7.3998 mask_loss: 6.8176 roll_mask_loss: 7.2876 density_loss: 9.0778 unmask_loss: 7.5655 Lr: 0.00069
[2025-12-10 17:04:49,637 INFO misc.py line 117 4140988] Train: [1/10][685/7400] Data 0.004 (0.004) Batch 0.758 (0.619) Remain 12:36:27 loss: 7.5876 mask_loss: 6.8977 roll_mask_loss: 7.6466 density_loss: 9.1779 unmask_loss: 7.7195 Lr: 0.00069
[2025-12-10 17:04:50,309 INFO misc.py line 117 4140988] Train: [1/10][686/7400] Data 0.004 (0.004) Batch 0.673 (0.619) Remain 12:36:32 loss: 7.7528 mask_loss: 7.1076 roll_mask_loss: 7.6224 density_loss: 8.3367 unmask_loss: 7.9739 Lr: 0.00070
[2025-12-10 17:04:50,820 INFO misc.py line 117 4140988] Train: [1/10][687/7400] Data 0.004 (0.004) Batch 0.510 (0.619) Remain 12:36:20 loss: 7.7808 mask_loss: 7.2529 roll_mask_loss: 7.6854 density_loss: 8.5720 unmask_loss: 7.9210 Lr: 0.00070
[2025-12-10 17:04:51,336 INFO misc.py line 117 4140988] Train: [1/10][688/7400] Data 0.003 (0.004) Batch 0.517 (0.619) Remain 12:36:09 loss: 8.1702 mask_loss: 7.8063 roll_mask_loss: 8.0495 density_loss: 8.5958 unmask_loss: 8.2405 Lr: 0.00070
[2025-12-10 17:04:51,682 INFO misc.py line 117 4140988] Train: [1/10][689/7400] Data 0.003 (0.004) Batch 0.345 (0.618) Remain 12:35:39 loss: 7.5220 mask_loss: 6.8715 roll_mask_loss: 7.3402 density_loss: 8.8493 unmask_loss: 7.7611 Lr: 0.00070
[2025-12-10 17:04:52,233 INFO misc.py line 117 4140988] Train: [1/10][690/7400] Data 0.004 (0.004) Batch 0.551 (0.618) Remain 12:35:31 loss: 8.2936 mask_loss: 8.0246 roll_mask_loss: 8.3400 density_loss: 8.4551 unmask_loss: 8.2358 Lr: 0.00070
[2025-12-10 17:04:52,781 INFO misc.py line 117 4140988] Train: [1/10][691/7400] Data 0.003 (0.004) Batch 0.548 (0.618) Remain 12:35:23 loss: 8.4546 mask_loss: 8.2618 roll_mask_loss: 8.4020 density_loss: 8.3717 unmask_loss: 8.4098 Lr: 0.00070
[2025-12-10 17:04:53,578 INFO misc.py line 117 4140988] Train: [1/10][692/7400] Data 0.003 (0.004) Batch 0.798 (0.619) Remain 12:35:41 loss: 7.5887 mask_loss: 7.0404 roll_mask_loss: 7.4925 density_loss: 8.8151 unmask_loss: 7.7346 Lr: 0.00070
[2025-12-10 17:04:54,615 INFO misc.py line 117 4140988] Train: [1/10][693/7400] Data 0.003 (0.004) Batch 1.036 (0.619) Remain 12:36:25 loss: 7.4683 mask_loss: 6.5768 roll_mask_loss: 7.2695 density_loss: 9.1441 unmask_loss: 7.8305 Lr: 0.00070
[2025-12-10 17:04:55,314 INFO misc.py line 117 4140988] Train: [1/10][694/7400] Data 0.004 (0.004) Batch 0.699 (0.619) Remain 12:36:33 loss: 7.4380 mask_loss: 6.8697 roll_mask_loss: 7.2950 density_loss: 8.4593 unmask_loss: 7.6244 Lr: 0.00070
[2025-12-10 17:04:55,993 INFO misc.py line 117 4140988] Train: [1/10][695/7400] Data 0.004 (0.004) Batch 0.679 (0.619) Remain 12:36:39 loss: 7.6228 mask_loss: 7.1645 roll_mask_loss: 7.5483 density_loss: 8.5017 unmask_loss: 7.7191 Lr: 0.00070
[2025-12-10 17:04:56,559 INFO misc.py line 117 4140988] Train: [1/10][696/7400] Data 0.004 (0.004) Batch 0.566 (0.619) Remain 12:36:32 loss: 7.4072 mask_loss: 6.8672 roll_mask_loss: 7.2582 density_loss: 8.5995 unmask_loss: 7.5797 Lr: 0.00070
[2025-12-10 17:04:57,072 INFO misc.py line 117 4140988] Train: [1/10][697/7400] Data 0.003 (0.004) Batch 0.513 (0.619) Remain 12:36:21 loss: 8.3931 mask_loss: 8.0208 roll_mask_loss: 8.4457 density_loss: 8.5140 unmask_loss: 8.3827 Lr: 0.00070
[2025-12-10 17:04:57,737 INFO misc.py line 117 4140988] Train: [1/10][698/7400] Data 0.004 (0.004) Batch 0.665 (0.619) Remain 12:36:25 loss: 7.6551 mask_loss: 7.0698 roll_mask_loss: 7.8580 density_loss: 8.4255 unmask_loss: 7.6778 Lr: 0.00071
[2025-12-10 17:04:58,408 INFO misc.py line 117 4140988] Train: [1/10][699/7400] Data 0.003 (0.004) Batch 0.671 (0.619) Remain 12:36:30 loss: 7.4829 mask_loss: 6.8944 roll_mask_loss: 7.3322 density_loss: 8.4412 unmask_loss: 7.6837 Lr: 0.00071
[2025-12-10 17:04:59,112 INFO misc.py line 117 4140988] Train: [1/10][700/7400] Data 0.004 (0.004) Batch 0.704 (0.619) Remain 12:36:38 loss: 7.3743 mask_loss: 6.6860 roll_mask_loss: 7.2175 density_loss: 8.9800 unmask_loss: 7.6172 Lr: 0.00071
[2025-12-10 17:04:59,765 INFO misc.py line 117 4140988] Train: [1/10][701/7400] Data 0.004 (0.004) Batch 0.652 (0.619) Remain 12:36:41 loss: 7.4845 mask_loss: 6.8834 roll_mask_loss: 7.2612 density_loss: 8.8874 unmask_loss: 7.7188 Lr: 0.00071
[2025-12-10 17:05:00,240 INFO misc.py line 117 4140988] Train: [1/10][702/7400] Data 0.004 (0.004) Batch 0.475 (0.619) Remain 12:36:25 loss: 7.8901 mask_loss: 7.4829 roll_mask_loss: 7.9395 density_loss: 8.4294 unmask_loss: 7.9004 Lr: 0.00071
[2025-12-10 17:05:01,031 INFO misc.py line 117 4140988] Train: [1/10][703/7400] Data 0.004 (0.004) Batch 0.791 (0.619) Remain 12:36:42 loss: 7.6745 mask_loss: 6.5494 roll_mask_loss: 8.0323 density_loss: 8.8972 unmask_loss: 7.8802 Lr: 0.00071
[2025-12-10 17:05:01,642 INFO misc.py line 117 4140988] Train: [1/10][704/7400] Data 0.004 (0.004) Batch 0.611 (0.619) Remain 12:36:41 loss: 7.6989 mask_loss: 7.2361 roll_mask_loss: 7.6205 density_loss: 8.2984 unmask_loss: 7.8035 Lr: 0.00071
[2025-12-10 17:05:02,594 INFO misc.py line 117 4140988] Train: [1/10][705/7400] Data 0.004 (0.004) Batch 0.952 (0.620) Remain 12:37:15 loss: 7.5016 mask_loss: 6.5919 roll_mask_loss: 7.4431 density_loss: 9.2515 unmask_loss: 7.8007 Lr: 0.00071
[2025-12-10 17:05:03,291 INFO misc.py line 117 4140988] Train: [1/10][706/7400] Data 0.004 (0.004) Batch 0.698 (0.620) Remain 12:37:22 loss: 7.4999 mask_loss: 6.8233 roll_mask_loss: 7.4077 density_loss: 7.8974 unmask_loss: 7.7264 Lr: 0.00071
[2025-12-10 17:05:04,084 INFO misc.py line 117 4140988] Train: [1/10][707/7400] Data 0.004 (0.004) Batch 0.793 (0.620) Remain 12:37:40 loss: 7.2626 mask_loss: 6.5231 roll_mask_loss: 7.0246 density_loss: 9.2868 unmask_loss: 7.5656 Lr: 0.00071
[2025-12-10 17:05:04,698 INFO misc.py line 117 4140988] Train: [1/10][708/7400] Data 0.003 (0.004) Batch 0.615 (0.620) Remain 12:37:39 loss: 7.5183 mask_loss: 7.0518 roll_mask_loss: 7.4963 density_loss: 8.4250 unmask_loss: 7.5940 Lr: 0.00071
[2025-12-10 17:05:05,189 INFO misc.py line 117 4140988] Train: [1/10][709/7400] Data 0.003 (0.004) Batch 0.490 (0.620) Remain 12:37:25 loss: 7.8667 mask_loss: 7.3294 roll_mask_loss: 7.7247 density_loss: 8.9234 unmask_loss: 8.0280 Lr: 0.00071
[2025-12-10 17:05:05,547 INFO misc.py line 117 4140988] Train: [1/10][710/7400] Data 0.004 (0.004) Batch 0.357 (0.620) Remain 12:36:57 loss: 7.9616 mask_loss: 7.2390 roll_mask_loss: 7.8420 density_loss: 8.2908 unmask_loss: 8.2169 Lr: 0.00072
[2025-12-10 17:05:06,187 INFO misc.py line 117 4140988] Train: [1/10][711/7400] Data 0.004 (0.004) Batch 0.639 (0.620) Remain 12:36:58 loss: 7.4380 mask_loss: 6.8038 roll_mask_loss: 7.4355 density_loss: 8.4007 unmask_loss: 7.5883 Lr: 0.00072
[2025-12-10 17:05:06,870 INFO misc.py line 117 4140988] Train: [1/10][712/7400] Data 0.004 (0.004) Batch 0.684 (0.620) Remain 12:37:04 loss: 7.6291 mask_loss: 6.6968 roll_mask_loss: 7.7374 density_loss: 9.1320 unmask_loss: 7.8584 Lr: 0.00072
[2025-12-10 17:05:07,680 INFO misc.py line 117 4140988] Train: [1/10][713/7400] Data 0.004 (0.004) Batch 0.810 (0.620) Remain 12:37:23 loss: 7.3160 mask_loss: 6.6717 roll_mask_loss: 7.2628 density_loss: 9.0862 unmask_loss: 7.4830 Lr: 0.00072
[2025-12-10 17:05:08,332 INFO misc.py line 117 4140988] Train: [1/10][714/7400] Data 0.004 (0.004) Batch 0.652 (0.620) Remain 12:37:26 loss: 7.5533 mask_loss: 6.9576 roll_mask_loss: 7.6040 density_loss: 8.7103 unmask_loss: 7.6515 Lr: 0.00072
[2025-12-10 17:05:09,025 INFO misc.py line 117 4140988] Train: [1/10][715/7400] Data 0.004 (0.004) Batch 0.693 (0.620) Remain 12:37:33 loss: 7.2673 mask_loss: 6.5020 roll_mask_loss: 7.1366 density_loss: 8.4887 unmask_loss: 7.5454 Lr: 0.00072
[2025-12-10 17:05:09,606 INFO misc.py line 117 4140988] Train: [1/10][716/7400] Data 0.004 (0.004) Batch 0.581 (0.620) Remain 12:37:28 loss: 7.3379 mask_loss: 6.7814 roll_mask_loss: 7.1317 density_loss: 9.0209 unmask_loss: 7.5389 Lr: 0.00072
[2025-12-10 17:05:10,377 INFO misc.py line 117 4140988] Train: [1/10][717/7400] Data 0.003 (0.004) Batch 0.771 (0.620) Remain 12:37:43 loss: 7.3655 mask_loss: 6.7055 roll_mask_loss: 7.3754 density_loss: 8.5866 unmask_loss: 7.5187 Lr: 0.00072
[2025-12-10 17:05:11,013 INFO misc.py line 117 4140988] Train: [1/10][718/7400] Data 0.004 (0.004) Batch 0.635 (0.620) Remain 12:37:44 loss: 7.4612 mask_loss: 6.8776 roll_mask_loss: 7.4915 density_loss: 8.3443 unmask_loss: 7.5710 Lr: 0.00072
[2025-12-10 17:05:11,647 INFO misc.py line 117 4140988] Train: [1/10][719/7400] Data 0.004 (0.004) Batch 0.634 (0.620) Remain 12:37:45 loss: 7.7224 mask_loss: 7.0636 roll_mask_loss: 7.7040 density_loss: 9.2683 unmask_loss: 7.8756 Lr: 0.00072
[2025-12-10 17:05:12,389 INFO misc.py line 117 4140988] Train: [1/10][720/7400] Data 0.004 (0.004) Batch 0.743 (0.621) Remain 12:37:57 loss: 7.3972 mask_loss: 6.7470 roll_mask_loss: 7.4748 density_loss: 7.8388 unmask_loss: 7.5268 Lr: 0.00072
[2025-12-10 17:05:13,094 INFO misc.py line 117 4140988] Train: [1/10][721/7400] Data 0.003 (0.004) Batch 0.704 (0.621) Remain 12:38:05 loss: 7.3069 mask_loss: 6.6808 roll_mask_loss: 7.1220 density_loss: 8.6597 unmask_loss: 7.5392 Lr: 0.00073
[2025-12-10 17:05:13,752 INFO misc.py line 117 4140988] Train: [1/10][722/7400] Data 0.004 (0.004) Batch 0.657 (0.621) Remain 12:38:08 loss: 7.7564 mask_loss: 7.1761 roll_mask_loss: 7.7130 density_loss: 8.6014 unmask_loss: 7.8963 Lr: 0.00073
[2025-12-10 17:05:14,287 INFO misc.py line 117 4140988] Train: [1/10][723/7400] Data 0.004 (0.004) Batch 0.536 (0.621) Remain 12:37:58 loss: 7.3000 mask_loss: 6.6572 roll_mask_loss: 7.1250 density_loss: 8.7593 unmask_loss: 7.5336 Lr: 0.00073
[2025-12-10 17:05:15,036 INFO misc.py line 117 4140988] Train: [1/10][724/7400] Data 0.004 (0.004) Batch 0.749 (0.621) Remain 12:38:11 loss: 7.3693 mask_loss: 6.7054 roll_mask_loss: 7.3592 density_loss: 8.8684 unmask_loss: 7.5289 Lr: 0.00073
[2025-12-10 17:05:15,640 INFO misc.py line 117 4140988] Train: [1/10][725/7400] Data 0.004 (0.004) Batch 0.603 (0.621) Remain 12:38:08 loss: 7.6891 mask_loss: 6.9342 roll_mask_loss: 8.0859 density_loss: 8.7976 unmask_loss: 7.6923 Lr: 0.00073
[2025-12-10 17:05:16,172 INFO misc.py line 117 4140988] Train: [1/10][726/7400] Data 0.004 (0.004) Batch 0.533 (0.621) Remain 12:37:59 loss: 7.9781 mask_loss: 7.6046 roll_mask_loss: 8.0533 density_loss: 8.1108 unmask_loss: 7.9650 Lr: 0.00073
[2025-12-10 17:05:16,707 INFO misc.py line 117 4140988] Train: [1/10][727/7400] Data 0.004 (0.004) Batch 0.535 (0.621) Remain 12:37:49 loss: 7.5931 mask_loss: 6.9357 roll_mask_loss: 7.4831 density_loss: 8.0641 unmask_loss: 7.8156 Lr: 0.00073
[2025-12-10 17:05:17,280 INFO misc.py line 117 4140988] Train: [1/10][728/7400] Data 0.004 (0.004) Batch 0.574 (0.620) Remain 12:37:44 loss: 8.3994 mask_loss: 7.4826 roll_mask_loss: 8.5843 density_loss: 8.1368 unmask_loss: 8.6026 Lr: 0.00073
[2025-12-10 17:05:17,827 INFO misc.py line 117 4140988] Train: [1/10][729/7400] Data 0.003 (0.004) Batch 0.547 (0.620) Remain 12:37:36 loss: 8.1749 mask_loss: 7.9014 roll_mask_loss: 8.0736 density_loss: 8.4811 unmask_loss: 8.1927 Lr: 0.00073
[2025-12-10 17:05:18,270 INFO misc.py line 117 4140988] Train: [1/10][730/7400] Data 0.003 (0.004) Batch 0.443 (0.620) Remain 12:37:18 loss: 8.0041 mask_loss: 7.6428 roll_mask_loss: 7.9767 density_loss: 8.6327 unmask_loss: 8.0258 Lr: 0.00073
[2025-12-10 17:05:18,761 INFO misc.py line 117 4140988] Train: [1/10][731/7400] Data 0.003 (0.004) Batch 0.490 (0.620) Remain 12:37:04 loss: 7.5216 mask_loss: 6.9500 roll_mask_loss: 7.5622 density_loss: 8.8112 unmask_loss: 7.6108 Lr: 0.00073
[2025-12-10 17:05:19,222 INFO misc.py line 117 4140988] Train: [1/10][732/7400] Data 0.003 (0.004) Batch 0.462 (0.620) Remain 12:36:47 loss: 8.4306 mask_loss: 8.2734 roll_mask_loss: 8.3535 density_loss: 8.3594 unmask_loss: 8.3805 Lr: 0.00074
[2025-12-10 17:05:19,995 INFO misc.py line 117 4140988] Train: [1/10][733/7400] Data 0.003 (0.004) Batch 0.772 (0.620) Remain 12:37:02 loss: 7.4646 mask_loss: 6.7786 roll_mask_loss: 7.3686 density_loss: 9.0868 unmask_loss: 7.6738 Lr: 0.00074
[2025-12-10 17:05:20,430 INFO misc.py line 117 4140988] Train: [1/10][734/7400] Data 0.003 (0.004) Batch 0.436 (0.620) Remain 12:36:43 loss: 7.6983 mask_loss: 7.2208 roll_mask_loss: 7.4420 density_loss: 8.2901 unmask_loss: 7.8994 Lr: 0.00074
[2025-12-10 17:05:20,725 INFO misc.py line 117 4140988] Train: [1/10][735/7400] Data 0.003 (0.004) Batch 0.294 (0.619) Remain 12:36:10 loss: 7.9929 mask_loss: 6.8980 roll_mask_loss: 7.6238 density_loss: 8.5075 unmask_loss: 8.5547 Lr: 0.00074
[2025-12-10 17:05:21,547 INFO misc.py line 117 4140988] Train: [1/10][736/7400] Data 0.005 (0.004) Batch 0.822 (0.620) Remain 12:36:29 loss: 7.4369 mask_loss: 6.7173 roll_mask_loss: 7.3157 density_loss: 9.0083 unmask_loss: 7.6771 Lr: 0.00074
[2025-12-10 17:05:22,147 INFO misc.py line 117 4140988] Train: [1/10][737/7400] Data 0.003 (0.004) Batch 0.600 (0.620) Remain 12:36:27 loss: 8.0244 mask_loss: 7.6843 roll_mask_loss: 8.2149 density_loss: 8.3623 unmask_loss: 7.9319 Lr: 0.00074
[2025-12-10 17:05:22,752 INFO misc.py line 117 4140988] Train: [1/10][738/7400] Data 0.004 (0.004) Batch 0.605 (0.619) Remain 12:36:25 loss: 7.4847 mask_loss: 6.8532 roll_mask_loss: 7.2450 density_loss: 8.9976 unmask_loss: 7.7404 Lr: 0.00074
[2025-12-10 17:05:23,322 INFO misc.py line 117 4140988] Train: [1/10][739/7400] Data 0.004 (0.004) Batch 0.571 (0.619) Remain 12:36:19 loss: 8.4534 mask_loss: 8.3122 roll_mask_loss: 8.3936 density_loss: 8.3864 unmask_loss: 8.3862 Lr: 0.00074
[2025-12-10 17:05:23,809 INFO misc.py line 117 4140988] Train: [1/10][740/7400] Data 0.003 (0.004) Batch 0.488 (0.619) Remain 12:36:06 loss: 8.3873 mask_loss: 8.1944 roll_mask_loss: 8.3700 density_loss: 8.4229 unmask_loss: 8.3240 Lr: 0.00074
[2025-12-10 17:05:24,310 INFO misc.py line 117 4140988] Train: [1/10][741/7400] Data 0.003 (0.004) Batch 0.501 (0.619) Remain 12:35:53 loss: 7.8869 mask_loss: 7.6027 roll_mask_loss: 7.7806 density_loss: 8.2605 unmask_loss: 7.9169 Lr: 0.00074
[2025-12-10 17:05:24,871 INFO misc.py line 117 4140988] Train: [1/10][742/7400] Data 0.003 (0.004) Batch 0.560 (0.619) Remain 12:35:47 loss: 7.6623 mask_loss: 7.0978 roll_mask_loss: 7.8656 density_loss: 8.7062 unmask_loss: 7.6687 Lr: 0.00074
[2025-12-10 17:05:25,563 INFO misc.py line 117 4140988] Train: [1/10][743/7400] Data 0.004 (0.004) Batch 0.693 (0.619) Remain 12:35:53 loss: 7.4611 mask_loss: 6.7805 roll_mask_loss: 7.3973 density_loss: 9.0852 unmask_loss: 7.6517 Lr: 0.00074
[2025-12-10 17:05:26,061 INFO misc.py line 117 4140988] Train: [1/10][744/7400] Data 0.004 (0.004) Batch 0.498 (0.619) Remain 12:35:41 loss: 8.3130 mask_loss: 7.8089 roll_mask_loss: 8.4367 density_loss: 8.7011 unmask_loss: 8.3292 Lr: 0.00075
[2025-12-10 17:05:26,778 INFO misc.py line 117 4140988] Train: [1/10][745/7400] Data 0.004 (0.004) Batch 0.717 (0.619) Remain 12:35:50 loss: 7.5930 mask_loss: 7.0264 roll_mask_loss: 7.3675 density_loss: 8.6110 unmask_loss: 7.8168 Lr: 0.00075
[2025-12-10 17:05:27,298 INFO misc.py line 117 4140988] Train: [1/10][746/7400] Data 0.004 (0.004) Batch 0.519 (0.619) Remain 12:35:39 loss: 8.4009 mask_loss: 8.2210 roll_mask_loss: 8.3712 density_loss: 8.3898 unmask_loss: 8.3379 Lr: 0.00075
[2025-12-10 17:05:28,078 INFO misc.py line 117 4140988] Train: [1/10][747/7400] Data 0.004 (0.004) Batch 0.781 (0.619) Remain 12:35:55 loss: 7.3507 mask_loss: 6.7842 roll_mask_loss: 7.2249 density_loss: 8.5731 unmask_loss: 7.5255 Lr: 0.00075
[2025-12-10 17:05:28,579 INFO misc.py line 117 4140988] Train: [1/10][748/7400] Data 0.004 (0.004) Batch 0.501 (0.619) Remain 12:35:42 loss: 7.7648 mask_loss: 7.2651 roll_mask_loss: 7.6930 density_loss: 9.0377 unmask_loss: 7.8698 Lr: 0.00075
[2025-12-10 17:05:29,283 INFO misc.py line 117 4140988] Train: [1/10][749/7400] Data 0.004 (0.004) Batch 0.704 (0.619) Remain 12:35:50 loss: 7.5903 mask_loss: 6.7194 roll_mask_loss: 7.7016 density_loss: 8.9135 unmask_loss: 7.7919 Lr: 0.00075
[2025-12-10 17:05:30,041 INFO misc.py line 117 4140988] Train: [1/10][750/7400] Data 0.004 (0.004) Batch 0.758 (0.619) Remain 12:36:03 loss: 7.2708 mask_loss: 6.6038 roll_mask_loss: 7.0700 density_loss: 8.7215 unmask_loss: 7.5302 Lr: 0.00075
[2025-12-10 17:05:30,890 INFO misc.py line 117 4140988] Train: [1/10][751/7400] Data 0.004 (0.004) Batch 0.850 (0.620) Remain 12:36:25 loss: 7.2442 mask_loss: 6.5976 roll_mask_loss: 7.0825 density_loss: 8.7286 unmask_loss: 7.4737 Lr: 0.00075
[2025-12-10 17:05:31,616 INFO misc.py line 117 4140988] Train: [1/10][752/7400] Data 0.004 (0.004) Batch 0.726 (0.620) Remain 12:36:35 loss: 7.4014 mask_loss: 6.7704 roll_mask_loss: 7.3798 density_loss: 8.6654 unmask_loss: 7.5544 Lr: 0.00075
[2025-12-10 17:05:32,103 INFO misc.py line 117 4140988] Train: [1/10][753/7400] Data 0.003 (0.004) Batch 0.487 (0.620) Remain 12:36:21 loss: 7.6042 mask_loss: 7.0162 roll_mask_loss: 7.4356 density_loss: 8.7088 unmask_loss: 7.8083 Lr: 0.00075
[2025-12-10 17:05:32,882 INFO misc.py line 117 4140988] Train: [1/10][754/7400] Data 0.004 (0.004) Batch 0.779 (0.620) Remain 12:36:36 loss: 7.4032 mask_loss: 6.5477 roll_mask_loss: 7.4188 density_loss: 8.9590 unmask_loss: 7.6439 Lr: 0.00075
[2025-12-10 17:05:33,442 INFO misc.py line 117 4140988] Train: [1/10][755/7400] Data 0.004 (0.004) Batch 0.559 (0.620) Remain 12:36:30 loss: 8.2719 mask_loss: 7.5342 roll_mask_loss: 8.4490 density_loss: 8.9157 unmask_loss: 8.3740 Lr: 0.00076
[2025-12-10 17:05:33,749 INFO misc.py line 117 4140988] Train: [1/10][756/7400] Data 0.004 (0.004) Batch 0.308 (0.619) Remain 12:35:59 loss: 8.2178 mask_loss: 7.2774 roll_mask_loss: 9.1099 density_loss: 8.3668 unmask_loss: 8.0747 Lr: 0.00076
[2025-12-10 17:05:34,370 INFO misc.py line 117 4140988] Train: [1/10][757/7400] Data 0.004 (0.004) Batch 0.620 (0.619) Remain 12:35:58 loss: 7.4744 mask_loss: 6.9474 roll_mask_loss: 7.4731 density_loss: 8.2659 unmask_loss: 7.5732 Lr: 0.00076
[2025-12-10 17:05:34,961 INFO misc.py line 117 4140988] Train: [1/10][758/7400] Data 0.004 (0.004) Batch 0.591 (0.619) Remain 12:35:55 loss: 8.0625 mask_loss: 7.5748 roll_mask_loss: 8.2479 density_loss: 8.5528 unmask_loss: 8.0425 Lr: 0.00076
[2025-12-10 17:05:35,500 INFO misc.py line 117 4140988] Train: [1/10][759/7400] Data 0.004 (0.004) Batch 0.540 (0.619) Remain 12:35:47 loss: 8.2644 mask_loss: 8.0676 roll_mask_loss: 8.1837 density_loss: 8.5629 unmask_loss: 8.2319 Lr: 0.00076
[2025-12-10 17:05:36,063 INFO misc.py line 117 4140988] Train: [1/10][760/7400] Data 0.003 (0.004) Batch 0.563 (0.619) Remain 12:35:41 loss: 7.5781 mask_loss: 6.9370 roll_mask_loss: 7.5038 density_loss: 8.9304 unmask_loss: 7.7573 Lr: 0.00076
[2025-12-10 17:05:36,794 INFO misc.py line 117 4140988] Train: [1/10][761/7400] Data 0.003 (0.004) Batch 0.730 (0.619) Remain 12:35:51 loss: 7.6639 mask_loss: 6.9401 roll_mask_loss: 7.7724 density_loss: 8.9208 unmask_loss: 7.7931 Lr: 0.00076
[2025-12-10 17:05:37,457 INFO misc.py line 117 4140988] Train: [1/10][762/7400] Data 0.004 (0.004) Batch 0.663 (0.619) Remain 12:35:54 loss: 7.5389 mask_loss: 7.0365 roll_mask_loss: 7.5453 density_loss: 8.7147 unmask_loss: 7.6126 Lr: 0.00076
[2025-12-10 17:05:38,112 INFO misc.py line 117 4140988] Train: [1/10][763/7400] Data 0.004 (0.004) Batch 0.655 (0.619) Remain 12:35:57 loss: 7.9795 mask_loss: 7.5864 roll_mask_loss: 7.9887 density_loss: 8.4923 unmask_loss: 8.0017 Lr: 0.00076
[2025-12-10 17:05:38,413 INFO misc.py line 117 4140988] Train: [1/10][764/7400] Data 0.004 (0.004) Batch 0.302 (0.619) Remain 12:35:26 loss: 7.7868 mask_loss: 7.3847 roll_mask_loss: 7.7918 density_loss: 8.3957 unmask_loss: 7.8175 Lr: 0.00076
[2025-12-10 17:05:38,977 INFO misc.py line 117 4140988] Train: [1/10][765/7400] Data 0.004 (0.004) Batch 0.563 (0.619) Remain 12:35:20 loss: 7.8082 mask_loss: 7.2681 roll_mask_loss: 7.6088 density_loss: 8.4705 unmask_loss: 8.0085 Lr: 0.00076
[2025-12-10 17:05:39,754 INFO misc.py line 117 4140988] Train: [1/10][766/7400] Data 0.004 (0.004) Batch 0.777 (0.619) Remain 12:35:34 loss: 7.2995 mask_loss: 6.5631 roll_mask_loss: 7.0543 density_loss: 8.7663 unmask_loss: 7.6151 Lr: 0.00077
[2025-12-10 17:05:40,262 INFO misc.py line 117 4140988] Train: [1/10][767/7400] Data 0.004 (0.004) Batch 0.509 (0.619) Remain 12:35:23 loss: 8.0598 mask_loss: 7.7204 roll_mask_loss: 7.9985 density_loss: 8.3675 unmask_loss: 8.0928 Lr: 0.00077
[2025-12-10 17:05:40,820 INFO misc.py line 117 4140988] Train: [1/10][768/7400] Data 0.004 (0.004) Batch 0.557 (0.619) Remain 12:35:17 loss: 7.6443 mask_loss: 7.2157 roll_mask_loss: 7.7042 density_loss: 8.9167 unmask_loss: 7.6503 Lr: 0.00077
[2025-12-10 17:05:41,393 INFO misc.py line 117 4140988] Train: [1/10][769/7400] Data 0.004 (0.004) Batch 0.574 (0.619) Remain 12:35:12 loss: 7.4227 mask_loss: 6.7877 roll_mask_loss: 7.4452 density_loss: 9.2963 unmask_loss: 7.5431 Lr: 0.00077
[2025-12-10 17:05:41,920 INFO misc.py line 117 4140988] Train: [1/10][770/7400] Data 0.004 (0.004) Batch 0.526 (0.619) Remain 12:35:02 loss: 8.2373 mask_loss: 7.9214 roll_mask_loss: 8.0497 density_loss: 8.8527 unmask_loss: 8.3121 Lr: 0.00077
[2025-12-10 17:05:42,497 INFO misc.py line 117 4140988] Train: [1/10][771/7400] Data 0.004 (0.004) Batch 0.578 (0.619) Remain 12:34:58 loss: 7.9566 mask_loss: 7.4633 roll_mask_loss: 7.8209 density_loss: 8.1995 unmask_loss: 8.1070 Lr: 0.00077
[2025-12-10 17:05:43,105 INFO misc.py line 117 4140988] Train: [1/10][772/7400] Data 0.004 (0.004) Batch 0.608 (0.619) Remain 12:34:56 loss: 7.4778 mask_loss: 6.9731 roll_mask_loss: 7.4454 density_loss: 8.2844 unmask_loss: 7.5806 Lr: 0.00077
[2025-12-10 17:05:43,874 INFO misc.py line 117 4140988] Train: [1/10][773/7400] Data 0.004 (0.004) Batch 0.768 (0.619) Remain 12:35:10 loss: 7.4425 mask_loss: 6.7110 roll_mask_loss: 7.5619 density_loss: 8.7133 unmask_loss: 7.5742 Lr: 0.00077
[2025-12-10 17:05:44,416 INFO misc.py line 117 4140988] Train: [1/10][774/7400] Data 0.004 (0.004) Batch 0.542 (0.619) Remain 12:35:02 loss: 7.4460 mask_loss: 6.9184 roll_mask_loss: 7.4522 density_loss: 8.6220 unmask_loss: 7.5344 Lr: 0.00077
[2025-12-10 17:05:45,091 INFO misc.py line 117 4140988] Train: [1/10][775/7400] Data 0.004 (0.004) Batch 0.676 (0.619) Remain 12:35:07 loss: 7.3918 mask_loss: 6.8095 roll_mask_loss: 7.2759 density_loss: 8.5249 unmask_loss: 7.5704 Lr: 0.00077
[2025-12-10 17:05:45,900 INFO misc.py line 117 4140988] Train: [1/10][776/7400] Data 0.004 (0.004) Batch 0.809 (0.619) Remain 12:35:24 loss: 7.2638 mask_loss: 6.4709 roll_mask_loss: 7.2198 density_loss: 8.9082 unmask_loss: 7.5041 Lr: 0.00078
[2025-12-10 17:05:46,423 INFO misc.py line 117 4140988] Train: [1/10][777/7400] Data 0.004 (0.004) Batch 0.523 (0.619) Remain 12:35:14 loss: 8.1434 mask_loss: 7.8460 roll_mask_loss: 8.1300 density_loss: 8.6181 unmask_loss: 8.1265 Lr: 0.00078
[2025-12-10 17:05:46,696 INFO misc.py line 117 4140988] Train: [1/10][778/7400] Data 0.004 (0.004) Batch 0.273 (0.618) Remain 12:34:41 loss: 8.5442 mask_loss: 8.4300 roll_mask_loss: 8.5025 density_loss: 8.4968 unmask_loss: 8.4522 Lr: 0.00078
[2025-12-10 17:05:47,234 INFO misc.py line 117 4140988] Train: [1/10][779/7400] Data 0.003 (0.004) Batch 0.537 (0.618) Remain 12:34:33 loss: 8.1929 mask_loss: 7.7803 roll_mask_loss: 8.2679 density_loss: 8.5360 unmask_loss: 8.1911 Lr: 0.00078
[2025-12-10 17:05:48,031 INFO misc.py line 117 4140988] Train: [1/10][780/7400] Data 0.004 (0.004) Batch 0.797 (0.619) Remain 12:34:49 loss: 7.4963 mask_loss: 6.9133 roll_mask_loss: 7.3502 density_loss: 8.9735 unmask_loss: 7.6814 Lr: 0.00078
[2025-12-10 17:05:48,634 INFO misc.py line 117 4140988] Train: [1/10][781/7400] Data 0.004 (0.004) Batch 0.603 (0.619) Remain 12:34:47 loss: 7.4741 mask_loss: 6.8594 roll_mask_loss: 7.4331 density_loss: 8.3347 unmask_loss: 7.6353 Lr: 0.00078
[2025-12-10 17:05:49,295 INFO misc.py line 117 4140988] Train: [1/10][782/7400] Data 0.004 (0.004) Batch 0.661 (0.619) Remain 12:34:50 loss: 7.5829 mask_loss: 7.0711 roll_mask_loss: 7.5180 density_loss: 9.0059 unmask_loss: 7.6911 Lr: 0.00078
[2025-12-10 17:05:49,916 INFO misc.py line 117 4140988] Train: [1/10][783/7400] Data 0.004 (0.004) Batch 0.621 (0.619) Remain 12:34:50 loss: 7.3521 mask_loss: 6.8004 roll_mask_loss: 7.1618 density_loss: 9.2133 unmask_loss: 7.5389 Lr: 0.00078
[2025-12-10 17:05:50,496 INFO misc.py line 117 4140988] Train: [1/10][784/7400] Data 0.004 (0.004) Batch 0.581 (0.619) Remain 12:34:46 loss: 7.7703 mask_loss: 7.1549 roll_mask_loss: 7.6912 density_loss: 8.3784 unmask_loss: 7.9500 Lr: 0.00078
[2025-12-10 17:05:51,062 INFO misc.py line 117 4140988] Train: [1/10][785/7400] Data 0.003 (0.004) Batch 0.563 (0.618) Remain 12:34:40 loss: 7.6252 mask_loss: 7.0329 roll_mask_loss: 7.7447 density_loss: 8.6684 unmask_loss: 7.6883 Lr: 0.00078
[2025-12-10 17:05:51,974 INFO misc.py line 117 4140988] Train: [1/10][786/7400] Data 0.005 (0.004) Batch 0.913 (0.619) Remain 12:35:07 loss: 7.3567 mask_loss: 6.5228 roll_mask_loss: 7.2866 density_loss: 9.4677 unmask_loss: 7.6193 Lr: 0.00078
[2025-12-10 17:05:52,604 INFO misc.py line 117 4140988] Train: [1/10][787/7400] Data 0.004 (0.004) Batch 0.630 (0.619) Remain 12:35:07 loss: 7.6696 mask_loss: 7.2067 roll_mask_loss: 7.6174 density_loss: 8.6360 unmask_loss: 7.7545 Lr: 0.00079
[2025-12-10 17:05:53,297 INFO misc.py line 117 4140988] Train: [1/10][788/7400] Data 0.004 (0.004) Batch 0.693 (0.619) Remain 12:35:14 loss: 7.3587 mask_loss: 6.7709 roll_mask_loss: 7.2057 density_loss: 8.9219 unmask_loss: 7.5506 Lr: 0.00079
[2025-12-10 17:05:53,969 INFO misc.py line 117 4140988] Train: [1/10][789/7400] Data 0.004 (0.004) Batch 0.672 (0.619) Remain 12:35:18 loss: 7.4532 mask_loss: 6.7980 roll_mask_loss: 7.4072 density_loss: 9.4786 unmask_loss: 7.6142 Lr: 0.00079
[2025-12-10 17:05:54,557 INFO misc.py line 117 4140988] Train: [1/10][790/7400] Data 0.004 (0.004) Batch 0.588 (0.619) Remain 12:35:15 loss: 7.1947 mask_loss: 6.4800 roll_mask_loss: 6.9311 density_loss: 8.6694 unmask_loss: 7.5104 Lr: 0.00079
[2025-12-10 17:05:55,215 INFO misc.py line 117 4140988] Train: [1/10][791/7400] Data 0.004 (0.004) Batch 0.658 (0.619) Remain 12:35:18 loss: 7.9285 mask_loss: 7.4275 roll_mask_loss: 8.4958 density_loss: 8.8832 unmask_loss: 7.7176 Lr: 0.00079
[2025-12-10 17:05:55,828 INFO misc.py line 117 4140988] Train: [1/10][792/7400] Data 0.004 (0.004) Batch 0.613 (0.619) Remain 12:35:16 loss: 7.7929 mask_loss: 7.3988 roll_mask_loss: 7.8137 density_loss: 9.1012 unmask_loss: 7.7976 Lr: 0.00079
[2025-12-10 17:05:56,505 INFO misc.py line 117 4140988] Train: [1/10][793/7400] Data 0.003 (0.004) Batch 0.676 (0.619) Remain 12:35:21 loss: 7.6507 mask_loss: 7.0845 roll_mask_loss: 7.5058 density_loss: 8.5229 unmask_loss: 7.8358 Lr: 0.00079
[2025-12-10 17:05:57,120 INFO misc.py line 117 4140988] Train: [1/10][794/7400] Data 0.004 (0.004) Batch 0.615 (0.619) Remain 12:35:20 loss: 7.7723 mask_loss: 7.2398 roll_mask_loss: 7.7439 density_loss: 8.9023 unmask_loss: 7.8747 Lr: 0.00079
[2025-12-10 17:05:57,874 INFO misc.py line 117 4140988] Train: [1/10][795/7400] Data 0.004 (0.004) Batch 0.754 (0.619) Remain 12:35:32 loss: 7.5032 mask_loss: 6.6218 roll_mask_loss: 7.5541 density_loss: 8.7121 unmask_loss: 7.7442 Lr: 0.00079
[2025-12-10 17:05:58,563 INFO misc.py line 117 4140988] Train: [1/10][796/7400] Data 0.004 (0.004) Batch 0.690 (0.619) Remain 12:35:38 loss: 7.3169 mask_loss: 6.6323 roll_mask_loss: 7.1699 density_loss: 9.1217 unmask_loss: 7.5502 Lr: 0.00079
[2025-12-10 17:05:59,269 INFO misc.py line 117 4140988] Train: [1/10][797/7400] Data 0.003 (0.004) Batch 0.706 (0.619) Remain 12:35:45 loss: 7.7061 mask_loss: 7.3242 roll_mask_loss: 7.5843 density_loss: 8.5075 unmask_loss: 7.7878 Lr: 0.00079
[2025-12-10 17:06:00,030 INFO misc.py line 117 4140988] Train: [1/10][798/7400] Data 0.003 (0.004) Batch 0.761 (0.620) Remain 12:35:58 loss: 7.2024 mask_loss: 6.5466 roll_mask_loss: 7.0820 density_loss: 9.2611 unmask_loss: 7.4052 Lr: 0.00080
[2025-12-10 17:06:00,542 INFO misc.py line 117 4140988] Train: [1/10][799/7400] Data 0.004 (0.004) Batch 0.512 (0.619) Remain 12:35:47 loss: 8.0360 mask_loss: 7.5860 roll_mask_loss: 8.1410 density_loss: 8.3654 unmask_loss: 8.0412 Lr: 0.00080
[2025-12-10 17:06:01,164 INFO misc.py line 117 4140988] Train: [1/10][800/7400] Data 0.003 (0.004) Batch 0.622 (0.619) Remain 12:35:47 loss: 7.6918 mask_loss: 7.1534 roll_mask_loss: 7.6011 density_loss: 8.8814 unmask_loss: 7.8287 Lr: 0.00080
[2025-12-10 17:06:01,942 INFO misc.py line 117 4140988] Train: [1/10][801/7400] Data 0.003 (0.004) Batch 0.776 (0.620) Remain 12:36:01 loss: 7.4690 mask_loss: 6.6980 roll_mask_loss: 7.3068 density_loss: 9.5332 unmask_loss: 7.7450 Lr: 0.00080
[2025-12-10 17:06:02,619 INFO misc.py line 117 4140988] Train: [1/10][802/7400] Data 0.005 (0.004) Batch 0.678 (0.620) Remain 12:36:05 loss: 7.7750 mask_loss: 7.1266 roll_mask_loss: 8.0278 density_loss: 9.3416 unmask_loss: 7.7859 Lr: 0.00080
[2025-12-10 17:06:03,089 INFO misc.py line 117 4140988] Train: [1/10][803/7400] Data 0.004 (0.004) Batch 0.470 (0.620) Remain 12:35:51 loss: 7.9722 mask_loss: 7.5317 roll_mask_loss: 7.9057 density_loss: 8.5204 unmask_loss: 8.0552 Lr: 0.00080
[2025-12-10 17:06:03,689 INFO misc.py line 117 4140988] Train: [1/10][804/7400] Data 0.004 (0.004) Batch 0.601 (0.620) Remain 12:35:49 loss: 7.2835 mask_loss: 6.5613 roll_mask_loss: 7.1811 density_loss: 8.9842 unmask_loss: 7.5162 Lr: 0.00080
[2025-12-10 17:06:04,306 INFO misc.py line 117 4140988] Train: [1/10][805/7400] Data 0.003 (0.004) Batch 0.616 (0.620) Remain 12:35:48 loss: 7.7325 mask_loss: 7.0079 roll_mask_loss: 7.6261 density_loss: 8.5706 unmask_loss: 7.9766 Lr: 0.00080
[2025-12-10 17:06:05,179 INFO misc.py line 117 4140988] Train: [1/10][806/7400] Data 0.004 (0.004) Batch 0.873 (0.620) Remain 12:36:10 loss: 7.4002 mask_loss: 6.8908 roll_mask_loss: 7.1996 density_loss: 8.5712 unmask_loss: 7.5837 Lr: 0.00080
[2025-12-10 17:06:05,826 INFO misc.py line 117 4140988] Train: [1/10][807/7400] Data 0.004 (0.004) Batch 0.648 (0.620) Remain 12:36:12 loss: 7.4010 mask_loss: 6.7850 roll_mask_loss: 7.3409 density_loss: 9.0773 unmask_loss: 7.5576 Lr: 0.00080
[2025-12-10 17:06:06,477 INFO misc.py line 117 4140988] Train: [1/10][808/7400] Data 0.004 (0.004) Batch 0.651 (0.620) Remain 12:36:14 loss: 7.4207 mask_loss: 6.8481 roll_mask_loss: 7.3317 density_loss: 8.5237 unmask_loss: 7.5809 Lr: 0.00081
[2025-12-10 17:06:07,246 INFO misc.py line 117 4140988] Train: [1/10][809/7400] Data 0.004 (0.004) Batch 0.769 (0.620) Remain 12:36:27 loss: 7.2756 mask_loss: 6.7013 roll_mask_loss: 7.1629 density_loss: 8.5237 unmask_loss: 7.4486 Lr: 0.00081
[2025-12-10 17:06:07,618 INFO misc.py line 117 4140988] Train: [1/10][810/7400] Data 0.004 (0.004) Batch 0.372 (0.620) Remain 12:36:04 loss: 7.7453 mask_loss: 7.1691 roll_mask_loss: 7.5167 density_loss: 9.3807 unmask_loss: 7.9601 Lr: 0.00081
[2025-12-10 17:06:08,303 INFO misc.py line 117 4140988] Train: [1/10][811/7400] Data 0.004 (0.004) Batch 0.685 (0.620) Remain 12:36:09 loss: 7.3507 mask_loss: 6.6844 roll_mask_loss: 7.1699 density_loss: 9.0969 unmask_loss: 7.5923 Lr: 0.00081
[2025-12-10 17:06:08,978 INFO misc.py line 117 4140988] Train: [1/10][812/7400] Data 0.004 (0.004) Batch 0.675 (0.620) Remain 12:36:14 loss: 7.5123 mask_loss: 6.8334 roll_mask_loss: 7.5049 density_loss: 9.0958 unmask_loss: 7.6736 Lr: 0.00081
[2025-12-10 17:06:09,624 INFO misc.py line 117 4140988] Train: [1/10][813/7400] Data 0.004 (0.004) Batch 0.646 (0.620) Remain 12:36:15 loss: 7.4163 mask_loss: 6.4618 roll_mask_loss: 7.5829 density_loss: 8.8739 unmask_loss: 7.6327 Lr: 0.00081
[2025-12-10 17:06:10,117 INFO misc.py line 117 4140988] Train: [1/10][814/7400] Data 0.004 (0.004) Batch 0.494 (0.620) Remain 12:36:03 loss: 7.6382 mask_loss: 6.9845 roll_mask_loss: 7.6984 density_loss: 8.4700 unmask_loss: 7.7656 Lr: 0.00081
[2025-12-10 17:06:10,902 INFO misc.py line 117 4140988] Train: [1/10][815/7400] Data 0.003 (0.004) Batch 0.785 (0.620) Remain 12:36:18 loss: 7.3714 mask_loss: 6.7227 roll_mask_loss: 7.3524 density_loss: 8.1398 unmask_loss: 7.5425 Lr: 0.00081
[2025-12-10 17:06:11,490 INFO misc.py line 117 4140988] Train: [1/10][816/7400] Data 0.003 (0.004) Batch 0.588 (0.620) Remain 12:36:14 loss: 7.9661 mask_loss: 7.6579 roll_mask_loss: 7.9195 density_loss: 8.4856 unmask_loss: 7.9737 Lr: 0.00081
[2025-12-10 17:06:11,930 INFO misc.py line 117 4140988] Train: [1/10][817/7400] Data 0.003 (0.004) Batch 0.440 (0.620) Remain 12:35:57 loss: 8.1535 mask_loss: 7.4162 roll_mask_loss: 8.4988 density_loss: 8.6068 unmask_loss: 8.1773 Lr: 0.00081
[2025-12-10 17:06:12,554 INFO misc.py line 117 4140988] Train: [1/10][818/7400] Data 0.004 (0.004) Batch 0.623 (0.620) Remain 12:35:57 loss: 7.6732 mask_loss: 7.2177 roll_mask_loss: 7.5238 density_loss: 8.9480 unmask_loss: 7.7967 Lr: 0.00082
[2025-12-10 17:06:13,551 INFO misc.py line 117 4140988] Train: [1/10][819/7400] Data 0.004 (0.004) Batch 0.997 (0.620) Remain 12:36:30 loss: 7.3905 mask_loss: 6.4948 roll_mask_loss: 7.4881 density_loss: 9.4388 unmask_loss: 7.6007 Lr: 0.00082
[2025-12-10 17:06:14,170 INFO misc.py line 117 4140988] Train: [1/10][820/7400] Data 0.004 (0.004) Batch 0.619 (0.620) Remain 12:36:30 loss: 7.2383 mask_loss: 6.5319 roll_mask_loss: 7.1766 density_loss: 8.6907 unmask_loss: 7.4486 Lr: 0.00082
[2025-12-10 17:06:14,849 INFO misc.py line 117 4140988] Train: [1/10][821/7400] Data 0.004 (0.004) Batch 0.678 (0.620) Remain 12:36:34 loss: 7.3785 mask_loss: 6.7502 roll_mask_loss: 7.2391 density_loss: 8.6965 unmask_loss: 7.5884 Lr: 0.00082
[2025-12-10 17:06:15,332 INFO misc.py line 117 4140988] Train: [1/10][822/7400] Data 0.004 (0.004) Batch 0.484 (0.620) Remain 12:36:21 loss: 7.4360 mask_loss: 6.8551 roll_mask_loss: 7.3253 density_loss: 8.8251 unmask_loss: 7.6054 Lr: 0.00082
[2025-12-10 17:06:16,152 INFO misc.py line 117 4140988] Train: [1/10][823/7400] Data 0.004 (0.004) Batch 0.819 (0.620) Remain 12:36:38 loss: 7.2013 mask_loss: 6.5386 roll_mask_loss: 6.9822 density_loss: 9.1090 unmask_loss: 7.4600 Lr: 0.00082
[2025-12-10 17:06:16,812 INFO misc.py line 117 4140988] Train: [1/10][824/7400] Data 0.004 (0.004) Batch 0.661 (0.620) Remain 12:36:41 loss: 7.1967 mask_loss: 6.4432 roll_mask_loss: 7.0342 density_loss: 8.8210 unmask_loss: 7.4784 Lr: 0.00082
[2025-12-10 17:06:17,453 INFO misc.py line 117 4140988] Train: [1/10][825/7400] Data 0.004 (0.004) Batch 0.641 (0.620) Remain 12:36:43 loss: 7.2400 mask_loss: 6.5112 roll_mask_loss: 6.9847 density_loss: 9.2198 unmask_loss: 7.5477 Lr: 0.00082
[2025-12-10 17:06:18,240 INFO misc.py line 117 4140988] Train: [1/10][826/7400] Data 0.004 (0.004) Batch 0.788 (0.621) Remain 12:36:57 loss: 7.2730 mask_loss: 6.5814 roll_mask_loss: 7.1638 density_loss: 9.0682 unmask_loss: 7.4921 Lr: 0.00082
[2025-12-10 17:06:18,718 INFO misc.py line 117 4140988] Train: [1/10][827/7400] Data 0.003 (0.004) Batch 0.477 (0.621) Remain 12:36:43 loss: 7.6492 mask_loss: 6.9776 roll_mask_loss: 7.8224 density_loss: 8.6661 unmask_loss: 7.7251 Lr: 0.00082
[2025-12-10 17:06:19,344 INFO misc.py line 117 4140988] Train: [1/10][828/7400] Data 0.004 (0.004) Batch 0.626 (0.621) Remain 12:36:43 loss: 8.0004 mask_loss: 7.3606 roll_mask_loss: 9.1246 density_loss: 8.3026 unmask_loss: 7.5921 Lr: 0.00083
[2025-12-10 17:06:20,091 INFO misc.py line 117 4140988] Train: [1/10][829/7400] Data 0.004 (0.004) Batch 0.747 (0.621) Remain 12:36:54 loss: 7.3176 mask_loss: 6.3772 roll_mask_loss: 7.3082 density_loss: 9.5012 unmask_loss: 7.6025 Lr: 0.00083
[2025-12-10 17:06:20,695 INFO misc.py line 117 4140988] Train: [1/10][830/7400] Data 0.004 (0.004) Batch 0.605 (0.621) Remain 12:36:52 loss: 7.5959 mask_loss: 7.0117 roll_mask_loss: 7.6824 density_loss: 8.6357 unmask_loss: 7.6719 Lr: 0.00083
[2025-12-10 17:06:21,190 INFO misc.py line 117 4140988] Train: [1/10][831/7400] Data 0.003 (0.004) Batch 0.495 (0.620) Remain 12:36:40 loss: 8.3499 mask_loss: 7.4803 roll_mask_loss: 8.5386 density_loss: 8.4065 unmask_loss: 8.5222 Lr: 0.00083
[2025-12-10 17:06:21,923 INFO misc.py line 117 4140988] Train: [1/10][832/7400] Data 0.003 (0.004) Batch 0.732 (0.621) Remain 12:36:49 loss: 7.3101 mask_loss: 6.6956 roll_mask_loss: 7.0520 density_loss: 8.6412 unmask_loss: 7.5736 Lr: 0.00083
[2025-12-10 17:06:22,482 INFO misc.py line 117 4140988] Train: [1/10][833/7400] Data 0.003 (0.004) Batch 0.558 (0.621) Remain 12:36:43 loss: 7.4864 mask_loss: 6.9366 roll_mask_loss: 7.4802 density_loss: 8.3848 unmask_loss: 7.5967 Lr: 0.00083
[2025-12-10 17:06:22,984 INFO misc.py line 117 4140988] Train: [1/10][834/7400] Data 0.004 (0.004) Batch 0.502 (0.620) Remain 12:36:32 loss: 8.5108 mask_loss: 8.2270 roll_mask_loss: 8.3976 density_loss: 8.4212 unmask_loss: 8.5409 Lr: 0.00083
[2025-12-10 17:06:23,622 INFO misc.py line 117 4140988] Train: [1/10][835/7400] Data 0.005 (0.004) Batch 0.639 (0.620) Remain 12:36:33 loss: 7.3490 mask_loss: 6.7533 roll_mask_loss: 7.2641 density_loss: 8.7454 unmask_loss: 7.5144 Lr: 0.00083
[2025-12-10 17:06:24,457 INFO misc.py line 117 4140988] Train: [1/10][836/7400] Data 0.004 (0.004) Batch 0.836 (0.621) Remain 12:36:51 loss: 7.3711 mask_loss: 6.4212 roll_mask_loss: 7.1121 density_loss: 9.5764 unmask_loss: 7.7840 Lr: 0.00083
[2025-12-10 17:06:25,029 INFO misc.py line 117 4140988] Train: [1/10][837/7400] Data 0.004 (0.004) Batch 0.572 (0.621) Remain 12:36:47 loss: 8.1141 mask_loss: 7.7037 roll_mask_loss: 7.9798 density_loss: 8.0847 unmask_loss: 8.2248 Lr: 0.00083
[2025-12-10 17:06:25,516 INFO misc.py line 117 4140988] Train: [1/10][838/7400] Data 0.003 (0.004) Batch 0.487 (0.620) Remain 12:36:34 loss: 7.4911 mask_loss: 6.8091 roll_mask_loss: 7.6506 density_loss: 8.4687 unmask_loss: 7.5830 Lr: 0.00083
[2025-12-10 17:06:26,249 INFO misc.py line 117 4140988] Train: [1/10][839/7400] Data 0.004 (0.004) Batch 0.733 (0.621) Remain 12:36:43 loss: 7.2201 mask_loss: 6.5305 roll_mask_loss: 7.0566 density_loss: 8.5770 unmask_loss: 7.4751 Lr: 0.00084
[2025-12-10 17:06:26,787 INFO misc.py line 117 4140988] Train: [1/10][840/7400] Data 0.004 (0.004) Batch 0.538 (0.621) Remain 12:36:36 loss: 7.6643 mask_loss: 7.1310 roll_mask_loss: 7.6957 density_loss: 8.6553 unmask_loss: 7.7421 Lr: 0.00084
[2025-12-10 17:06:27,669 INFO misc.py line 117 4140988] Train: [1/10][841/7400] Data 0.004 (0.004) Batch 0.881 (0.621) Remain 12:36:58 loss: 7.2866 mask_loss: 6.4160 roll_mask_loss: 7.0088 density_loss: 8.4820 unmask_loss: 7.6912 Lr: 0.00084
[2025-12-10 17:06:28,416 INFO misc.py line 117 4140988] Train: [1/10][842/7400] Data 0.004 (0.004) Batch 0.747 (0.621) Remain 12:37:08 loss: 7.1578 mask_loss: 6.4918 roll_mask_loss: 6.9800 density_loss: 8.9583 unmask_loss: 7.4005 Lr: 0.00084
[2025-12-10 17:06:29,038 INFO misc.py line 117 4140988] Train: [1/10][843/7400] Data 0.004 (0.004) Batch 0.622 (0.621) Remain 12:37:08 loss: 7.3903 mask_loss: 6.7025 roll_mask_loss: 7.2073 density_loss: 8.4423 unmask_loss: 7.6569 Lr: 0.00084
[2025-12-10 17:06:29,635 INFO misc.py line 117 4140988] Train: [1/10][844/7400] Data 0.004 (0.004) Batch 0.597 (0.621) Remain 12:37:05 loss: 7.5906 mask_loss: 7.0551 roll_mask_loss: 7.3888 density_loss: 9.4177 unmask_loss: 7.7709 Lr: 0.00084
[2025-12-10 17:06:29,976 INFO misc.py line 117 4140988] Train: [1/10][845/7400] Data 0.004 (0.004) Batch 0.341 (0.621) Remain 12:36:40 loss: 8.1770 mask_loss: 7.5162 roll_mask_loss: 8.3880 density_loss: 8.0079 unmask_loss: 8.2418 Lr: 0.00084
[2025-12-10 17:06:30,977 INFO misc.py line 117 4140988] Train: [1/10][846/7400] Data 0.004 (0.004) Batch 1.000 (0.621) Remain 12:37:12 loss: 7.3144 mask_loss: 6.4946 roll_mask_loss: 7.1850 density_loss: 9.0479 unmask_loss: 7.6080 Lr: 0.00084
[2025-12-10 17:06:31,729 INFO misc.py line 117 4140988] Train: [1/10][847/7400] Data 0.004 (0.004) Batch 0.752 (0.621) Remain 12:37:23 loss: 7.3491 mask_loss: 6.7421 roll_mask_loss: 7.1645 density_loss: 8.8301 unmask_loss: 7.5682 Lr: 0.00084
[2025-12-10 17:06:32,283 INFO misc.py line 117 4140988] Train: [1/10][848/7400] Data 0.004 (0.004) Batch 0.554 (0.621) Remain 12:37:17 loss: 8.5253 mask_loss: 7.8792 roll_mask_loss: 8.9030 density_loss: 8.3937 unmask_loss: 8.4916 Lr: 0.00084
[2025-12-10 17:06:32,919 INFO misc.py line 117 4140988] Train: [1/10][849/7400] Data 0.004 (0.004) Batch 0.636 (0.621) Remain 12:37:17 loss: 7.3523 mask_loss: 6.6633 roll_mask_loss: 7.5375 density_loss: 8.5801 unmask_loss: 7.4325 Lr: 0.00085
[2025-12-10 17:06:33,441 INFO misc.py line 117 4140988] Train: [1/10][850/7400] Data 0.004 (0.004) Batch 0.522 (0.621) Remain 12:37:08 loss: 7.6649 mask_loss: 7.0115 roll_mask_loss: 7.6205 density_loss: 9.3743 unmask_loss: 7.8264 Lr: 0.00085
[2025-12-10 17:06:34,021 INFO misc.py line 117 4140988] Train: [1/10][851/7400] Data 0.004 (0.004) Batch 0.580 (0.621) Remain 12:37:04 loss: 7.4634 mask_loss: 6.8522 roll_mask_loss: 7.4039 density_loss: 9.0841 unmask_loss: 7.6171 Lr: 0.00085
[2025-12-10 17:06:34,668 INFO misc.py line 117 4140988] Train: [1/10][852/7400] Data 0.004 (0.004) Batch 0.647 (0.621) Remain 12:37:06 loss: 7.2395 mask_loss: 6.4616 roll_mask_loss: 7.2949 density_loss: 8.4069 unmask_loss: 7.4327 Lr: 0.00085
[2025-12-10 17:06:35,291 INFO misc.py line 117 4140988] Train: [1/10][853/7400] Data 0.004 (0.004) Batch 0.622 (0.621) Remain 12:37:05 loss: 7.3505 mask_loss: 6.5568 roll_mask_loss: 7.1877 density_loss: 9.4165 unmask_loss: 7.6404 Lr: 0.00085
[2025-12-10 17:06:35,960 INFO misc.py line 117 4140988] Train: [1/10][854/7400] Data 0.004 (0.004) Batch 0.670 (0.621) Remain 12:37:09 loss: 7.3839 mask_loss: 6.8158 roll_mask_loss: 7.2131 density_loss: 8.6691 unmask_loss: 7.5800 Lr: 0.00085
[2025-12-10 17:06:36,509 INFO misc.py line 117 4140988] Train: [1/10][855/7400] Data 0.004 (0.004) Batch 0.549 (0.621) Remain 12:37:02 loss: 8.2157 mask_loss: 7.9547 roll_mask_loss: 8.2916 density_loss: 8.4188 unmask_loss: 8.1399 Lr: 0.00085
[2025-12-10 17:06:37,100 INFO misc.py line 117 4140988] Train: [1/10][856/7400] Data 0.004 (0.004) Batch 0.591 (0.621) Remain 12:36:59 loss: 7.5836 mask_loss: 6.9793 roll_mask_loss: 7.7794 density_loss: 8.5986 unmask_loss: 7.6159 Lr: 0.00085
[2025-12-10 17:06:37,616 INFO misc.py line 117 4140988] Train: [1/10][857/7400] Data 0.004 (0.004) Batch 0.516 (0.621) Remain 12:36:49 loss: 7.1731 mask_loss: 6.4424 roll_mask_loss: 6.9664 density_loss: 9.4936 unmask_loss: 7.4520 Lr: 0.00085
[2025-12-10 17:06:38,098 INFO misc.py line 117 4140988] Train: [1/10][858/7400] Data 0.004 (0.004) Batch 0.482 (0.621) Remain 12:36:37 loss: 7.7907 mask_loss: 7.3187 roll_mask_loss: 7.6477 density_loss: 8.2459 unmask_loss: 7.9333 Lr: 0.00086
[2025-12-10 17:06:38,749 INFO misc.py line 117 4140988] Train: [1/10][859/7400] Data 0.004 (0.004) Batch 0.651 (0.621) Remain 12:36:39 loss: 7.5691 mask_loss: 6.9647 roll_mask_loss: 7.4276 density_loss: 8.3762 unmask_loss: 7.7746 Lr: 0.00086
[2025-12-10 17:06:39,352 INFO misc.py line 117 4140988] Train: [1/10][860/7400] Data 0.004 (0.004) Batch 0.603 (0.621) Remain 12:36:36 loss: 7.4539 mask_loss: 6.8133 roll_mask_loss: 7.5993 density_loss: 8.9668 unmask_loss: 7.5222 Lr: 0.00086
[2025-12-10 17:06:39,882 INFO misc.py line 117 4140988] Train: [1/10][861/7400] Data 0.004 (0.004) Batch 0.531 (0.621) Remain 12:36:28 loss: 8.1800 mask_loss: 7.7619 roll_mask_loss: 8.2584 density_loss: 8.2732 unmask_loss: 8.1844 Lr: 0.00086
[2025-12-10 17:06:40,476 INFO misc.py line 117 4140988] Train: [1/10][862/7400] Data 0.004 (0.004) Batch 0.593 (0.621) Remain 12:36:25 loss: 7.4526 mask_loss: 6.8362 roll_mask_loss: 7.2397 density_loss: 8.9553 unmask_loss: 7.6883 Lr: 0.00086
[2025-12-10 17:06:41,125 INFO misc.py line 117 4140988] Train: [1/10][863/7400] Data 0.004 (0.004) Batch 0.650 (0.621) Remain 12:36:27 loss: 7.8897 mask_loss: 7.4725 roll_mask_loss: 7.5907 density_loss: 8.6462 unmask_loss: 8.0749 Lr: 0.00086
[2025-12-10 17:06:41,750 INFO misc.py line 117 4140988] Train: [1/10][864/7400] Data 0.004 (0.004) Batch 0.625 (0.621) Remain 12:36:27 loss: 7.4028 mask_loss: 6.8212 roll_mask_loss: 7.3679 density_loss: 7.9947 unmask_loss: 7.5512 Lr: 0.00086
[2025-12-10 17:06:42,300 INFO misc.py line 117 4140988] Train: [1/10][865/7400] Data 0.003 (0.004) Batch 0.549 (0.621) Remain 12:36:20 loss: 8.4453 mask_loss: 8.2608 roll_mask_loss: 8.4060 density_loss: 8.4141 unmask_loss: 8.3890 Lr: 0.00086
[2025-12-10 17:06:42,958 INFO misc.py line 117 4140988] Train: [1/10][866/7400] Data 0.004 (0.004) Batch 0.658 (0.621) Remain 12:36:23 loss: 7.1642 mask_loss: 6.2587 roll_mask_loss: 6.9033 density_loss: 9.2251 unmask_loss: 7.5629 Lr: 0.00086
[2025-12-10 17:06:43,305 INFO misc.py line 117 4140988] Train: [1/10][867/7400] Data 0.004 (0.004) Batch 0.347 (0.620) Remain 12:35:59 loss: 7.2546 mask_loss: 6.4821 roll_mask_loss: 7.1396 density_loss: 9.6912 unmask_loss: 7.5045 Lr: 0.00086
[2025-12-10 17:06:44,155 INFO misc.py line 117 4140988] Train: [1/10][868/7400] Data 0.003 (0.004) Batch 0.850 (0.620) Remain 12:36:18 loss: 7.2373 mask_loss: 6.3834 roll_mask_loss: 7.2884 density_loss: 9.1030 unmask_loss: 7.4567 Lr: 0.00087
[2025-12-10 17:06:44,684 INFO misc.py line 117 4140988] Train: [1/10][869/7400] Data 0.004 (0.004) Batch 0.529 (0.620) Remain 12:36:09 loss: 7.9290 mask_loss: 7.5319 roll_mask_loss: 7.7964 density_loss: 8.5323 unmask_loss: 8.0232 Lr: 0.00087
[2025-12-10 17:06:45,393 INFO misc.py line 117 4140988] Train: [1/10][870/7400] Data 0.004 (0.004) Batch 0.708 (0.620) Remain 12:36:16 loss: 7.4085 mask_loss: 6.7498 roll_mask_loss: 7.2573 density_loss: 8.8274 unmask_loss: 7.6370 Lr: 0.00087
[2025-12-10 17:06:46,172 INFO misc.py line 117 4140988] Train: [1/10][871/7400] Data 0.004 (0.004) Batch 0.779 (0.621) Remain 12:36:29 loss: 7.3464 mask_loss: 6.8339 roll_mask_loss: 7.1192 density_loss: 8.4323 unmask_loss: 7.5475 Lr: 0.00087
[2025-12-10 17:06:46,941 INFO misc.py line 117 4140988] Train: [1/10][872/7400] Data 0.004 (0.004) Batch 0.770 (0.621) Remain 12:36:41 loss: 7.4247 mask_loss: 6.6609 roll_mask_loss: 7.4663 density_loss: 9.1396 unmask_loss: 7.6030 Lr: 0.00087
[2025-12-10 17:06:47,465 INFO misc.py line 117 4140988] Train: [1/10][873/7400] Data 0.004 (0.004) Batch 0.524 (0.621) Remain 12:36:32 loss: 7.9105 mask_loss: 7.4678 roll_mask_loss: 7.9126 density_loss: 8.2205 unmask_loss: 7.9663 Lr: 0.00087
[2025-12-10 17:06:48,173 INFO misc.py line 117 4140988] Train: [1/10][874/7400] Data 0.004 (0.004) Batch 0.708 (0.621) Remain 12:36:39 loss: 7.2836 mask_loss: 6.6353 roll_mask_loss: 7.1260 density_loss: 9.3512 unmask_loss: 7.4995 Lr: 0.00087
[2025-12-10 17:06:48,839 INFO misc.py line 117 4140988] Train: [1/10][875/7400] Data 0.004 (0.004) Batch 0.666 (0.621) Remain 12:36:42 loss: 7.5350 mask_loss: 6.5228 roll_mask_loss: 7.6719 density_loss: 9.8040 unmask_loss: 7.7766 Lr: 0.00087
[2025-12-10 17:06:49,382 INFO misc.py line 117 4140988] Train: [1/10][876/7400] Data 0.004 (0.004) Batch 0.543 (0.621) Remain 12:36:35 loss: 7.3257 mask_loss: 6.6002 roll_mask_loss: 7.1933 density_loss: 9.6402 unmask_loss: 7.5619 Lr: 0.00087
[2025-12-10 17:06:49,910 INFO misc.py line 117 4140988] Train: [1/10][877/7400] Data 0.003 (0.004) Batch 0.528 (0.621) Remain 12:36:26 loss: 8.4258 mask_loss: 8.3023 roll_mask_loss: 8.3926 density_loss: 8.4010 unmask_loss: 8.3362 Lr: 0.00087
[2025-12-10 17:06:50,487 INFO misc.py line 117 4140988] Train: [1/10][878/7400] Data 0.003 (0.004) Batch 0.577 (0.621) Remain 12:36:22 loss: 7.4629 mask_loss: 6.8260 roll_mask_loss: 7.4747 density_loss: 9.2297 unmask_loss: 7.5908 Lr: 0.00088
[2025-12-10 17:06:51,059 INFO misc.py line 117 4140988] Train: [1/10][879/7400] Data 0.003 (0.004) Batch 0.572 (0.621) Remain 12:36:18 loss: 8.4104 mask_loss: 8.2488 roll_mask_loss: 8.3811 density_loss: 8.4010 unmask_loss: 8.3377 Lr: 0.00088
[2025-12-10 17:06:51,715 INFO misc.py line 117 4140988] Train: [1/10][880/7400] Data 0.003 (0.004) Batch 0.656 (0.621) Remain 12:36:20 loss: 7.4526 mask_loss: 6.8030 roll_mask_loss: 7.4477 density_loss: 8.4698 unmask_loss: 7.6104 Lr: 0.00088
[2025-12-10 17:06:52,299 INFO misc.py line 117 4140988] Train: [1/10][881/7400] Data 0.003 (0.004) Batch 0.583 (0.621) Remain 12:36:16 loss: 8.3681 mask_loss: 8.1068 roll_mask_loss: 8.3722 density_loss: 8.3768 unmask_loss: 8.3292 Lr: 0.00088
[2025-12-10 17:06:53,101 INFO misc.py line 117 4140988] Train: [1/10][882/7400] Data 0.004 (0.004) Batch 0.802 (0.621) Remain 12:36:31 loss: 7.3543 mask_loss: 6.5875 roll_mask_loss: 7.3938 density_loss: 9.0892 unmask_loss: 7.5361 Lr: 0.00088
[2025-12-10 17:06:53,712 INFO misc.py line 117 4140988] Train: [1/10][883/7400] Data 0.003 (0.004) Batch 0.611 (0.621) Remain 12:36:29 loss: 7.3306 mask_loss: 6.6551 roll_mask_loss: 7.2274 density_loss: 8.5654 unmask_loss: 7.5487 Lr: 0.00088
[2025-12-10 17:06:54,240 INFO misc.py line 117 4140988] Train: [1/10][884/7400] Data 0.003 (0.004) Batch 0.528 (0.621) Remain 12:36:21 loss: 7.7034 mask_loss: 7.1583 roll_mask_loss: 7.7415 density_loss: 8.1603 unmask_loss: 7.7937 Lr: 0.00088
[2025-12-10 17:06:54,820 INFO misc.py line 117 4140988] Train: [1/10][885/7400] Data 0.003 (0.004) Batch 0.579 (0.621) Remain 12:36:17 loss: 7.2752 mask_loss: 6.3986 roll_mask_loss: 7.2310 density_loss: 9.2258 unmask_loss: 7.5512 Lr: 0.00088
[2025-12-10 17:06:55,443 INFO misc.py line 117 4140988] Train: [1/10][886/7400] Data 0.004 (0.004) Batch 0.624 (0.621) Remain 12:36:16 loss: 7.2160 mask_loss: 6.4073 roll_mask_loss: 7.1509 density_loss: 9.3238 unmask_loss: 7.4665 Lr: 0.00088
[2025-12-10 17:06:56,137 INFO misc.py line 117 4140988] Train: [1/10][887/7400] Data 0.004 (0.004) Batch 0.693 (0.621) Remain 12:36:22 loss: 7.6057 mask_loss: 6.9711 roll_mask_loss: 7.5603 density_loss: 8.9776 unmask_loss: 7.7662 Lr: 0.00088
[2025-12-10 17:06:56,646 INFO misc.py line 117 4140988] Train: [1/10][888/7400] Data 0.004 (0.004) Batch 0.510 (0.621) Remain 12:36:12 loss: 7.7648 mask_loss: 7.3620 roll_mask_loss: 7.8104 density_loss: 8.7945 unmask_loss: 7.7675 Lr: 0.00089
[2025-12-10 17:06:57,178 INFO misc.py line 117 4140988] Train: [1/10][889/7400] Data 0.004 (0.004) Batch 0.531 (0.620) Remain 12:36:04 loss: 7.8052 mask_loss: 7.2778 roll_mask_loss: 7.8071 density_loss: 8.5653 unmask_loss: 7.8968 Lr: 0.00089
[2025-12-10 17:06:57,878 INFO misc.py line 117 4140988] Train: [1/10][890/7400] Data 0.004 (0.004) Batch 0.701 (0.621) Remain 12:36:10 loss: 7.3508 mask_loss: 6.7122 roll_mask_loss: 7.3595 density_loss: 9.1010 unmask_loss: 7.4838 Lr: 0.00089
[2025-12-10 17:06:58,525 INFO misc.py line 117 4140988] Train: [1/10][891/7400] Data 0.003 (0.004) Batch 0.646 (0.621) Remain 12:36:12 loss: 7.2201 mask_loss: 6.4875 roll_mask_loss: 7.1445 density_loss: 9.1118 unmask_loss: 7.4419 Lr: 0.00089
[2025-12-10 17:06:59,061 INFO misc.py line 117 4140988] Train: [1/10][892/7400] Data 0.004 (0.004) Batch 0.536 (0.621) Remain 12:36:04 loss: 7.1811 mask_loss: 6.3540 roll_mask_loss: 7.0246 density_loss: 10.2817 unmask_loss: 7.4673 Lr: 0.00089
[2025-12-10 17:06:59,677 INFO misc.py line 117 4140988] Train: [1/10][893/7400] Data 0.004 (0.004) Batch 0.616 (0.621) Remain 12:36:03 loss: 8.1240 mask_loss: 7.4439 roll_mask_loss: 8.1879 density_loss: 8.9238 unmask_loss: 8.2536 Lr: 0.00089
[2025-12-10 17:07:00,221 INFO misc.py line 117 4140988] Train: [1/10][894/7400] Data 0.004 (0.004) Batch 0.544 (0.620) Remain 12:35:56 loss: 7.3756 mask_loss: 6.7762 roll_mask_loss: 7.3164 density_loss: 9.2128 unmask_loss: 7.5207 Lr: 0.00089
[2025-12-10 17:07:00,911 INFO misc.py line 117 4140988] Train: [1/10][895/7400] Data 0.004 (0.004) Batch 0.691 (0.621) Remain 12:36:01 loss: 7.5233 mask_loss: 6.9808 roll_mask_loss: 7.3810 density_loss: 8.3457 unmask_loss: 7.6988 Lr: 0.00089
[2025-12-10 17:07:01,523 INFO misc.py line 117 4140988] Train: [1/10][896/7400] Data 0.004 (0.004) Batch 0.612 (0.620) Remain 12:36:00 loss: 7.9558 mask_loss: 7.3974 roll_mask_loss: 8.2222 density_loss: 9.0042 unmask_loss: 7.9217 Lr: 0.00089
[2025-12-10 17:07:02,258 INFO misc.py line 117 4140988] Train: [1/10][897/7400] Data 0.003 (0.004) Batch 0.735 (0.621) Remain 12:36:09 loss: 7.1654 mask_loss: 6.4599 roll_mask_loss: 6.9978 density_loss: 8.5694 unmask_loss: 7.4306 Lr: 0.00090
[2025-12-10 17:07:02,932 INFO misc.py line 117 4140988] Train: [1/10][898/7400] Data 0.004 (0.004) Batch 0.674 (0.621) Remain 12:36:12 loss: 7.4702 mask_loss: 6.6804 roll_mask_loss: 7.3440 density_loss: 8.6700 unmask_loss: 7.7548 Lr: 0.00090
[2025-12-10 17:07:03,543 INFO misc.py line 117 4140988] Train: [1/10][899/7400] Data 0.004 (0.004) Batch 0.611 (0.621) Remain 12:36:11 loss: 7.3097 mask_loss: 6.6910 roll_mask_loss: 7.0065 density_loss: 8.8787 unmask_loss: 7.5932 Lr: 0.00090
[2025-12-10 17:07:04,040 INFO misc.py line 117 4140988] Train: [1/10][900/7400] Data 0.004 (0.004) Batch 0.498 (0.621) Remain 12:36:00 loss: 8.5004 mask_loss: 8.2982 roll_mask_loss: 8.4504 density_loss: 8.4457 unmask_loss: 8.4575 Lr: 0.00090
[2025-12-10 17:07:04,584 INFO misc.py line 117 4140988] Train: [1/10][901/7400] Data 0.003 (0.004) Batch 0.544 (0.620) Remain 12:35:53 loss: 8.2706 mask_loss: 7.3387 roll_mask_loss: 8.7333 density_loss: 8.7141 unmask_loss: 8.3309 Lr: 0.00090
[2025-12-10 17:07:05,310 INFO misc.py line 117 4140988] Train: [1/10][902/7400] Data 0.004 (0.004) Batch 0.726 (0.621) Remain 12:36:01 loss: 7.1278 mask_loss: 6.4095 roll_mask_loss: 6.9920 density_loss: 8.9377 unmask_loss: 7.3760 Lr: 0.00090
[2025-12-10 17:07:05,753 INFO misc.py line 117 4140988] Train: [1/10][903/7400] Data 0.004 (0.004) Batch 0.443 (0.620) Remain 12:35:46 loss: 7.5979 mask_loss: 7.0187 roll_mask_loss: 7.4996 density_loss: 8.4617 unmask_loss: 7.7675 Lr: 0.00090
[2025-12-10 17:07:06,085 INFO misc.py line 117 4140988] Train: [1/10][904/7400] Data 0.004 (0.004) Batch 0.331 (0.620) Remain 12:35:22 loss: 7.6721 mask_loss: 7.0501 roll_mask_loss: 7.7315 density_loss: 8.0268 unmask_loss: 7.7928 Lr: 0.00090
[2025-12-10 17:07:06,762 INFO misc.py line 117 4140988] Train: [1/10][905/7400] Data 0.004 (0.004) Batch 0.677 (0.620) Remain 12:35:26 loss: 7.4718 mask_loss: 6.7997 roll_mask_loss: 7.2465 density_loss: 8.5233 unmask_loss: 7.7501 Lr: 0.00090
[2025-12-10 17:07:07,262 INFO misc.py line 117 4140988] Train: [1/10][906/7400] Data 0.004 (0.004) Batch 0.500 (0.620) Remain 12:35:16 loss: 8.4121 mask_loss: 8.2895 roll_mask_loss: 8.3768 density_loss: 8.4089 unmask_loss: 8.3229 Lr: 0.00090
[2025-12-10 17:07:07,861 INFO misc.py line 117 4140988] Train: [1/10][907/7400] Data 0.004 (0.004) Batch 0.599 (0.620) Remain 12:35:14 loss: 7.4592 mask_loss: 6.9287 roll_mask_loss: 7.2827 density_loss: 8.8125 unmask_loss: 7.6364 Lr: 0.00091
[2025-12-10 17:07:08,810 INFO misc.py line 117 4140988] Train: [1/10][908/7400] Data 0.004 (0.004) Batch 0.949 (0.620) Remain 12:35:40 loss: 7.2451 mask_loss: 6.3497 roll_mask_loss: 7.0305 density_loss: 8.9649 unmask_loss: 7.6208 Lr: 0.00091
[2025-12-10 17:07:09,184 INFO misc.py line 117 4140988] Train: [1/10][909/7400] Data 0.003 (0.004) Batch 0.375 (0.620) Remain 12:35:19 loss: 7.5039 mask_loss: 6.9489 roll_mask_loss: 7.5026 density_loss: 7.7477 unmask_loss: 7.6270 Lr: 0.00091
[2025-12-10 17:07:09,707 INFO misc.py line 117 4140988] Train: [1/10][910/7400] Data 0.003 (0.004) Batch 0.523 (0.620) Remain 12:35:11 loss: 8.3870 mask_loss: 8.2257 roll_mask_loss: 8.3208 density_loss: 8.3427 unmask_loss: 8.3339 Lr: 0.00091
[2025-12-10 17:07:10,154 INFO misc.py line 117 4140988] Train: [1/10][911/7400] Data 0.003 (0.004) Batch 0.446 (0.620) Remain 12:34:56 loss: 8.3644 mask_loss: 8.1381 roll_mask_loss: 8.2659 density_loss: 8.3403 unmask_loss: 8.3600 Lr: 0.00091
[2025-12-10 17:07:10,935 INFO misc.py line 117 4140988] Train: [1/10][912/7400] Data 0.003 (0.004) Batch 0.781 (0.620) Remain 12:35:08 loss: 7.2636 mask_loss: 6.3752 roll_mask_loss: 7.1878 density_loss: 8.8672 unmask_loss: 7.5684 Lr: 0.00091
[2025-12-10 17:07:11,448 INFO misc.py line 117 4140988] Train: [1/10][913/7400] Data 0.003 (0.004) Batch 0.513 (0.620) Remain 12:34:59 loss: 8.4054 mask_loss: 8.2697 roll_mask_loss: 8.3587 density_loss: 8.3365 unmask_loss: 8.3299 Lr: 0.00091
[2025-12-10 17:07:12,136 INFO misc.py line 117 4140988] Train: [1/10][914/7400] Data 0.004 (0.004) Batch 0.688 (0.620) Remain 12:35:04 loss: 8.3457 mask_loss: 8.1738 roll_mask_loss: 8.3309 density_loss: 8.3261 unmask_loss: 8.2725 Lr: 0.00091
[2025-12-10 17:07:12,667 INFO misc.py line 117 4140988] Train: [1/10][915/7400] Data 0.004 (0.004) Batch 0.530 (0.620) Remain 12:34:56 loss: 8.4021 mask_loss: 8.2641 roll_mask_loss: 8.3610 density_loss: 8.3425 unmask_loss: 8.3247 Lr: 0.00091
[2025-12-10 17:07:13,032 INFO misc.py line 117 4140988] Train: [1/10][916/7400] Data 0.005 (0.004) Batch 0.366 (0.620) Remain 12:34:35 loss: 7.2742 mask_loss: 6.2182 roll_mask_loss: 7.0489 density_loss: 9.5114 unmask_loss: 7.7245 Lr: 0.00092
[2025-12-10 17:07:13,652 INFO misc.py line 117 4140988] Train: [1/10][917/7400] Data 0.004 (0.004) Batch 0.620 (0.620) Remain 12:34:35 loss: 7.5562 mask_loss: 7.0778 roll_mask_loss: 7.5202 density_loss: 8.7658 unmask_loss: 7.6382 Lr: 0.00092
[2025-12-10 17:07:14,237 INFO misc.py line 117 4140988] Train: [1/10][918/7400] Data 0.004 (0.004) Batch 0.584 (0.619) Remain 12:34:31 loss: 7.8738 mask_loss: 7.2578 roll_mask_loss: 8.0968 density_loss: 8.3883 unmask_loss: 7.9024 Lr: 0.00092
[2025-12-10 17:07:14,751 INFO misc.py line 117 4140988] Train: [1/10][919/7400] Data 0.004 (0.004) Batch 0.515 (0.619) Remain 12:34:22 loss: 7.4002 mask_loss: 6.9620 roll_mask_loss: 7.3777 density_loss: 8.6342 unmask_loss: 7.4578 Lr: 0.00092
[2025-12-10 17:07:15,409 INFO misc.py line 117 4140988] Train: [1/10][920/7400] Data 0.004 (0.004) Batch 0.658 (0.619) Remain 12:34:25 loss: 7.2491 mask_loss: 6.2324 roll_mask_loss: 7.4054 density_loss: 9.4207 unmask_loss: 7.4909 Lr: 0.00092
[2025-12-10 17:07:15,744 INFO misc.py line 117 4140988] Train: [1/10][921/7400] Data 0.004 (0.004) Batch 0.336 (0.619) Remain 12:34:02 loss: 8.6846 mask_loss: 7.8635 roll_mask_loss: 9.5140 density_loss: 8.5835 unmask_loss: 8.5087 Lr: 0.00092
[2025-12-10 17:07:16,490 INFO misc.py line 117 4140988] Train: [1/10][922/7400] Data 0.004 (0.004) Batch 0.745 (0.619) Remain 12:34:11 loss: 7.0381 mask_loss: 6.3382 roll_mask_loss: 6.8415 density_loss: 8.3741 unmask_loss: 7.3188 Lr: 0.00092
[2025-12-10 17:07:17,145 INFO misc.py line 117 4140988] Train: [1/10][923/7400] Data 0.004 (0.004) Batch 0.655 (0.619) Remain 12:34:13 loss: 7.3150 mask_loss: 6.3702 roll_mask_loss: 7.3186 density_loss: 9.1147 unmask_loss: 7.6033 Lr: 0.00092
[2025-12-10 17:07:17,743 INFO misc.py line 117 4140988] Train: [1/10][924/7400] Data 0.004 (0.004) Batch 0.598 (0.619) Remain 12:34:11 loss: 8.4251 mask_loss: 8.2774 roll_mask_loss: 8.3576 density_loss: 8.3513 unmask_loss: 8.3656 Lr: 0.00092
[2025-12-10 17:07:18,272 INFO misc.py line 117 4140988] Train: [1/10][925/7400] Data 0.004 (0.004) Batch 0.530 (0.619) Remain 12:34:03 loss: 7.8628 mask_loss: 7.3263 roll_mask_loss: 7.8137 density_loss: 8.4652 unmask_loss: 7.9862 Lr: 0.00093
[2025-12-10 17:07:18,899 INFO misc.py line 117 4140988] Train: [1/10][926/7400] Data 0.004 (0.004) Batch 0.627 (0.619) Remain 12:34:03 loss: 7.3223 mask_loss: 6.6480 roll_mask_loss: 7.2028 density_loss: 8.1939 unmask_loss: 7.5553 Lr: 0.00093
[2025-12-10 17:07:19,656 INFO misc.py line 117 4140988] Train: [1/10][927/7400] Data 0.004 (0.004) Batch 0.757 (0.619) Remain 12:34:13 loss: 7.1393 mask_loss: 6.4391 roll_mask_loss: 6.9564 density_loss: 9.1666 unmask_loss: 7.3974 Lr: 0.00093
[2025-12-10 17:07:19,976 INFO misc.py line 117 4140988] Train: [1/10][928/7400] Data 0.004 (0.004) Batch 0.320 (0.619) Remain 12:33:49 loss: 8.0951 mask_loss: 7.7263 roll_mask_loss: 7.9985 density_loss: 8.4081 unmask_loss: 8.1596 Lr: 0.00093
[2025-12-10 17:07:20,515 INFO misc.py line 117 4140988] Train: [1/10][929/7400] Data 0.004 (0.004) Batch 0.539 (0.619) Remain 12:33:42 loss: 7.1598 mask_loss: 6.4252 roll_mask_loss: 6.9737 density_loss: 8.1597 unmask_loss: 7.4570 Lr: 0.00093
[2025-12-10 17:07:21,428 INFO misc.py line 117 4140988] Train: [1/10][930/7400] Data 0.004 (0.004) Batch 0.913 (0.619) Remain 12:34:05 loss: 7.2134 mask_loss: 6.2611 roll_mask_loss: 7.2939 density_loss: 9.6947 unmask_loss: 7.4553 Lr: 0.00093
[2025-12-10 17:07:22,035 INFO misc.py line 117 4140988] Train: [1/10][931/7400] Data 0.004 (0.004) Batch 0.608 (0.619) Remain 12:34:03 loss: 7.4799 mask_loss: 6.8821 roll_mask_loss: 7.3412 density_loss: 9.3995 unmask_loss: 7.6602 Lr: 0.00093
[2025-12-10 17:07:22,627 INFO misc.py line 117 4140988] Train: [1/10][932/7400] Data 0.004 (0.004) Batch 0.592 (0.619) Remain 12:34:01 loss: 7.1994 mask_loss: 6.5245 roll_mask_loss: 7.0492 density_loss: 9.1417 unmask_loss: 7.4291 Lr: 0.00093
[2025-12-10 17:07:23,178 INFO misc.py line 117 4140988] Train: [1/10][933/7400] Data 0.004 (0.004) Batch 0.551 (0.619) Remain 12:33:55 loss: 7.4235 mask_loss: 6.7672 roll_mask_loss: 7.5375 density_loss: 7.9557 unmask_loss: 7.5355 Lr: 0.00093
[2025-12-10 17:07:24,122 INFO misc.py line 117 4140988] Train: [1/10][934/7400] Data 0.004 (0.004) Batch 0.944 (0.619) Remain 12:34:19 loss: 7.1137 mask_loss: 6.3319 roll_mask_loss: 6.9935 density_loss: 9.5543 unmask_loss: 7.3736 Lr: 0.00094
[2025-12-10 17:07:24,754 INFO misc.py line 117 4140988] Train: [1/10][935/7400] Data 0.004 (0.004) Batch 0.631 (0.619) Remain 12:34:20 loss: 7.2644 mask_loss: 6.5474 roll_mask_loss: 7.1537 density_loss: 8.8391 unmask_loss: 7.5014 Lr: 0.00094
[2025-12-10 17:07:25,285 INFO misc.py line 117 4140988] Train: [1/10][936/7400] Data 0.005 (0.004) Batch 0.532 (0.619) Remain 12:34:12 loss: 8.0741 mask_loss: 7.4794 roll_mask_loss: 7.8680 density_loss: 8.8150 unmask_loss: 8.2981 Lr: 0.00094
[2025-12-10 17:07:25,803 INFO misc.py line 117 4140988] Train: [1/10][937/7400] Data 0.003 (0.004) Batch 0.517 (0.619) Remain 12:34:04 loss: 8.2721 mask_loss: 8.0605 roll_mask_loss: 8.1714 density_loss: 8.3948 unmask_loss: 8.2604 Lr: 0.00094
[2025-12-10 17:07:26,281 INFO misc.py line 117 4140988] Train: [1/10][938/7400] Data 0.004 (0.004) Batch 0.478 (0.619) Remain 12:33:52 loss: 8.1680 mask_loss: 7.9214 roll_mask_loss: 8.1038 density_loss: 8.4256 unmask_loss: 8.1548 Lr: 0.00094
[2025-12-10 17:07:27,055 INFO misc.py line 117 4140988] Train: [1/10][939/7400] Data 0.004 (0.004) Batch 0.774 (0.619) Remain 12:34:03 loss: 7.4560 mask_loss: 6.9686 roll_mask_loss: 7.3531 density_loss: 8.3782 unmask_loss: 7.5836 Lr: 0.00094
[2025-12-10 17:07:27,782 INFO misc.py line 117 4140988] Train: [1/10][940/7400] Data 0.004 (0.004) Batch 0.727 (0.619) Remain 12:34:11 loss: 7.4131 mask_loss: 6.7920 roll_mask_loss: 7.2632 density_loss: 8.7502 unmask_loss: 7.6237 Lr: 0.00094
[2025-12-10 17:07:28,464 INFO misc.py line 117 4140988] Train: [1/10][941/7400] Data 0.004 (0.004) Batch 0.682 (0.619) Remain 12:34:16 loss: 7.2372 mask_loss: 6.6867 roll_mask_loss: 7.1111 density_loss: 9.1093 unmask_loss: 7.3933 Lr: 0.00094
[2025-12-10 17:07:29,039 INFO misc.py line 117 4140988] Train: [1/10][942/7400] Data 0.004 (0.004) Batch 0.576 (0.619) Remain 12:34:11 loss: 7.3175 mask_loss: 6.6486 roll_mask_loss: 7.2307 density_loss: 9.1646 unmask_loss: 7.5121 Lr: 0.00094
[2025-12-10 17:07:29,826 INFO misc.py line 117 4140988] Train: [1/10][943/7400] Data 0.003 (0.004) Batch 0.787 (0.620) Remain 12:34:24 loss: 7.2501 mask_loss: 6.5019 roll_mask_loss: 7.2138 density_loss: 8.8875 unmask_loss: 7.4646 Lr: 0.00094
[2025-12-10 17:07:30,418 INFO misc.py line 117 4140988] Train: [1/10][944/7400] Data 0.003 (0.004) Batch 0.593 (0.620) Remain 12:34:21 loss: 7.7654 mask_loss: 7.3547 roll_mask_loss: 8.0123 density_loss: 8.5880 unmask_loss: 7.6756 Lr: 0.00095
[2025-12-10 17:07:31,205 INFO misc.py line 117 4140988] Train: [1/10][945/7400] Data 0.003 (0.004) Batch 0.786 (0.620) Remain 12:34:33 loss: 7.1201 mask_loss: 6.4232 roll_mask_loss: 6.8750 density_loss: 8.6109 unmask_loss: 7.4188 Lr: 0.00095
[2025-12-10 17:07:31,765 INFO misc.py line 117 4140988] Train: [1/10][946/7400] Data 0.005 (0.004) Batch 0.560 (0.620) Remain 12:34:28 loss: 7.4832 mask_loss: 6.8040 roll_mask_loss: 7.2814 density_loss: 8.2845 unmask_loss: 7.7581 Lr: 0.00095
[2025-12-10 17:07:32,265 INFO misc.py line 117 4140988] Train: [1/10][947/7400] Data 0.004 (0.004) Batch 0.500 (0.620) Remain 12:34:18 loss: 7.5475 mask_loss: 6.9919 roll_mask_loss: 7.4188 density_loss: 8.7235 unmask_loss: 7.7152 Lr: 0.00095
[2025-12-10 17:07:33,063 INFO misc.py line 117 4140988] Train: [1/10][948/7400] Data 0.004 (0.004) Batch 0.799 (0.620) Remain 12:34:32 loss: 7.3255 mask_loss: 6.6067 roll_mask_loss: 7.2811 density_loss: 8.7456 unmask_loss: 7.5321 Lr: 0.00095
[2025-12-10 17:07:33,820 INFO misc.py line 117 4140988] Train: [1/10][949/7400] Data 0.003 (0.004) Batch 0.757 (0.620) Remain 12:34:42 loss: 7.1935 mask_loss: 6.5430 roll_mask_loss: 7.0386 density_loss: 8.8049 unmask_loss: 7.4202 Lr: 0.00095
[2025-12-10 17:07:34,298 INFO misc.py line 117 4140988] Train: [1/10][950/7400] Data 0.003 (0.004) Batch 0.478 (0.620) Remain 12:34:30 loss: 8.2492 mask_loss: 7.2748 roll_mask_loss: 8.8312 density_loss: 8.5485 unmask_loss: 8.2744 Lr: 0.00095
[2025-12-10 17:07:34,933 INFO misc.py line 117 4140988] Train: [1/10][951/7400] Data 0.003 (0.004) Batch 0.636 (0.620) Remain 12:34:31 loss: 7.2102 mask_loss: 6.2814 roll_mask_loss: 7.1319 density_loss: 8.7742 unmask_loss: 7.5383 Lr: 0.00095
[2025-12-10 17:07:35,684 INFO misc.py line 117 4140988] Train: [1/10][952/7400] Data 0.003 (0.004) Batch 0.750 (0.620) Remain 12:34:40 loss: 7.2496 mask_loss: 6.4698 roll_mask_loss: 7.1767 density_loss: 9.3376 unmask_loss: 7.4892 Lr: 0.00095
[2025-12-10 17:07:36,322 INFO misc.py line 117 4140988] Train: [1/10][953/7400] Data 0.003 (0.004) Batch 0.638 (0.620) Remain 12:34:41 loss: 7.5977 mask_loss: 6.6423 roll_mask_loss: 7.4070 density_loss: 9.0506 unmask_loss: 7.9898 Lr: 0.00096
[2025-12-10 17:07:36,972 INFO misc.py line 117 4140988] Train: [1/10][954/7400] Data 0.004 (0.004) Batch 0.650 (0.620) Remain 12:34:42 loss: 7.1587 mask_loss: 6.5100 roll_mask_loss: 7.0399 density_loss: 9.5948 unmask_loss: 7.3505 Lr: 0.00096
[2025-12-10 17:07:37,737 INFO misc.py line 117 4140988] Train: [1/10][955/7400] Data 0.004 (0.004) Batch 0.765 (0.620) Remain 12:34:53 loss: 7.2430 mask_loss: 6.4209 roll_mask_loss: 7.2023 density_loss: 9.5080 unmask_loss: 7.4843 Lr: 0.00096
[2025-12-10 17:07:38,067 INFO misc.py line 117 4140988] Train: [1/10][956/7400] Data 0.004 (0.004) Batch 0.330 (0.620) Remain 12:34:30 loss: 7.2550 mask_loss: 6.5026 roll_mask_loss: 7.1666 density_loss: 9.3329 unmask_loss: 7.4887 Lr: 0.00096
[2025-12-10 17:07:38,709 INFO misc.py line 117 4140988] Train: [1/10][957/7400] Data 0.004 (0.004) Batch 0.642 (0.620) Remain 12:34:31 loss: 7.1589 mask_loss: 6.5945 roll_mask_loss: 7.0703 density_loss: 9.6086 unmask_loss: 7.2932 Lr: 0.00096
[2025-12-10 17:07:39,298 INFO misc.py line 117 4140988] Train: [1/10][958/7400] Data 0.004 (0.004) Batch 0.589 (0.620) Remain 12:34:28 loss: 7.7589 mask_loss: 7.3339 roll_mask_loss: 7.6238 density_loss: 8.7396 unmask_loss: 7.8641 Lr: 0.00096
[2025-12-10 17:07:40,056 INFO misc.py line 117 4140988] Train: [1/10][959/7400] Data 0.004 (0.004) Batch 0.758 (0.620) Remain 12:34:38 loss: 7.2439 mask_loss: 6.3130 roll_mask_loss: 7.1447 density_loss: 8.7847 unmask_loss: 7.5833 Lr: 0.00096
[2025-12-10 17:07:40,667 INFO misc.py line 117 4140988] Train: [1/10][960/7400] Data 0.004 (0.004) Batch 0.612 (0.620) Remain 12:34:37 loss: 7.1216 mask_loss: 6.4194 roll_mask_loss: 6.9921 density_loss: 8.6680 unmask_loss: 7.3642 Lr: 0.00096
[2025-12-10 17:07:41,343 INFO misc.py line 117 4140988] Train: [1/10][961/7400] Data 0.003 (0.004) Batch 0.676 (0.620) Remain 12:34:41 loss: 7.4143 mask_loss: 6.7619 roll_mask_loss: 7.4175 density_loss: 8.9632 unmask_loss: 7.5596 Lr: 0.00096
[2025-12-10 17:07:41,875 INFO misc.py line 117 4140988] Train: [1/10][962/7400] Data 0.004 (0.004) Batch 0.532 (0.620) Remain 12:34:33 loss: 8.2710 mask_loss: 8.0345 roll_mask_loss: 8.7078 density_loss: 8.2976 unmask_loss: 8.0048 Lr: 0.00097
[2025-12-10 17:07:42,413 INFO misc.py line 117 4140988] Train: [1/10][963/7400] Data 0.005 (0.004) Batch 0.538 (0.620) Remain 12:34:26 loss: 7.6743 mask_loss: 7.3551 roll_mask_loss: 7.9548 density_loss: 8.3842 unmask_loss: 7.5259 Lr: 0.00097
[2025-12-10 17:07:43,083 INFO misc.py line 117 4140988] Train: [1/10][964/7400] Data 0.004 (0.004) Batch 0.670 (0.620) Remain 12:34:30 loss: 7.6593 mask_loss: 6.9812 roll_mask_loss: 7.5906 density_loss: 8.9081 unmask_loss: 7.8544 Lr: 0.00097
[2025-12-10 17:07:43,708 INFO misc.py line 117 4140988] Train: [1/10][965/7400] Data 0.003 (0.004) Batch 0.625 (0.620) Remain 12:34:29 loss: 7.1547 mask_loss: 6.4527 roll_mask_loss: 7.0928 density_loss: 7.8700 unmask_loss: 7.3793 Lr: 0.00097
[2025-12-10 17:07:44,296 INFO misc.py line 117 4140988] Train: [1/10][966/7400] Data 0.004 (0.004) Batch 0.588 (0.620) Remain 12:34:26 loss: 7.3127 mask_loss: 6.5819 roll_mask_loss: 7.3814 density_loss: 8.9618 unmask_loss: 7.4645 Lr: 0.00097
[2025-12-10 17:07:44,842 INFO misc.py line 117 4140988] Train: [1/10][967/7400] Data 0.004 (0.004) Batch 0.546 (0.620) Remain 12:34:20 loss: 8.0499 mask_loss: 7.3650 roll_mask_loss: 7.6975 density_loss: 8.2728 unmask_loss: 8.4032 Lr: 0.00097
[2025-12-10 17:07:45,372 INFO misc.py line 117 4140988] Train: [1/10][968/7400] Data 0.004 (0.004) Batch 0.531 (0.620) Remain 12:34:13 loss: 7.5937 mask_loss: 6.9085 roll_mask_loss: 7.6229 density_loss: 8.9481 unmask_loss: 7.7429 Lr: 0.00097
[2025-12-10 17:07:46,061 INFO misc.py line 117 4140988] Train: [1/10][969/7400] Data 0.003 (0.004) Batch 0.689 (0.620) Remain 12:34:17 loss: 7.1875 mask_loss: 6.4641 roll_mask_loss: 7.1862 density_loss: 9.2685 unmask_loss: 7.3644 Lr: 0.00097
[2025-12-10 17:07:46,724 INFO misc.py line 117 4140988] Train: [1/10][970/7400] Data 0.004 (0.004) Batch 0.663 (0.620) Remain 12:34:20 loss: 7.3696 mask_loss: 6.7508 roll_mask_loss: 7.2916 density_loss: 8.9341 unmask_loss: 7.5393 Lr: 0.00097
[2025-12-10 17:07:47,443 INFO misc.py line 117 4140988] Train: [1/10][971/7400] Data 0.004 (0.004) Batch 0.719 (0.620) Remain 12:34:27 loss: 7.3441 mask_loss: 6.6668 roll_mask_loss: 7.2639 density_loss: 8.5607 unmask_loss: 7.5515 Lr: 0.00098
[2025-12-10 17:07:47,759 INFO misc.py line 117 4140988] Train: [1/10][972/7400] Data 0.004 (0.004) Batch 0.317 (0.620) Remain 12:34:03 loss: 7.3065 mask_loss: 6.6523 roll_mask_loss: 7.1339 density_loss: 9.4203 unmask_loss: 7.5315 Lr: 0.00098
[2025-12-10 17:07:48,298 INFO misc.py line 117 4140988] Train: [1/10][973/7400] Data 0.004 (0.004) Batch 0.538 (0.619) Remain 12:33:57 loss: 7.9142 mask_loss: 7.5419 roll_mask_loss: 7.9930 density_loss: 8.2139 unmask_loss: 7.8967 Lr: 0.00098
[2025-12-10 17:07:49,151 INFO misc.py line 117 4140988] Train: [1/10][974/7400] Data 0.004 (0.004) Batch 0.854 (0.620) Remain 12:34:14 loss: 7.2839 mask_loss: 6.3197 roll_mask_loss: 7.0168 density_loss: 9.7987 unmask_loss: 7.7036 Lr: 0.00098
[2025-12-10 17:07:49,769 INFO misc.py line 117 4140988] Train: [1/10][975/7400] Data 0.004 (0.004) Batch 0.618 (0.620) Remain 12:34:13 loss: 7.1440 mask_loss: 6.4424 roll_mask_loss: 7.0513 density_loss: 9.5356 unmask_loss: 7.3504 Lr: 0.00098
[2025-12-10 17:07:50,531 INFO misc.py line 117 4140988] Train: [1/10][976/7400] Data 0.004 (0.004) Batch 0.762 (0.620) Remain 12:34:23 loss: 7.1808 mask_loss: 6.5122 roll_mask_loss: 7.0760 density_loss: 8.2718 unmask_loss: 7.4020 Lr: 0.00098
[2025-12-10 17:07:51,232 INFO misc.py line 117 4140988] Train: [1/10][977/7400] Data 0.004 (0.004) Batch 0.701 (0.620) Remain 12:34:28 loss: 7.8220 mask_loss: 7.2469 roll_mask_loss: 7.6409 density_loss: 8.6282 unmask_loss: 8.0275 Lr: 0.00098
[2025-12-10 17:07:51,835 INFO misc.py line 117 4140988] Train: [1/10][978/7400] Data 0.003 (0.004) Batch 0.604 (0.620) Remain 12:34:26 loss: 8.5441 mask_loss: 8.3099 roll_mask_loss: 8.3775 density_loss: 8.3662 unmask_loss: 8.5771 Lr: 0.00098
[2025-12-10 17:07:52,362 INFO misc.py line 117 4140988] Train: [1/10][979/7400] Data 0.003 (0.004) Batch 0.527 (0.620) Remain 12:34:19 loss: 7.2657 mask_loss: 6.5080 roll_mask_loss: 7.3345 density_loss: 9.7719 unmask_loss: 7.4148 Lr: 0.00098
[2025-12-10 17:07:52,827 INFO misc.py line 117 4140988] Train: [1/10][980/7400] Data 0.003 (0.004) Batch 0.464 (0.620) Remain 12:34:07 loss: 7.8557 mask_loss: 7.1556 roll_mask_loss: 7.8232 density_loss: 8.4134 unmask_loss: 8.0538 Lr: 0.00099
[2025-12-10 17:07:53,419 INFO misc.py line 117 4140988] Train: [1/10][981/7400] Data 0.004 (0.004) Batch 0.592 (0.620) Remain 12:34:04 loss: 7.2854 mask_loss: 6.6602 roll_mask_loss: 7.1461 density_loss: 8.4619 unmask_loss: 7.4984 Lr: 0.00099
[2025-12-10 17:07:53,939 INFO misc.py line 117 4140988] Train: [1/10][982/7400] Data 0.004 (0.004) Batch 0.520 (0.620) Remain 12:33:56 loss: 7.1164 mask_loss: 6.3951 roll_mask_loss: 6.8915 density_loss: 8.8017 unmask_loss: 7.4134 Lr: 0.00099
[2025-12-10 17:07:54,429 INFO misc.py line 117 4140988] Train: [1/10][983/7400] Data 0.005 (0.004) Batch 0.490 (0.619) Remain 12:33:46 loss: 8.1211 mask_loss: 7.3365 roll_mask_loss: 8.0892 density_loss: 8.6179 unmask_loss: 8.3571 Lr: 0.00099
[2025-12-10 17:07:55,032 INFO misc.py line 117 4140988] Train: [1/10][984/7400] Data 0.004 (0.004) Batch 0.603 (0.619) Remain 12:33:44 loss: 7.3807 mask_loss: 6.6971 roll_mask_loss: 7.2329 density_loss: 8.4477 unmask_loss: 7.6274 Lr: 0.00099
[2025-12-10 17:07:55,575 INFO misc.py line 117 4140988] Train: [1/10][985/7400] Data 0.004 (0.004) Batch 0.543 (0.619) Remain 12:33:38 loss: 7.4339 mask_loss: 6.8910 roll_mask_loss: 7.1779 density_loss: 7.9259 unmask_loss: 7.6748 Lr: 0.00099
[2025-12-10 17:07:55,991 INFO misc.py line 117 4140988] Train: [1/10][986/7400] Data 0.004 (0.004) Batch 0.415 (0.619) Remain 12:33:22 loss: 8.4539 mask_loss: 8.3322 roll_mask_loss: 8.3858 density_loss: 8.3800 unmask_loss: 8.3812 Lr: 0.00099
[2025-12-10 17:07:56,750 INFO misc.py line 117 4140988] Train: [1/10][987/7400] Data 0.004 (0.004) Batch 0.760 (0.619) Remain 12:33:32 loss: 7.3131 mask_loss: 6.4706 roll_mask_loss: 7.1831 density_loss: 8.9212 unmask_loss: 7.6210 Lr: 0.00099
[2025-12-10 17:07:57,510 INFO misc.py line 117 4140988] Train: [1/10][988/7400] Data 0.004 (0.004) Batch 0.759 (0.619) Remain 12:33:41 loss: 7.0549 mask_loss: 6.3397 roll_mask_loss: 6.7924 density_loss: 8.9978 unmask_loss: 7.3638 Lr: 0.00100
[2025-12-10 17:07:58,136 INFO misc.py line 117 4140988] Train: [1/10][989/7400] Data 0.003 (0.004) Batch 0.626 (0.619) Remain 12:33:41 loss: 8.3879 mask_loss: 8.1952 roll_mask_loss: 8.3557 density_loss: 8.3845 unmask_loss: 8.3326 Lr: 0.00100
[2025-12-10 17:07:58,848 INFO misc.py line 117 4140988] Train: [1/10][990/7400] Data 0.004 (0.004) Batch 0.712 (0.619) Remain 12:33:47 loss: 7.3155 mask_loss: 6.5550 roll_mask_loss: 7.2379 density_loss: 8.4675 unmask_loss: 7.5652 Lr: 0.00100
[2025-12-10 17:07:59,627 INFO misc.py line 117 4140988] Train: [1/10][991/7400] Data 0.004 (0.004) Batch 0.779 (0.620) Remain 12:33:59 loss: 7.7072 mask_loss: 7.0480 roll_mask_loss: 7.6411 density_loss: 8.8617 unmask_loss: 7.8926 Lr: 0.00100
[2025-12-10 17:08:00,166 INFO misc.py line 117 4140988] Train: [1/10][992/7400] Data 0.004 (0.004) Batch 0.538 (0.620) Remain 12:33:52 loss: 7.2400 mask_loss: 6.5641 roll_mask_loss: 7.2136 density_loss: 9.5150 unmask_loss: 7.4009 Lr: 0.00100
[2025-12-10 17:08:00,661 INFO misc.py line 117 4140988] Train: [1/10][993/7400] Data 0.004 (0.004) Batch 0.495 (0.619) Remain 12:33:42 loss: 7.9518 mask_loss: 7.4770 roll_mask_loss: 7.9962 density_loss: 8.4502 unmask_loss: 7.9980 Lr: 0.00100
[2025-12-10 17:08:01,419 INFO misc.py line 117 4140988] Train: [1/10][994/7400] Data 0.004 (0.004) Batch 0.758 (0.620) Remain 12:33:52 loss: 7.2944 mask_loss: 6.5422 roll_mask_loss: 7.0179 density_loss: 8.9629 unmask_loss: 7.6295 Lr: 0.00100
[2025-12-10 17:08:02,368 INFO misc.py line 117 4140988] Train: [1/10][995/7400] Data 0.004 (0.004) Batch 0.950 (0.620) Remain 12:34:16 loss: 7.2876 mask_loss: 6.4410 roll_mask_loss: 7.4671 density_loss: 9.7351 unmask_loss: 7.4265 Lr: 0.00100
[2025-12-10 17:08:02,981 INFO misc.py line 117 4140988] Train: [1/10][996/7400] Data 0.004 (0.004) Batch 0.613 (0.620) Remain 12:34:14 loss: 7.0499 mask_loss: 6.2792 roll_mask_loss: 6.9004 density_loss: 8.4536 unmask_loss: 7.3410 Lr: 0.00100
[2025-12-10 17:08:03,535 INFO misc.py line 117 4140988] Train: [1/10][997/7400] Data 0.003 (0.004) Batch 0.554 (0.620) Remain 12:34:09 loss: 7.2790 mask_loss: 6.6420 roll_mask_loss: 7.2061 density_loss: 8.3983 unmask_loss: 7.4660 Lr: 0.00101
[2025-12-10 17:08:04,144 INFO misc.py line 117 4140988] Train: [1/10][998/7400] Data 0.003 (0.004) Batch 0.609 (0.620) Remain 12:34:08 loss: 7.3443 mask_loss: 6.7868 roll_mask_loss: 7.3154 density_loss: 8.3875 unmask_loss: 7.4697 Lr: 0.00101
[2025-12-10 17:08:04,796 INFO misc.py line 117 4140988] Train: [1/10][999/7400] Data 0.004 (0.004) Batch 0.651 (0.620) Remain 12:34:09 loss: 7.3286 mask_loss: 6.6843 roll_mask_loss: 7.3532 density_loss: 8.9298 unmask_loss: 7.4598 Lr: 0.00101
[2025-12-10 17:08:05,515 INFO misc.py line 117 4140988] Train: [1/10][1000/7400] Data 0.004 (0.004) Batch 0.719 (0.620) Remain 12:34:16 loss: 7.2508 mask_loss: 6.4694 roll_mask_loss: 7.2759 density_loss: 9.3435 unmask_loss: 7.4421 Lr: 0.00101
[2025-12-10 17:08:06,130 INFO misc.py line 117 4140988] Train: [1/10][1001/7400] Data 0.004 (0.004) Batch 0.615 (0.620) Remain 12:34:15 loss: 7.8837 mask_loss: 7.4837 roll_mask_loss: 7.8053 density_loss: 8.3295 unmask_loss: 7.9562 Lr: 0.00101
[2025-12-10 17:08:07,035 INFO misc.py line 117 4140988] Train: [1/10][1002/7400] Data 0.004 (0.004) Batch 0.905 (0.620) Remain 12:34:35 loss: 7.2129 mask_loss: 6.4796 roll_mask_loss: 7.1577 density_loss: 8.7599 unmask_loss: 7.4319 Lr: 0.00101
[2025-12-10 17:08:07,703 INFO misc.py line 117 4140988] Train: [1/10][1003/7400] Data 0.004 (0.004) Batch 0.668 (0.620) Remain 12:34:38 loss: 7.4668 mask_loss: 7.0492 roll_mask_loss: 7.3262 density_loss: 8.7291 unmask_loss: 7.5714 Lr: 0.00101
[2025-12-10 17:08:08,282 INFO misc.py line 117 4140988] Train: [1/10][1004/7400] Data 0.003 (0.004) Batch 0.580 (0.620) Remain 12:34:34 loss: 7.3683 mask_loss: 6.7299 roll_mask_loss: 7.2104 density_loss: 9.7072 unmask_loss: 7.5723 Lr: 0.00101
[2025-12-10 17:08:08,802 INFO misc.py line 117 4140988] Train: [1/10][1005/7400] Data 0.003 (0.004) Batch 0.520 (0.620) Remain 12:34:26 loss: 8.0186 mask_loss: 7.7392 roll_mask_loss: 7.8831 density_loss: 8.6150 unmask_loss: 8.0537 Lr: 0.00101
[2025-12-10 17:08:09,307 INFO misc.py line 117 4140988] Train: [1/10][1006/7400] Data 0.004 (0.004) Batch 0.504 (0.620) Remain 12:34:17 loss: 7.3142 mask_loss: 6.7079 roll_mask_loss: 7.2670 density_loss: 9.4143 unmask_loss: 7.4527 Lr: 0.00102
[2025-12-10 17:08:09,597 INFO misc.py line 117 4140988] Train: [1/10][1007/7400] Data 0.004 (0.004) Batch 0.290 (0.620) Remain 12:33:53 loss: 8.3604 mask_loss: 8.1302 roll_mask_loss: 8.3358 density_loss: 8.5385 unmask_loss: 8.3169 Lr: 0.00102
[2025-12-10 17:08:10,453 INFO misc.py line 117 4140988] Train: [1/10][1008/7400] Data 0.004 (0.004) Batch 0.855 (0.620) Remain 12:34:09 loss: 7.1728 mask_loss: 6.4213 roll_mask_loss: 7.0343 density_loss: 8.8995 unmask_loss: 7.4398 Lr: 0.00102
[2025-12-10 17:08:11,130 INFO misc.py line 117 4140988] Train: [1/10][1009/7400] Data 0.004 (0.004) Batch 0.678 (0.620) Remain 12:34:13 loss: 8.0567 mask_loss: 7.7783 roll_mask_loss: 8.2611 density_loss: 8.7803 unmask_loss: 7.9181 Lr: 0.00102
[2025-12-10 17:08:11,593 INFO misc.py line 117 4140988] Train: [1/10][1010/7400] Data 0.004 (0.004) Batch 0.463 (0.620) Remain 12:34:01 loss: 8.3879 mask_loss: 8.0619 roll_mask_loss: 8.5794 density_loss: 8.4199 unmask_loss: 8.2868 Lr: 0.00102
[2025-12-10 17:08:12,234 INFO misc.py line 117 4140988] Train: [1/10][1011/7400] Data 0.004 (0.004) Batch 0.642 (0.620) Remain 12:34:02 loss: 7.5471 mask_loss: 6.9110 roll_mask_loss: 7.4277 density_loss: 8.6914 unmask_loss: 7.7510 Lr: 0.00102
[2025-12-10 17:08:12,788 INFO misc.py line 117 4140988] Train: [1/10][1012/7400] Data 0.004 (0.004) Batch 0.554 (0.620) Remain 12:33:56 loss: 7.7965 mask_loss: 7.2066 roll_mask_loss: 7.8244 density_loss: 8.3040 unmask_loss: 7.9113 Lr: 0.00102
[2025-12-10 17:08:13,360 INFO misc.py line 117 4140988] Train: [1/10][1013/7400] Data 0.004 (0.004) Batch 0.572 (0.620) Remain 12:33:52 loss: 7.0944 mask_loss: 6.3077 roll_mask_loss: 6.9983 density_loss: 9.1709 unmask_loss: 7.3524 Lr: 0.00102
[2025-12-10 17:08:14,158 INFO misc.py line 117 4140988] Train: [1/10][1014/7400] Data 0.003 (0.004) Batch 0.798 (0.620) Remain 12:34:05 loss: 7.2900 mask_loss: 6.6887 roll_mask_loss: 7.0677 density_loss: 8.9370 unmask_loss: 7.5231 Lr: 0.00102
[2025-12-10 17:08:14,722 INFO misc.py line 117 4140988] Train: [1/10][1015/7400] Data 0.003 (0.004) Batch 0.564 (0.620) Remain 12:34:00 loss: 7.1206 mask_loss: 6.3670 roll_mask_loss: 7.1037 density_loss: 8.2781 unmask_loss: 7.3404 Lr: 0.00103
[2025-12-10 17:08:15,458 INFO misc.py line 117 4140988] Train: [1/10][1016/7400] Data 0.003 (0.004) Batch 0.735 (0.620) Remain 12:34:08 loss: 7.2881 mask_loss: 6.6296 roll_mask_loss: 7.2006 density_loss: 8.7394 unmask_loss: 7.4863 Lr: 0.00103
[2025-12-10 17:08:16,234 INFO misc.py line 117 4140988] Train: [1/10][1017/7400] Data 0.003 (0.004) Batch 0.775 (0.620) Remain 12:34:18 loss: 6.9883 mask_loss: 6.0878 roll_mask_loss: 6.8079 density_loss: 9.1987 unmask_loss: 7.3448 Lr: 0.00103
[2025-12-10 17:08:16,546 INFO misc.py line 117 4140988] Train: [1/10][1018/7400] Data 0.004 (0.004) Batch 0.312 (0.620) Remain 12:33:55 loss: 7.3036 mask_loss: 6.5706 roll_mask_loss: 7.2653 density_loss: 9.8366 unmask_loss: 7.4924 Lr: 0.00103
[2025-12-10 17:08:17,268 INFO misc.py line 117 4140988] Train: [1/10][1019/7400] Data 0.004 (0.004) Batch 0.722 (0.620) Remain 12:34:02 loss: 7.3945 mask_loss: 6.8024 roll_mask_loss: 7.2621 density_loss: 9.0438 unmask_loss: 7.5758 Lr: 0.00103
[2025-12-10 17:08:18,175 INFO misc.py line 117 4140988] Train: [1/10][1020/7400] Data 0.004 (0.004) Batch 0.907 (0.620) Remain 12:34:22 loss: 7.1379 mask_loss: 6.2058 roll_mask_loss: 7.0029 density_loss: 9.4771 unmask_loss: 7.4820 Lr: 0.00103
[2025-12-10 17:08:18,921 INFO misc.py line 117 4140988] Train: [1/10][1021/7400] Data 0.004 (0.004) Batch 0.746 (0.620) Remain 12:34:31 loss: 7.3792 mask_loss: 6.1737 roll_mask_loss: 7.0986 density_loss: 8.8182 unmask_loss: 7.9459 Lr: 0.00103
[2025-12-10 17:08:19,580 INFO misc.py line 117 4140988] Train: [1/10][1022/7400] Data 0.004 (0.004) Batch 0.659 (0.620) Remain 12:34:33 loss: 7.1040 mask_loss: 6.1771 roll_mask_loss: 7.1192 density_loss: 8.6471 unmask_loss: 7.3868 Lr: 0.00103
[2025-12-10 17:08:20,297 INFO misc.py line 117 4140988] Train: [1/10][1023/7400] Data 0.003 (0.004) Batch 0.716 (0.620) Remain 12:34:39 loss: 7.3076 mask_loss: 6.6632 roll_mask_loss: 7.1818 density_loss: 9.8874 unmask_loss: 7.4949 Lr: 0.00104
[2025-12-10 17:08:20,869 INFO misc.py line 117 4140988] Train: [1/10][1024/7400] Data 0.004 (0.004) Batch 0.573 (0.620) Remain 12:34:35 loss: 7.3081 mask_loss: 6.5413 roll_mask_loss: 7.4492 density_loss: 10.1394 unmask_loss: 7.4181 Lr: 0.00104
[2025-12-10 17:08:21,510 INFO misc.py line 117 4140988] Train: [1/10][1025/7400] Data 0.003 (0.004) Batch 0.641 (0.620) Remain 12:34:36 loss: 7.1782 mask_loss: 6.4648 roll_mask_loss: 7.1380 density_loss: 9.0939 unmask_loss: 7.3732 Lr: 0.00104
[2025-12-10 17:08:22,023 INFO misc.py line 117 4140988] Train: [1/10][1026/7400] Data 0.003 (0.004) Batch 0.514 (0.620) Remain 12:34:28 loss: 7.2016 mask_loss: 6.3540 roll_mask_loss: 7.2186 density_loss: 9.7199 unmask_loss: 7.4224 Lr: 0.00104
[2025-12-10 17:08:22,651 INFO misc.py line 117 4140988] Train: [1/10][1027/7400] Data 0.003 (0.004) Batch 0.628 (0.620) Remain 12:34:28 loss: 7.0612 mask_loss: 6.1618 roll_mask_loss: 6.8362 density_loss: 9.4465 unmask_loss: 7.4343 Lr: 0.00104
[2025-12-10 17:08:23,372 INFO misc.py line 117 4140988] Train: [1/10][1028/7400] Data 0.003 (0.004) Batch 0.720 (0.620) Remain 12:34:34 loss: 7.0429 mask_loss: 6.2145 roll_mask_loss: 6.8619 density_loss: 9.6361 unmask_loss: 7.3549 Lr: 0.00104
[2025-12-10 17:08:23,679 INFO misc.py line 117 4140988] Train: [1/10][1029/7400] Data 0.003 (0.004) Batch 0.306 (0.620) Remain 12:34:11 loss: 8.5581 mask_loss: 8.3293 roll_mask_loss: 8.3423 density_loss: 8.3430 unmask_loss: 8.6135 Lr: 0.00104
[2025-12-10 17:08:24,254 INFO misc.py line 117 4140988] Train: [1/10][1030/7400] Data 0.004 (0.004) Batch 0.575 (0.620) Remain 12:34:07 loss: 8.3933 mask_loss: 7.8372 roll_mask_loss: 8.2674 density_loss: 8.4941 unmask_loss: 8.5643 Lr: 0.00104
[2025-12-10 17:08:24,773 INFO misc.py line 117 4140988] Train: [1/10][1031/7400] Data 0.004 (0.004) Batch 0.519 (0.620) Remain 12:33:59 loss: 8.4751 mask_loss: 8.0695 roll_mask_loss: 8.2468 density_loss: 8.4953 unmask_loss: 8.6221 Lr: 0.00104
[2025-12-10 17:08:25,386 INFO misc.py line 117 4140988] Train: [1/10][1032/7400] Data 0.003 (0.004) Batch 0.613 (0.620) Remain 12:33:58 loss: 7.9861 mask_loss: 7.3863 roll_mask_loss: 7.9935 density_loss: 8.7212 unmask_loss: 8.1080 Lr: 0.00105
[2025-12-10 17:08:26,149 INFO misc.py line 117 4140988] Train: [1/10][1033/7400] Data 0.004 (0.004) Batch 0.764 (0.620) Remain 12:34:08 loss: 7.2504 mask_loss: 6.3351 roll_mask_loss: 7.0686 density_loss: 8.9718 unmask_loss: 7.6195 Lr: 0.00105
[2025-12-10 17:08:26,857 INFO misc.py line 117 4140988] Train: [1/10][1034/7400] Data 0.003 (0.004) Batch 0.708 (0.620) Remain 12:34:13 loss: 7.3124 mask_loss: 6.7576 roll_mask_loss: 7.3555 density_loss: 8.4616 unmask_loss: 7.3991 Lr: 0.00105
[2025-12-10 17:08:27,462 INFO misc.py line 117 4140988] Train: [1/10][1035/7400] Data 0.003 (0.004) Batch 0.605 (0.620) Remain 12:34:12 loss: 7.7009 mask_loss: 7.0563 roll_mask_loss: 7.5182 density_loss: 8.7137 unmask_loss: 7.9403 Lr: 0.00105
[2025-12-10 17:08:28,371 INFO misc.py line 117 4140988] Train: [1/10][1036/7400] Data 0.004 (0.004) Batch 0.909 (0.620) Remain 12:34:32 loss: 7.2291 mask_loss: 6.4157 roll_mask_loss: 7.0406 density_loss: 8.9965 unmask_loss: 7.5500 Lr: 0.00105
[2025-12-10 17:08:28,827 INFO misc.py line 117 4140988] Train: [1/10][1037/7400] Data 0.004 (0.004) Batch 0.456 (0.620) Remain 12:34:19 loss: 7.9256 mask_loss: 7.1729 roll_mask_loss: 8.1042 density_loss: 9.1063 unmask_loss: 8.0305 Lr: 0.00105
[2025-12-10 17:08:29,643 INFO misc.py line 117 4140988] Train: [1/10][1038/7400] Data 0.004 (0.004) Batch 0.815 (0.620) Remain 12:34:32 loss: 7.2461 mask_loss: 6.1342 roll_mask_loss: 7.2439 density_loss: 9.7547 unmask_loss: 7.6080 Lr: 0.00105
[2025-12-10 17:08:30,332 INFO misc.py line 117 4140988] Train: [1/10][1039/7400] Data 0.004 (0.004) Batch 0.690 (0.621) Remain 12:34:37 loss: 7.3247 mask_loss: 6.7507 roll_mask_loss: 7.2939 density_loss: 8.6498 unmask_loss: 7.4541 Lr: 0.00105
[2025-12-10 17:08:30,869 INFO misc.py line 117 4140988] Train: [1/10][1040/7400] Data 0.003 (0.004) Batch 0.537 (0.620) Remain 12:34:30 loss: 7.2229 mask_loss: 6.6531 roll_mask_loss: 7.0033 density_loss: 9.5231 unmask_loss: 7.4272 Lr: 0.00106
[2025-12-10 17:08:31,411 INFO misc.py line 117 4140988] Train: [1/10][1041/7400] Data 0.003 (0.004) Batch 0.542 (0.620) Remain 12:34:24 loss: 7.3673 mask_loss: 6.6015 roll_mask_loss: 7.6049 density_loss: 9.0838 unmask_loss: 7.4498 Lr: 0.00106
[2025-12-10 17:08:32,373 INFO misc.py line 117 4140988] Train: [1/10][1042/7400] Data 0.003 (0.004) Batch 0.962 (0.621) Remain 12:34:47 loss: 7.2138 mask_loss: 6.1238 roll_mask_loss: 7.0515 density_loss: 9.3260 unmask_loss: 7.6534 Lr: 0.00106
[2025-12-10 17:08:32,940 INFO misc.py line 117 4140988] Train: [1/10][1043/7400] Data 0.003 (0.004) Batch 0.567 (0.621) Remain 12:34:43 loss: 7.4880 mask_loss: 6.6552 roll_mask_loss: 7.2111 density_loss: 8.7542 unmask_loss: 7.8678 Lr: 0.00106
[2025-12-10 17:08:33,853 INFO misc.py line 117 4140988] Train: [1/10][1044/7400] Data 0.003 (0.004) Batch 0.913 (0.621) Remain 12:35:03 loss: 7.0508 mask_loss: 6.1855 roll_mask_loss: 6.8018 density_loss: 10.0356 unmask_loss: 7.4071 Lr: 0.00106
[2025-12-10 17:08:34,171 INFO misc.py line 117 4140988] Train: [1/10][1045/7400] Data 0.003 (0.004) Batch 0.318 (0.621) Remain 12:34:41 loss: 7.4298 mask_loss: 6.5416 roll_mask_loss: 7.1848 density_loss: 8.3991 unmask_loss: 7.8284 Lr: 0.00106
[2025-12-10 17:08:34,768 INFO misc.py line 117 4140988] Train: [1/10][1046/7400] Data 0.003 (0.004) Batch 0.596 (0.621) Remain 12:34:39 loss: 7.3231 mask_loss: 6.6446 roll_mask_loss: 7.1901 density_loss: 9.2055 unmask_loss: 7.5448 Lr: 0.00106
[2025-12-10 17:08:35,443 INFO misc.py line 117 4140988] Train: [1/10][1047/7400] Data 0.004 (0.004) Batch 0.675 (0.621) Remain 12:34:42 loss: 7.2432 mask_loss: 6.4248 roll_mask_loss: 7.1732 density_loss: 9.4804 unmask_loss: 7.4977 Lr: 0.00106
[2025-12-10 17:08:36,027 INFO misc.py line 117 4140988] Train: [1/10][1048/7400] Data 0.003 (0.004) Batch 0.584 (0.621) Remain 12:34:39 loss: 7.2486 mask_loss: 6.6925 roll_mask_loss: 7.1097 density_loss: 8.6308 unmask_loss: 7.4235 Lr: 0.00106
[2025-12-10 17:08:36,549 INFO misc.py line 117 4140988] Train: [1/10][1049/7400] Data 0.003 (0.004) Batch 0.522 (0.621) Remain 12:34:31 loss: 7.6539 mask_loss: 6.9152 roll_mask_loss: 7.6006 density_loss: 8.6376 unmask_loss: 7.8772 Lr: 0.00107
[2025-12-10 17:08:37,269 INFO misc.py line 117 4140988] Train: [1/10][1050/7400] Data 0.004 (0.004) Batch 0.720 (0.621) Remain 12:34:38 loss: 7.8766 mask_loss: 6.6717 roll_mask_loss: 8.1196 density_loss: 9.5008 unmask_loss: 8.1676 Lr: 0.00107
[2025-12-10 17:08:37,940 INFO misc.py line 117 4140988] Train: [1/10][1051/7400] Data 0.004 (0.004) Batch 0.671 (0.621) Remain 12:34:40 loss: 7.2130 mask_loss: 6.3949 roll_mask_loss: 7.1331 density_loss: 9.1879 unmask_loss: 7.4783 Lr: 0.00107
[2025-12-10 17:08:38,478 INFO misc.py line 117 4140988] Train: [1/10][1052/7400] Data 0.003 (0.004) Batch 0.538 (0.621) Remain 12:34:34 loss: 7.4568 mask_loss: 6.6749 roll_mask_loss: 7.4224 density_loss: 9.4858 unmask_loss: 7.6753 Lr: 0.00107
[2025-12-10 17:08:39,022 INFO misc.py line 117 4140988] Train: [1/10][1053/7400] Data 0.003 (0.004) Batch 0.544 (0.621) Remain 12:34:28 loss: 7.3799 mask_loss: 6.7996 roll_mask_loss: 7.3402 density_loss: 8.4811 unmask_loss: 7.5203 Lr: 0.00107
[2025-12-10 17:08:39,853 INFO misc.py line 117 4140988] Train: [1/10][1054/7400] Data 0.004 (0.004) Batch 0.830 (0.621) Remain 12:34:42 loss: 7.4306 mask_loss: 6.8946 roll_mask_loss: 7.3385 density_loss: 8.5775 unmask_loss: 7.5730 Lr: 0.00107
[2025-12-10 17:08:40,335 INFO misc.py line 117 4140988] Train: [1/10][1055/7400] Data 0.005 (0.004) Batch 0.483 (0.621) Remain 12:34:32 loss: 7.8512 mask_loss: 7.2843 roll_mask_loss: 7.7538 density_loss: 8.7095 unmask_loss: 8.0091 Lr: 0.00107
[2025-12-10 17:08:40,912 INFO misc.py line 117 4140988] Train: [1/10][1056/7400] Data 0.004 (0.004) Batch 0.577 (0.621) Remain 12:34:28 loss: 7.3617 mask_loss: 6.7181 roll_mask_loss: 7.2650 density_loss: 8.9862 unmask_loss: 7.5522 Lr: 0.00107
[2025-12-10 17:08:41,761 INFO misc.py line 117 4140988] Train: [1/10][1057/7400] Data 0.004 (0.004) Batch 0.848 (0.621) Remain 12:34:43 loss: 7.0161 mask_loss: 6.1873 roll_mask_loss: 6.7578 density_loss: 9.3294 unmask_loss: 7.3730 Lr: 0.00108
[2025-12-10 17:08:42,367 INFO misc.py line 117 4140988] Train: [1/10][1058/7400] Data 0.004 (0.004) Batch 0.606 (0.621) Remain 12:34:42 loss: 8.6170 mask_loss: 8.4116 roll_mask_loss: 9.0272 density_loss: 8.9124 unmask_loss: 8.3364 Lr: 0.00108
[2025-12-10 17:08:43,062 INFO misc.py line 117 4140988] Train: [1/10][1059/7400] Data 0.003 (0.004) Batch 0.695 (0.621) Remain 12:34:46 loss: 7.8075 mask_loss: 7.2336 roll_mask_loss: 7.6194 density_loss: 8.3520 unmask_loss: 8.0216 Lr: 0.00108
[2025-12-10 17:08:43,620 INFO misc.py line 117 4140988] Train: [1/10][1060/7400] Data 0.004 (0.004) Batch 0.559 (0.621) Remain 12:34:41 loss: 7.3417 mask_loss: 6.6466 roll_mask_loss: 7.3083 density_loss: 9.2690 unmask_loss: 7.5206 Lr: 0.00108
[2025-12-10 17:08:44,262 INFO misc.py line 117 4140988] Train: [1/10][1061/7400] Data 0.003 (0.004) Batch 0.641 (0.621) Remain 12:34:42 loss: 7.6341 mask_loss: 6.9638 roll_mask_loss: 7.5438 density_loss: 8.4329 unmask_loss: 7.8457 Lr: 0.00108
[2025-12-10 17:08:44,828 INFO misc.py line 117 4140988] Train: [1/10][1062/7400] Data 0.004 (0.004) Batch 0.565 (0.621) Remain 12:34:38 loss: 7.4757 mask_loss: 6.9722 roll_mask_loss: 7.2983 density_loss: 8.5649 unmask_loss: 7.6449 Lr: 0.00108
[2025-12-10 17:08:45,310 INFO misc.py line 117 4140988] Train: [1/10][1063/7400] Data 0.004 (0.004) Batch 0.482 (0.621) Remain 12:34:28 loss: 8.4749 mask_loss: 8.4238 roll_mask_loss: 8.4637 density_loss: 8.4675 unmask_loss: 8.3366 Lr: 0.00108
[2025-12-10 17:08:46,125 INFO misc.py line 117 4140988] Train: [1/10][1064/7400] Data 0.004 (0.004) Batch 0.815 (0.621) Remain 12:34:40 loss: 7.1596 mask_loss: 6.3402 roll_mask_loss: 6.9642 density_loss: 9.3241 unmask_loss: 7.4806 Lr: 0.00108
[2025-12-10 17:08:46,759 INFO misc.py line 117 4140988] Train: [1/10][1065/7400] Data 0.004 (0.004) Batch 0.634 (0.621) Remain 12:34:41 loss: 7.2078 mask_loss: 6.5983 roll_mask_loss: 7.1316 density_loss: 8.7276 unmask_loss: 7.3761 Lr: 0.00109
[2025-12-10 17:08:47,417 INFO misc.py line 117 4140988] Train: [1/10][1066/7400] Data 0.004 (0.004) Batch 0.659 (0.621) Remain 12:34:43 loss: 7.3578 mask_loss: 6.5288 roll_mask_loss: 7.0341 density_loss: 9.4105 unmask_loss: 7.7459 Lr: 0.00109
[2025-12-10 17:08:47,919 INFO misc.py line 117 4140988] Train: [1/10][1067/7400] Data 0.004 (0.004) Batch 0.501 (0.621) Remain 12:34:34 loss: 7.4627 mask_loss: 6.8244 roll_mask_loss: 7.6726 density_loss: 8.2531 unmask_loss: 7.5119 Lr: 0.00109
[2025-12-10 17:08:48,522 INFO misc.py line 117 4140988] Train: [1/10][1068/7400] Data 0.004 (0.004) Batch 0.603 (0.621) Remain 12:34:32 loss: 7.5871 mask_loss: 7.0282 roll_mask_loss: 7.5718 density_loss: 9.0013 unmask_loss: 7.6943 Lr: 0.00109
[2025-12-10 17:08:49,113 INFO misc.py line 117 4140988] Train: [1/10][1069/7400] Data 0.004 (0.004) Batch 0.592 (0.621) Remain 12:34:29 loss: 7.2596 mask_loss: 6.5480 roll_mask_loss: 7.0913 density_loss: 9.0704 unmask_loss: 7.5180 Lr: 0.00109
[2025-12-10 17:08:49,725 INFO misc.py line 117 4140988] Train: [1/10][1070/7400] Data 0.004 (0.004) Batch 0.612 (0.621) Remain 12:34:28 loss: 7.5705 mask_loss: 6.8912 roll_mask_loss: 7.4210 density_loss: 8.9061 unmask_loss: 7.8067 Lr: 0.00109
[2025-12-10 17:08:50,453 INFO misc.py line 117 4140988] Train: [1/10][1071/7400] Data 0.004 (0.004) Batch 0.729 (0.621) Remain 12:34:35 loss: 7.1949 mask_loss: 6.0809 roll_mask_loss: 7.2424 density_loss: 8.6064 unmask_loss: 7.5560 Lr: 0.00109
[2025-12-10 17:08:51,310 INFO misc.py line 117 4140988] Train: [1/10][1072/7400] Data 0.003 (0.004) Batch 0.857 (0.621) Remain 12:34:50 loss: 7.2138 mask_loss: 6.4696 roll_mask_loss: 7.2390 density_loss: 8.8528 unmask_loss: 7.3963 Lr: 0.00109
[2025-12-10 17:08:51,901 INFO misc.py line 117 4140988] Train: [1/10][1073/7400] Data 0.003 (0.004) Batch 0.590 (0.621) Remain 12:34:48 loss: 7.3387 mask_loss: 6.7104 roll_mask_loss: 7.2326 density_loss: 8.4904 unmask_loss: 7.5361 Lr: 0.00109
[2025-12-10 17:08:52,521 INFO misc.py line 117 4140988] Train: [1/10][1074/7400] Data 0.004 (0.004) Batch 0.620 (0.621) Remain 12:34:47 loss: 7.6094 mask_loss: 7.1748 roll_mask_loss: 7.7469 density_loss: 8.8418 unmask_loss: 7.5812 Lr: 0.00110
[2025-12-10 17:08:53,143 INFO misc.py line 117 4140988] Train: [1/10][1075/7400] Data 0.004 (0.004) Batch 0.622 (0.621) Remain 12:34:46 loss: 8.3193 mask_loss: 7.9681 roll_mask_loss: 8.1429 density_loss: 8.5813 unmask_loss: 8.4115 Lr: 0.00110
[2025-12-10 17:08:53,893 INFO misc.py line 117 4140988] Train: [1/10][1076/7400] Data 0.004 (0.004) Batch 0.750 (0.621) Remain 12:34:55 loss: 7.0740 mask_loss: 6.0682 roll_mask_loss: 7.1133 density_loss: 8.8983 unmask_loss: 7.3792 Lr: 0.00110
[2025-12-10 17:08:54,198 INFO misc.py line 117 4140988] Train: [1/10][1077/7400] Data 0.003 (0.004) Batch 0.304 (0.621) Remain 12:34:32 loss: 7.3370 mask_loss: 6.6470 roll_mask_loss: 7.1167 density_loss: 8.6615 unmask_loss: 7.6190 Lr: 0.00110
[2025-12-10 17:08:54,805 INFO misc.py line 117 4140988] Train: [1/10][1078/7400] Data 0.004 (0.004) Batch 0.607 (0.621) Remain 12:34:31 loss: 7.3546 mask_loss: 6.7429 roll_mask_loss: 7.2208 density_loss: 8.7500 unmask_loss: 7.5523 Lr: 0.00110
[2025-12-10 17:08:55,843 INFO misc.py line 117 4140988] Train: [1/10][1079/7400] Data 0.004 (0.004) Batch 1.038 (0.621) Remain 12:34:58 loss: 7.0512 mask_loss: 5.9999 roll_mask_loss: 6.8730 density_loss: 9.8264 unmask_loss: 7.4693 Lr: 0.00110
[2025-12-10 17:08:56,375 INFO misc.py line 117 4140988] Train: [1/10][1080/7400] Data 0.004 (0.004) Batch 0.532 (0.621) Remain 12:34:52 loss: 8.1966 mask_loss: 7.6893 roll_mask_loss: 8.1542 density_loss: 8.3450 unmask_loss: 8.3046 Lr: 0.00110
[2025-12-10 17:08:56,912 INFO misc.py line 117 4140988] Train: [1/10][1081/7400] Data 0.004 (0.004) Batch 0.537 (0.621) Remain 12:34:45 loss: 7.2351 mask_loss: 6.4002 roll_mask_loss: 7.1792 density_loss: 8.8426 unmask_loss: 7.5038 Lr: 0.00110
[2025-12-10 17:08:57,593 INFO misc.py line 117 4140988] Train: [1/10][1082/7400] Data 0.004 (0.004) Batch 0.682 (0.621) Remain 12:34:49 loss: 7.3846 mask_loss: 6.6051 roll_mask_loss: 7.4535 density_loss: 8.6253 unmask_loss: 7.5674 Lr: 0.00111
[2025-12-10 17:08:57,880 INFO misc.py line 117 4140988] Train: [1/10][1083/7400] Data 0.004 (0.004) Batch 0.287 (0.621) Remain 12:34:26 loss: 8.4566 mask_loss: 8.1658 roll_mask_loss: 8.4743 density_loss: 8.5961 unmask_loss: 8.4213 Lr: 0.00111
[2025-12-10 17:08:58,785 INFO misc.py line 117 4140988] Train: [1/10][1084/7400] Data 0.004 (0.004) Batch 0.905 (0.621) Remain 12:34:44 loss: 7.0432 mask_loss: 6.1250 roll_mask_loss: 7.0282 density_loss: 9.3556 unmask_loss: 7.3226 Lr: 0.00111
[2025-12-10 17:08:59,327 INFO misc.py line 117 4140988] Train: [1/10][1085/7400] Data 0.003 (0.004) Batch 0.542 (0.621) Remain 12:34:38 loss: 7.2445 mask_loss: 6.6347 roll_mask_loss: 6.9587 density_loss: 8.7013 unmask_loss: 7.5181 Lr: 0.00111
[2025-12-10 17:09:00,163 INFO misc.py line 117 4140988] Train: [1/10][1086/7400] Data 0.004 (0.004) Batch 0.836 (0.621) Remain 12:34:52 loss: 7.1545 mask_loss: 6.3443 roll_mask_loss: 7.1378 density_loss: 9.1301 unmask_loss: 7.3854 Lr: 0.00111
[2025-12-10 17:09:00,666 INFO misc.py line 117 4140988] Train: [1/10][1087/7400] Data 0.003 (0.004) Batch 0.504 (0.621) Remain 12:34:44 loss: 8.3769 mask_loss: 8.1859 roll_mask_loss: 8.3518 density_loss: 8.3552 unmask_loss: 8.3179 Lr: 0.00111
[2025-12-10 17:09:01,280 INFO misc.py line 117 4140988] Train: [1/10][1088/7400] Data 0.003 (0.004) Batch 0.613 (0.621) Remain 12:34:43 loss: 7.1925 mask_loss: 6.4509 roll_mask_loss: 7.0332 density_loss: 8.8895 unmask_loss: 7.4651 Lr: 0.00111
[2025-12-10 17:09:01,878 INFO misc.py line 117 4140988] Train: [1/10][1089/7400] Data 0.003 (0.004) Batch 0.598 (0.621) Remain 12:34:40 loss: 7.3006 mask_loss: 6.6306 roll_mask_loss: 7.2193 density_loss: 8.1998 unmask_loss: 7.5122 Lr: 0.00111
[2025-12-10 17:09:02,338 INFO misc.py line 117 4140988] Train: [1/10][1090/7400] Data 0.003 (0.004) Batch 0.460 (0.621) Remain 12:34:29 loss: 7.3789 mask_loss: 6.8599 roll_mask_loss: 7.1381 density_loss: 7.9417 unmask_loss: 7.6000 Lr: 0.00112
[2025-12-10 17:09:03,262 INFO misc.py line 117 4140988] Train: [1/10][1091/7400] Data 0.003 (0.004) Batch 0.925 (0.621) Remain 12:34:49 loss: 7.1236 mask_loss: 6.1097 roll_mask_loss: 7.1905 density_loss: 9.8188 unmask_loss: 7.4007 Lr: 0.00112
[2025-12-10 17:09:03,741 INFO misc.py line 117 4140988] Train: [1/10][1092/7400] Data 0.003 (0.004) Batch 0.479 (0.621) Remain 12:34:39 loss: 7.3930 mask_loss: 6.6509 roll_mask_loss: 7.3132 density_loss: 8.7665 unmask_loss: 7.6286 Lr: 0.00112
[2025-12-10 17:09:04,325 INFO misc.py line 117 4140988] Train: [1/10][1093/7400] Data 0.003 (0.004) Batch 0.583 (0.621) Remain 12:34:35 loss: 7.0794 mask_loss: 6.3274 roll_mask_loss: 6.9399 density_loss: 8.4078 unmask_loss: 7.3571 Lr: 0.00112
[2025-12-10 17:09:04,965 INFO misc.py line 117 4140988] Train: [1/10][1094/7400] Data 0.003 (0.004) Batch 0.640 (0.621) Remain 12:34:36 loss: 7.0065 mask_loss: 6.2471 roll_mask_loss: 6.9406 density_loss: 9.0896 unmask_loss: 7.2374 Lr: 0.00112
[2025-12-10 17:09:05,582 INFO misc.py line 117 4140988] Train: [1/10][1095/7400] Data 0.004 (0.004) Batch 0.617 (0.621) Remain 12:34:35 loss: 7.7757 mask_loss: 7.1215 roll_mask_loss: 7.7879 density_loss: 8.6669 unmask_loss: 7.9234 Lr: 0.00112
[2025-12-10 17:09:06,129 INFO misc.py line 117 4140988] Train: [1/10][1096/7400] Data 0.004 (0.004) Batch 0.547 (0.621) Remain 12:34:30 loss: 8.0392 mask_loss: 7.6171 roll_mask_loss: 7.9708 density_loss: 8.7306 unmask_loss: 8.1098 Lr: 0.00112
[2025-12-10 17:09:06,768 INFO misc.py line 117 4140988] Train: [1/10][1097/7400] Data 0.003 (0.004) Batch 0.639 (0.621) Remain 12:34:30 loss: 7.0911 mask_loss: 6.3608 roll_mask_loss: 6.9646 density_loss: 8.7273 unmask_loss: 7.3450 Lr: 0.00112
[2025-12-10 17:09:07,323 INFO misc.py line 117 4140988] Train: [1/10][1098/7400] Data 0.004 (0.004) Batch 0.555 (0.621) Remain 12:34:25 loss: 7.2179 mask_loss: 6.3805 roll_mask_loss: 7.1499 density_loss: 9.2939 unmask_loss: 7.4848 Lr: 0.00113
[2025-12-10 17:09:08,146 INFO misc.py line 117 4140988] Train: [1/10][1099/7400] Data 0.003 (0.004) Batch 0.823 (0.621) Remain 12:34:38 loss: 7.3134 mask_loss: 6.6921 roll_mask_loss: 7.2974 density_loss: 8.5755 unmask_loss: 7.4606 Lr: 0.00113
[2025-12-10 17:09:08,768 INFO misc.py line 117 4140988] Train: [1/10][1100/7400] Data 0.004 (0.004) Batch 0.622 (0.621) Remain 12:34:37 loss: 7.4671 mask_loss: 6.9861 roll_mask_loss: 7.3566 density_loss: 8.6031 unmask_loss: 7.5909 Lr: 0.00113
[2025-12-10 17:09:09,372 INFO misc.py line 117 4140988] Train: [1/10][1101/7400] Data 0.003 (0.004) Batch 0.604 (0.621) Remain 12:34:36 loss: 7.1880 mask_loss: 6.3463 roll_mask_loss: 7.0376 density_loss: 8.3175 unmask_loss: 7.5176 Lr: 0.00113
[2025-12-10 17:09:09,962 INFO misc.py line 117 4140988] Train: [1/10][1102/7400] Data 0.004 (0.004) Batch 0.590 (0.621) Remain 12:34:33 loss: 7.2265 mask_loss: 6.4725 roll_mask_loss: 6.9792 density_loss: 9.0130 unmask_loss: 7.5468 Lr: 0.00113
[2025-12-10 17:09:10,568 INFO misc.py line 117 4140988] Train: [1/10][1103/7400] Data 0.004 (0.004) Batch 0.607 (0.621) Remain 12:34:31 loss: 7.2100 mask_loss: 6.3669 roll_mask_loss: 7.1524 density_loss: 9.0255 unmask_loss: 7.4799 Lr: 0.00113
[2025-12-10 17:09:11,110 INFO misc.py line 117 4140988] Train: [1/10][1104/7400] Data 0.004 (0.004) Batch 0.542 (0.621) Remain 12:34:26 loss: 8.1263 mask_loss: 7.8853 roll_mask_loss: 7.9871 density_loss: 8.3386 unmask_loss: 8.1496 Lr: 0.00113
[2025-12-10 17:09:11,750 INFO misc.py line 117 4140988] Train: [1/10][1105/7400] Data 0.004 (0.004) Batch 0.641 (0.621) Remain 12:34:26 loss: 8.5358 mask_loss: 8.3662 roll_mask_loss: 8.4435 density_loss: 8.4214 unmask_loss: 8.4982 Lr: 0.00113
[2025-12-10 17:09:12,370 INFO misc.py line 117 4140988] Train: [1/10][1106/7400] Data 0.003 (0.004) Batch 0.620 (0.621) Remain 12:34:26 loss: 7.1944 mask_loss: 6.5348 roll_mask_loss: 7.2303 density_loss: 8.8868 unmask_loss: 7.3285 Lr: 0.00113
[2025-12-10 17:09:13,089 INFO misc.py line 117 4140988] Train: [1/10][1107/7400] Data 0.003 (0.004) Batch 0.719 (0.621) Remain 12:34:31 loss: 7.1012 mask_loss: 6.3219 roll_mask_loss: 7.1102 density_loss: 9.0521 unmask_loss: 7.3052 Lr: 0.00114
[2025-12-10 17:09:13,802 INFO misc.py line 117 4140988] Train: [1/10][1108/7400] Data 0.003 (0.004) Batch 0.713 (0.621) Remain 12:34:37 loss: 7.1586 mask_loss: 6.1374 roll_mask_loss: 6.9583 density_loss: 9.5791 unmask_loss: 7.5778 Lr: 0.00114
[2025-12-10 17:09:14,560 INFO misc.py line 117 4140988] Train: [1/10][1109/7400] Data 0.003 (0.004) Batch 0.757 (0.621) Remain 12:34:45 loss: 7.3059 mask_loss: 6.0662 roll_mask_loss: 7.4698 density_loss: 9.8894 unmask_loss: 7.6461 Lr: 0.00114
[2025-12-10 17:09:15,222 INFO misc.py line 117 4140988] Train: [1/10][1110/7400] Data 0.004 (0.004) Batch 0.662 (0.621) Remain 12:34:47 loss: 7.2173 mask_loss: 6.4076 roll_mask_loss: 7.0671 density_loss: 8.5868 unmask_loss: 7.5256 Lr: 0.00114
[2025-12-10 17:09:15,843 INFO misc.py line 117 4140988] Train: [1/10][1111/7400] Data 0.004 (0.004) Batch 0.621 (0.621) Remain 12:34:47 loss: 7.0247 mask_loss: 6.3247 roll_mask_loss: 6.7638 density_loss: 9.4068 unmask_loss: 7.3169 Lr: 0.00114
[2025-12-10 17:09:16,334 INFO misc.py line 117 4140988] Train: [1/10][1112/7400] Data 0.003 (0.004) Batch 0.491 (0.621) Remain 12:34:37 loss: 7.5856 mask_loss: 7.2566 roll_mask_loss: 7.4788 density_loss: 8.9400 unmask_loss: 7.6247 Lr: 0.00114
[2025-12-10 17:09:16,813 INFO misc.py line 117 4140988] Train: [1/10][1113/7400] Data 0.003 (0.004) Batch 0.479 (0.621) Remain 12:34:27 loss: 8.3695 mask_loss: 7.6861 roll_mask_loss: 9.2186 density_loss: 8.4365 unmask_loss: 8.1179 Lr: 0.00114
[2025-12-10 17:09:17,194 INFO misc.py line 117 4140988] Train: [1/10][1114/7400] Data 0.004 (0.004) Batch 0.380 (0.621) Remain 12:34:11 loss: 7.2195 mask_loss: 6.5657 roll_mask_loss: 7.0701 density_loss: 8.9877 unmask_loss: 7.4414 Lr: 0.00114
[2025-12-10 17:09:17,527 INFO misc.py line 117 4140988] Train: [1/10][1115/7400] Data 0.004 (0.004) Batch 0.333 (0.621) Remain 12:33:52 loss: 7.3801 mask_loss: 6.5482 roll_mask_loss: 7.3689 density_loss: 8.9017 unmask_loss: 7.6236 Lr: 0.00115
[2025-12-10 17:09:18,210 INFO misc.py line 117 4140988] Train: [1/10][1116/7400] Data 0.004 (0.004) Batch 0.683 (0.621) Remain 12:33:55 loss: 7.4058 mask_loss: 6.4929 roll_mask_loss: 7.4728 density_loss: 8.9360 unmask_loss: 7.6501 Lr: 0.00115
[2025-12-10 17:09:18,701 INFO misc.py line 117 4140988] Train: [1/10][1117/7400] Data 0.003 (0.004) Batch 0.492 (0.621) Remain 12:33:46 loss: 8.2346 mask_loss: 8.0298 roll_mask_loss: 8.1603 density_loss: 8.3903 unmask_loss: 8.2063 Lr: 0.00115
[2025-12-10 17:09:19,356 INFO misc.py line 117 4140988] Train: [1/10][1118/7400] Data 0.003 (0.004) Batch 0.655 (0.621) Remain 12:33:48 loss: 7.3663 mask_loss: 6.8034 roll_mask_loss: 7.3402 density_loss: 9.3459 unmask_loss: 7.4738 Lr: 0.00115
[2025-12-10 17:09:20,113 INFO misc.py line 117 4140988] Train: [1/10][1119/7400] Data 0.003 (0.004) Batch 0.757 (0.621) Remain 12:33:56 loss: 7.1109 mask_loss: 6.3368 roll_mask_loss: 7.0080 density_loss: 8.9478 unmask_loss: 7.3704 Lr: 0.00115
[2025-12-10 17:09:20,911 INFO misc.py line 117 4140988] Train: [1/10][1120/7400] Data 0.003 (0.004) Batch 0.798 (0.621) Remain 12:34:07 loss: 7.8846 mask_loss: 7.5530 roll_mask_loss: 7.8735 density_loss: 8.6951 unmask_loss: 7.8821 Lr: 0.00115
[2025-12-10 17:09:21,224 INFO misc.py line 117 4140988] Train: [1/10][1121/7400] Data 0.004 (0.004) Batch 0.313 (0.621) Remain 12:33:46 loss: 8.4431 mask_loss: 8.3118 roll_mask_loss: 8.3365 density_loss: 8.3403 unmask_loss: 8.3952 Lr: 0.00115
[2025-12-10 17:09:21,744 INFO misc.py line 117 4140988] Train: [1/10][1122/7400] Data 0.004 (0.004) Batch 0.519 (0.620) Remain 12:33:39 loss: 8.4428 mask_loss: 8.3069 roll_mask_loss: 8.3441 density_loss: 8.3386 unmask_loss: 8.3934 Lr: 0.00115
[2025-12-10 17:09:22,313 INFO misc.py line 117 4140988] Train: [1/10][1123/7400] Data 0.004 (0.004) Batch 0.570 (0.620) Remain 12:33:35 loss: 7.3277 mask_loss: 6.3555 roll_mask_loss: 7.4691 density_loss: 8.9379 unmask_loss: 7.5643 Lr: 0.00116
[2025-12-10 17:09:22,827 INFO misc.py line 117 4140988] Train: [1/10][1124/7400] Data 0.003 (0.004) Batch 0.514 (0.620) Remain 12:33:28 loss: 7.9737 mask_loss: 7.1939 roll_mask_loss: 8.0156 density_loss: 8.6845 unmask_loss: 8.1689 Lr: 0.00116
[2025-12-10 17:09:23,149 INFO misc.py line 117 4140988] Train: [1/10][1125/7400] Data 0.003 (0.004) Batch 0.322 (0.620) Remain 12:33:07 loss: 7.3524 mask_loss: 6.3960 roll_mask_loss: 7.7120 density_loss: 8.4798 unmask_loss: 7.4812 Lr: 0.00116
[2025-12-10 17:09:23,757 INFO misc.py line 117 4140988] Train: [1/10][1126/7400] Data 0.003 (0.004) Batch 0.608 (0.620) Remain 12:33:06 loss: 7.4617 mask_loss: 6.9527 roll_mask_loss: 7.4957 density_loss: 8.3638 unmask_loss: 7.5320 Lr: 0.00116
[2025-12-10 17:09:24,277 INFO misc.py line 117 4140988] Train: [1/10][1127/7400] Data 0.003 (0.004) Batch 0.520 (0.620) Remain 12:32:59 loss: 8.0300 mask_loss: 7.4026 roll_mask_loss: 7.8934 density_loss: 8.6636 unmask_loss: 8.2387 Lr: 0.00116
[2025-12-10 17:09:24,864 INFO misc.py line 117 4140988] Train: [1/10][1128/7400] Data 0.003 (0.004) Batch 0.587 (0.620) Remain 12:32:56 loss: 7.2805 mask_loss: 6.4274 roll_mask_loss: 7.1770 density_loss: 9.6438 unmask_loss: 7.5659 Lr: 0.00116
[2025-12-10 17:09:25,489 INFO misc.py line 117 4140988] Train: [1/10][1129/7400] Data 0.003 (0.004) Batch 0.625 (0.620) Remain 12:32:56 loss: 7.6068 mask_loss: 7.1593 roll_mask_loss: 7.5200 density_loss: 8.4477 unmask_loss: 7.7051 Lr: 0.00116
[2025-12-10 17:09:26,085 INFO misc.py line 117 4140988] Train: [1/10][1130/7400] Data 0.004 (0.004) Batch 0.596 (0.620) Remain 12:32:54 loss: 7.2936 mask_loss: 6.8155 roll_mask_loss: 7.1591 density_loss: 8.3089 unmask_loss: 7.4337 Lr: 0.00116
[2025-12-10 17:09:26,802 INFO misc.py line 117 4140988] Train: [1/10][1131/7400] Data 0.003 (0.004) Batch 0.717 (0.620) Remain 12:32:59 loss: 7.0905 mask_loss: 6.3200 roll_mask_loss: 6.8792 density_loss: 8.7938 unmask_loss: 7.4054 Lr: 0.00117
[2025-12-10 17:09:27,480 INFO misc.py line 117 4140988] Train: [1/10][1132/7400] Data 0.003 (0.004) Batch 0.679 (0.620) Remain 12:33:03 loss: 7.0980 mask_loss: 6.2870 roll_mask_loss: 6.9050 density_loss: 9.6594 unmask_loss: 7.4069 Lr: 0.00117
[2025-12-10 17:09:28,205 INFO misc.py line 117 4140988] Train: [1/10][1133/7400] Data 0.003 (0.004) Batch 0.725 (0.620) Remain 12:33:09 loss: 7.5220 mask_loss: 6.8760 roll_mask_loss: 7.6248 density_loss: 8.7368 unmask_loss: 7.6189 Lr: 0.00117
[2025-12-10 17:09:28,814 INFO misc.py line 117 4140988] Train: [1/10][1134/7400] Data 0.004 (0.004) Batch 0.609 (0.620) Remain 12:33:07 loss: 7.0713 mask_loss: 6.2556 roll_mask_loss: 6.9931 density_loss: 10.0069 unmask_loss: 7.3181 Lr: 0.00117
[2025-12-10 17:09:29,646 INFO misc.py line 117 4140988] Train: [1/10][1135/7400] Data 0.004 (0.004) Batch 0.832 (0.620) Remain 12:33:20 loss: 7.2367 mask_loss: 6.4982 roll_mask_loss: 7.2587 density_loss: 8.7982 unmask_loss: 7.4189 Lr: 0.00117
[2025-12-10 17:09:30,305 INFO misc.py line 117 4140988] Train: [1/10][1136/7400] Data 0.004 (0.004) Batch 0.659 (0.620) Remain 12:33:22 loss: 7.0373 mask_loss: 6.2397 roll_mask_loss: 6.9038 density_loss: 9.0897 unmask_loss: 7.3211 Lr: 0.00117
[2025-12-10 17:09:30,610 INFO misc.py line 117 4140988] Train: [1/10][1137/7400] Data 0.003 (0.004) Batch 0.304 (0.620) Remain 12:33:01 loss: 8.0988 mask_loss: 7.7656 roll_mask_loss: 7.9875 density_loss: 8.2415 unmask_loss: 8.1561 Lr: 0.00117
[2025-12-10 17:09:31,395 INFO misc.py line 117 4140988] Train: [1/10][1138/7400] Data 0.004 (0.004) Batch 0.785 (0.620) Remain 12:33:11 loss: 7.3800 mask_loss: 6.1242 roll_mask_loss: 6.9623 density_loss: 9.9218 unmask_loss: 8.0182 Lr: 0.00117
[2025-12-10 17:09:31,905 INFO misc.py line 117 4140988] Train: [1/10][1139/7400] Data 0.003 (0.004) Batch 0.511 (0.620) Remain 12:33:04 loss: 6.9914 mask_loss: 6.3088 roll_mask_loss: 6.7432 density_loss: 8.6220 unmask_loss: 7.2844 Lr: 0.00118
[2025-12-10 17:09:32,529 INFO misc.py line 117 4140988] Train: [1/10][1140/7400] Data 0.004 (0.004) Batch 0.624 (0.620) Remain 12:33:03 loss: 7.2321 mask_loss: 6.5784 roll_mask_loss: 7.1964 density_loss: 8.5781 unmask_loss: 7.4052 Lr: 0.00118
[2025-12-10 17:09:33,229 INFO misc.py line 117 4140988] Train: [1/10][1141/7400] Data 0.003 (0.004) Batch 0.699 (0.620) Remain 12:33:08 loss: 7.1640 mask_loss: 6.3969 roll_mask_loss: 7.1693 density_loss: 8.4034 unmask_loss: 7.3768 Lr: 0.00118
[2025-12-10 17:09:33,990 INFO misc.py line 117 4140988] Train: [1/10][1142/7400] Data 0.004 (0.004) Batch 0.762 (0.620) Remain 12:33:16 loss: 7.2830 mask_loss: 6.5142 roll_mask_loss: 6.9352 density_loss: 8.9464 unmask_loss: 7.6623 Lr: 0.00118
[2025-12-10 17:09:34,517 INFO misc.py line 117 4140988] Train: [1/10][1143/7400] Data 0.004 (0.004) Batch 0.527 (0.620) Remain 12:33:10 loss: 7.6886 mask_loss: 6.9551 roll_mask_loss: 7.7047 density_loss: 8.5261 unmask_loss: 7.8767 Lr: 0.00118
[2025-12-10 17:09:35,449 INFO misc.py line 117 4140988] Train: [1/10][1144/7400] Data 0.004 (0.004) Batch 0.933 (0.621) Remain 12:33:29 loss: 6.9737 mask_loss: 6.1411 roll_mask_loss: 6.8285 density_loss: 9.4326 unmask_loss: 7.2740 Lr: 0.00118
[2025-12-10 17:09:36,081 INFO misc.py line 117 4140988] Train: [1/10][1145/7400] Data 0.003 (0.004) Batch 0.631 (0.621) Remain 12:33:29 loss: 7.2510 mask_loss: 6.4736 roll_mask_loss: 7.4160 density_loss: 8.6093 unmask_loss: 7.3850 Lr: 0.00118
[2025-12-10 17:09:36,755 INFO misc.py line 117 4140988] Train: [1/10][1146/7400] Data 0.004 (0.004) Batch 0.674 (0.621) Remain 12:33:32 loss: 7.4277 mask_loss: 6.7582 roll_mask_loss: 7.4631 density_loss: 9.2205 unmask_loss: 7.5605 Lr: 0.00118
[2025-12-10 17:09:37,305 INFO misc.py line 117 4140988] Train: [1/10][1147/7400] Data 0.003 (0.004) Batch 0.550 (0.621) Remain 12:33:27 loss: 7.4704 mask_loss: 6.8014 roll_mask_loss: 7.5927 density_loss: 8.5798 unmask_loss: 7.5722 Lr: 0.00119
[2025-12-10 17:09:37,832 INFO misc.py line 117 4140988] Train: [1/10][1148/7400] Data 0.004 (0.004) Batch 0.527 (0.620) Remain 12:33:20 loss: 8.2528 mask_loss: 7.6414 roll_mask_loss: 8.7575 density_loss: 8.5904 unmask_loss: 8.1343 Lr: 0.00119
[2025-12-10 17:09:38,138 INFO misc.py line 117 4140988] Train: [1/10][1149/7400] Data 0.003 (0.004) Batch 0.305 (0.620) Remain 12:32:59 loss: 7.6465 mask_loss: 7.0433 roll_mask_loss: 7.9411 density_loss: 8.8915 unmask_loss: 7.6230 Lr: 0.00119
[2025-12-10 17:09:38,838 INFO misc.py line 117 4140988] Train: [1/10][1150/7400] Data 0.004 (0.004) Batch 0.700 (0.620) Remain 12:33:04 loss: 7.6353 mask_loss: 7.1086 roll_mask_loss: 7.4748 density_loss: 9.0313 unmask_loss: 7.7982 Lr: 0.00119
[2025-12-10 17:09:39,807 INFO misc.py line 117 4140988] Train: [1/10][1151/7400] Data 0.004 (0.004) Batch 0.969 (0.621) Remain 12:33:25 loss: 7.0966 mask_loss: 6.4625 roll_mask_loss: 7.0139 density_loss: 8.8811 unmask_loss: 7.2773 Lr: 0.00119
[2025-12-10 17:09:40,435 INFO misc.py line 117 4140988] Train: [1/10][1152/7400] Data 0.004 (0.004) Batch 0.629 (0.621) Remain 12:33:25 loss: 8.3034 mask_loss: 8.1153 roll_mask_loss: 8.3498 density_loss: 8.3310 unmask_loss: 8.2075 Lr: 0.00119
[2025-12-10 17:09:41,056 INFO misc.py line 117 4140988] Train: [1/10][1153/7400] Data 0.003 (0.004) Batch 0.621 (0.621) Remain 12:33:25 loss: 7.4140 mask_loss: 6.7263 roll_mask_loss: 7.3467 density_loss: 8.0532 unmask_loss: 7.6305 Lr: 0.00119
[2025-12-10 17:09:41,637 INFO misc.py line 117 4140988] Train: [1/10][1154/7400] Data 0.004 (0.004) Batch 0.581 (0.621) Remain 12:33:21 loss: 7.1012 mask_loss: 6.2540 roll_mask_loss: 6.9622 density_loss: 9.9904 unmask_loss: 7.3945 Lr: 0.00119
[2025-12-10 17:09:42,252 INFO misc.py line 117 4140988] Train: [1/10][1155/7400] Data 0.004 (0.004) Batch 0.616 (0.621) Remain 12:33:21 loss: 7.1828 mask_loss: 6.5677 roll_mask_loss: 7.0918 density_loss: 9.2244 unmask_loss: 7.3513 Lr: 0.00120
[2025-12-10 17:09:43,105 INFO misc.py line 117 4140988] Train: [1/10][1156/7400] Data 0.003 (0.004) Batch 0.852 (0.621) Remain 12:33:35 loss: 6.9868 mask_loss: 6.2931 roll_mask_loss: 6.7815 density_loss: 9.1865 unmask_loss: 7.2525 Lr: 0.00120
[2025-12-10 17:09:43,702 INFO misc.py line 117 4140988] Train: [1/10][1157/7400] Data 0.003 (0.004) Batch 0.598 (0.621) Remain 12:33:33 loss: 7.2688 mask_loss: 6.6535 roll_mask_loss: 7.1427 density_loss: 9.1655 unmask_loss: 7.4562 Lr: 0.00120
[2025-12-10 17:09:44,537 INFO misc.py line 117 4140988] Train: [1/10][1158/7400] Data 0.003 (0.004) Batch 0.834 (0.621) Remain 12:33:45 loss: 7.1760 mask_loss: 6.0448 roll_mask_loss: 7.1969 density_loss: 9.5442 unmask_loss: 7.5403 Lr: 0.00120
[2025-12-10 17:09:45,108 INFO misc.py line 117 4140988] Train: [1/10][1159/7400] Data 0.004 (0.004) Batch 0.571 (0.621) Remain 12:33:42 loss: 7.6240 mask_loss: 6.8885 roll_mask_loss: 7.2615 density_loss: 8.4903 unmask_loss: 8.0032 Lr: 0.00120
[2025-12-10 17:09:45,699 INFO misc.py line 117 4140988] Train: [1/10][1160/7400] Data 0.003 (0.004) Batch 0.591 (0.621) Remain 12:33:39 loss: 7.2142 mask_loss: 6.3524 roll_mask_loss: 7.2622 density_loss: 9.5605 unmask_loss: 7.4299 Lr: 0.00120
[2025-12-10 17:09:46,276 INFO misc.py line 117 4140988] Train: [1/10][1161/7400] Data 0.003 (0.004) Batch 0.576 (0.621) Remain 12:33:36 loss: 7.1155 mask_loss: 6.4819 roll_mask_loss: 7.0306 density_loss: 8.8788 unmask_loss: 7.2971 Lr: 0.00120
[2025-12-10 17:09:47,109 INFO misc.py line 117 4140988] Train: [1/10][1162/7400] Data 0.004 (0.004) Batch 0.833 (0.621) Remain 12:33:48 loss: 7.2076 mask_loss: 6.3424 roll_mask_loss: 7.1504 density_loss: 9.1338 unmask_loss: 7.4861 Lr: 0.00121
[2025-12-10 17:09:47,871 INFO misc.py line 117 4140988] Train: [1/10][1163/7400] Data 0.004 (0.004) Batch 0.761 (0.621) Remain 12:33:57 loss: 6.9935 mask_loss: 6.3111 roll_mask_loss: 6.8940 density_loss: 8.8698 unmask_loss: 7.2071 Lr: 0.00121
[2025-12-10 17:09:48,432 INFO misc.py line 117 4140988] Train: [1/10][1164/7400] Data 0.004 (0.004) Batch 0.561 (0.621) Remain 12:33:52 loss: 7.3030 mask_loss: 6.6250 roll_mask_loss: 7.3461 density_loss: 9.5453 unmask_loss: 7.4296 Lr: 0.00121
[2025-12-10 17:09:48,946 INFO misc.py line 117 4140988] Train: [1/10][1165/7400] Data 0.004 (0.004) Batch 0.515 (0.621) Remain 12:33:45 loss: 7.3541 mask_loss: 6.8160 roll_mask_loss: 7.3145 density_loss: 8.0304 unmask_loss: 7.4823 Lr: 0.00121
[2025-12-10 17:09:49,264 INFO misc.py line 117 4140988] Train: [1/10][1166/7400] Data 0.004 (0.004) Batch 0.317 (0.621) Remain 12:33:25 loss: 7.6036 mask_loss: 6.7530 roll_mask_loss: 7.6374 density_loss: 8.9508 unmask_loss: 7.8330 Lr: 0.00121
[2025-12-10 17:09:49,756 INFO misc.py line 117 4140988] Train: [1/10][1167/7400] Data 0.004 (0.004) Batch 0.492 (0.621) Remain 12:33:17 loss: 7.9524 mask_loss: 7.2251 roll_mask_loss: 8.0072 density_loss: 8.4309 unmask_loss: 8.1200 Lr: 0.00121
[2025-12-10 17:09:50,345 INFO misc.py line 117 4140988] Train: [1/10][1168/7400] Data 0.004 (0.004) Batch 0.590 (0.621) Remain 12:33:14 loss: 7.2400 mask_loss: 6.5734 roll_mask_loss: 7.2516 density_loss: 8.2911 unmask_loss: 7.4017 Lr: 0.00121
[2025-12-10 17:09:50,974 INFO misc.py line 117 4140988] Train: [1/10][1169/7400] Data 0.004 (0.004) Batch 0.629 (0.621) Remain 12:33:14 loss: 7.2538 mask_loss: 6.3851 roll_mask_loss: 7.2244 density_loss: 9.3943 unmask_loss: 7.5150 Lr: 0.00121
[2025-12-10 17:09:51,694 INFO misc.py line 117 4140988] Train: [1/10][1170/7400] Data 0.003 (0.004) Batch 0.720 (0.621) Remain 12:33:20 loss: 7.1887 mask_loss: 6.3525 roll_mask_loss: 7.0405 density_loss: 8.8235 unmask_loss: 7.5044 Lr: 0.00122
[2025-12-10 17:09:52,330 INFO misc.py line 117 4140988] Train: [1/10][1171/7400] Data 0.003 (0.004) Batch 0.636 (0.621) Remain 12:33:20 loss: 7.7007 mask_loss: 7.2470 roll_mask_loss: 7.8535 density_loss: 8.5209 unmask_loss: 7.6807 Lr: 0.00122
[2025-12-10 17:09:53,032 INFO misc.py line 117 4140988] Train: [1/10][1172/7400] Data 0.003 (0.004) Batch 0.702 (0.621) Remain 12:33:24 loss: 7.0765 mask_loss: 6.1396 roll_mask_loss: 6.9804 density_loss: 8.6981 unmask_loss: 7.4191 Lr: 0.00122
[2025-12-10 17:09:53,659 INFO misc.py line 117 4140988] Train: [1/10][1173/7400] Data 0.003 (0.004) Batch 0.627 (0.621) Remain 12:33:24 loss: 7.1119 mask_loss: 6.2481 roll_mask_loss: 6.8871 density_loss: 9.6816 unmask_loss: 7.4625 Lr: 0.00122
[2025-12-10 17:09:54,239 INFO misc.py line 117 4140988] Train: [1/10][1174/7400] Data 0.004 (0.004) Batch 0.579 (0.621) Remain 12:33:21 loss: 7.6632 mask_loss: 6.9397 roll_mask_loss: 7.5183 density_loss: 8.6286 unmask_loss: 7.9247 Lr: 0.00122
[2025-12-10 17:09:54,983 INFO misc.py line 117 4140988] Train: [1/10][1175/7400] Data 0.004 (0.004) Batch 0.745 (0.621) Remain 12:33:28 loss: 6.9478 mask_loss: 6.1220 roll_mask_loss: 6.7133 density_loss: 8.8093 unmask_loss: 7.3018 Lr: 0.00122
[2025-12-10 17:09:55,625 INFO misc.py line 117 4140988] Train: [1/10][1176/7400] Data 0.004 (0.004) Batch 0.642 (0.621) Remain 12:33:29 loss: 7.1953 mask_loss: 6.5834 roll_mask_loss: 6.9894 density_loss: 9.1396 unmask_loss: 7.4214 Lr: 0.00122
[2025-12-10 17:09:56,439 INFO misc.py line 117 4140988] Train: [1/10][1177/7400] Data 0.004 (0.004) Batch 0.814 (0.621) Remain 12:33:40 loss: 7.4525 mask_loss: 6.6599 roll_mask_loss: 7.3355 density_loss: 8.4974 unmask_loss: 7.7373 Lr: 0.00122
[2025-12-10 17:09:57,087 INFO misc.py line 117 4140988] Train: [1/10][1178/7400] Data 0.004 (0.004) Batch 0.647 (0.621) Remain 12:33:41 loss: 7.6691 mask_loss: 7.1949 roll_mask_loss: 7.7482 density_loss: 8.5884 unmask_loss: 7.6949 Lr: 0.00123
[2025-12-10 17:09:57,604 INFO misc.py line 117 4140988] Train: [1/10][1179/7400] Data 0.004 (0.004) Batch 0.517 (0.621) Remain 12:33:34 loss: 7.0997 mask_loss: 6.2235 roll_mask_loss: 7.1283 density_loss: 9.6197 unmask_loss: 7.3310 Lr: 0.00123
[2025-12-10 17:09:58,264 INFO misc.py line 117 4140988] Train: [1/10][1180/7400] Data 0.004 (0.004) Batch 0.660 (0.621) Remain 12:33:36 loss: 8.1475 mask_loss: 7.8735 roll_mask_loss: 8.1917 density_loss: 8.6537 unmask_loss: 8.0893 Lr: 0.00123
[2025-12-10 17:09:59,149 INFO misc.py line 117 4140988] Train: [1/10][1181/7400] Data 0.003 (0.004) Batch 0.885 (0.621) Remain 12:33:52 loss: 7.0298 mask_loss: 6.0434 roll_mask_loss: 6.6479 density_loss: 8.9647 unmask_loss: 7.5347 Lr: 0.00123
[2025-12-10 17:09:59,945 INFO misc.py line 117 4140988] Train: [1/10][1182/7400] Data 0.004 (0.004) Batch 0.796 (0.621) Remain 12:34:02 loss: 7.1549 mask_loss: 6.2275 roll_mask_loss: 7.0202 density_loss: 8.6044 unmask_loss: 7.5138 Lr: 0.00123
[2025-12-10 17:10:00,584 INFO misc.py line 117 4140988] Train: [1/10][1183/7400] Data 0.004 (0.004) Batch 0.639 (0.621) Remain 12:34:02 loss: 7.5472 mask_loss: 6.8605 roll_mask_loss: 7.3327 density_loss: 8.2862 unmask_loss: 7.8321 Lr: 0.00123
[2025-12-10 17:10:00,864 INFO misc.py line 117 4140988] Train: [1/10][1184/7400] Data 0.003 (0.004) Batch 0.280 (0.621) Remain 12:33:41 loss: 8.5155 mask_loss: 8.2950 roll_mask_loss: 8.3555 density_loss: 8.3376 unmask_loss: 8.5390 Lr: 0.00123
[2025-12-10 17:10:01,418 INFO misc.py line 117 4140988] Train: [1/10][1185/7400] Data 0.003 (0.004) Batch 0.554 (0.621) Remain 12:33:36 loss: 8.0401 mask_loss: 7.6710 roll_mask_loss: 7.9382 density_loss: 8.6086 unmask_loss: 8.1034 Lr: 0.00123
[2025-12-10 17:10:02,016 INFO misc.py line 117 4140988] Train: [1/10][1186/7400] Data 0.004 (0.004) Batch 0.597 (0.621) Remain 12:33:34 loss: 7.3353 mask_loss: 6.7047 roll_mask_loss: 7.3053 density_loss: 8.3146 unmask_loss: 7.4993 Lr: 0.00124
[2025-12-10 17:10:02,671 INFO misc.py line 117 4140988] Train: [1/10][1187/7400] Data 0.004 (0.004) Batch 0.656 (0.621) Remain 12:33:35 loss: 7.2455 mask_loss: 6.2060 roll_mask_loss: 7.0289 density_loss: 10.0209 unmask_loss: 7.6731 Lr: 0.00124
[2025-12-10 17:10:03,188 INFO misc.py line 117 4140988] Train: [1/10][1188/7400] Data 0.004 (0.004) Batch 0.517 (0.621) Remain 12:33:28 loss: 8.1460 mask_loss: 7.8083 roll_mask_loss: 8.3417 density_loss: 8.5430 unmask_loss: 8.0461 Lr: 0.00124
[2025-12-10 17:10:03,486 INFO misc.py line 117 4140988] Train: [1/10][1189/7400] Data 0.003 (0.004) Batch 0.298 (0.621) Remain 12:33:08 loss: 8.3935 mask_loss: 7.7353 roll_mask_loss: 9.5296 density_loss: 7.9180 unmask_loss: 7.9961 Lr: 0.00124
[2025-12-10 17:10:04,061 INFO misc.py line 117 4140988] Train: [1/10][1190/7400] Data 0.004 (0.004) Batch 0.574 (0.621) Remain 12:33:04 loss: 8.2394 mask_loss: 7.5429 roll_mask_loss: 8.4271 density_loss: 8.5382 unmask_loss: 8.3230 Lr: 0.00124
[2025-12-10 17:10:04,637 INFO misc.py line 117 4140988] Train: [1/10][1191/7400] Data 0.004 (0.004) Batch 0.576 (0.621) Remain 12:33:01 loss: 7.3282 mask_loss: 6.6457 roll_mask_loss: 7.1200 density_loss: 8.6555 unmask_loss: 7.6003 Lr: 0.00124
[2025-12-10 17:10:05,334 INFO misc.py line 117 4140988] Train: [1/10][1192/7400] Data 0.004 (0.004) Batch 0.697 (0.621) Remain 12:33:05 loss: 7.0563 mask_loss: 6.2177 roll_mask_loss: 6.9101 density_loss: 9.6890 unmask_loss: 7.3548 Lr: 0.00124
[2025-12-10 17:10:06,007 INFO misc.py line 117 4140988] Train: [1/10][1193/7400] Data 0.004 (0.004) Batch 0.673 (0.621) Remain 12:33:08 loss: 6.9932 mask_loss: 6.0991 roll_mask_loss: 6.8708 density_loss: 9.2932 unmask_loss: 7.3155 Lr: 0.00124
[2025-12-10 17:10:06,671 INFO misc.py line 117 4140988] Train: [1/10][1194/7400] Data 0.004 (0.004) Batch 0.665 (0.621) Remain 12:33:10 loss: 7.1018 mask_loss: 6.3604 roll_mask_loss: 7.0649 density_loss: 8.5131 unmask_loss: 7.3206 Lr: 0.00125
[2025-12-10 17:10:07,224 INFO misc.py line 117 4140988] Train: [1/10][1195/7400] Data 0.003 (0.004) Batch 0.552 (0.621) Remain 12:33:05 loss: 7.6447 mask_loss: 7.0136 roll_mask_loss: 7.3341 density_loss: 8.4795 unmask_loss: 7.9459 Lr: 0.00125
[2025-12-10 17:10:07,735 INFO misc.py line 117 4140988] Train: [1/10][1196/7400] Data 0.004 (0.004) Batch 0.511 (0.621) Remain 12:32:58 loss: 7.8791 mask_loss: 7.4749 roll_mask_loss: 7.7964 density_loss: 8.3317 unmask_loss: 7.9558 Lr: 0.00125
[2025-12-10 17:10:08,273 INFO misc.py line 117 4140988] Train: [1/10][1197/7400] Data 0.004 (0.004) Batch 0.538 (0.620) Remain 12:32:52 loss: 8.0202 mask_loss: 7.6550 roll_mask_loss: 7.8211 density_loss: 8.3169 unmask_loss: 8.1360 Lr: 0.00125
[2025-12-10 17:10:08,756 INFO misc.py line 117 4140988] Train: [1/10][1198/7400] Data 0.004 (0.004) Batch 0.483 (0.620) Remain 12:32:43 loss: 7.0236 mask_loss: 6.1645 roll_mask_loss: 7.0428 density_loss: 9.5026 unmask_loss: 7.2535 Lr: 0.00125
[2025-12-10 17:10:09,477 INFO misc.py line 117 4140988] Train: [1/10][1199/7400] Data 0.004 (0.004) Batch 0.721 (0.620) Remain 12:32:48 loss: 7.1086 mask_loss: 6.3399 roll_mask_loss: 6.8733 density_loss: 8.2384 unmask_loss: 7.4459 Lr: 0.00125
[2025-12-10 17:10:09,760 INFO misc.py line 117 4140988] Train: [1/10][1200/7400] Data 0.004 (0.004) Batch 0.283 (0.620) Remain 12:32:27 loss: 8.4936 mask_loss: 8.4247 roll_mask_loss: 8.4429 density_loss: 8.4412 unmask_loss: 8.3845 Lr: 0.00125
[2025-12-10 17:10:10,316 INFO misc.py line 117 4140988] Train: [1/10][1201/7400] Data 0.003 (0.004) Batch 0.557 (0.620) Remain 12:32:23 loss: 7.6142 mask_loss: 6.8347 roll_mask_loss: 7.6550 density_loss: 8.2559 unmask_loss: 7.8183 Lr: 0.00126
[2025-12-10 17:10:10,919 INFO misc.py line 117 4140988] Train: [1/10][1202/7400] Data 0.004 (0.004) Batch 0.602 (0.620) Remain 12:32:21 loss: 7.2328 mask_loss: 6.5754 roll_mask_loss: 7.1913 density_loss: 9.4206 unmask_loss: 7.3939 Lr: 0.00126
[2025-12-10 17:10:11,589 INFO misc.py line 117 4140988] Train: [1/10][1203/7400] Data 0.004 (0.004) Batch 0.670 (0.620) Remain 12:32:24 loss: 7.0313 mask_loss: 6.1766 roll_mask_loss: 7.0312 density_loss: 9.2184 unmask_loss: 7.2744 Lr: 0.00126
[2025-12-10 17:10:12,066 INFO misc.py line 117 4140988] Train: [1/10][1204/7400] Data 0.004 (0.004) Batch 0.478 (0.620) Remain 12:32:14 loss: 7.2926 mask_loss: 6.5001 roll_mask_loss: 7.4289 density_loss: 9.6598 unmask_loss: 7.4275 Lr: 0.00126
[2025-12-10 17:10:12,792 INFO misc.py line 117 4140988] Train: [1/10][1205/7400] Data 0.003 (0.004) Batch 0.726 (0.620) Remain 12:32:20 loss: 6.9704 mask_loss: 6.0687 roll_mask_loss: 6.8130 density_loss: 9.9776 unmask_loss: 7.3003 Lr: 0.00126
[2025-12-10 17:10:13,450 INFO misc.py line 117 4140988] Train: [1/10][1206/7400] Data 0.004 (0.004) Batch 0.657 (0.620) Remain 12:32:22 loss: 8.3961 mask_loss: 8.1199 roll_mask_loss: 8.4128 density_loss: 8.5519 unmask_loss: 8.3548 Lr: 0.00126
[2025-12-10 17:10:13,991 INFO misc.py line 117 4140988] Train: [1/10][1207/7400] Data 0.004 (0.004) Batch 0.541 (0.620) Remain 12:32:16 loss: 8.4482 mask_loss: 8.3430 roll_mask_loss: 8.3886 density_loss: 8.3820 unmask_loss: 8.3630 Lr: 0.00126
[2025-12-10 17:10:14,937 INFO misc.py line 117 4140988] Train: [1/10][1208/7400] Data 0.004 (0.004) Batch 0.946 (0.620) Remain 12:32:35 loss: 6.9838 mask_loss: 6.0478 roll_mask_loss: 7.0187 density_loss: 9.8813 unmask_loss: 7.2368 Lr: 0.00126
[2025-12-10 17:10:15,488 INFO misc.py line 117 4140988] Train: [1/10][1209/7400] Data 0.004 (0.004) Batch 0.552 (0.620) Remain 12:32:31 loss: 8.1987 mask_loss: 7.8086 roll_mask_loss: 8.1009 density_loss: 8.3211 unmask_loss: 8.2761 Lr: 0.00127
[2025-12-10 17:10:15,964 INFO misc.py line 117 4140988] Train: [1/10][1210/7400] Data 0.004 (0.004) Batch 0.476 (0.620) Remain 12:32:21 loss: 8.1528 mask_loss: 7.7436 roll_mask_loss: 8.1791 density_loss: 8.3700 unmask_loss: 8.1768 Lr: 0.00127
[2025-12-10 17:10:16,687 INFO misc.py line 117 4140988] Train: [1/10][1211/7400] Data 0.004 (0.004) Batch 0.723 (0.620) Remain 12:32:27 loss: 7.3158 mask_loss: 6.6815 roll_mask_loss: 7.4095 density_loss: 8.8814 unmask_loss: 7.4084 Lr: 0.00127
[2025-12-10 17:10:17,366 INFO misc.py line 117 4140988] Train: [1/10][1212/7400] Data 0.004 (0.004) Batch 0.679 (0.620) Remain 12:32:30 loss: 7.5057 mask_loss: 6.8044 roll_mask_loss: 7.4030 density_loss: 8.7197 unmask_loss: 7.7333 Lr: 0.00127
[2025-12-10 17:10:17,943 INFO misc.py line 117 4140988] Train: [1/10][1213/7400] Data 0.004 (0.004) Batch 0.577 (0.620) Remain 12:32:27 loss: 7.2877 mask_loss: 6.4387 roll_mask_loss: 7.3362 density_loss: 8.8019 unmask_loss: 7.5119 Lr: 0.00127
[2025-12-10 17:10:18,646 INFO misc.py line 117 4140988] Train: [1/10][1214/7400] Data 0.004 (0.004) Batch 0.703 (0.620) Remain 12:32:31 loss: 7.1196 mask_loss: 6.3496 roll_mask_loss: 6.9560 density_loss: 8.5915 unmask_loss: 7.4146 Lr: 0.00127
[2025-12-10 17:10:19,292 INFO misc.py line 117 4140988] Train: [1/10][1215/7400] Data 0.003 (0.004) Batch 0.647 (0.620) Remain 12:32:32 loss: 6.8866 mask_loss: 6.0518 roll_mask_loss: 6.6078 density_loss: 8.6490 unmask_loss: 7.2704 Lr: 0.00127
[2025-12-10 17:10:20,009 INFO misc.py line 117 4140988] Train: [1/10][1216/7400] Data 0.003 (0.004) Batch 0.716 (0.620) Remain 12:32:37 loss: 7.5844 mask_loss: 6.6782 roll_mask_loss: 7.3764 density_loss: 8.7641 unmask_loss: 7.9661 Lr: 0.00127
[2025-12-10 17:10:20,518 INFO misc.py line 117 4140988] Train: [1/10][1217/7400] Data 0.003 (0.004) Batch 0.508 (0.620) Remain 12:32:30 loss: 8.1026 mask_loss: 7.5316 roll_mask_loss: 8.2483 density_loss: 8.8771 unmask_loss: 8.1378 Lr: 0.00128
[2025-12-10 17:10:20,871 INFO misc.py line 117 4140988] Train: [1/10][1218/7400] Data 0.004 (0.004) Batch 0.354 (0.620) Remain 12:32:13 loss: 7.1277 mask_loss: 6.0070 roll_mask_loss: 6.9441 density_loss: 9.3300 unmask_loss: 7.5933 Lr: 0.00128
[2025-12-10 17:10:21,777 INFO misc.py line 117 4140988] Train: [1/10][1219/7400] Data 0.003 (0.004) Batch 0.907 (0.620) Remain 12:32:30 loss: 6.9257 mask_loss: 6.0741 roll_mask_loss: 6.6818 density_loss: 9.5698 unmask_loss: 7.2820 Lr: 0.00128
[2025-12-10 17:10:22,238 INFO misc.py line 117 4140988] Train: [1/10][1220/7400] Data 0.003 (0.004) Batch 0.461 (0.620) Remain 12:32:19 loss: 7.5702 mask_loss: 7.1052 roll_mask_loss: 7.3598 density_loss: 8.5225 unmask_loss: 7.7373 Lr: 0.00128
[2025-12-10 17:10:22,865 INFO misc.py line 117 4140988] Train: [1/10][1221/7400] Data 0.003 (0.004) Batch 0.626 (0.620) Remain 12:32:19 loss: 7.4749 mask_loss: 7.0268 roll_mask_loss: 7.4988 density_loss: 8.6968 unmask_loss: 7.5130 Lr: 0.00128
[2025-12-10 17:10:23,376 INFO misc.py line 117 4140988] Train: [1/10][1222/7400] Data 0.004 (0.004) Batch 0.511 (0.620) Remain 12:32:12 loss: 7.7946 mask_loss: 7.3415 roll_mask_loss: 7.9930 density_loss: 8.6689 unmask_loss: 7.7485 Lr: 0.00128
[2025-12-10 17:10:23,754 INFO misc.py line 117 4140988] Train: [1/10][1223/7400] Data 0.004 (0.004) Batch 0.378 (0.620) Remain 12:31:57 loss: 7.3753 mask_loss: 6.6240 roll_mask_loss: 7.2330 density_loss: 8.9066 unmask_loss: 7.6439 Lr: 0.00128
[2025-12-10 17:10:24,420 INFO misc.py line 117 4140988] Train: [1/10][1224/7400] Data 0.003 (0.004) Batch 0.665 (0.620) Remain 12:31:59 loss: 7.1161 mask_loss: 6.3649 roll_mask_loss: 6.9064 density_loss: 8.7345 unmask_loss: 7.4219 Lr: 0.00129
[2025-12-10 17:10:25,067 INFO misc.py line 117 4140988] Train: [1/10][1225/7400] Data 0.004 (0.004) Batch 0.648 (0.620) Remain 12:32:00 loss: 7.2476 mask_loss: 6.7337 roll_mask_loss: 7.1708 density_loss: 9.0719 unmask_loss: 7.3616 Lr: 0.00129
[2025-12-10 17:10:25,594 INFO misc.py line 117 4140988] Train: [1/10][1226/7400] Data 0.003 (0.004) Batch 0.528 (0.620) Remain 12:31:54 loss: 7.8803 mask_loss: 7.2255 roll_mask_loss: 7.9780 density_loss: 8.6013 unmask_loss: 7.9867 Lr: 0.00129
[2025-12-10 17:10:26,283 INFO misc.py line 117 4140988] Train: [1/10][1227/7400] Data 0.003 (0.004) Batch 0.688 (0.620) Remain 12:31:57 loss: 7.2692 mask_loss: 6.5978 roll_mask_loss: 7.0945 density_loss: 9.4925 unmask_loss: 7.5025 Lr: 0.00129
[2025-12-10 17:10:26,991 INFO misc.py line 117 4140988] Train: [1/10][1228/7400] Data 0.004 (0.004) Batch 0.708 (0.620) Remain 12:32:02 loss: 7.2437 mask_loss: 6.5249 roll_mask_loss: 7.0821 density_loss: 9.1061 unmask_loss: 7.5018 Lr: 0.00129
[2025-12-10 17:10:27,550 INFO misc.py line 117 4140988] Train: [1/10][1229/7400] Data 0.004 (0.004) Batch 0.559 (0.620) Remain 12:31:58 loss: 7.6434 mask_loss: 6.5976 roll_mask_loss: 7.8199 density_loss: 9.7412 unmask_loss: 7.8831 Lr: 0.00129
[2025-12-10 17:10:28,129 INFO misc.py line 117 4140988] Train: [1/10][1230/7400] Data 0.004 (0.004) Batch 0.579 (0.620) Remain 12:31:55 loss: 8.0890 mask_loss: 7.7964 roll_mask_loss: 7.8718 density_loss: 8.3719 unmask_loss: 8.1766 Lr: 0.00129
[2025-12-10 17:10:28,834 INFO misc.py line 117 4140988] Train: [1/10][1231/7400] Data 0.004 (0.004) Batch 0.705 (0.620) Remain 12:31:59 loss: 7.2902 mask_loss: 6.5445 roll_mask_loss: 7.2741 density_loss: 8.9127 unmask_loss: 7.4928 Lr: 0.00129
[2025-12-10 17:10:29,462 INFO misc.py line 117 4140988] Train: [1/10][1232/7400] Data 0.004 (0.004) Batch 0.629 (0.620) Remain 12:31:59 loss: 7.0471 mask_loss: 6.2093 roll_mask_loss: 6.8289 density_loss: 9.5649 unmask_loss: 7.3838 Lr: 0.00130
[2025-12-10 17:10:30,221 INFO misc.py line 117 4140988] Train: [1/10][1233/7400] Data 0.003 (0.004) Batch 0.759 (0.620) Remain 12:32:07 loss: 7.0999 mask_loss: 6.0406 roll_mask_loss: 6.9386 density_loss: 8.9265 unmask_loss: 7.5317 Lr: 0.00130
[2025-12-10 17:10:30,736 INFO misc.py line 117 4140988] Train: [1/10][1234/7400] Data 0.003 (0.004) Batch 0.515 (0.620) Remain 12:32:00 loss: 7.7405 mask_loss: 7.2351 roll_mask_loss: 7.6526 density_loss: 8.5484 unmask_loss: 7.8663 Lr: 0.00130
[2025-12-10 17:10:31,621 INFO misc.py line 117 4140988] Train: [1/10][1235/7400] Data 0.003 (0.004) Batch 0.885 (0.620) Remain 12:32:15 loss: 7.2803 mask_loss: 6.1292 roll_mask_loss: 7.3788 density_loss: 9.3917 unmask_loss: 7.6189 Lr: 0.00130
[2025-12-10 17:10:32,245 INFO misc.py line 117 4140988] Train: [1/10][1236/7400] Data 0.003 (0.004) Batch 0.624 (0.620) Remain 12:32:14 loss: 7.1096 mask_loss: 6.3846 roll_mask_loss: 7.0807 density_loss: 9.1088 unmask_loss: 7.3044 Lr: 0.00130
[2025-12-10 17:10:33,012 INFO misc.py line 117 4140988] Train: [1/10][1237/7400] Data 0.003 (0.004) Batch 0.766 (0.620) Remain 12:32:22 loss: 7.0343 mask_loss: 6.1797 roll_mask_loss: 7.0025 density_loss: 9.0200 unmask_loss: 7.2972 Lr: 0.00130
[2025-12-10 17:10:33,859 INFO misc.py line 117 4140988] Train: [1/10][1238/7400] Data 0.003 (0.004) Batch 0.847 (0.621) Remain 12:32:35 loss: 7.0512 mask_loss: 6.3021 roll_mask_loss: 6.8261 density_loss: 9.2666 unmask_loss: 7.3529 Lr: 0.00130
[2025-12-10 17:10:34,567 INFO misc.py line 117 4140988] Train: [1/10][1239/7400] Data 0.004 (0.004) Batch 0.707 (0.621) Remain 12:32:40 loss: 7.1276 mask_loss: 6.0664 roll_mask_loss: 7.1807 density_loss: 9.0287 unmask_loss: 7.4511 Lr: 0.00131
[2025-12-10 17:10:35,315 INFO misc.py line 117 4140988] Train: [1/10][1240/7400] Data 0.004 (0.004) Batch 0.749 (0.621) Remain 12:32:47 loss: 7.0420 mask_loss: 6.0457 roll_mask_loss: 7.0753 density_loss: 10.0116 unmask_loss: 7.3232 Lr: 0.00131
[2025-12-10 17:10:36,366 INFO misc.py line 117 4140988] Train: [1/10][1241/7400] Data 0.004 (0.004) Batch 1.052 (0.621) Remain 12:33:11 loss: 7.1930 mask_loss: 6.1204 roll_mask_loss: 7.3054 density_loss: 9.1600 unmask_loss: 7.4898 Lr: 0.00131
[2025-12-10 17:10:36,963 INFO misc.py line 117 4140988] Train: [1/10][1242/7400] Data 0.003 (0.004) Batch 0.597 (0.621) Remain 12:33:09 loss: 7.3368 mask_loss: 6.6467 roll_mask_loss: 7.3768 density_loss: 9.2448 unmask_loss: 7.4770 Lr: 0.00131
[2025-12-10 17:10:37,680 INFO misc.py line 117 4140988] Train: [1/10][1243/7400] Data 0.003 (0.004) Batch 0.717 (0.621) Remain 12:33:14 loss: 7.0124 mask_loss: 6.0738 roll_mask_loss: 6.8784 density_loss: 10.0629 unmask_loss: 7.3474 Lr: 0.00131
[2025-12-10 17:10:38,338 INFO misc.py line 117 4140988] Train: [1/10][1244/7400] Data 0.004 (0.004) Batch 0.658 (0.621) Remain 12:33:16 loss: 7.1129 mask_loss: 6.3796 roll_mask_loss: 6.9785 density_loss: 8.3230 unmask_loss: 7.3803 Lr: 0.00131
[2025-12-10 17:10:38,895 INFO misc.py line 117 4140988] Train: [1/10][1245/7400] Data 0.003 (0.004) Batch 0.557 (0.621) Remain 12:33:11 loss: 7.8001 mask_loss: 7.1313 roll_mask_loss: 7.7985 density_loss: 8.9544 unmask_loss: 7.9562 Lr: 0.00131
[2025-12-10 17:10:39,327 INFO misc.py line 117 4140988] Train: [1/10][1246/7400] Data 0.004 (0.004) Batch 0.431 (0.621) Remain 12:33:00 loss: 8.5565 mask_loss: 8.3537 roll_mask_loss: 8.4039 density_loss: 8.3999 unmask_loss: 8.5663 Lr: 0.00131
[2025-12-10 17:10:40,167 INFO misc.py line 117 4140988] Train: [1/10][1247/7400] Data 0.004 (0.004) Batch 0.841 (0.621) Remain 12:33:12 loss: 7.0430 mask_loss: 6.0555 roll_mask_loss: 7.1237 density_loss: 9.5143 unmask_loss: 7.3061 Lr: 0.00132
[2025-12-10 17:10:40,848 INFO misc.py line 117 4140988] Train: [1/10][1248/7400] Data 0.003 (0.004) Batch 0.682 (0.621) Remain 12:33:15 loss: 7.1752 mask_loss: 6.4507 roll_mask_loss: 7.1256 density_loss: 8.7241 unmask_loss: 7.3877 Lr: 0.00132
[2025-12-10 17:10:41,721 INFO misc.py line 117 4140988] Train: [1/10][1249/7400] Data 0.003 (0.004) Batch 0.872 (0.621) Remain 12:33:29 loss: 7.0474 mask_loss: 6.0685 roll_mask_loss: 6.9838 density_loss: 9.1530 unmask_loss: 7.3857 Lr: 0.00132
[2025-12-10 17:10:42,102 INFO misc.py line 117 4140988] Train: [1/10][1250/7400] Data 0.004 (0.004) Batch 0.381 (0.621) Remain 12:33:14 loss: 8.2162 mask_loss: 7.3521 roll_mask_loss: 8.4695 density_loss: 8.7458 unmask_loss: 8.3467 Lr: 0.00132
[2025-12-10 17:10:42,619 INFO misc.py line 117 4140988] Train: [1/10][1251/7400] Data 0.004 (0.004) Batch 0.517 (0.621) Remain 12:33:07 loss: 8.4685 mask_loss: 8.3112 roll_mask_loss: 8.3517 density_loss: 8.3581 unmask_loss: 8.4383 Lr: 0.00132
[2025-12-10 17:10:42,929 INFO misc.py line 117 4140988] Train: [1/10][1252/7400] Data 0.004 (0.004) Batch 0.310 (0.621) Remain 12:32:49 loss: 7.5464 mask_loss: 6.6116 roll_mask_loss: 7.9747 density_loss: 8.8453 unmask_loss: 7.6227 Lr: 0.00132
[2025-12-10 17:10:43,438 INFO misc.py line 117 4140988] Train: [1/10][1253/7400] Data 0.003 (0.004) Batch 0.509 (0.621) Remain 12:32:42 loss: 8.4414 mask_loss: 8.3058 roll_mask_loss: 8.3482 density_loss: 8.3448 unmask_loss: 8.3889 Lr: 0.00132
[2025-12-10 17:10:43,997 INFO misc.py line 117 4140988] Train: [1/10][1254/7400] Data 0.003 (0.004) Batch 0.560 (0.621) Remain 12:32:37 loss: 8.0115 mask_loss: 7.7064 roll_mask_loss: 8.0386 density_loss: 8.4633 unmask_loss: 7.9812 Lr: 0.00133
[2025-12-10 17:10:44,551 INFO misc.py line 117 4140988] Train: [1/10][1255/7400] Data 0.003 (0.004) Batch 0.554 (0.621) Remain 12:32:33 loss: 7.3328 mask_loss: 6.6786 roll_mask_loss: 6.9567 density_loss: 8.7751 unmask_loss: 7.6724 Lr: 0.00133
[2025-12-10 17:10:45,234 INFO misc.py line 117 4140988] Train: [1/10][1256/7400] Data 0.003 (0.004) Batch 0.684 (0.621) Remain 12:32:36 loss: 7.3889 mask_loss: 6.7988 roll_mask_loss: 7.2913 density_loss: 8.5564 unmask_loss: 7.5615 Lr: 0.00133
[2025-12-10 17:10:45,564 INFO misc.py line 117 4140988] Train: [1/10][1257/7400] Data 0.003 (0.004) Batch 0.330 (0.621) Remain 12:32:18 loss: 8.4149 mask_loss: 8.2984 roll_mask_loss: 8.3493 density_loss: 8.3573 unmask_loss: 8.3387 Lr: 0.00133
[2025-12-10 17:10:46,133 INFO misc.py line 117 4140988] Train: [1/10][1258/7400] Data 0.003 (0.004) Batch 0.569 (0.620) Remain 12:32:15 loss: 7.2001 mask_loss: 6.5688 roll_mask_loss: 7.1499 density_loss: 9.1061 unmask_loss: 7.3587 Lr: 0.00133
[2025-12-10 17:10:46,766 INFO misc.py line 117 4140988] Train: [1/10][1259/7400] Data 0.003 (0.004) Batch 0.632 (0.620) Remain 12:32:15 loss: 7.1459 mask_loss: 6.2327 roll_mask_loss: 7.2537 density_loss: 9.6429 unmask_loss: 7.3558 Lr: 0.00133
[2025-12-10 17:10:47,475 INFO misc.py line 117 4140988] Train: [1/10][1260/7400] Data 0.003 (0.004) Batch 0.709 (0.621) Remain 12:32:19 loss: 7.4171 mask_loss: 6.7993 roll_mask_loss: 7.2055 density_loss: 8.7120 unmask_loss: 7.6577 Lr: 0.00133
[2025-12-10 17:10:48,012 INFO misc.py line 117 4140988] Train: [1/10][1261/7400] Data 0.003 (0.004) Batch 0.536 (0.620) Remain 12:32:14 loss: 8.4009 mask_loss: 8.2300 roll_mask_loss: 8.4747 density_loss: 8.5453 unmask_loss: 8.2785 Lr: 0.00133
[2025-12-10 17:10:48,578 INFO misc.py line 117 4140988] Train: [1/10][1262/7400] Data 0.004 (0.004) Batch 0.565 (0.620) Remain 12:32:10 loss: 7.7097 mask_loss: 7.0973 roll_mask_loss: 7.8303 density_loss: 8.7297 unmask_loss: 7.7809 Lr: 0.00134
[2025-12-10 17:10:49,049 INFO misc.py line 117 4140988] Train: [1/10][1263/7400] Data 0.004 (0.004) Batch 0.472 (0.620) Remain 12:32:01 loss: 7.5987 mask_loss: 7.1964 roll_mask_loss: 7.4713 density_loss: 8.7601 unmask_loss: 7.6884 Lr: 0.00134
[2025-12-10 17:10:49,596 INFO misc.py line 117 4140988] Train: [1/10][1264/7400] Data 0.003 (0.004) Batch 0.547 (0.620) Remain 12:31:56 loss: 7.2463 mask_loss: 6.5707 roll_mask_loss: 7.1196 density_loss: 8.8196 unmask_loss: 7.4710 Lr: 0.00134
[2025-12-10 17:10:50,260 INFO misc.py line 117 4140988] Train: [1/10][1265/7400] Data 0.003 (0.004) Batch 0.663 (0.620) Remain 12:31:58 loss: 7.1338 mask_loss: 6.5142 roll_mask_loss: 7.1036 density_loss: 9.4207 unmask_loss: 7.2703 Lr: 0.00134
[2025-12-10 17:10:50,777 INFO misc.py line 117 4140988] Train: [1/10][1266/7400] Data 0.004 (0.004) Batch 0.517 (0.620) Remain 12:31:51 loss: 8.3583 mask_loss: 7.8517 roll_mask_loss: 8.4875 density_loss: 8.3821 unmask_loss: 8.3794 Lr: 0.00134
[2025-12-10 17:10:51,405 INFO misc.py line 117 4140988] Train: [1/10][1267/7400] Data 0.004 (0.004) Batch 0.629 (0.620) Remain 12:31:51 loss: 8.1153 mask_loss: 7.7819 roll_mask_loss: 8.2497 density_loss: 8.7127 unmask_loss: 8.0406 Lr: 0.00134
[2025-12-10 17:10:52,209 INFO misc.py line 117 4140988] Train: [1/10][1268/7400] Data 0.004 (0.004) Batch 0.804 (0.620) Remain 12:32:01 loss: 7.2011 mask_loss: 6.3963 roll_mask_loss: 7.2092 density_loss: 9.0992 unmask_loss: 7.4175 Lr: 0.00134
[2025-12-10 17:10:53,038 INFO misc.py line 117 4140988] Train: [1/10][1269/7400] Data 0.004 (0.004) Batch 0.828 (0.621) Remain 12:32:12 loss: 6.9861 mask_loss: 6.0254 roll_mask_loss: 6.8636 density_loss: 9.7361 unmask_loss: 7.3329 Lr: 0.00135
[2025-12-10 17:10:53,674 INFO misc.py line 117 4140988] Train: [1/10][1270/7400] Data 0.004 (0.004) Batch 0.637 (0.621) Remain 12:32:13 loss: 7.4903 mask_loss: 6.9688 roll_mask_loss: 7.3901 density_loss: 8.9554 unmask_loss: 7.6219 Lr: 0.00135
[2025-12-10 17:10:54,348 INFO misc.py line 117 4140988] Train: [1/10][1271/7400] Data 0.004 (0.004) Batch 0.675 (0.621) Remain 12:32:15 loss: 7.0226 mask_loss: 6.3251 roll_mask_loss: 6.9125 density_loss: 8.8464 unmask_loss: 7.2494 Lr: 0.00135
[2025-12-10 17:10:54,987 INFO misc.py line 117 4140988] Train: [1/10][1272/7400] Data 0.003 (0.004) Batch 0.639 (0.621) Remain 12:32:16 loss: 7.2137 mask_loss: 6.5591 roll_mask_loss: 7.0424 density_loss: 8.7928 unmask_loss: 7.4508 Lr: 0.00135
[2025-12-10 17:10:55,788 INFO misc.py line 117 4140988] Train: [1/10][1273/7400] Data 0.003 (0.004) Batch 0.800 (0.621) Remain 12:32:25 loss: 7.1022 mask_loss: 6.2831 roll_mask_loss: 7.0263 density_loss: 8.9420 unmask_loss: 7.3709 Lr: 0.00135
[2025-12-10 17:10:56,592 INFO misc.py line 117 4140988] Train: [1/10][1274/7400] Data 0.004 (0.004) Batch 0.805 (0.621) Remain 12:32:35 loss: 6.9682 mask_loss: 6.1405 roll_mask_loss: 6.7517 density_loss: 8.3423 unmask_loss: 7.3235 Lr: 0.00135
[2025-12-10 17:10:57,155 INFO misc.py line 117 4140988] Train: [1/10][1275/7400] Data 0.003 (0.004) Batch 0.563 (0.621) Remain 12:32:31 loss: 7.8383 mask_loss: 7.1127 roll_mask_loss: 8.5257 density_loss: 8.8399 unmask_loss: 7.6806 Lr: 0.00135
[2025-12-10 17:10:58,002 INFO misc.py line 117 4140988] Train: [1/10][1276/7400] Data 0.003 (0.004) Batch 0.847 (0.621) Remain 12:32:44 loss: 7.4563 mask_loss: 5.9032 roll_mask_loss: 7.9387 density_loss: 9.9662 unmask_loss: 7.7924 Lr: 0.00135
[2025-12-10 17:10:58,745 INFO misc.py line 117 4140988] Train: [1/10][1277/7400] Data 0.003 (0.004) Batch 0.742 (0.621) Remain 12:32:50 loss: 7.2963 mask_loss: 6.2387 roll_mask_loss: 7.2087 density_loss: 9.0149 unmask_loss: 7.6885 Lr: 0.00136
[2025-12-10 17:10:59,407 INFO misc.py line 117 4140988] Train: [1/10][1278/7400] Data 0.003 (0.004) Batch 0.663 (0.621) Remain 12:32:52 loss: 7.0753 mask_loss: 6.4055 roll_mask_loss: 6.9398 density_loss: 9.2614 unmask_loss: 7.2926 Lr: 0.00136
[2025-12-10 17:10:59,764 INFO misc.py line 117 4140988] Train: [1/10][1279/7400] Data 0.003 (0.004) Batch 0.356 (0.621) Remain 12:32:36 loss: 6.9190 mask_loss: 5.8437 roll_mask_loss: 6.7645 density_loss: 9.4392 unmask_loss: 7.3451 Lr: 0.00136
[2025-12-10 17:11:00,277 INFO misc.py line 117 4140988] Train: [1/10][1280/7400] Data 0.003 (0.004) Batch 0.513 (0.621) Remain 12:32:29 loss: 7.9377 mask_loss: 7.4222 roll_mask_loss: 7.6904 density_loss: 8.6504 unmask_loss: 8.1461 Lr: 0.00136
[2025-12-10 17:11:00,836 INFO misc.py line 117 4140988] Train: [1/10][1281/7400] Data 0.003 (0.004) Batch 0.559 (0.621) Remain 12:32:25 loss: 8.1198 mask_loss: 7.6191 roll_mask_loss: 8.2039 density_loss: 8.3168 unmask_loss: 8.1617 Lr: 0.00136
[2025-12-10 17:11:01,486 INFO misc.py line 117 4140988] Train: [1/10][1282/7400] Data 0.004 (0.004) Batch 0.650 (0.621) Remain 12:32:26 loss: 7.3982 mask_loss: 6.7468 roll_mask_loss: 7.3499 density_loss: 9.0426 unmask_loss: 7.5672 Lr: 0.00136
[2025-12-10 17:11:02,026 INFO misc.py line 117 4140988] Train: [1/10][1283/7400] Data 0.004 (0.004) Batch 0.539 (0.621) Remain 12:32:21 loss: 7.3885 mask_loss: 6.6497 roll_mask_loss: 7.2528 density_loss: 9.2521 unmask_loss: 7.6407 Lr: 0.00136
[2025-12-10 17:11:02,745 INFO misc.py line 117 4140988] Train: [1/10][1284/7400] Data 0.004 (0.004) Batch 0.720 (0.621) Remain 12:32:26 loss: 7.1056 mask_loss: 6.5451 roll_mask_loss: 6.9554 density_loss: 8.7440 unmask_loss: 7.2860 Lr: 0.00137
[2025-12-10 17:11:03,326 INFO misc.py line 117 4140988] Train: [1/10][1285/7400] Data 0.003 (0.004) Batch 0.580 (0.621) Remain 12:32:23 loss: 6.8857 mask_loss: 5.9532 roll_mask_loss: 6.6619 density_loss: 9.4236 unmask_loss: 7.2753 Lr: 0.00137
[2025-12-10 17:11:04,008 INFO misc.py line 117 4140988] Train: [1/10][1286/7400] Data 0.004 (0.004) Batch 0.682 (0.621) Remain 12:32:26 loss: 7.4464 mask_loss: 6.7583 roll_mask_loss: 7.4708 density_loss: 9.6110 unmask_loss: 7.5861 Lr: 0.00137
[2025-12-10 17:11:04,684 INFO misc.py line 117 4140988] Train: [1/10][1287/7400] Data 0.004 (0.004) Batch 0.676 (0.621) Remain 12:32:28 loss: 7.4091 mask_loss: 6.8231 roll_mask_loss: 7.7781 density_loss: 7.5917 unmask_loss: 7.3658 Lr: 0.00137
[2025-12-10 17:11:05,428 INFO misc.py line 117 4140988] Train: [1/10][1288/7400] Data 0.003 (0.004) Batch 0.744 (0.621) Remain 12:32:35 loss: 7.1677 mask_loss: 6.3883 roll_mask_loss: 6.8967 density_loss: 9.3264 unmask_loss: 7.5063 Lr: 0.00137
[2025-12-10 17:11:05,791 INFO misc.py line 117 4140988] Train: [1/10][1289/7400] Data 0.004 (0.004) Batch 0.364 (0.621) Remain 12:32:19 loss: 7.3291 mask_loss: 6.8062 roll_mask_loss: 7.1963 density_loss: 7.6810 unmask_loss: 7.5034 Lr: 0.00137
[2025-12-10 17:11:06,090 INFO misc.py line 117 4140988] Train: [1/10][1290/7400] Data 0.003 (0.004) Batch 0.299 (0.621) Remain 12:32:01 loss: 8.4437 mask_loss: 8.3236 roll_mask_loss: 8.3605 density_loss: 8.3458 unmask_loss: 8.3785 Lr: 0.00137
[2025-12-10 17:11:06,878 INFO misc.py line 117 4140988] Train: [1/10][1291/7400] Data 0.003 (0.004) Batch 0.788 (0.621) Remain 12:32:09 loss: 7.1472 mask_loss: 6.4333 roll_mask_loss: 7.1499 density_loss: 8.2893 unmask_loss: 7.3370 Lr: 0.00138
[2025-12-10 17:11:07,590 INFO misc.py line 117 4140988] Train: [1/10][1292/7400] Data 0.004 (0.004) Batch 0.712 (0.621) Remain 12:32:14 loss: 6.9947 mask_loss: 6.3619 roll_mask_loss: 6.8900 density_loss: 8.5066 unmask_loss: 7.1933 Lr: 0.00138
[2025-12-10 17:11:08,227 INFO misc.py line 117 4140988] Train: [1/10][1293/7400] Data 0.004 (0.004) Batch 0.637 (0.621) Remain 12:32:14 loss: 7.5025 mask_loss: 6.7863 roll_mask_loss: 7.1767 density_loss: 9.0573 unmask_loss: 7.8424 Lr: 0.00138
[2025-12-10 17:11:09,056 INFO misc.py line 117 4140988] Train: [1/10][1294/7400] Data 0.004 (0.004) Batch 0.829 (0.621) Remain 12:32:25 loss: 7.0177 mask_loss: 5.9817 roll_mask_loss: 7.0149 density_loss: 9.3519 unmask_loss: 7.3500 Lr: 0.00138
[2025-12-10 17:11:09,788 INFO misc.py line 117 4140988] Train: [1/10][1295/7400] Data 0.004 (0.004) Batch 0.733 (0.621) Remain 12:32:31 loss: 7.0770 mask_loss: 6.2838 roll_mask_loss: 6.9839 density_loss: 9.5570 unmask_loss: 7.3291 Lr: 0.00138
[2025-12-10 17:11:10,442 INFO misc.py line 117 4140988] Train: [1/10][1296/7400] Data 0.004 (0.004) Batch 0.654 (0.621) Remain 12:32:32 loss: 7.3424 mask_loss: 6.7597 roll_mask_loss: 7.2415 density_loss: 9.6392 unmask_loss: 7.4913 Lr: 0.00138
[2025-12-10 17:11:11,159 INFO misc.py line 117 4140988] Train: [1/10][1297/7400] Data 0.004 (0.004) Batch 0.717 (0.621) Remain 12:32:37 loss: 7.1259 mask_loss: 6.4541 roll_mask_loss: 7.0359 density_loss: 8.6775 unmask_loss: 7.3332 Lr: 0.00138
[2025-12-10 17:11:11,465 INFO misc.py line 117 4140988] Train: [1/10][1298/7400] Data 0.003 (0.004) Batch 0.306 (0.621) Remain 12:32:19 loss: 7.1099 mask_loss: 6.3505 roll_mask_loss: 7.0365 density_loss: 8.0672 unmask_loss: 7.3650 Lr: 0.00138
[2025-12-10 17:11:12,102 INFO misc.py line 117 4140988] Train: [1/10][1299/7400] Data 0.003 (0.004) Batch 0.637 (0.621) Remain 12:32:19 loss: 7.7780 mask_loss: 7.1012 roll_mask_loss: 7.4350 density_loss: 9.0256 unmask_loss: 8.1075 Lr: 0.00139
[2025-12-10 17:11:12,704 INFO misc.py line 117 4140988] Train: [1/10][1300/7400] Data 0.003 (0.004) Batch 0.602 (0.621) Remain 12:32:17 loss: 6.9444 mask_loss: 6.1297 roll_mask_loss: 6.8635 density_loss: 8.9174 unmask_loss: 7.2137 Lr: 0.00139
[2025-12-10 17:11:13,335 INFO misc.py line 117 4140988] Train: [1/10][1301/7400] Data 0.003 (0.004) Batch 0.630 (0.621) Remain 12:32:17 loss: 7.6260 mask_loss: 6.9603 roll_mask_loss: 7.4067 density_loss: 8.8140 unmask_loss: 7.8923 Lr: 0.00139
[2025-12-10 17:11:14,037 INFO misc.py line 117 4140988] Train: [1/10][1302/7400] Data 0.003 (0.004) Batch 0.703 (0.621) Remain 12:32:21 loss: 7.0085 mask_loss: 6.2304 roll_mask_loss: 6.9373 density_loss: 8.5481 unmask_loss: 7.2622 Lr: 0.00139
[2025-12-10 17:11:14,684 INFO misc.py line 117 4140988] Train: [1/10][1303/7400] Data 0.004 (0.004) Batch 0.646 (0.621) Remain 12:32:22 loss: 7.2838 mask_loss: 6.4491 roll_mask_loss: 6.9125 density_loss: 8.3618 unmask_loss: 7.7195 Lr: 0.00139
[2025-12-10 17:11:15,229 INFO misc.py line 117 4140988] Train: [1/10][1304/7400] Data 0.004 (0.004) Batch 0.545 (0.621) Remain 12:32:17 loss: 7.2786 mask_loss: 6.5478 roll_mask_loss: 7.1488 density_loss: 9.2805 unmask_loss: 7.5233 Lr: 0.00139
[2025-12-10 17:11:15,965 INFO misc.py line 117 4140988] Train: [1/10][1305/7400] Data 0.004 (0.004) Batch 0.737 (0.621) Remain 12:32:23 loss: 7.3150 mask_loss: 6.5837 roll_mask_loss: 7.2754 density_loss: 8.9708 unmask_loss: 7.5211 Lr: 0.00139
[2025-12-10 17:11:16,608 INFO misc.py line 117 4140988] Train: [1/10][1306/7400] Data 0.003 (0.004) Batch 0.643 (0.621) Remain 12:32:24 loss: 7.0728 mask_loss: 6.4087 roll_mask_loss: 6.9401 density_loss: 9.1796 unmask_loss: 7.2876 Lr: 0.00140
[2025-12-10 17:11:17,115 INFO misc.py line 117 4140988] Train: [1/10][1307/7400] Data 0.003 (0.004) Batch 0.507 (0.621) Remain 12:32:17 loss: 7.3777 mask_loss: 6.7553 roll_mask_loss: 7.2177 density_loss: 9.2148 unmask_loss: 7.5847 Lr: 0.00140
[2025-12-10 17:11:17,581 INFO misc.py line 117 4140988] Train: [1/10][1308/7400] Data 0.003 (0.004) Batch 0.466 (0.621) Remain 12:32:07 loss: 7.7700 mask_loss: 7.1194 roll_mask_loss: 8.3027 density_loss: 8.6434 unmask_loss: 7.6560 Lr: 0.00140
[2025-12-10 17:11:18,306 INFO misc.py line 117 4140988] Train: [1/10][1309/7400] Data 0.003 (0.004) Batch 0.725 (0.621) Remain 12:32:13 loss: 7.2087 mask_loss: 6.3629 roll_mask_loss: 7.1637 density_loss: 9.0216 unmask_loss: 7.4736 Lr: 0.00140
[2025-12-10 17:11:18,865 INFO misc.py line 117 4140988] Train: [1/10][1310/7400] Data 0.004 (0.004) Batch 0.558 (0.621) Remain 12:32:08 loss: 8.4343 mask_loss: 8.3117 roll_mask_loss: 8.3529 density_loss: 8.3579 unmask_loss: 8.3691 Lr: 0.00140
[2025-12-10 17:11:19,573 INFO misc.py line 117 4140988] Train: [1/10][1311/7400] Data 0.004 (0.004) Batch 0.708 (0.621) Remain 12:32:13 loss: 7.3852 mask_loss: 6.6444 roll_mask_loss: 7.5386 density_loss: 8.7380 unmask_loss: 7.5040 Lr: 0.00140
[2025-12-10 17:11:20,237 INFO misc.py line 117 4140988] Train: [1/10][1312/7400] Data 0.003 (0.004) Batch 0.665 (0.621) Remain 12:32:15 loss: 7.8072 mask_loss: 7.1493 roll_mask_loss: 7.7406 density_loss: 9.5618 unmask_loss: 7.9781 Lr: 0.00140
[2025-12-10 17:11:20,793 INFO misc.py line 117 4140988] Train: [1/10][1313/7400] Data 0.003 (0.004) Batch 0.555 (0.621) Remain 12:32:10 loss: 7.4569 mask_loss: 6.6020 roll_mask_loss: 7.5248 density_loss: 9.2651 unmask_loss: 7.6650 Lr: 0.00141
[2025-12-10 17:11:21,370 INFO misc.py line 117 4140988] Train: [1/10][1314/7400] Data 0.004 (0.004) Batch 0.578 (0.621) Remain 12:32:07 loss: 7.5162 mask_loss: 6.8721 roll_mask_loss: 7.3160 density_loss: 8.4831 unmask_loss: 7.7688 Lr: 0.00141
[2025-12-10 17:11:21,953 INFO misc.py line 117 4140988] Train: [1/10][1315/7400] Data 0.004 (0.004) Batch 0.583 (0.621) Remain 12:32:04 loss: 7.1450 mask_loss: 6.4394 roll_mask_loss: 7.0675 density_loss: 8.5176 unmask_loss: 7.3661 Lr: 0.00141
[2025-12-10 17:11:22,870 INFO misc.py line 117 4140988] Train: [1/10][1316/7400] Data 0.003 (0.004) Batch 0.917 (0.621) Remain 12:32:20 loss: 6.9556 mask_loss: 5.8488 roll_mask_loss: 6.8558 density_loss: 9.2871 unmask_loss: 7.3732 Lr: 0.00141
[2025-12-10 17:11:23,615 INFO misc.py line 117 4140988] Train: [1/10][1317/7400] Data 0.003 (0.004) Batch 0.744 (0.621) Remain 12:32:26 loss: 7.2024 mask_loss: 6.3724 roll_mask_loss: 7.0214 density_loss: 8.5061 unmask_loss: 7.5379 Lr: 0.00141
[2025-12-10 17:11:23,910 INFO misc.py line 117 4140988] Train: [1/10][1318/7400] Data 0.004 (0.004) Batch 0.295 (0.621) Remain 12:32:08 loss: 7.7055 mask_loss: 6.2990 roll_mask_loss: 7.8826 density_loss: 8.7890 unmask_loss: 8.1444 Lr: 0.00141
[2025-12-10 17:11:24,610 INFO misc.py line 117 4140988] Train: [1/10][1319/7400] Data 0.004 (0.004) Batch 0.700 (0.621) Remain 12:32:12 loss: 7.3991 mask_loss: 6.5846 roll_mask_loss: 7.5309 density_loss: 9.3430 unmask_loss: 7.5535 Lr: 0.00141
[2025-12-10 17:11:25,131 INFO misc.py line 117 4140988] Train: [1/10][1320/7400] Data 0.004 (0.004) Batch 0.521 (0.621) Remain 12:32:05 loss: 8.3162 mask_loss: 8.0407 roll_mask_loss: 8.4106 density_loss: 8.4412 unmask_loss: 8.2379 Lr: 0.00141
[2025-12-10 17:11:25,870 INFO misc.py line 117 4140988] Train: [1/10][1321/7400] Data 0.004 (0.004) Batch 0.739 (0.621) Remain 12:32:11 loss: 7.3286 mask_loss: 6.5422 roll_mask_loss: 7.1623 density_loss: 9.3097 unmask_loss: 7.6187 Lr: 0.00142
[2025-12-10 17:11:26,475 INFO misc.py line 117 4140988] Train: [1/10][1322/7400] Data 0.004 (0.004) Batch 0.606 (0.621) Remain 12:32:10 loss: 6.9918 mask_loss: 6.3300 roll_mask_loss: 6.8417 density_loss: 8.3352 unmask_loss: 7.2311 Lr: 0.00142
[2025-12-10 17:11:27,124 INFO misc.py line 117 4140988] Train: [1/10][1323/7400] Data 0.004 (0.004) Batch 0.648 (0.621) Remain 12:32:11 loss: 7.1396 mask_loss: 6.3902 roll_mask_loss: 7.0041 density_loss: 9.1587 unmask_loss: 7.3989 Lr: 0.00142
[2025-12-10 17:11:27,837 INFO misc.py line 117 4140988] Train: [1/10][1324/7400] Data 0.004 (0.004) Batch 0.713 (0.621) Remain 12:32:15 loss: 7.0072 mask_loss: 5.8877 roll_mask_loss: 7.0285 density_loss: 9.6263 unmask_loss: 7.3639 Lr: 0.00142
[2025-12-10 17:11:28,452 INFO misc.py line 117 4140988] Train: [1/10][1325/7400] Data 0.004 (0.004) Batch 0.616 (0.621) Remain 12:32:14 loss: 6.9199 mask_loss: 6.1818 roll_mask_loss: 6.7180 density_loss: 9.1723 unmask_loss: 7.2064 Lr: 0.00142
[2025-12-10 17:11:29,029 INFO misc.py line 117 4140988] Train: [1/10][1326/7400] Data 0.003 (0.004) Batch 0.577 (0.621) Remain 12:32:11 loss: 7.1435 mask_loss: 6.4558 roll_mask_loss: 7.1538 density_loss: 8.1326 unmask_loss: 7.3195 Lr: 0.00142
[2025-12-10 17:11:29,568 INFO misc.py line 117 4140988] Train: [1/10][1327/7400] Data 0.003 (0.004) Batch 0.539 (0.621) Remain 12:32:06 loss: 7.7306 mask_loss: 7.3251 roll_mask_loss: 7.6940 density_loss: 8.4088 unmask_loss: 7.7835 Lr: 0.00142
[2025-12-10 17:11:30,250 INFO misc.py line 117 4140988] Train: [1/10][1328/7400] Data 0.003 (0.004) Batch 0.682 (0.621) Remain 12:32:09 loss: 6.9352 mask_loss: 6.0320 roll_mask_loss: 6.6971 density_loss: 9.7054 unmask_loss: 7.3117 Lr: 0.00143
[2025-12-10 17:11:30,530 INFO misc.py line 117 4140988] Train: [1/10][1329/7400] Data 0.003 (0.004) Batch 0.278 (0.621) Remain 12:31:49 loss: 8.3623 mask_loss: 8.1024 roll_mask_loss: 8.2704 density_loss: 8.5017 unmask_loss: 8.3682 Lr: 0.00143
[2025-12-10 17:11:31,072 INFO misc.py line 117 4140988] Train: [1/10][1330/7400] Data 0.005 (0.004) Batch 0.544 (0.621) Remain 12:31:45 loss: 7.8277 mask_loss: 7.1470 roll_mask_loss: 7.6438 density_loss: 9.1719 unmask_loss: 8.0766 Lr: 0.00143
[2025-12-10 17:11:31,877 INFO misc.py line 117 4140988] Train: [1/10][1331/7400] Data 0.004 (0.004) Batch 0.805 (0.621) Remain 12:31:54 loss: 7.0918 mask_loss: 6.1513 roll_mask_loss: 7.0831 density_loss: 9.3016 unmask_loss: 7.3805 Lr: 0.00143
[2025-12-10 17:11:32,514 INFO misc.py line 117 4140988] Train: [1/10][1332/7400] Data 0.004 (0.004) Batch 0.636 (0.621) Remain 12:31:54 loss: 7.6933 mask_loss: 7.0573 roll_mask_loss: 7.9453 density_loss: 8.6656 unmask_loss: 7.7120 Lr: 0.00143
[2025-12-10 17:11:33,304 INFO misc.py line 117 4140988] Train: [1/10][1333/7400] Data 0.004 (0.004) Batch 0.789 (0.621) Remain 12:32:03 loss: 7.1743 mask_loss: 6.3302 roll_mask_loss: 6.8730 density_loss: 8.9656 unmask_loss: 7.5676 Lr: 0.00143
[2025-12-10 17:11:33,884 INFO misc.py line 117 4140988] Train: [1/10][1334/7400] Data 0.004 (0.004) Batch 0.581 (0.621) Remain 12:32:00 loss: 8.0983 mask_loss: 7.5979 roll_mask_loss: 7.9640 density_loss: 8.3099 unmask_loss: 8.2494 Lr: 0.00143
[2025-12-10 17:11:34,177 INFO misc.py line 117 4140988] Train: [1/10][1335/7400] Data 0.004 (0.004) Batch 0.293 (0.621) Remain 12:31:42 loss: 8.4184 mask_loss: 8.3316 roll_mask_loss: 8.3336 density_loss: 8.3333 unmask_loss: 8.3376 Lr: 0.00144
[2025-12-10 17:11:35,007 INFO misc.py line 117 4140988] Train: [1/10][1336/7400] Data 0.004 (0.004) Batch 0.830 (0.621) Remain 12:31:52 loss: 6.9553 mask_loss: 6.1631 roll_mask_loss: 6.8004 density_loss: 8.6236 unmask_loss: 7.2564 Lr: 0.00144
[2025-12-10 17:11:35,297 INFO misc.py line 117 4140988] Train: [1/10][1337/7400] Data 0.004 (0.004) Batch 0.290 (0.621) Remain 12:31:34 loss: 8.4101 mask_loss: 8.3278 roll_mask_loss: 8.3288 density_loss: 8.3292 unmask_loss: 8.3253 Lr: 0.00144
[2025-12-10 17:11:35,617 INFO misc.py line 117 4140988] Train: [1/10][1338/7400] Data 0.004 (0.004) Batch 0.320 (0.620) Remain 12:31:17 loss: 8.0701 mask_loss: 7.7187 roll_mask_loss: 7.9960 density_loss: 8.3592 unmask_loss: 8.1156 Lr: 0.00144
[2025-12-10 17:11:35,988 INFO misc.py line 117 4140988] Train: [1/10][1339/7400] Data 0.004 (0.004) Batch 0.371 (0.620) Remain 12:31:02 loss: 7.5202 mask_loss: 6.6787 roll_mask_loss: 7.4383 density_loss: 9.3979 unmask_loss: 7.7940 Lr: 0.00144
[2025-12-10 17:11:36,390 INFO misc.py line 117 4140988] Train: [1/10][1340/7400] Data 0.004 (0.004) Batch 0.403 (0.620) Remain 12:30:50 loss: 7.1226 mask_loss: 6.3324 roll_mask_loss: 7.1493 density_loss: 8.9171 unmask_loss: 7.3261 Lr: 0.00144
[2025-12-10 17:11:36,946 INFO misc.py line 117 4140988] Train: [1/10][1341/7400] Data 0.004 (0.004) Batch 0.555 (0.620) Remain 12:30:46 loss: 7.0652 mask_loss: 6.2531 roll_mask_loss: 6.9332 density_loss: 9.3770 unmask_loss: 7.3498 Lr: 0.00144
[2025-12-10 17:11:37,477 INFO misc.py line 117 4140988] Train: [1/10][1342/7400] Data 0.004 (0.004) Batch 0.531 (0.620) Remain 12:30:40 loss: 8.1914 mask_loss: 7.7558 roll_mask_loss: 8.2455 density_loss: 8.7593 unmask_loss: 8.2070 Lr: 0.00145
[2025-12-10 17:11:38,030 INFO misc.py line 117 4140988] Train: [1/10][1343/7400] Data 0.004 (0.004) Batch 0.553 (0.620) Remain 12:30:36 loss: 7.5023 mask_loss: 6.5080 roll_mask_loss: 8.0947 density_loss: 9.2542 unmask_loss: 7.5183 Lr: 0.00145
[2025-12-10 17:11:38,574 INFO misc.py line 117 4140988] Train: [1/10][1344/7400] Data 0.004 (0.004) Batch 0.545 (0.620) Remain 12:30:32 loss: 6.8477 mask_loss: 5.8827 roll_mask_loss: 6.8429 density_loss: 9.3215 unmask_loss: 7.1462 Lr: 0.00145
[2025-12-10 17:11:39,370 INFO misc.py line 117 4140988] Train: [1/10][1345/7400] Data 0.004 (0.004) Batch 0.796 (0.620) Remain 12:30:40 loss: 6.9610 mask_loss: 5.9131 roll_mask_loss: 7.1638 density_loss: 9.9626 unmask_loss: 7.1842 Lr: 0.00145
[2025-12-10 17:11:39,700 INFO misc.py line 117 4140988] Train: [1/10][1346/7400] Data 0.004 (0.004) Batch 0.329 (0.620) Remain 12:30:24 loss: 8.4137 mask_loss: 8.3196 roll_mask_loss: 8.3361 density_loss: 8.3380 unmask_loss: 8.3328 Lr: 0.00145
[2025-12-10 17:11:40,283 INFO misc.py line 117 4140988] Train: [1/10][1347/7400] Data 0.004 (0.004) Batch 0.583 (0.620) Remain 12:30:22 loss: 8.1573 mask_loss: 7.7547 roll_mask_loss: 8.1417 density_loss: 8.5023 unmask_loss: 8.1963 Lr: 0.00145
[2025-12-10 17:11:41,004 INFO misc.py line 117 4140988] Train: [1/10][1348/7400] Data 0.004 (0.004) Batch 0.721 (0.620) Remain 12:30:26 loss: 7.3464 mask_loss: 6.7716 roll_mask_loss: 7.3275 density_loss: 8.3220 unmask_loss: 7.4768 Lr: 0.00145
[2025-12-10 17:11:41,878 INFO misc.py line 117 4140988] Train: [1/10][1349/7400] Data 0.004 (0.004) Batch 0.874 (0.620) Remain 12:30:39 loss: 7.2177 mask_loss: 5.8876 roll_mask_loss: 7.5459 density_loss: 9.2819 unmask_loss: 7.5329 Lr: 0.00145
[2025-12-10 17:11:42,664 INFO misc.py line 117 4140988] Train: [1/10][1350/7400] Data 0.004 (0.004) Batch 0.786 (0.620) Remain 12:30:48 loss: 6.8877 mask_loss: 5.9802 roll_mask_loss: 6.8189 density_loss: 8.8055 unmask_loss: 7.1997 Lr: 0.00146
[2025-12-10 17:11:43,482 INFO misc.py line 117 4140988] Train: [1/10][1351/7400] Data 0.004 (0.004) Batch 0.818 (0.620) Remain 12:30:58 loss: 7.1445 mask_loss: 6.2563 roll_mask_loss: 7.2113 density_loss: 9.6653 unmask_loss: 7.3619 Lr: 0.00146
[2025-12-10 17:11:44,152 INFO misc.py line 117 4140988] Train: [1/10][1352/7400] Data 0.004 (0.004) Batch 0.671 (0.620) Remain 12:31:00 loss: 7.4257 mask_loss: 6.7774 roll_mask_loss: 7.3966 density_loss: 9.1246 unmask_loss: 7.5820 Lr: 0.00146
[2025-12-10 17:11:44,638 INFO misc.py line 117 4140988] Train: [1/10][1353/7400] Data 0.004 (0.004) Batch 0.486 (0.620) Remain 12:30:52 loss: 7.7957 mask_loss: 6.8939 roll_mask_loss: 8.0346 density_loss: 8.6175 unmask_loss: 7.9547 Lr: 0.00146
[2025-12-10 17:11:45,211 INFO misc.py line 117 4140988] Train: [1/10][1354/7400] Data 0.004 (0.004) Batch 0.573 (0.620) Remain 12:30:49 loss: 7.1150 mask_loss: 6.4947 roll_mask_loss: 6.9591 density_loss: 8.7984 unmask_loss: 7.3271 Lr: 0.00146
[2025-12-10 17:11:45,821 INFO misc.py line 117 4140988] Train: [1/10][1355/7400] Data 0.004 (0.004) Batch 0.610 (0.620) Remain 12:30:48 loss: 7.1263 mask_loss: 5.9451 roll_mask_loss: 6.6562 density_loss: 8.7916 unmask_loss: 7.7761 Lr: 0.00146
[2025-12-10 17:11:46,354 INFO misc.py line 117 4140988] Train: [1/10][1356/7400] Data 0.004 (0.004) Batch 0.533 (0.620) Remain 12:30:42 loss: 8.4861 mask_loss: 8.3272 roll_mask_loss: 8.3543 density_loss: 8.3548 unmask_loss: 8.4643 Lr: 0.00146
[2025-12-10 17:11:46,943 INFO misc.py line 117 4140988] Train: [1/10][1357/7400] Data 0.004 (0.004) Batch 0.589 (0.620) Remain 12:30:40 loss: 7.5373 mask_loss: 7.0531 roll_mask_loss: 7.4841 density_loss: 9.2856 unmask_loss: 7.6204 Lr: 0.00147
[2025-12-10 17:11:47,472 INFO misc.py line 117 4140988] Train: [1/10][1358/7400] Data 0.004 (0.004) Batch 0.530 (0.620) Remain 12:30:35 loss: 8.4041 mask_loss: 8.2957 roll_mask_loss: 8.3175 density_loss: 8.3405 unmask_loss: 8.3348 Lr: 0.00147
[2025-12-10 17:11:48,225 INFO misc.py line 117 4140988] Train: [1/10][1359/7400] Data 0.003 (0.004) Batch 0.753 (0.620) Remain 12:30:41 loss: 6.9691 mask_loss: 6.0211 roll_mask_loss: 6.9406 density_loss: 8.5948 unmask_loss: 7.2854 Lr: 0.00147
[2025-12-10 17:11:48,501 INFO misc.py line 117 4140988] Train: [1/10][1360/7400] Data 0.003 (0.004) Batch 0.276 (0.620) Remain 12:30:22 loss: 7.4108 mask_loss: 6.1855 roll_mask_loss: 7.2380 density_loss: 9.3237 unmask_loss: 7.9233 Lr: 0.00147
[2025-12-10 17:11:49,227 INFO misc.py line 117 4140988] Train: [1/10][1361/7400] Data 0.003 (0.004) Batch 0.726 (0.620) Remain 12:30:27 loss: 7.1434 mask_loss: 6.5009 roll_mask_loss: 6.9925 density_loss: 8.8526 unmask_loss: 7.3631 Lr: 0.00147
[2025-12-10 17:11:49,862 INFO misc.py line 117 4140988] Train: [1/10][1362/7400] Data 0.004 (0.004) Batch 0.634 (0.620) Remain 12:30:27 loss: 6.9899 mask_loss: 6.0706 roll_mask_loss: 6.8396 density_loss: 8.3494 unmask_loss: 7.3578 Lr: 0.00147
[2025-12-10 17:11:50,421 INFO misc.py line 117 4140988] Train: [1/10][1363/7400] Data 0.004 (0.004) Batch 0.559 (0.620) Remain 12:30:24 loss: 7.1153 mask_loss: 6.3823 roll_mask_loss: 6.9773 density_loss: 8.9272 unmask_loss: 7.3723 Lr: 0.00147
[2025-12-10 17:11:51,059 INFO misc.py line 117 4140988] Train: [1/10][1364/7400] Data 0.004 (0.004) Batch 0.638 (0.620) Remain 12:30:24 loss: 7.7957 mask_loss: 7.3123 roll_mask_loss: 7.7849 density_loss: 8.8495 unmask_loss: 7.8658 Lr: 0.00148
[2025-12-10 17:11:51,681 INFO misc.py line 117 4140988] Train: [1/10][1365/7400] Data 0.004 (0.004) Batch 0.622 (0.620) Remain 12:30:23 loss: 7.5292 mask_loss: 6.9155 roll_mask_loss: 7.3595 density_loss: 8.9102 unmask_loss: 7.7428 Lr: 0.00148
[2025-12-10 17:11:52,323 INFO misc.py line 117 4140988] Train: [1/10][1366/7400] Data 0.004 (0.004) Batch 0.642 (0.620) Remain 12:30:24 loss: 7.0983 mask_loss: 6.3044 roll_mask_loss: 6.8458 density_loss: 9.2407 unmask_loss: 7.4368 Lr: 0.00148
[2025-12-10 17:11:53,054 INFO misc.py line 117 4140988] Train: [1/10][1367/7400] Data 0.004 (0.004) Batch 0.731 (0.620) Remain 12:30:29 loss: 7.1829 mask_loss: 6.4698 roll_mask_loss: 7.0719 density_loss: 8.4788 unmask_loss: 7.4253 Lr: 0.00148
[2025-12-10 17:11:53,725 INFO misc.py line 117 4140988] Train: [1/10][1368/7400] Data 0.004 (0.004) Batch 0.672 (0.620) Remain 12:30:31 loss: 6.9554 mask_loss: 6.2074 roll_mask_loss: 6.9263 density_loss: 8.9187 unmask_loss: 7.1655 Lr: 0.00148
[2025-12-10 17:11:54,525 INFO misc.py line 117 4140988] Train: [1/10][1369/7400] Data 0.004 (0.004) Batch 0.800 (0.620) Remain 12:30:40 loss: 6.9788 mask_loss: 6.0243 roll_mask_loss: 6.8059 density_loss: 8.9730 unmask_loss: 7.3631 Lr: 0.00148
[2025-12-10 17:11:55,024 INFO misc.py line 117 4140988] Train: [1/10][1370/7400] Data 0.004 (0.004) Batch 0.499 (0.620) Remain 12:30:33 loss: 8.5699 mask_loss: 8.3783 roll_mask_loss: 8.3926 density_loss: 8.3955 unmask_loss: 8.5864 Lr: 0.00148
[2025-12-10 17:11:55,814 INFO misc.py line 117 4140988] Train: [1/10][1371/7400] Data 0.003 (0.004) Batch 0.790 (0.620) Remain 12:30:42 loss: 6.9194 mask_loss: 6.1665 roll_mask_loss: 6.8296 density_loss: 8.9080 unmask_loss: 7.1626 Lr: 0.00149
[2025-12-10 17:11:56,420 INFO misc.py line 117 4140988] Train: [1/10][1372/7400] Data 0.003 (0.004) Batch 0.606 (0.620) Remain 12:30:40 loss: 7.0959 mask_loss: 6.3314 roll_mask_loss: 7.1228 density_loss: 8.8403 unmask_loss: 7.2878 Lr: 0.00149
[2025-12-10 17:11:57,148 INFO misc.py line 117 4140988] Train: [1/10][1373/7400] Data 0.003 (0.004) Batch 0.727 (0.620) Remain 12:30:45 loss: 7.0056 mask_loss: 5.9829 roll_mask_loss: 6.7391 density_loss: 9.5983 unmask_loss: 7.4582 Lr: 0.00149
[2025-12-10 17:11:57,753 INFO misc.py line 117 4140988] Train: [1/10][1374/7400] Data 0.004 (0.004) Batch 0.605 (0.620) Remain 12:30:44 loss: 7.2991 mask_loss: 6.6570 roll_mask_loss: 7.1194 density_loss: 9.2926 unmask_loss: 7.5241 Lr: 0.00149
[2025-12-10 17:11:58,315 INFO misc.py line 117 4140988] Train: [1/10][1375/7400] Data 0.004 (0.004) Batch 0.563 (0.620) Remain 12:30:40 loss: 7.4546 mask_loss: 6.8010 roll_mask_loss: 7.3530 density_loss: 8.7670 unmask_loss: 7.6568 Lr: 0.00149
[2025-12-10 17:11:58,942 INFO misc.py line 117 4140988] Train: [1/10][1376/7400] Data 0.004 (0.004) Batch 0.627 (0.620) Remain 12:30:40 loss: 7.0963 mask_loss: 6.2034 roll_mask_loss: 7.1450 density_loss: 8.5928 unmask_loss: 7.3465 Lr: 0.00149
[2025-12-10 17:11:59,634 INFO misc.py line 117 4140988] Train: [1/10][1377/7400] Data 0.004 (0.004) Batch 0.692 (0.620) Remain 12:30:43 loss: 6.9820 mask_loss: 6.0176 roll_mask_loss: 6.6959 density_loss: 10.4435 unmask_loss: 7.3984 Lr: 0.00149
[2025-12-10 17:12:00,348 INFO misc.py line 117 4140988] Train: [1/10][1378/7400] Data 0.003 (0.004) Batch 0.714 (0.620) Remain 12:30:47 loss: 6.9133 mask_loss: 6.0260 roll_mask_loss: 6.7806 density_loss: 9.9763 unmask_loss: 7.2238 Lr: 0.00150
[2025-12-10 17:12:00,629 INFO misc.py line 117 4140988] Train: [1/10][1379/7400] Data 0.003 (0.004) Batch 0.281 (0.620) Remain 12:30:29 loss: 7.8227 mask_loss: 7.3833 roll_mask_loss: 7.7064 density_loss: 7.9670 unmask_loss: 7.9411 Lr: 0.00150
[2025-12-10 17:12:01,228 INFO misc.py line 117 4140988] Train: [1/10][1380/7400] Data 0.003 (0.004) Batch 0.599 (0.620) Remain 12:30:27 loss: 7.8941 mask_loss: 7.4659 roll_mask_loss: 7.7532 density_loss: 8.2867 unmask_loss: 8.0128 Lr: 0.00150
[2025-12-10 17:12:01,757 INFO misc.py line 117 4140988] Train: [1/10][1381/7400] Data 0.003 (0.004) Batch 0.528 (0.620) Remain 12:30:22 loss: 8.0100 mask_loss: 7.5134 roll_mask_loss: 8.0577 density_loss: 8.2702 unmask_loss: 8.0690 Lr: 0.00150
[2025-12-10 17:12:02,517 INFO misc.py line 117 4140988] Train: [1/10][1382/7400] Data 0.003 (0.004) Batch 0.759 (0.620) Remain 12:30:29 loss: 6.9703 mask_loss: 6.2051 roll_mask_loss: 6.7831 density_loss: 9.2036 unmask_loss: 7.2624 Lr: 0.00150
[2025-12-10 17:12:03,037 INFO misc.py line 117 4140988] Train: [1/10][1383/7400] Data 0.004 (0.004) Batch 0.520 (0.620) Remain 12:30:23 loss: 8.5008 mask_loss: 8.3628 roll_mask_loss: 8.3884 density_loss: 8.3764 unmask_loss: 8.4584 Lr: 0.00150
[2025-12-10 17:12:03,357 INFO misc.py line 117 4140988] Train: [1/10][1384/7400] Data 0.004 (0.004) Batch 0.320 (0.620) Remain 12:30:06 loss: 7.5066 mask_loss: 6.4387 roll_mask_loss: 7.6089 density_loss: 8.2294 unmask_loss: 7.8247 Lr: 0.00150
[2025-12-10 17:12:04,078 INFO misc.py line 117 4140988] Train: [1/10][1385/7400] Data 0.004 (0.004) Batch 0.721 (0.620) Remain 12:30:11 loss: 6.9208 mask_loss: 6.1582 roll_mask_loss: 6.6947 density_loss: 8.2938 unmask_loss: 7.2493 Lr: 0.00151
[2025-12-10 17:12:04,863 INFO misc.py line 117 4140988] Train: [1/10][1386/7400] Data 0.004 (0.004) Batch 0.786 (0.620) Remain 12:30:19 loss: 6.9785 mask_loss: 5.8778 roll_mask_loss: 6.9618 density_loss: 8.9943 unmask_loss: 7.3572 Lr: 0.00151
[2025-12-10 17:12:05,572 INFO misc.py line 117 4140988] Train: [1/10][1387/7400] Data 0.003 (0.004) Batch 0.708 (0.620) Remain 12:30:23 loss: 8.3771 mask_loss: 8.1121 roll_mask_loss: 8.3177 density_loss: 8.4254 unmask_loss: 8.3708 Lr: 0.00151
[2025-12-10 17:12:06,181 INFO misc.py line 117 4140988] Train: [1/10][1388/7400] Data 0.004 (0.004) Batch 0.609 (0.620) Remain 12:30:22 loss: 6.9254 mask_loss: 6.1383 roll_mask_loss: 6.8304 density_loss: 9.0817 unmask_loss: 7.1848 Lr: 0.00151
[2025-12-10 17:12:06,692 INFO misc.py line 117 4140988] Train: [1/10][1389/7400] Data 0.004 (0.004) Batch 0.511 (0.620) Remain 12:30:16 loss: 7.5337 mask_loss: 6.8537 roll_mask_loss: 7.7971 density_loss: 8.9042 unmask_loss: 7.5639 Lr: 0.00151
[2025-12-10 17:12:07,281 INFO misc.py line 117 4140988] Train: [1/10][1390/7400] Data 0.004 (0.004) Batch 0.589 (0.620) Remain 12:30:13 loss: 7.5455 mask_loss: 7.0084 roll_mask_loss: 7.5232 density_loss: 9.0957 unmask_loss: 7.6432 Lr: 0.00151
[2025-12-10 17:12:08,095 INFO misc.py line 117 4140988] Train: [1/10][1391/7400] Data 0.004 (0.004) Batch 0.814 (0.620) Remain 12:30:23 loss: 7.0837 mask_loss: 6.0259 roll_mask_loss: 6.9844 density_loss: 10.1425 unmask_loss: 7.4594 Lr: 0.00151
[2025-12-10 17:12:08,703 INFO misc.py line 117 4140988] Train: [1/10][1392/7400] Data 0.003 (0.004) Batch 0.609 (0.620) Remain 12:30:22 loss: 7.2112 mask_loss: 6.4047 roll_mask_loss: 7.5059 density_loss: 9.0255 unmask_loss: 7.2867 Lr: 0.00152
[2025-12-10 17:12:09,225 INFO misc.py line 117 4140988] Train: [1/10][1393/7400] Data 0.003 (0.004) Batch 0.521 (0.620) Remain 12:30:16 loss: 8.4958 mask_loss: 8.3248 roll_mask_loss: 8.4412 density_loss: 8.4738 unmask_loss: 8.4392 Lr: 0.00152
[2025-12-10 17:12:09,871 INFO misc.py line 117 4140988] Train: [1/10][1394/7400] Data 0.004 (0.004) Batch 0.646 (0.620) Remain 12:30:17 loss: 6.9624 mask_loss: 6.0879 roll_mask_loss: 6.8764 density_loss: 9.9815 unmask_loss: 7.2431 Lr: 0.00152
[2025-12-10 17:12:10,170 INFO misc.py line 117 4140988] Train: [1/10][1395/7400] Data 0.004 (0.004) Batch 0.299 (0.620) Remain 12:29:59 loss: 7.9916 mask_loss: 7.5176 roll_mask_loss: 8.1714 density_loss: 8.8918 unmask_loss: 7.9610 Lr: 0.00152
[2025-12-10 17:12:10,895 INFO misc.py line 117 4140988] Train: [1/10][1396/7400] Data 0.003 (0.004) Batch 0.726 (0.620) Remain 12:30:04 loss: 7.0371 mask_loss: 6.3755 roll_mask_loss: 6.8518 density_loss: 9.3364 unmask_loss: 7.2737 Lr: 0.00152
[2025-12-10 17:12:11,394 INFO misc.py line 117 4140988] Train: [1/10][1397/7400] Data 0.003 (0.004) Batch 0.498 (0.620) Remain 12:29:57 loss: 8.2826 mask_loss: 8.0442 roll_mask_loss: 8.3731 density_loss: 8.2689 unmask_loss: 8.1913 Lr: 0.00152
[2025-12-10 17:12:12,342 INFO misc.py line 117 4140988] Train: [1/10][1398/7400] Data 0.004 (0.004) Batch 0.949 (0.620) Remain 12:30:14 loss: 6.9709 mask_loss: 5.9572 roll_mask_loss: 7.0586 density_loss: 9.8769 unmask_loss: 7.2364 Lr: 0.00152
[2025-12-10 17:12:12,894 INFO misc.py line 117 4140988] Train: [1/10][1399/7400] Data 0.004 (0.004) Batch 0.552 (0.620) Remain 12:30:09 loss: 8.1173 mask_loss: 7.7530 roll_mask_loss: 8.0393 density_loss: 8.1955 unmask_loss: 8.1745 Lr: 0.00153
[2025-12-10 17:12:13,589 INFO misc.py line 117 4140988] Train: [1/10][1400/7400] Data 0.004 (0.004) Batch 0.695 (0.620) Remain 12:30:13 loss: 7.1845 mask_loss: 6.5760 roll_mask_loss: 7.2238 density_loss: 9.4130 unmask_loss: 7.2809 Lr: 0.00153
[2025-12-10 17:12:14,187 INFO misc.py line 117 4140988] Train: [1/10][1401/7400] Data 0.003 (0.004) Batch 0.597 (0.620) Remain 12:30:11 loss: 8.3625 mask_loss: 7.8880 roll_mask_loss: 8.4194 density_loss: 8.5913 unmask_loss: 8.3994 Lr: 0.00153
[2025-12-10 17:12:14,874 INFO misc.py line 117 4140988] Train: [1/10][1402/7400] Data 0.004 (0.004) Batch 0.687 (0.620) Remain 12:30:14 loss: 7.5663 mask_loss: 6.8298 roll_mask_loss: 8.0983 density_loss: 9.2236 unmask_loss: 7.4842 Lr: 0.00153
[2025-12-10 17:12:15,245 INFO misc.py line 117 4140988] Train: [1/10][1403/7400] Data 0.004 (0.004) Batch 0.372 (0.620) Remain 12:30:00 loss: 7.6167 mask_loss: 7.0623 roll_mask_loss: 7.4434 density_loss: 8.3645 unmask_loss: 7.8134 Lr: 0.00153
[2025-12-10 17:12:16,028 INFO misc.py line 117 4140988] Train: [1/10][1404/7400] Data 0.004 (0.004) Batch 0.783 (0.620) Remain 12:30:08 loss: 7.0886 mask_loss: 6.5017 roll_mask_loss: 6.8891 density_loss: 8.7210 unmask_loss: 7.3073 Lr: 0.00153
[2025-12-10 17:12:16,562 INFO misc.py line 117 4140988] Train: [1/10][1405/7400] Data 0.003 (0.004) Batch 0.534 (0.620) Remain 12:30:03 loss: 7.1005 mask_loss: 6.1964 roll_mask_loss: 7.2315 density_loss: 8.5956 unmask_loss: 7.3152 Lr: 0.00153
[2025-12-10 17:12:17,454 INFO misc.py line 117 4140988] Train: [1/10][1406/7400] Data 0.004 (0.004) Batch 0.892 (0.620) Remain 12:30:17 loss: 6.8961 mask_loss: 6.1288 roll_mask_loss: 6.6847 density_loss: 8.7367 unmask_loss: 7.2106 Lr: 0.00154
[2025-12-10 17:12:17,943 INFO misc.py line 117 4140988] Train: [1/10][1407/7400] Data 0.003 (0.004) Batch 0.489 (0.620) Remain 12:30:09 loss: 7.7567 mask_loss: 7.2310 roll_mask_loss: 7.7412 density_loss: 8.8149 unmask_loss: 7.8511 Lr: 0.00154
[2025-12-10 17:12:18,649 INFO misc.py line 117 4140988] Train: [1/10][1408/7400] Data 0.003 (0.004) Batch 0.706 (0.620) Remain 12:30:13 loss: 6.8594 mask_loss: 6.0440 roll_mask_loss: 6.5304 density_loss: 9.2984 unmask_loss: 7.2457 Lr: 0.00154
[2025-12-10 17:12:19,097 INFO misc.py line 117 4140988] Train: [1/10][1409/7400] Data 0.003 (0.004) Batch 0.447 (0.620) Remain 12:30:03 loss: 8.2409 mask_loss: 7.4970 roll_mask_loss: 8.6629 density_loss: 8.5329 unmask_loss: 8.2312 Lr: 0.00154
[2025-12-10 17:12:19,557 INFO misc.py line 117 4140988] Train: [1/10][1410/7400] Data 0.004 (0.004) Batch 0.460 (0.620) Remain 12:29:55 loss: 7.2022 mask_loss: 6.6632 roll_mask_loss: 7.0314 density_loss: 8.5537 unmask_loss: 7.3860 Lr: 0.00154
[2025-12-10 17:12:20,438 INFO misc.py line 117 4140988] Train: [1/10][1411/7400] Data 0.004 (0.004) Batch 0.880 (0.620) Remain 12:30:07 loss: 7.1194 mask_loss: 6.2941 roll_mask_loss: 7.0833 density_loss: 9.1868 unmask_loss: 7.3664 Lr: 0.00154
[2025-12-10 17:12:21,116 INFO misc.py line 117 4140988] Train: [1/10][1412/7400] Data 0.004 (0.004) Batch 0.679 (0.620) Remain 12:30:10 loss: 6.8846 mask_loss: 6.1315 roll_mask_loss: 6.7638 density_loss: 9.2989 unmask_loss: 7.1356 Lr: 0.00154
[2025-12-10 17:12:21,766 INFO misc.py line 117 4140988] Train: [1/10][1413/7400] Data 0.003 (0.004) Batch 0.651 (0.620) Remain 12:30:11 loss: 7.0746 mask_loss: 6.4545 roll_mask_loss: 6.7427 density_loss: 8.5335 unmask_loss: 7.3799 Lr: 0.00155
[2025-12-10 17:12:22,564 INFO misc.py line 117 4140988] Train: [1/10][1414/7400] Data 0.003 (0.004) Batch 0.797 (0.620) Remain 12:30:19 loss: 7.0206 mask_loss: 6.1255 roll_mask_loss: 6.7922 density_loss: 8.2103 unmask_loss: 7.4182 Lr: 0.00155
[2025-12-10 17:12:23,173 INFO misc.py line 117 4140988] Train: [1/10][1415/7400] Data 0.004 (0.004) Batch 0.609 (0.620) Remain 12:30:18 loss: 7.4017 mask_loss: 6.7158 roll_mask_loss: 7.1446 density_loss: 8.9192 unmask_loss: 7.6948 Lr: 0.00155
[2025-12-10 17:12:23,821 INFO misc.py line 117 4140988] Train: [1/10][1416/7400] Data 0.004 (0.004) Batch 0.649 (0.620) Remain 12:30:19 loss: 7.7021 mask_loss: 6.8176 roll_mask_loss: 7.3109 density_loss: 9.1468 unmask_loss: 8.1570 Lr: 0.00155
[2025-12-10 17:12:24,181 INFO misc.py line 117 4140988] Train: [1/10][1417/7400] Data 0.004 (0.004) Batch 0.359 (0.620) Remain 12:30:05 loss: 8.4369 mask_loss: 8.3613 roll_mask_loss: 8.3810 density_loss: 8.3816 unmask_loss: 8.3351 Lr: 0.00155
[2025-12-10 17:12:24,696 INFO misc.py line 117 4140988] Train: [1/10][1418/7400] Data 0.004 (0.004) Batch 0.516 (0.620) Remain 12:29:59 loss: 8.2774 mask_loss: 7.8053 roll_mask_loss: 8.2485 density_loss: 8.4920 unmask_loss: 8.3581 Lr: 0.00155
[2025-12-10 17:12:25,182 INFO misc.py line 117 4140988] Train: [1/10][1419/7400] Data 0.004 (0.004) Batch 0.486 (0.620) Remain 12:29:51 loss: 7.3476 mask_loss: 6.6221 roll_mask_loss: 7.1274 density_loss: 9.0684 unmask_loss: 7.6390 Lr: 0.00155
[2025-12-10 17:12:25,760 INFO misc.py line 117 4140988] Train: [1/10][1420/7400] Data 0.004 (0.004) Batch 0.578 (0.620) Remain 12:29:49 loss: 7.8298 mask_loss: 6.9963 roll_mask_loss: 7.6716 density_loss: 8.7137 unmask_loss: 8.1513 Lr: 0.00156
[2025-12-10 17:12:26,250 INFO misc.py line 117 4140988] Train: [1/10][1421/7400] Data 0.004 (0.004) Batch 0.490 (0.620) Remain 12:29:41 loss: 8.1636 mask_loss: 7.9638 roll_mask_loss: 8.3943 density_loss: 8.3742 unmask_loss: 7.9807 Lr: 0.00156
[2025-12-10 17:12:26,874 INFO misc.py line 117 4140988] Train: [1/10][1422/7400] Data 0.004 (0.004) Batch 0.624 (0.620) Remain 12:29:41 loss: 7.2992 mask_loss: 6.4698 roll_mask_loss: 7.2325 density_loss: 9.4793 unmask_loss: 7.5576 Lr: 0.00156
[2025-12-10 17:12:27,494 INFO misc.py line 117 4140988] Train: [1/10][1423/7400] Data 0.004 (0.004) Batch 0.620 (0.620) Remain 12:29:40 loss: 8.1751 mask_loss: 7.6768 roll_mask_loss: 8.1489 density_loss: 8.6981 unmask_loss: 8.2634 Lr: 0.00156
[2025-12-10 17:12:28,212 INFO misc.py line 117 4140988] Train: [1/10][1424/7400] Data 0.004 (0.004) Batch 0.718 (0.620) Remain 12:29:45 loss: 7.0562 mask_loss: 6.3124 roll_mask_loss: 7.1155 density_loss: 9.1712 unmask_loss: 7.2151 Lr: 0.00156
[2025-12-10 17:12:28,896 INFO misc.py line 117 4140988] Train: [1/10][1425/7400] Data 0.004 (0.004) Batch 0.684 (0.620) Remain 12:29:47 loss: 7.0922 mask_loss: 6.2711 roll_mask_loss: 6.8878 density_loss: 8.3159 unmask_loss: 7.4387 Lr: 0.00156
[2025-12-10 17:12:29,567 INFO misc.py line 117 4140988] Train: [1/10][1426/7400] Data 0.004 (0.004) Batch 0.671 (0.620) Remain 12:29:49 loss: 7.0095 mask_loss: 6.0651 roll_mask_loss: 6.7502 density_loss: 9.2930 unmask_loss: 7.4254 Lr: 0.00156
[2025-12-10 17:12:30,236 INFO misc.py line 117 4140988] Train: [1/10][1427/7400] Data 0.003 (0.004) Batch 0.670 (0.620) Remain 12:29:51 loss: 7.2439 mask_loss: 6.3990 roll_mask_loss: 7.2697 density_loss: 9.0426 unmask_loss: 7.4726 Lr: 0.00157
[2025-12-10 17:12:31,099 INFO misc.py line 117 4140988] Train: [1/10][1428/7400] Data 0.003 (0.004) Batch 0.863 (0.620) Remain 12:30:03 loss: 7.1485 mask_loss: 6.0727 roll_mask_loss: 6.8331 density_loss: 10.1656 unmask_loss: 7.6408 Lr: 0.00157
[2025-12-10 17:12:31,646 INFO misc.py line 117 4140988] Train: [1/10][1429/7400] Data 0.003 (0.004) Batch 0.547 (0.620) Remain 12:29:59 loss: 8.3745 mask_loss: 8.2225 roll_mask_loss: 8.2423 density_loss: 8.3478 unmask_loss: 8.3496 Lr: 0.00157
[2025-12-10 17:12:32,265 INFO misc.py line 117 4140988] Train: [1/10][1430/7400] Data 0.003 (0.004) Batch 0.619 (0.620) Remain 12:29:58 loss: 6.9257 mask_loss: 5.8539 roll_mask_loss: 6.8894 density_loss: 10.3380 unmask_loss: 7.2730 Lr: 0.00157
[2025-12-10 17:12:32,744 INFO misc.py line 117 4140988] Train: [1/10][1431/7400] Data 0.004 (0.004) Batch 0.479 (0.620) Remain 12:29:50 loss: 8.2032 mask_loss: 7.8777 roll_mask_loss: 8.0999 density_loss: 8.4201 unmask_loss: 8.2492 Lr: 0.00157
[2025-12-10 17:12:33,359 INFO misc.py line 117 4140988] Train: [1/10][1432/7400] Data 0.003 (0.004) Batch 0.616 (0.620) Remain 12:29:49 loss: 8.1361 mask_loss: 7.7004 roll_mask_loss: 8.2030 density_loss: 8.5954 unmask_loss: 8.1487 Lr: 0.00157
[2025-12-10 17:12:34,081 INFO misc.py line 117 4140988] Train: [1/10][1433/7400] Data 0.003 (0.004) Batch 0.721 (0.620) Remain 12:29:54 loss: 7.2502 mask_loss: 6.2221 roll_mask_loss: 7.3731 density_loss: 9.5061 unmask_loss: 7.5127 Lr: 0.00157
[2025-12-10 17:12:34,616 INFO misc.py line 117 4140988] Train: [1/10][1434/7400] Data 0.003 (0.004) Batch 0.535 (0.620) Remain 12:29:49 loss: 7.6124 mask_loss: 6.9359 roll_mask_loss: 7.5970 density_loss: 9.2057 unmask_loss: 7.7742 Lr: 0.00158
[2025-12-10 17:12:35,275 INFO misc.py line 117 4140988] Train: [1/10][1435/7400] Data 0.003 (0.004) Batch 0.658 (0.620) Remain 12:29:50 loss: 6.9710 mask_loss: 6.1401 roll_mask_loss: 6.7933 density_loss: 9.1403 unmask_loss: 7.2925 Lr: 0.00158
[2025-12-10 17:12:35,787 INFO misc.py line 117 4140988] Train: [1/10][1436/7400] Data 0.003 (0.004) Batch 0.513 (0.620) Remain 12:29:44 loss: 8.0569 mask_loss: 7.7301 roll_mask_loss: 8.0381 density_loss: 8.7056 unmask_loss: 8.0555 Lr: 0.00158
[2025-12-10 17:12:36,432 INFO misc.py line 117 4140988] Train: [1/10][1437/7400] Data 0.003 (0.004) Batch 0.644 (0.620) Remain 12:29:45 loss: 8.3975 mask_loss: 8.1745 roll_mask_loss: 8.3969 density_loss: 8.4716 unmask_loss: 8.3399 Lr: 0.00158
[2025-12-10 17:12:36,952 INFO misc.py line 117 4140988] Train: [1/10][1438/7400] Data 0.004 (0.004) Batch 0.520 (0.620) Remain 12:29:39 loss: 7.1605 mask_loss: 6.4767 roll_mask_loss: 7.0925 density_loss: 8.9401 unmask_loss: 7.3576 Lr: 0.00158
[2025-12-10 17:12:37,483 INFO misc.py line 117 4140988] Train: [1/10][1439/7400] Data 0.004 (0.004) Batch 0.532 (0.620) Remain 12:29:34 loss: 8.4199 mask_loss: 8.3264 roll_mask_loss: 8.3519 density_loss: 8.3471 unmask_loss: 8.3337 Lr: 0.00158
[2025-12-10 17:12:38,072 INFO misc.py line 117 4140988] Train: [1/10][1440/7400] Data 0.004 (0.004) Batch 0.589 (0.620) Remain 12:29:32 loss: 8.2102 mask_loss: 8.0210 roll_mask_loss: 8.1654 density_loss: 8.5156 unmask_loss: 8.1569 Lr: 0.00158
[2025-12-10 17:12:38,778 INFO misc.py line 117 4140988] Train: [1/10][1441/7400] Data 0.004 (0.004) Batch 0.706 (0.620) Remain 12:29:36 loss: 7.0135 mask_loss: 6.0869 roll_mask_loss: 6.7673 density_loss: 9.5025 unmask_loss: 7.4098 Lr: 0.00159
[2025-12-10 17:12:39,473 INFO misc.py line 117 4140988] Train: [1/10][1442/7400] Data 0.004 (0.004) Batch 0.695 (0.620) Remain 12:29:39 loss: 7.2027 mask_loss: 6.5076 roll_mask_loss: 7.0661 density_loss: 9.5672 unmask_loss: 7.4273 Lr: 0.00159
[2025-12-10 17:12:40,075 INFO misc.py line 117 4140988] Train: [1/10][1443/7400] Data 0.004 (0.004) Batch 0.602 (0.620) Remain 12:29:37 loss: 7.4022 mask_loss: 6.8311 roll_mask_loss: 7.0323 density_loss: 8.4722 unmask_loss: 7.7032 Lr: 0.00159
[2025-12-10 17:12:40,741 INFO misc.py line 117 4140988] Train: [1/10][1444/7400] Data 0.004 (0.004) Batch 0.666 (0.620) Remain 12:29:39 loss: 7.0940 mask_loss: 6.3348 roll_mask_loss: 6.8499 density_loss: 8.4883 unmask_loss: 7.4259 Lr: 0.00159
[2025-12-10 17:12:41,356 INFO misc.py line 117 4140988] Train: [1/10][1445/7400] Data 0.003 (0.004) Batch 0.614 (0.620) Remain 12:29:38 loss: 7.1095 mask_loss: 6.4713 roll_mask_loss: 6.9514 density_loss: 9.1327 unmask_loss: 7.3251 Lr: 0.00159
[2025-12-10 17:12:41,950 INFO misc.py line 117 4140988] Train: [1/10][1446/7400] Data 0.004 (0.004) Batch 0.594 (0.620) Remain 12:29:36 loss: 7.3616 mask_loss: 6.6140 roll_mask_loss: 7.2546 density_loss: 8.9738 unmask_loss: 7.6094 Lr: 0.00159
[2025-12-10 17:12:42,717 INFO misc.py line 117 4140988] Train: [1/10][1447/7400] Data 0.004 (0.004) Batch 0.767 (0.620) Remain 12:29:43 loss: 7.0475 mask_loss: 6.2257 roll_mask_loss: 6.9635 density_loss: 8.9904 unmask_loss: 7.3207 Lr: 0.00159
[2025-12-10 17:12:43,320 INFO misc.py line 117 4140988] Train: [1/10][1448/7400] Data 0.003 (0.004) Batch 0.604 (0.620) Remain 12:29:41 loss: 6.9481 mask_loss: 6.0586 roll_mask_loss: 6.7617 density_loss: 9.7740 unmask_loss: 7.2905 Lr: 0.00160
[2025-12-10 17:12:43,855 INFO misc.py line 117 4140988] Train: [1/10][1449/7400] Data 0.003 (0.004) Batch 0.535 (0.620) Remain 12:29:37 loss: 6.9947 mask_loss: 6.1394 roll_mask_loss: 6.9131 density_loss: 9.9224 unmask_loss: 7.2647 Lr: 0.00160
[2025-12-10 17:12:44,480 INFO misc.py line 117 4140988] Train: [1/10][1450/7400] Data 0.004 (0.004) Batch 0.626 (0.620) Remain 12:29:36 loss: 7.2031 mask_loss: 6.3793 roll_mask_loss: 7.2867 density_loss: 9.3935 unmask_loss: 7.3854 Lr: 0.00160
[2025-12-10 17:12:44,978 INFO misc.py line 117 4140988] Train: [1/10][1451/7400] Data 0.003 (0.004) Batch 0.497 (0.620) Remain 12:29:29 loss: 7.3973 mask_loss: 6.7250 roll_mask_loss: 7.3119 density_loss: 8.5671 unmask_loss: 7.6049 Lr: 0.00160
[2025-12-10 17:12:45,290 INFO misc.py line 117 4140988] Train: [1/10][1452/7400] Data 0.004 (0.004) Batch 0.312 (0.620) Remain 12:29:13 loss: 6.9428 mask_loss: 6.2785 roll_mask_loss: 6.8216 density_loss: 10.1210 unmask_loss: 7.1331 Lr: 0.00160
[2025-12-10 17:12:45,910 INFO misc.py line 117 4140988] Train: [1/10][1453/7400] Data 0.003 (0.004) Batch 0.620 (0.620) Remain 12:29:13 loss: 7.9666 mask_loss: 7.5760 roll_mask_loss: 8.0430 density_loss: 9.0062 unmask_loss: 7.9435 Lr: 0.00160
[2025-12-10 17:12:46,468 INFO misc.py line 117 4140988] Train: [1/10][1454/7400] Data 0.004 (0.004) Batch 0.558 (0.620) Remain 12:29:09 loss: 8.1093 mask_loss: 7.5222 roll_mask_loss: 8.0005 density_loss: 8.5837 unmask_loss: 8.2857 Lr: 0.00160
[2025-12-10 17:12:47,175 INFO misc.py line 117 4140988] Train: [1/10][1455/7400] Data 0.004 (0.004) Batch 0.708 (0.620) Remain 12:29:13 loss: 7.1681 mask_loss: 6.4501 roll_mask_loss: 7.2846 density_loss: 9.9161 unmask_loss: 7.2705 Lr: 0.00161
[2025-12-10 17:12:47,484 INFO misc.py line 117 4140988] Train: [1/10][1456/7400] Data 0.004 (0.004) Batch 0.309 (0.619) Remain 12:28:57 loss: 7.1916 mask_loss: 6.4046 roll_mask_loss: 7.3532 density_loss: 10.1469 unmask_loss: 7.3014 Lr: 0.00161
[2025-12-10 17:12:48,126 INFO misc.py line 117 4140988] Train: [1/10][1457/7400] Data 0.004 (0.004) Batch 0.642 (0.619) Remain 12:28:57 loss: 7.0867 mask_loss: 6.3021 roll_mask_loss: 6.8394 density_loss: 9.2316 unmask_loss: 7.4180 Lr: 0.00161
[2025-12-10 17:12:48,863 INFO misc.py line 117 4140988] Train: [1/10][1458/7400] Data 0.004 (0.004) Batch 0.737 (0.620) Remain 12:29:03 loss: 7.1539 mask_loss: 6.2791 roll_mask_loss: 7.3188 density_loss: 8.9903 unmask_loss: 7.3290 Lr: 0.00161
[2025-12-10 17:12:49,414 INFO misc.py line 117 4140988] Train: [1/10][1459/7400] Data 0.004 (0.004) Batch 0.551 (0.619) Remain 12:28:58 loss: 8.3342 mask_loss: 7.9214 roll_mask_loss: 8.4863 density_loss: 8.5034 unmask_loss: 8.2946 Lr: 0.00161
[2025-12-10 17:12:50,084 INFO misc.py line 117 4140988] Train: [1/10][1460/7400] Data 0.004 (0.004) Batch 0.670 (0.620) Remain 12:29:00 loss: 6.8169 mask_loss: 6.1307 roll_mask_loss: 6.6140 density_loss: 9.3751 unmask_loss: 7.0739 Lr: 0.00161
[2025-12-10 17:12:50,399 INFO misc.py line 117 4140988] Train: [1/10][1461/7400] Data 0.003 (0.004) Batch 0.315 (0.619) Remain 12:28:45 loss: 7.5400 mask_loss: 6.7932 roll_mask_loss: 7.4486 density_loss: 8.6005 unmask_loss: 7.7871 Lr: 0.00161
[2025-12-10 17:12:50,978 INFO misc.py line 117 4140988] Train: [1/10][1462/7400] Data 0.004 (0.004) Batch 0.579 (0.619) Remain 12:28:42 loss: 8.4324 mask_loss: 8.1905 roll_mask_loss: 8.4340 density_loss: 8.3855 unmask_loss: 8.3848 Lr: 0.00162
[2025-12-10 17:12:51,705 INFO misc.py line 117 4140988] Train: [1/10][1463/7400] Data 0.004 (0.004) Batch 0.727 (0.619) Remain 12:28:47 loss: 7.2337 mask_loss: 6.0970 roll_mask_loss: 7.1756 density_loss: 9.5981 unmask_loss: 7.6391 Lr: 0.00162
[2025-12-10 17:12:52,242 INFO misc.py line 117 4140988] Train: [1/10][1464/7400] Data 0.004 (0.004) Batch 0.537 (0.619) Remain 12:28:42 loss: 7.2440 mask_loss: 6.6308 roll_mask_loss: 7.2929 density_loss: 8.4061 unmask_loss: 7.3579 Lr: 0.00162
[2025-12-10 17:12:52,805 INFO misc.py line 117 4140988] Train: [1/10][1465/7400] Data 0.003 (0.004) Batch 0.563 (0.619) Remain 12:28:39 loss: 7.8218 mask_loss: 7.2994 roll_mask_loss: 8.4741 density_loss: 8.3500 unmask_loss: 7.5899 Lr: 0.00162
[2025-12-10 17:12:53,402 INFO misc.py line 117 4140988] Train: [1/10][1466/7400] Data 0.003 (0.004) Batch 0.597 (0.619) Remain 12:28:37 loss: 7.1875 mask_loss: 6.3891 roll_mask_loss: 7.1887 density_loss: 8.8999 unmask_loss: 7.4081 Lr: 0.00162
[2025-12-10 17:12:53,697 INFO misc.py line 117 4140988] Train: [1/10][1467/7400] Data 0.003 (0.004) Batch 0.294 (0.619) Remain 12:28:20 loss: 8.4201 mask_loss: 8.3273 roll_mask_loss: 8.3325 density_loss: 8.3323 unmask_loss: 8.3436 Lr: 0.00162
[2025-12-10 17:12:54,426 INFO misc.py line 117 4140988] Train: [1/10][1468/7400] Data 0.004 (0.004) Batch 0.729 (0.619) Remain 12:28:25 loss: 7.4754 mask_loss: 6.9987 roll_mask_loss: 7.3976 density_loss: 8.8588 unmask_loss: 7.5755 Lr: 0.00162
[2025-12-10 17:12:55,258 INFO misc.py line 117 4140988] Train: [1/10][1469/7400] Data 0.004 (0.004) Batch 0.832 (0.619) Remain 12:28:35 loss: 7.3518 mask_loss: 6.6679 roll_mask_loss: 7.1025 density_loss: 8.9366 unmask_loss: 7.6396 Lr: 0.00163
[2025-12-10 17:12:55,828 INFO misc.py line 117 4140988] Train: [1/10][1470/7400] Data 0.004 (0.004) Batch 0.570 (0.619) Remain 12:28:32 loss: 7.4699 mask_loss: 6.7389 roll_mask_loss: 7.8079 density_loss: 9.3966 unmask_loss: 7.4785 Lr: 0.00163
[2025-12-10 17:12:56,462 INFO misc.py line 117 4140988] Train: [1/10][1471/7400] Data 0.004 (0.004) Batch 0.634 (0.619) Remain 12:28:32 loss: 7.0800 mask_loss: 6.2734 roll_mask_loss: 7.0497 density_loss: 9.6252 unmask_loss: 7.3060 Lr: 0.00163
[2025-12-10 17:12:57,132 INFO misc.py line 117 4140988] Train: [1/10][1472/7400] Data 0.004 (0.004) Batch 0.670 (0.619) Remain 12:28:34 loss: 7.4128 mask_loss: 6.6325 roll_mask_loss: 7.3016 density_loss: 8.9149 unmask_loss: 7.6802 Lr: 0.00163
[2025-12-10 17:12:57,689 INFO misc.py line 117 4140988] Train: [1/10][1473/7400] Data 0.003 (0.004) Batch 0.557 (0.619) Remain 12:28:30 loss: 8.5104 mask_loss: 8.3275 roll_mask_loss: 8.3565 density_loss: 8.3601 unmask_loss: 8.5117 Lr: 0.00163
[2025-12-10 17:12:58,006 INFO misc.py line 117 4140988] Train: [1/10][1474/7400] Data 0.004 (0.004) Batch 0.317 (0.619) Remain 12:28:15 loss: 7.0580 mask_loss: 6.0551 roll_mask_loss: 6.8757 density_loss: 8.8589 unmask_loss: 7.4734 Lr: 0.00163
[2025-12-10 17:12:58,691 INFO misc.py line 117 4140988] Train: [1/10][1475/7400] Data 0.004 (0.004) Batch 0.685 (0.619) Remain 12:28:17 loss: 8.0737 mask_loss: 7.6361 roll_mask_loss: 7.9316 density_loss: 8.6492 unmask_loss: 8.1906 Lr: 0.00163
[2025-12-10 17:12:58,977 INFO misc.py line 117 4140988] Train: [1/10][1476/7400] Data 0.004 (0.004) Batch 0.286 (0.619) Remain 12:28:00 loss: 8.3254 mask_loss: 8.0589 roll_mask_loss: 8.3426 density_loss: 8.2787 unmask_loss: 8.2844 Lr: 0.00164
[2025-12-10 17:12:59,692 INFO misc.py line 117 4140988] Train: [1/10][1477/7400] Data 0.004 (0.004) Batch 0.715 (0.619) Remain 12:28:04 loss: 7.0851 mask_loss: 6.2271 roll_mask_loss: 6.9634 density_loss: 9.7394 unmask_loss: 7.3802 Lr: 0.00164
[2025-12-10 17:13:00,284 INFO misc.py line 117 4140988] Train: [1/10][1478/7400] Data 0.004 (0.004) Batch 0.592 (0.619) Remain 12:28:02 loss: 7.4236 mask_loss: 6.7392 roll_mask_loss: 7.2318 density_loss: 8.9479 unmask_loss: 7.6827 Lr: 0.00164
[2025-12-10 17:13:00,794 INFO misc.py line 117 4140988] Train: [1/10][1479/7400] Data 0.004 (0.004) Batch 0.511 (0.619) Remain 12:27:56 loss: 7.6635 mask_loss: 6.8657 roll_mask_loss: 7.1948 density_loss: 8.4478 unmask_loss: 8.1278 Lr: 0.00164
[2025-12-10 17:13:01,466 INFO misc.py line 117 4140988] Train: [1/10][1480/7400] Data 0.004 (0.004) Batch 0.671 (0.619) Remain 12:27:58 loss: 7.1942 mask_loss: 6.6520 roll_mask_loss: 6.9956 density_loss: 8.8669 unmask_loss: 7.3873 Lr: 0.00164
[2025-12-10 17:13:02,121 INFO misc.py line 117 4140988] Train: [1/10][1481/7400] Data 0.004 (0.004) Batch 0.655 (0.619) Remain 12:28:00 loss: 6.9409 mask_loss: 6.1344 roll_mask_loss: 6.7462 density_loss: 9.3559 unmask_loss: 7.2544 Lr: 0.00164
[2025-12-10 17:13:02,710 INFO misc.py line 117 4140988] Train: [1/10][1482/7400] Data 0.004 (0.004) Batch 0.589 (0.619) Remain 12:27:58 loss: 7.1032 mask_loss: 6.4191 roll_mask_loss: 7.0882 density_loss: 8.8860 unmask_loss: 7.2751 Lr: 0.00164
[2025-12-10 17:13:03,577 INFO misc.py line 117 4140988] Train: [1/10][1483/7400] Data 0.004 (0.004) Batch 0.867 (0.619) Remain 12:28:09 loss: 6.9981 mask_loss: 6.2899 roll_mask_loss: 6.9116 density_loss: 8.7608 unmask_loss: 7.2202 Lr: 0.00165
[2025-12-10 17:13:04,022 INFO misc.py line 117 4140988] Train: [1/10][1484/7400] Data 0.004 (0.004) Batch 0.445 (0.619) Remain 12:28:00 loss: 7.0690 mask_loss: 6.3744 roll_mask_loss: 6.9964 density_loss: 9.2925 unmask_loss: 7.2668 Lr: 0.00165
[2025-12-10 17:13:04,546 INFO misc.py line 117 4140988] Train: [1/10][1485/7400] Data 0.004 (0.004) Batch 0.524 (0.619) Remain 12:27:55 loss: 7.7808 mask_loss: 6.9427 roll_mask_loss: 7.6323 density_loss: 8.7367 unmask_loss: 8.0993 Lr: 0.00165
[2025-12-10 17:13:05,139 INFO misc.py line 117 4140988] Train: [1/10][1486/7400] Data 0.004 (0.004) Batch 0.593 (0.619) Remain 12:27:53 loss: 7.7928 mask_loss: 7.1188 roll_mask_loss: 8.1377 density_loss: 8.9898 unmask_loss: 7.7776 Lr: 0.00165
[2025-12-10 17:13:05,680 INFO misc.py line 117 4140988] Train: [1/10][1487/7400] Data 0.004 (0.004) Batch 0.542 (0.619) Remain 12:27:48 loss: 7.3950 mask_loss: 6.9514 roll_mask_loss: 7.2953 density_loss: 9.1057 unmask_loss: 7.4846 Lr: 0.00165
[2025-12-10 17:13:06,498 INFO misc.py line 117 4140988] Train: [1/10][1488/7400] Data 0.003 (0.004) Batch 0.818 (0.619) Remain 12:27:58 loss: 7.0430 mask_loss: 6.2355 roll_mask_loss: 7.1072 density_loss: 9.3400 unmask_loss: 7.2279 Lr: 0.00165
[2025-12-10 17:13:07,120 INFO misc.py line 117 4140988] Train: [1/10][1489/7400] Data 0.003 (0.004) Batch 0.621 (0.619) Remain 12:27:57 loss: 7.2255 mask_loss: 6.6926 roll_mask_loss: 7.1121 density_loss: 8.7483 unmask_loss: 7.3737 Lr: 0.00165
[2025-12-10 17:13:07,712 INFO misc.py line 117 4140988] Train: [1/10][1490/7400] Data 0.004 (0.004) Batch 0.592 (0.619) Remain 12:27:55 loss: 6.8885 mask_loss: 5.9062 roll_mask_loss: 6.8306 density_loss: 9.5086 unmask_loss: 7.2184 Lr: 0.00166
[2025-12-10 17:13:08,369 INFO misc.py line 117 4140988] Train: [1/10][1491/7400] Data 0.004 (0.004) Batch 0.657 (0.619) Remain 12:27:56 loss: 7.0308 mask_loss: 6.2877 roll_mask_loss: 6.9022 density_loss: 9.2265 unmask_loss: 7.2821 Lr: 0.00166
[2025-12-10 17:13:08,847 INFO misc.py line 117 4140988] Train: [1/10][1492/7400] Data 0.004 (0.004) Batch 0.478 (0.619) Remain 12:27:49 loss: 7.2305 mask_loss: 6.4255 roll_mask_loss: 7.0008 density_loss: 9.6299 unmask_loss: 7.5552 Lr: 0.00166
[2025-12-10 17:13:09,485 INFO misc.py line 117 4140988] Train: [1/10][1493/7400] Data 0.004 (0.004) Batch 0.638 (0.619) Remain 12:27:49 loss: 7.3147 mask_loss: 6.5356 roll_mask_loss: 7.4192 density_loss: 8.7920 unmask_loss: 7.4761 Lr: 0.00166
[2025-12-10 17:13:10,013 INFO misc.py line 117 4140988] Train: [1/10][1494/7400] Data 0.004 (0.004) Batch 0.528 (0.619) Remain 12:27:44 loss: 7.2373 mask_loss: 6.5739 roll_mask_loss: 7.0427 density_loss: 8.5643 unmask_loss: 7.4951 Lr: 0.00166
[2025-12-10 17:13:10,840 INFO misc.py line 117 4140988] Train: [1/10][1495/7400] Data 0.004 (0.004) Batch 0.827 (0.619) Remain 12:27:54 loss: 7.3483 mask_loss: 6.6023 roll_mask_loss: 7.2977 density_loss: 8.7718 unmask_loss: 7.5711 Lr: 0.00166
[2025-12-10 17:13:11,367 INFO misc.py line 117 4140988] Train: [1/10][1496/7400] Data 0.004 (0.004) Batch 0.528 (0.619) Remain 12:27:49 loss: 8.5867 mask_loss: 8.5129 roll_mask_loss: 8.5631 density_loss: 8.5580 unmask_loss: 8.4643 Lr: 0.00166
[2025-12-10 17:13:11,996 INFO misc.py line 117 4140988] Train: [1/10][1497/7400] Data 0.004 (0.004) Batch 0.628 (0.619) Remain 12:27:48 loss: 7.7529 mask_loss: 7.2204 roll_mask_loss: 7.6777 density_loss: 9.0503 unmask_loss: 7.8757 Lr: 0.00167
[2025-12-10 17:13:12,648 INFO misc.py line 117 4140988] Train: [1/10][1498/7400] Data 0.004 (0.004) Batch 0.653 (0.619) Remain 12:27:49 loss: 7.0460 mask_loss: 6.3076 roll_mask_loss: 6.8469 density_loss: 8.8361 unmask_loss: 7.3380 Lr: 0.00167
[2025-12-10 17:13:13,260 INFO misc.py line 117 4140988] Train: [1/10][1499/7400] Data 0.004 (0.004) Batch 0.612 (0.619) Remain 12:27:48 loss: 7.1896 mask_loss: 6.4428 roll_mask_loss: 7.0404 density_loss: 9.2261 unmask_loss: 7.4531 Lr: 0.00167
[2025-12-10 17:13:13,869 INFO misc.py line 117 4140988] Train: [1/10][1500/7400] Data 0.004 (0.004) Batch 0.608 (0.619) Remain 12:27:47 loss: 7.0934 mask_loss: 6.5393 roll_mask_loss: 6.8211 density_loss: 9.6627 unmask_loss: 7.3133 Lr: 0.00167
[2025-12-10 17:13:14,347 INFO misc.py line 117 4140988] Train: [1/10][1501/7400] Data 0.004 (0.004) Batch 0.478 (0.619) Remain 12:27:40 loss: 8.4621 mask_loss: 7.7768 roll_mask_loss: 8.8977 density_loss: 8.4507 unmask_loss: 8.4179 Lr: 0.00167
[2025-12-10 17:13:14,964 INFO misc.py line 117 4140988] Train: [1/10][1502/7400] Data 0.004 (0.004) Batch 0.618 (0.619) Remain 12:27:39 loss: 7.1008 mask_loss: 6.1869 roll_mask_loss: 7.3718 density_loss: 9.1195 unmask_loss: 7.2398 Lr: 0.00167
[2025-12-10 17:13:15,621 INFO misc.py line 117 4140988] Train: [1/10][1503/7400] Data 0.004 (0.004) Batch 0.657 (0.619) Remain 12:27:40 loss: 6.9177 mask_loss: 6.1464 roll_mask_loss: 6.8471 density_loss: 8.8537 unmask_loss: 7.1616 Lr: 0.00167
[2025-12-10 17:13:16,006 INFO misc.py line 117 4140988] Train: [1/10][1504/7400] Data 0.003 (0.004) Batch 0.386 (0.619) Remain 12:27:29 loss: 7.2857 mask_loss: 6.7749 roll_mask_loss: 7.1386 density_loss: 8.8475 unmask_loss: 7.4377 Lr: 0.00168
[2025-12-10 17:13:16,783 INFO misc.py line 117 4140988] Train: [1/10][1505/7400] Data 0.003 (0.004) Batch 0.776 (0.619) Remain 12:27:36 loss: 6.9888 mask_loss: 6.1175 roll_mask_loss: 6.9835 density_loss: 9.6007 unmask_loss: 7.2350 Lr: 0.00168
[2025-12-10 17:13:17,496 INFO misc.py line 117 4140988] Train: [1/10][1506/7400] Data 0.004 (0.004) Batch 0.713 (0.619) Remain 12:27:39 loss: 6.9978 mask_loss: 6.2362 roll_mask_loss: 6.9337 density_loss: 8.6478 unmask_loss: 7.2376 Lr: 0.00168
[2025-12-10 17:13:18,154 INFO misc.py line 117 4140988] Train: [1/10][1507/7400] Data 0.003 (0.004) Batch 0.658 (0.619) Remain 12:27:41 loss: 7.0492 mask_loss: 6.3641 roll_mask_loss: 6.9725 density_loss: 9.4647 unmask_loss: 7.2408 Lr: 0.00168
[2025-12-10 17:13:18,474 INFO misc.py line 117 4140988] Train: [1/10][1508/7400] Data 0.003 (0.004) Batch 0.321 (0.619) Remain 12:27:26 loss: 6.9930 mask_loss: 5.8981 roll_mask_loss: 6.8591 density_loss: 8.2737 unmask_loss: 7.4419 Lr: 0.00168
[2025-12-10 17:13:19,073 INFO misc.py line 117 4140988] Train: [1/10][1509/7400] Data 0.003 (0.004) Batch 0.597 (0.619) Remain 12:27:24 loss: 7.3390 mask_loss: 6.5218 roll_mask_loss: 7.2743 density_loss: 8.9778 unmask_loss: 7.6004 Lr: 0.00168
[2025-12-10 17:13:19,647 INFO misc.py line 117 4140988] Train: [1/10][1510/7400] Data 0.004 (0.004) Batch 0.574 (0.619) Remain 12:27:21 loss: 7.2901 mask_loss: 6.6488 roll_mask_loss: 7.2189 density_loss: 9.8956 unmask_loss: 7.4483 Lr: 0.00169
[2025-12-10 17:13:20,447 INFO misc.py line 117 4140988] Train: [1/10][1511/7400] Data 0.004 (0.004) Batch 0.801 (0.619) Remain 12:27:30 loss: 7.1931 mask_loss: 6.3446 roll_mask_loss: 7.0453 density_loss: 9.2589 unmask_loss: 7.5060 Lr: 0.00169
[2025-12-10 17:13:20,918 INFO misc.py line 117 4140988] Train: [1/10][1512/7400] Data 0.003 (0.004) Batch 0.471 (0.619) Remain 12:27:22 loss: 8.3728 mask_loss: 8.0389 roll_mask_loss: 8.4437 density_loss: 8.4702 unmask_loss: 8.3350 Lr: 0.00169
[2025-12-10 17:13:21,629 INFO misc.py line 117 4140988] Train: [1/10][1513/7400] Data 0.003 (0.004) Batch 0.711 (0.619) Remain 12:27:26 loss: 7.0100 mask_loss: 6.3029 roll_mask_loss: 6.9267 density_loss: 8.6962 unmask_loss: 7.2313 Lr: 0.00169
[2025-12-10 17:13:22,234 INFO misc.py line 117 4140988] Train: [1/10][1514/7400] Data 0.004 (0.004) Batch 0.604 (0.619) Remain 12:27:24 loss: 6.9461 mask_loss: 6.1304 roll_mask_loss: 6.7526 density_loss: 8.9602 unmask_loss: 7.2716 Lr: 0.00169
[2025-12-10 17:13:23,002 INFO misc.py line 117 4140988] Train: [1/10][1515/7400] Data 0.004 (0.004) Batch 0.769 (0.619) Remain 12:27:31 loss: 6.9309 mask_loss: 5.7872 roll_mask_loss: 6.6732 density_loss: 9.9125 unmask_loss: 7.4333 Lr: 0.00169
[2025-12-10 17:13:23,664 INFO misc.py line 117 4140988] Train: [1/10][1516/7400] Data 0.004 (0.004) Batch 0.661 (0.619) Remain 12:27:32 loss: 6.9689 mask_loss: 6.1292 roll_mask_loss: 6.7881 density_loss: 8.7952 unmask_loss: 7.3032 Lr: 0.00169
[2025-12-10 17:13:24,407 INFO misc.py line 117 4140988] Train: [1/10][1517/7400] Data 0.004 (0.004) Batch 0.744 (0.619) Remain 12:27:38 loss: 6.6858 mask_loss: 5.7934 roll_mask_loss: 6.3998 density_loss: 8.4915 unmask_loss: 7.1052 Lr: 0.00170
[2025-12-10 17:13:24,935 INFO misc.py line 117 4140988] Train: [1/10][1518/7400] Data 0.004 (0.004) Batch 0.528 (0.619) Remain 12:27:33 loss: 6.7742 mask_loss: 5.9740 roll_mask_loss: 6.4685 density_loss: 8.5832 unmask_loss: 7.1554 Lr: 0.00170
[2025-12-10 17:13:25,472 INFO misc.py line 117 4140988] Train: [1/10][1519/7400] Data 0.003 (0.004) Batch 0.537 (0.619) Remain 12:27:28 loss: 7.4594 mask_loss: 7.1635 roll_mask_loss: 7.3402 density_loss: 8.9887 unmask_loss: 7.4872 Lr: 0.00170
[2025-12-10 17:13:25,992 INFO misc.py line 117 4140988] Train: [1/10][1520/7400] Data 0.003 (0.004) Batch 0.520 (0.619) Remain 12:27:23 loss: 7.8023 mask_loss: 7.0757 roll_mask_loss: 7.9129 density_loss: 8.0772 unmask_loss: 7.9487 Lr: 0.00170
[2025-12-10 17:13:26,568 INFO misc.py line 117 4140988] Train: [1/10][1521/7400] Data 0.003 (0.004) Batch 0.576 (0.619) Remain 12:27:20 loss: 7.0984 mask_loss: 6.3991 roll_mask_loss: 7.0025 density_loss: 9.6813 unmask_loss: 7.3023 Lr: 0.00170
[2025-12-10 17:13:27,008 INFO misc.py line 117 4140988] Train: [1/10][1522/7400] Data 0.004 (0.004) Batch 0.440 (0.619) Remain 12:27:11 loss: 8.3587 mask_loss: 8.1565 roll_mask_loss: 8.3248 density_loss: 8.3649 unmask_loss: 8.3094 Lr: 0.00170
[2025-12-10 17:13:27,544 INFO misc.py line 117 4140988] Train: [1/10][1523/7400] Data 0.004 (0.004) Batch 0.536 (0.618) Remain 12:27:06 loss: 7.3441 mask_loss: 6.5947 roll_mask_loss: 7.2475 density_loss: 8.4991 unmask_loss: 7.5971 Lr: 0.00170
[2025-12-10 17:13:28,234 INFO misc.py line 117 4140988] Train: [1/10][1524/7400] Data 0.003 (0.004) Batch 0.690 (0.619) Remain 12:27:09 loss: 7.1213 mask_loss: 6.1341 roll_mask_loss: 6.9352 density_loss: 9.6169 unmask_loss: 7.5157 Lr: 0.00171
[2025-12-10 17:13:28,785 INFO misc.py line 117 4140988] Train: [1/10][1525/7400] Data 0.003 (0.004) Batch 0.550 (0.619) Remain 12:27:05 loss: 7.5533 mask_loss: 6.6687 roll_mask_loss: 7.6734 density_loss: 9.2472 unmask_loss: 7.7506 Lr: 0.00171
[2025-12-10 17:13:29,441 INFO misc.py line 117 4140988] Train: [1/10][1526/7400] Data 0.004 (0.004) Batch 0.656 (0.619) Remain 12:27:07 loss: 8.0651 mask_loss: 7.5914 roll_mask_loss: 8.4298 density_loss: 8.9439 unmask_loss: 7.9407 Lr: 0.00171
[2025-12-10 17:13:30,132 INFO misc.py line 117 4140988] Train: [1/10][1527/7400] Data 0.004 (0.004) Batch 0.691 (0.619) Remain 12:27:09 loss: 7.6503 mask_loss: 6.6132 roll_mask_loss: 7.7752 density_loss: 9.4419 unmask_loss: 7.9176 Lr: 0.00171
[2025-12-10 17:13:30,701 INFO misc.py line 117 4140988] Train: [1/10][1528/7400] Data 0.004 (0.004) Batch 0.568 (0.619) Remain 12:27:06 loss: 7.9676 mask_loss: 7.5196 roll_mask_loss: 7.7894 density_loss: 8.9542 unmask_loss: 8.1017 Lr: 0.00171
[2025-12-10 17:13:31,320 INFO misc.py line 117 4140988] Train: [1/10][1529/7400] Data 0.004 (0.004) Batch 0.620 (0.619) Remain 12:27:06 loss: 7.9525 mask_loss: 7.7991 roll_mask_loss: 7.9923 density_loss: 8.6921 unmask_loss: 7.8355 Lr: 0.00171
[2025-12-10 17:13:31,860 INFO misc.py line 117 4140988] Train: [1/10][1530/7400] Data 0.003 (0.004) Batch 0.539 (0.618) Remain 12:27:01 loss: 8.0485 mask_loss: 7.2912 roll_mask_loss: 7.9539 density_loss: 8.4536 unmask_loss: 8.3054 Lr: 0.00171
[2025-12-10 17:13:32,679 INFO misc.py line 117 4140988] Train: [1/10][1531/7400] Data 0.003 (0.004) Batch 0.819 (0.619) Remain 12:27:10 loss: 6.9254 mask_loss: 6.1560 roll_mask_loss: 6.7788 density_loss: 9.6446 unmask_loss: 7.1904 Lr: 0.00172
[2025-12-10 17:13:33,233 INFO misc.py line 117 4140988] Train: [1/10][1532/7400] Data 0.003 (0.004) Batch 0.554 (0.619) Remain 12:27:07 loss: 7.9919 mask_loss: 7.5683 roll_mask_loss: 8.1388 density_loss: 8.8234 unmask_loss: 7.9538 Lr: 0.00172
[2025-12-10 17:13:33,692 INFO misc.py line 117 4140988] Train: [1/10][1533/7400] Data 0.003 (0.004) Batch 0.458 (0.618) Remain 12:26:59 loss: 8.4276 mask_loss: 8.3349 roll_mask_loss: 8.3618 density_loss: 8.3615 unmask_loss: 8.3397 Lr: 0.00172
[2025-12-10 17:13:34,263 INFO misc.py line 117 4140988] Train: [1/10][1534/7400] Data 0.004 (0.004) Batch 0.572 (0.618) Remain 12:26:56 loss: 7.3934 mask_loss: 6.5422 roll_mask_loss: 7.6797 density_loss: 8.7078 unmask_loss: 7.5017 Lr: 0.00172
[2025-12-10 17:13:34,829 INFO misc.py line 117 4140988] Train: [1/10][1535/7400] Data 0.003 (0.004) Batch 0.566 (0.618) Remain 12:26:53 loss: 8.2151 mask_loss: 7.9986 roll_mask_loss: 8.1048 density_loss: 8.4639 unmask_loss: 8.2092 Lr: 0.00172
[2025-12-10 17:13:35,512 INFO misc.py line 117 4140988] Train: [1/10][1536/7400] Data 0.003 (0.004) Batch 0.683 (0.618) Remain 12:26:55 loss: 7.4494 mask_loss: 6.8387 roll_mask_loss: 7.3572 density_loss: 8.6702 unmask_loss: 7.6275 Lr: 0.00172
[2025-12-10 17:13:36,148 INFO misc.py line 117 4140988] Train: [1/10][1537/7400] Data 0.003 (0.004) Batch 0.635 (0.618) Remain 12:26:55 loss: 7.5901 mask_loss: 7.1697 roll_mask_loss: 7.4943 density_loss: 8.8105 unmask_loss: 7.6721 Lr: 0.00172
[2025-12-10 17:13:36,881 INFO misc.py line 117 4140988] Train: [1/10][1538/7400] Data 0.004 (0.004) Batch 0.733 (0.619) Remain 12:27:00 loss: 7.1050 mask_loss: 6.1758 roll_mask_loss: 7.1494 density_loss: 8.8983 unmask_loss: 7.3694 Lr: 0.00173
[2025-12-10 17:13:37,706 INFO misc.py line 117 4140988] Train: [1/10][1539/7400] Data 0.004 (0.004) Batch 0.826 (0.619) Remain 12:27:09 loss: 7.2066 mask_loss: 6.1945 roll_mask_loss: 7.1107 density_loss: 9.7178 unmask_loss: 7.5663 Lr: 0.00173
[2025-12-10 17:13:38,283 INFO misc.py line 117 4140988] Train: [1/10][1540/7400] Data 0.003 (0.004) Batch 0.577 (0.619) Remain 12:27:07 loss: 7.5494 mask_loss: 6.8921 roll_mask_loss: 7.5632 density_loss: 9.4261 unmask_loss: 7.6826 Lr: 0.00173
[2025-12-10 17:13:38,873 INFO misc.py line 117 4140988] Train: [1/10][1541/7400] Data 0.003 (0.004) Batch 0.590 (0.619) Remain 12:27:05 loss: 7.7236 mask_loss: 7.1322 roll_mask_loss: 7.9818 density_loss: 8.2618 unmask_loss: 7.7250 Lr: 0.00173
[2025-12-10 17:13:39,280 INFO misc.py line 117 4140988] Train: [1/10][1542/7400] Data 0.003 (0.004) Batch 0.406 (0.618) Remain 12:26:54 loss: 7.1741 mask_loss: 6.3680 roll_mask_loss: 7.1293 density_loss: 9.1542 unmask_loss: 7.4165 Lr: 0.00173
[2025-12-10 17:13:39,950 INFO misc.py line 117 4140988] Train: [1/10][1543/7400] Data 0.004 (0.004) Batch 0.670 (0.619) Remain 12:26:56 loss: 6.9518 mask_loss: 5.7885 roll_mask_loss: 6.7650 density_loss: 9.8946 unmask_loss: 7.4289 Lr: 0.00173
[2025-12-10 17:13:40,690 INFO misc.py line 117 4140988] Train: [1/10][1544/7400] Data 0.004 (0.004) Batch 0.741 (0.619) Remain 12:27:01 loss: 6.8079 mask_loss: 6.0621 roll_mask_loss: 6.5472 density_loss: 9.4248 unmask_loss: 7.1226 Lr: 0.00174
[2025-12-10 17:13:41,226 INFO misc.py line 117 4140988] Train: [1/10][1545/7400] Data 0.004 (0.004) Batch 0.536 (0.619) Remain 12:26:56 loss: 8.5634 mask_loss: 8.4416 roll_mask_loss: 8.4532 density_loss: 8.4419 unmask_loss: 8.5106 Lr: 0.00174
[2025-12-10 17:13:42,065 INFO misc.py line 117 4140988] Train: [1/10][1546/7400] Data 0.003 (0.004) Batch 0.839 (0.619) Remain 12:27:06 loss: 7.0042 mask_loss: 5.9342 roll_mask_loss: 6.7381 density_loss: 10.2335 unmask_loss: 7.4675 Lr: 0.00174
[2025-12-10 17:13:42,890 INFO misc.py line 117 4140988] Train: [1/10][1547/7400] Data 0.003 (0.004) Batch 0.825 (0.619) Remain 12:27:15 loss: 6.8852 mask_loss: 6.0789 roll_mask_loss: 6.8047 density_loss: 9.6280 unmask_loss: 7.1361 Lr: 0.00174
[2025-12-10 17:13:43,725 INFO misc.py line 117 4140988] Train: [1/10][1548/7400] Data 0.003 (0.004) Batch 0.836 (0.619) Remain 12:27:25 loss: 7.0456 mask_loss: 5.9147 roll_mask_loss: 6.8451 density_loss: 9.9830 unmask_loss: 7.5116 Lr: 0.00174
[2025-12-10 17:13:44,251 INFO misc.py line 117 4140988] Train: [1/10][1549/7400] Data 0.003 (0.004) Batch 0.525 (0.619) Remain 12:27:20 loss: 8.4218 mask_loss: 8.0819 roll_mask_loss: 8.4080 density_loss: 8.5011 unmask_loss: 8.4287 Lr: 0.00174
[2025-12-10 17:13:44,858 INFO misc.py line 117 4140988] Train: [1/10][1550/7400] Data 0.004 (0.004) Batch 0.607 (0.619) Remain 12:27:19 loss: 7.0692 mask_loss: 6.2017 roll_mask_loss: 7.0104 density_loss: 8.2127 unmask_loss: 7.3681 Lr: 0.00174
[2025-12-10 17:13:45,522 INFO misc.py line 117 4140988] Train: [1/10][1551/7400] Data 0.004 (0.004) Batch 0.664 (0.619) Remain 12:27:20 loss: 7.0244 mask_loss: 6.1120 roll_mask_loss: 7.0586 density_loss: 9.3983 unmask_loss: 7.2756 Lr: 0.00175
[2025-12-10 17:13:45,803 INFO misc.py line 117 4140988] Train: [1/10][1552/7400] Data 0.004 (0.004) Batch 0.281 (0.619) Remain 12:27:04 loss: 8.4164 mask_loss: 8.3360 roll_mask_loss: 8.3414 density_loss: 8.3393 unmask_loss: 8.3273 Lr: 0.00175
[2025-12-10 17:13:46,376 INFO misc.py line 117 4140988] Train: [1/10][1553/7400] Data 0.003 (0.004) Batch 0.572 (0.619) Remain 12:27:01 loss: 7.7428 mask_loss: 7.1708 roll_mask_loss: 7.6828 density_loss: 8.0569 unmask_loss: 7.8977 Lr: 0.00175
[2025-12-10 17:13:46,977 INFO misc.py line 117 4140988] Train: [1/10][1554/7400] Data 0.004 (0.004) Batch 0.601 (0.619) Remain 12:26:59 loss: 7.4218 mask_loss: 6.5265 roll_mask_loss: 7.4408 density_loss: 8.9551 unmask_loss: 7.6808 Lr: 0.00175
[2025-12-10 17:13:47,603 INFO misc.py line 117 4140988] Train: [1/10][1555/7400] Data 0.004 (0.004) Batch 0.627 (0.619) Remain 12:26:59 loss: 8.0726 mask_loss: 7.8267 roll_mask_loss: 8.0226 density_loss: 8.4527 unmask_loss: 8.0516 Lr: 0.00175
[2025-12-10 17:13:47,882 INFO misc.py line 117 4140988] Train: [1/10][1556/7400] Data 0.003 (0.004) Batch 0.278 (0.618) Remain 12:26:43 loss: 8.4176 mask_loss: 8.3371 roll_mask_loss: 8.3401 density_loss: 8.3437 unmask_loss: 8.3297 Lr: 0.00175
[2025-12-10 17:13:48,574 INFO misc.py line 117 4140988] Train: [1/10][1557/7400] Data 0.003 (0.004) Batch 0.691 (0.618) Remain 12:26:45 loss: 7.4799 mask_loss: 6.8612 roll_mask_loss: 7.5626 density_loss: 9.2999 unmask_loss: 7.5619 Lr: 0.00175
[2025-12-10 17:13:49,139 INFO misc.py line 117 4140988] Train: [1/10][1558/7400] Data 0.004 (0.004) Batch 0.566 (0.618) Remain 12:26:42 loss: 7.6847 mask_loss: 6.9054 roll_mask_loss: 7.7032 density_loss: 8.3863 unmask_loss: 7.8974 Lr: 0.00176
[2025-12-10 17:13:49,741 INFO misc.py line 117 4140988] Train: [1/10][1559/7400] Data 0.004 (0.004) Batch 0.601 (0.618) Remain 12:26:41 loss: 7.3509 mask_loss: 6.4025 roll_mask_loss: 7.2434 density_loss: 9.5699 unmask_loss: 7.6875 Lr: 0.00176
[2025-12-10 17:13:50,377 INFO misc.py line 117 4140988] Train: [1/10][1560/7400] Data 0.004 (0.004) Batch 0.637 (0.618) Remain 12:26:41 loss: 7.2827 mask_loss: 6.5298 roll_mask_loss: 7.1233 density_loss: 9.7841 unmask_loss: 7.5432 Lr: 0.00176
[2025-12-10 17:13:50,985 INFO misc.py line 117 4140988] Train: [1/10][1561/7400] Data 0.004 (0.004) Batch 0.609 (0.618) Remain 12:26:40 loss: 7.1882 mask_loss: 6.3818 roll_mask_loss: 7.0107 density_loss: 8.7948 unmask_loss: 7.5042 Lr: 0.00176
[2025-12-10 17:13:51,558 INFO misc.py line 117 4140988] Train: [1/10][1562/7400] Data 0.003 (0.004) Batch 0.573 (0.618) Remain 12:26:37 loss: 6.9548 mask_loss: 6.0356 roll_mask_loss: 6.9197 density_loss: 9.7379 unmask_loss: 7.2372 Lr: 0.00176
[2025-12-10 17:13:52,078 INFO misc.py line 117 4140988] Train: [1/10][1563/7400] Data 0.003 (0.004) Batch 0.520 (0.618) Remain 12:26:32 loss: 8.2158 mask_loss: 7.9471 roll_mask_loss: 8.1486 density_loss: 8.3343 unmask_loss: 8.2170 Lr: 0.00176
[2025-12-10 17:13:52,671 INFO misc.py line 117 4140988] Train: [1/10][1564/7400] Data 0.004 (0.004) Batch 0.592 (0.618) Remain 12:26:30 loss: 7.7018 mask_loss: 7.1661 roll_mask_loss: 7.5520 density_loss: 8.8717 unmask_loss: 7.8672 Lr: 0.00176
[2025-12-10 17:13:53,333 INFO misc.py line 117 4140988] Train: [1/10][1565/7400] Data 0.004 (0.004) Batch 0.662 (0.618) Remain 12:26:32 loss: 6.8492 mask_loss: 5.9847 roll_mask_loss: 6.6643 density_loss: 9.2917 unmask_loss: 7.1880 Lr: 0.00177
[2025-12-10 17:13:53,950 INFO misc.py line 117 4140988] Train: [1/10][1566/7400] Data 0.003 (0.004) Batch 0.618 (0.618) Remain 12:26:31 loss: 7.0999 mask_loss: 6.4440 roll_mask_loss: 7.1123 density_loss: 8.6631 unmask_loss: 7.2483 Lr: 0.00177
[2025-12-10 17:13:54,560 INFO misc.py line 117 4140988] Train: [1/10][1567/7400] Data 0.003 (0.004) Batch 0.609 (0.618) Remain 12:26:30 loss: 7.9196 mask_loss: 7.3370 roll_mask_loss: 7.9498 density_loss: 8.9261 unmask_loss: 8.0173 Lr: 0.00177
[2025-12-10 17:13:55,278 INFO misc.py line 117 4140988] Train: [1/10][1568/7400] Data 0.004 (0.004) Batch 0.717 (0.618) Remain 12:26:34 loss: 6.9548 mask_loss: 5.8952 roll_mask_loss: 7.0009 density_loss: 9.8307 unmask_loss: 7.2650 Lr: 0.00177
[2025-12-10 17:13:55,736 INFO misc.py line 117 4140988] Train: [1/10][1569/7400] Data 0.004 (0.004) Batch 0.458 (0.618) Remain 12:26:26 loss: 8.5357 mask_loss: 8.3554 roll_mask_loss: 8.3686 density_loss: 8.3662 unmask_loss: 8.5421 Lr: 0.00177
[2025-12-10 17:13:56,341 INFO misc.py line 117 4140988] Train: [1/10][1570/7400] Data 0.003 (0.004) Batch 0.605 (0.618) Remain 12:26:25 loss: 7.0762 mask_loss: 6.3037 roll_mask_loss: 7.0531 density_loss: 8.4365 unmask_loss: 7.3053 Lr: 0.00177
[2025-12-10 17:13:56,827 INFO misc.py line 117 4140988] Train: [1/10][1571/7400] Data 0.003 (0.004) Batch 0.486 (0.618) Remain 12:26:18 loss: 7.0491 mask_loss: 6.2865 roll_mask_loss: 6.9169 density_loss: 9.1939 unmask_loss: 7.3125 Lr: 0.00178
[2025-12-10 17:13:57,373 INFO misc.py line 117 4140988] Train: [1/10][1572/7400] Data 0.003 (0.004) Batch 0.547 (0.618) Remain 12:26:14 loss: 6.9018 mask_loss: 6.0436 roll_mask_loss: 6.9097 density_loss: 8.5639 unmask_loss: 7.1557 Lr: 0.00178
[2025-12-10 17:13:57,980 INFO misc.py line 117 4140988] Train: [1/10][1573/7400] Data 0.003 (0.004) Batch 0.606 (0.618) Remain 12:26:13 loss: 7.5460 mask_loss: 6.9068 roll_mask_loss: 7.8002 density_loss: 8.7027 unmask_loss: 7.5643 Lr: 0.00178
[2025-12-10 17:13:58,652 INFO misc.py line 117 4140988] Train: [1/10][1574/7400] Data 0.004 (0.004) Batch 0.672 (0.618) Remain 12:26:15 loss: 7.2679 mask_loss: 6.7315 roll_mask_loss: 7.1906 density_loss: 8.6168 unmask_loss: 7.4025 Lr: 0.00178
[2025-12-10 17:13:59,257 INFO misc.py line 117 4140988] Train: [1/10][1575/7400] Data 0.004 (0.004) Batch 0.605 (0.618) Remain 12:26:14 loss: 7.1852 mask_loss: 6.1119 roll_mask_loss: 7.2922 density_loss: 9.5336 unmask_loss: 7.4777 Lr: 0.00178
[2025-12-10 17:13:59,966 INFO misc.py line 117 4140988] Train: [1/10][1576/7400] Data 0.003 (0.004) Batch 0.709 (0.618) Remain 12:26:17 loss: 6.7745 mask_loss: 5.7687 roll_mask_loss: 6.5828 density_loss: 9.7136 unmask_loss: 7.1790 Lr: 0.00178
[2025-12-10 17:14:00,261 INFO misc.py line 117 4140988] Train: [1/10][1577/7400] Data 0.003 (0.004) Batch 0.294 (0.618) Remain 12:26:02 loss: 8.4234 mask_loss: 8.3365 roll_mask_loss: 8.3375 density_loss: 8.3372 unmask_loss: 8.3431 Lr: 0.00178
[2025-12-10 17:14:00,787 INFO misc.py line 117 4140988] Train: [1/10][1578/7400] Data 0.004 (0.004) Batch 0.526 (0.618) Remain 12:25:57 loss: 7.9694 mask_loss: 7.1841 roll_mask_loss: 7.9334 density_loss: 8.4940 unmask_loss: 8.2101 Lr: 0.00179
[2025-12-10 17:14:01,277 INFO misc.py line 117 4140988] Train: [1/10][1579/7400] Data 0.004 (0.004) Batch 0.491 (0.618) Remain 12:25:50 loss: 7.7040 mask_loss: 7.0571 roll_mask_loss: 7.5446 density_loss: 8.7528 unmask_loss: 7.9320 Lr: 0.00179
[2025-12-10 17:14:01,888 INFO misc.py line 117 4140988] Train: [1/10][1580/7400] Data 0.004 (0.004) Batch 0.611 (0.618) Remain 12:25:49 loss: 6.8659 mask_loss: 6.1303 roll_mask_loss: 6.6387 density_loss: 8.3042 unmask_loss: 7.1812 Lr: 0.00179
[2025-12-10 17:14:02,504 INFO misc.py line 117 4140988] Train: [1/10][1581/7400] Data 0.004 (0.004) Batch 0.617 (0.618) Remain 12:25:49 loss: 7.7643 mask_loss: 7.1492 roll_mask_loss: 7.7577 density_loss: 9.2067 unmask_loss: 7.8910 Lr: 0.00179
[2025-12-10 17:14:03,254 INFO misc.py line 117 4140988] Train: [1/10][1582/7400] Data 0.003 (0.004) Batch 0.750 (0.618) Remain 12:25:54 loss: 6.9172 mask_loss: 6.0838 roll_mask_loss: 6.9609 density_loss: 9.1118 unmask_loss: 7.1298 Lr: 0.00179
[2025-12-10 17:14:03,798 INFO misc.py line 117 4140988] Train: [1/10][1583/7400] Data 0.003 (0.004) Batch 0.544 (0.618) Remain 12:25:50 loss: 8.0273 mask_loss: 7.7113 roll_mask_loss: 7.9313 density_loss: 8.5867 unmask_loss: 8.0616 Lr: 0.00179
[2025-12-10 17:14:04,542 INFO misc.py line 117 4140988] Train: [1/10][1584/7400] Data 0.003 (0.004) Batch 0.744 (0.618) Remain 12:25:55 loss: 7.1224 mask_loss: 5.8951 roll_mask_loss: 6.9423 density_loss: 9.9172 unmask_loss: 7.6278 Lr: 0.00179
[2025-12-10 17:14:05,076 INFO misc.py line 117 4140988] Train: [1/10][1585/7400] Data 0.003 (0.004) Batch 0.533 (0.618) Remain 12:25:51 loss: 7.1754 mask_loss: 6.3321 roll_mask_loss: 7.1811 density_loss: 8.9615 unmask_loss: 7.4150 Lr: 0.00180
[2025-12-10 17:14:05,637 INFO misc.py line 117 4140988] Train: [1/10][1586/7400] Data 0.004 (0.004) Batch 0.562 (0.618) Remain 12:25:48 loss: 7.4005 mask_loss: 6.6874 roll_mask_loss: 7.3584 density_loss: 8.5738 unmask_loss: 7.6067 Lr: 0.00180
[2025-12-10 17:14:06,183 INFO misc.py line 117 4140988] Train: [1/10][1587/7400] Data 0.004 (0.004) Batch 0.546 (0.618) Remain 12:25:44 loss: 7.3328 mask_loss: 6.6567 roll_mask_loss: 7.1208 density_loss: 8.8136 unmask_loss: 7.6005 Lr: 0.00180
[2025-12-10 17:14:06,790 INFO misc.py line 117 4140988] Train: [1/10][1588/7400] Data 0.003 (0.004) Batch 0.607 (0.618) Remain 12:25:43 loss: 7.1164 mask_loss: 6.4071 roll_mask_loss: 6.8476 density_loss: 8.8641 unmask_loss: 7.4283 Lr: 0.00180
[2025-12-10 17:14:07,365 INFO misc.py line 117 4140988] Train: [1/10][1589/7400] Data 0.003 (0.004) Batch 0.575 (0.618) Remain 12:25:40 loss: 6.7870 mask_loss: 5.9956 roll_mask_loss: 6.6724 density_loss: 8.2053 unmask_loss: 7.0759 Lr: 0.00180
[2025-12-10 17:14:07,906 INFO misc.py line 117 4140988] Train: [1/10][1590/7400] Data 0.004 (0.004) Batch 0.540 (0.618) Remain 12:25:36 loss: 7.6042 mask_loss: 7.2253 roll_mask_loss: 7.6107 density_loss: 8.5898 unmask_loss: 7.6185 Lr: 0.00180
[2025-12-10 17:14:08,565 INFO misc.py line 117 4140988] Train: [1/10][1591/7400] Data 0.004 (0.004) Batch 0.660 (0.618) Remain 12:25:37 loss: 7.1825 mask_loss: 6.5706 roll_mask_loss: 7.0740 density_loss: 8.8430 unmask_loss: 7.3659 Lr: 0.00181
[2025-12-10 17:14:09,150 INFO misc.py line 117 4140988] Train: [1/10][1592/7400] Data 0.004 (0.004) Batch 0.584 (0.618) Remain 12:25:35 loss: 7.4249 mask_loss: 6.5018 roll_mask_loss: 7.3596 density_loss: 9.2297 unmask_loss: 7.7344 Lr: 0.00181
[2025-12-10 17:14:09,468 INFO misc.py line 117 4140988] Train: [1/10][1593/7400] Data 0.004 (0.004) Batch 0.318 (0.618) Remain 12:25:21 loss: 7.0098 mask_loss: 6.2951 roll_mask_loss: 6.9553 density_loss: 9.7260 unmask_loss: 7.2000 Lr: 0.00181
[2025-12-10 17:14:10,236 INFO misc.py line 117 4140988] Train: [1/10][1594/7400] Data 0.004 (0.004) Batch 0.769 (0.618) Remain 12:25:27 loss: 6.9329 mask_loss: 5.9603 roll_mask_loss: 6.7922 density_loss: 9.5830 unmask_loss: 7.2980 Lr: 0.00181
[2025-12-10 17:14:10,966 INFO misc.py line 117 4140988] Train: [1/10][1595/7400] Data 0.004 (0.004) Batch 0.729 (0.618) Remain 12:25:31 loss: 6.8809 mask_loss: 5.7615 roll_mask_loss: 6.7100 density_loss: 9.5430 unmask_loss: 7.3352 Lr: 0.00181
[2025-12-10 17:14:11,532 INFO misc.py line 117 4140988] Train: [1/10][1596/7400] Data 0.004 (0.004) Batch 0.566 (0.618) Remain 12:25:28 loss: 7.5269 mask_loss: 6.7323 roll_mask_loss: 7.5147 density_loss: 8.6898 unmask_loss: 7.7566 Lr: 0.00181
[2025-12-10 17:14:12,000 INFO misc.py line 117 4140988] Train: [1/10][1597/7400] Data 0.004 (0.004) Batch 0.468 (0.618) Remain 12:25:21 loss: 8.6923 mask_loss: 8.4277 roll_mask_loss: 8.5644 density_loss: 8.5671 unmask_loss: 8.7172 Lr: 0.00181
[2025-12-10 17:14:12,507 INFO misc.py line 117 4140988] Train: [1/10][1598/7400] Data 0.004 (0.004) Batch 0.507 (0.618) Remain 12:25:15 loss: 8.0362 mask_loss: 7.3767 roll_mask_loss: 8.4009 density_loss: 8.4182 unmask_loss: 8.0152 Lr: 0.00182
[2025-12-10 17:14:13,242 INFO misc.py line 117 4140988] Train: [1/10][1599/7400] Data 0.004 (0.004) Batch 0.736 (0.618) Remain 12:25:20 loss: 7.1217 mask_loss: 6.4747 roll_mask_loss: 7.0064 density_loss: 8.6155 unmask_loss: 7.3305 Lr: 0.00182
[2025-12-10 17:14:13,793 INFO misc.py line 117 4140988] Train: [1/10][1600/7400] Data 0.004 (0.004) Batch 0.552 (0.618) Remain 12:25:17 loss: 8.2732 mask_loss: 7.8727 roll_mask_loss: 8.3654 density_loss: 8.5829 unmask_loss: 8.2557 Lr: 0.00182
[2025-12-10 17:14:14,417 INFO misc.py line 117 4140988] Train: [1/10][1601/7400] Data 0.003 (0.004) Batch 0.623 (0.618) Remain 12:25:16 loss: 7.0272 mask_loss: 6.2523 roll_mask_loss: 7.0541 density_loss: 9.2020 unmask_loss: 7.2171 Lr: 0.00182
[2025-12-10 17:14:14,967 INFO misc.py line 117 4140988] Train: [1/10][1602/7400] Data 0.003 (0.004) Batch 0.551 (0.618) Remain 12:25:13 loss: 7.0792 mask_loss: 6.1859 roll_mask_loss: 6.9902 density_loss: 8.6425 unmask_loss: 7.3975 Lr: 0.00182
[2025-12-10 17:14:15,421 INFO misc.py line 117 4140988] Train: [1/10][1603/7400] Data 0.003 (0.004) Batch 0.454 (0.617) Remain 12:25:04 loss: 8.4517 mask_loss: 8.3361 roll_mask_loss: 8.3439 density_loss: 8.3395 unmask_loss: 8.3965 Lr: 0.00182
[2025-12-10 17:14:16,309 INFO misc.py line 117 4140988] Train: [1/10][1604/7400] Data 0.003 (0.004) Batch 0.888 (0.618) Remain 12:25:16 loss: 6.8676 mask_loss: 5.9309 roll_mask_loss: 6.6079 density_loss: 8.4979 unmask_loss: 7.2958 Lr: 0.00182
[2025-12-10 17:14:16,807 INFO misc.py line 117 4140988] Train: [1/10][1605/7400] Data 0.003 (0.004) Batch 0.498 (0.618) Remain 12:25:10 loss: 8.1855 mask_loss: 8.0440 roll_mask_loss: 8.1574 density_loss: 8.3683 unmask_loss: 8.1029 Lr: 0.00183
[2025-12-10 17:14:17,477 INFO misc.py line 117 4140988] Train: [1/10][1606/7400] Data 0.003 (0.004) Batch 0.670 (0.618) Remain 12:25:12 loss: 6.9069 mask_loss: 6.1828 roll_mask_loss: 6.7300 density_loss: 8.8157 unmask_loss: 7.1811 Lr: 0.00183
[2025-12-10 17:14:18,047 INFO misc.py line 117 4140988] Train: [1/10][1607/7400] Data 0.003 (0.004) Batch 0.569 (0.618) Remain 12:25:09 loss: 7.4270 mask_loss: 6.8293 roll_mask_loss: 7.5393 density_loss: 8.6231 unmask_loss: 7.4972 Lr: 0.00183
[2025-12-10 17:14:18,497 INFO misc.py line 117 4140988] Train: [1/10][1608/7400] Data 0.004 (0.004) Batch 0.451 (0.617) Remain 12:25:01 loss: 8.4275 mask_loss: 7.7204 roll_mask_loss: 8.8040 density_loss: 8.5076 unmask_loss: 8.4226 Lr: 0.00183
[2025-12-10 17:14:19,160 INFO misc.py line 117 4140988] Train: [1/10][1609/7400] Data 0.004 (0.004) Batch 0.663 (0.618) Remain 12:25:02 loss: 6.9136 mask_loss: 5.8594 roll_mask_loss: 6.7426 density_loss: 10.1351 unmask_loss: 7.3235 Lr: 0.00183
[2025-12-10 17:14:19,675 INFO misc.py line 117 4140988] Train: [1/10][1610/7400] Data 0.004 (0.004) Batch 0.515 (0.617) Remain 12:24:57 loss: 8.4094 mask_loss: 8.2521 roll_mask_loss: 8.3568 density_loss: 8.3669 unmask_loss: 8.3469 Lr: 0.00183
[2025-12-10 17:14:20,393 INFO misc.py line 117 4140988] Train: [1/10][1611/7400] Data 0.003 (0.004) Batch 0.717 (0.618) Remain 12:25:01 loss: 7.0176 mask_loss: 5.8577 roll_mask_loss: 6.8585 density_loss: 10.0820 unmask_loss: 7.4755 Lr: 0.00183
[2025-12-10 17:14:20,946 INFO misc.py line 117 4140988] Train: [1/10][1612/7400] Data 0.004 (0.004) Batch 0.554 (0.617) Remain 12:24:57 loss: 7.6235 mask_loss: 7.2434 roll_mask_loss: 7.8820 density_loss: 8.5412 unmask_loss: 7.5134 Lr: 0.00184
[2025-12-10 17:14:21,585 INFO misc.py line 117 4140988] Train: [1/10][1613/7400] Data 0.003 (0.004) Batch 0.638 (0.617) Remain 12:24:58 loss: 7.6170 mask_loss: 6.9874 roll_mask_loss: 7.7201 density_loss: 9.2183 unmask_loss: 7.6958 Lr: 0.00184
[2025-12-10 17:14:22,140 INFO misc.py line 117 4140988] Train: [1/10][1614/7400] Data 0.004 (0.004) Batch 0.556 (0.617) Remain 12:24:54 loss: 7.3813 mask_loss: 6.8541 roll_mask_loss: 7.1679 density_loss: 8.9517 unmask_loss: 7.5726 Lr: 0.00184
[2025-12-10 17:14:22,915 INFO misc.py line 117 4140988] Train: [1/10][1615/7400] Data 0.003 (0.004) Batch 0.775 (0.618) Remain 12:25:01 loss: 7.3312 mask_loss: 6.4961 roll_mask_loss: 7.2499 density_loss: 9.4372 unmask_loss: 7.6007 Lr: 0.00184
[2025-12-10 17:14:23,497 INFO misc.py line 117 4140988] Train: [1/10][1616/7400] Data 0.003 (0.004) Batch 0.582 (0.618) Remain 12:24:59 loss: 7.2845 mask_loss: 6.4235 roll_mask_loss: 6.9086 density_loss: 8.9831 unmask_loss: 7.7232 Lr: 0.00184
[2025-12-10 17:14:24,220 INFO misc.py line 117 4140988] Train: [1/10][1617/7400] Data 0.003 (0.004) Batch 0.723 (0.618) Remain 12:25:03 loss: 6.9541 mask_loss: 5.9332 roll_mask_loss: 6.9460 density_loss: 9.6578 unmask_loss: 7.2754 Lr: 0.00184
[2025-12-10 17:14:25,018 INFO misc.py line 117 4140988] Train: [1/10][1618/7400] Data 0.004 (0.004) Batch 0.798 (0.618) Remain 12:25:10 loss: 6.7528 mask_loss: 5.8536 roll_mask_loss: 6.6985 density_loss: 9.5315 unmask_loss: 7.0390 Lr: 0.00185
[2025-12-10 17:14:25,707 INFO misc.py line 117 4140988] Train: [1/10][1619/7400] Data 0.003 (0.004) Batch 0.690 (0.618) Remain 12:25:13 loss: 8.3141 mask_loss: 8.0211 roll_mask_loss: 8.3384 density_loss: 9.1302 unmask_loss: 8.2658 Lr: 0.00185
[2025-12-10 17:14:26,326 INFO misc.py line 117 4140988] Train: [1/10][1620/7400] Data 0.003 (0.004) Batch 0.618 (0.618) Remain 12:25:12 loss: 7.8862 mask_loss: 7.5741 roll_mask_loss: 7.8494 density_loss: 8.4352 unmask_loss: 7.8920 Lr: 0.00185
[2025-12-10 17:14:27,004 INFO misc.py line 117 4140988] Train: [1/10][1621/7400] Data 0.003 (0.004) Batch 0.678 (0.618) Remain 12:25:14 loss: 7.3375 mask_loss: 6.6705 roll_mask_loss: 7.4009 density_loss: 8.5816 unmask_loss: 7.4677 Lr: 0.00185
[2025-12-10 17:14:27,572 INFO misc.py line 117 4140988] Train: [1/10][1622/7400] Data 0.004 (0.004) Batch 0.567 (0.618) Remain 12:25:11 loss: 7.0463 mask_loss: 6.3832 roll_mask_loss: 6.7561 density_loss: 8.8447 unmask_loss: 7.3461 Lr: 0.00185
[2025-12-10 17:14:28,121 INFO misc.py line 117 4140988] Train: [1/10][1623/7400] Data 0.004 (0.004) Batch 0.549 (0.618) Remain 12:25:08 loss: 7.0658 mask_loss: 6.3464 roll_mask_loss: 6.8413 density_loss: 9.3182 unmask_loss: 7.3514 Lr: 0.00185
[2025-12-10 17:14:28,853 INFO misc.py line 117 4140988] Train: [1/10][1624/7400] Data 0.004 (0.004) Batch 0.732 (0.618) Remain 12:25:12 loss: 6.9783 mask_loss: 6.2281 roll_mask_loss: 6.7895 density_loss: 8.5600 unmask_loss: 7.2767 Lr: 0.00185
[2025-12-10 17:14:29,417 INFO misc.py line 117 4140988] Train: [1/10][1625/7400] Data 0.004 (0.004) Batch 0.564 (0.618) Remain 12:25:09 loss: 7.3546 mask_loss: 6.7080 roll_mask_loss: 7.4562 density_loss: 8.8575 unmask_loss: 7.4499 Lr: 0.00186
[2025-12-10 17:14:30,076 INFO misc.py line 117 4140988] Train: [1/10][1626/7400] Data 0.004 (0.004) Batch 0.659 (0.618) Remain 12:25:10 loss: 7.5041 mask_loss: 6.7761 roll_mask_loss: 7.2830 density_loss: 8.6961 unmask_loss: 7.8046 Lr: 0.00186
[2025-12-10 17:14:30,849 INFO misc.py line 117 4140988] Train: [1/10][1627/7400] Data 0.004 (0.004) Batch 0.773 (0.618) Remain 12:25:17 loss: 7.0934 mask_loss: 6.3387 roll_mask_loss: 6.8337 density_loss: 8.8846 unmask_loss: 7.4229 Lr: 0.00186
[2025-12-10 17:14:31,366 INFO misc.py line 117 4140988] Train: [1/10][1628/7400] Data 0.004 (0.004) Batch 0.517 (0.618) Remain 12:25:12 loss: 7.5044 mask_loss: 6.9822 roll_mask_loss: 7.5143 density_loss: 8.9232 unmask_loss: 7.5820 Lr: 0.00186
[2025-12-10 17:14:32,068 INFO misc.py line 117 4140988] Train: [1/10][1629/7400] Data 0.004 (0.004) Batch 0.702 (0.618) Remain 12:25:15 loss: 7.0055 mask_loss: 6.3886 roll_mask_loss: 6.9049 density_loss: 10.1680 unmask_loss: 7.1610 Lr: 0.00186
[2025-12-10 17:14:32,699 INFO misc.py line 117 4140988] Train: [1/10][1630/7400] Data 0.004 (0.004) Batch 0.631 (0.618) Remain 12:25:15 loss: 7.0987 mask_loss: 6.3186 roll_mask_loss: 6.8178 density_loss: 8.2447 unmask_loss: 7.4644 Lr: 0.00186
[2025-12-10 17:14:33,339 INFO misc.py line 117 4140988] Train: [1/10][1631/7400] Data 0.004 (0.004) Batch 0.640 (0.618) Remain 12:25:15 loss: 7.0173 mask_loss: 6.3496 roll_mask_loss: 6.9755 density_loss: 9.2785 unmask_loss: 7.1866 Lr: 0.00186
[2025-12-10 17:14:33,941 INFO misc.py line 117 4140988] Train: [1/10][1632/7400] Data 0.004 (0.004) Batch 0.602 (0.618) Remain 12:25:14 loss: 7.4199 mask_loss: 6.9033 roll_mask_loss: 7.4689 density_loss: 8.7168 unmask_loss: 7.4794 Lr: 0.00187
[2025-12-10 17:14:34,267 INFO misc.py line 117 4140988] Train: [1/10][1633/7400] Data 0.004 (0.004) Batch 0.326 (0.618) Remain 12:25:00 loss: 7.0935 mask_loss: 6.1782 roll_mask_loss: 6.9706 density_loss: 8.6572 unmask_loss: 7.4394 Lr: 0.00187
[2025-12-10 17:14:34,757 INFO misc.py line 117 4140988] Train: [1/10][1634/7400] Data 0.003 (0.004) Batch 0.490 (0.618) Remain 12:24:54 loss: 7.6244 mask_loss: 6.7086 roll_mask_loss: 7.4007 density_loss: 8.7178 unmask_loss: 8.0198 Lr: 0.00187
[2025-12-10 17:14:35,535 INFO misc.py line 117 4140988] Train: [1/10][1635/7400] Data 0.003 (0.004) Batch 0.778 (0.618) Remain 12:25:00 loss: 7.3618 mask_loss: 6.3199 roll_mask_loss: 7.2304 density_loss: 9.9717 unmask_loss: 7.7490 Lr: 0.00187
[2025-12-10 17:14:36,192 INFO misc.py line 117 4140988] Train: [1/10][1636/7400] Data 0.003 (0.004) Batch 0.657 (0.618) Remain 12:25:02 loss: 6.9762 mask_loss: 6.0488 roll_mask_loss: 7.0076 density_loss: 9.8691 unmask_loss: 7.2267 Lr: 0.00187
[2025-12-10 17:14:36,612 INFO misc.py line 117 4140988] Train: [1/10][1637/7400] Data 0.003 (0.004) Batch 0.419 (0.618) Remain 12:24:52 loss: 7.8786 mask_loss: 7.4105 roll_mask_loss: 7.7396 density_loss: 8.2619 unmask_loss: 8.0169 Lr: 0.00187
[2025-12-10 17:14:37,229 INFO misc.py line 117 4140988] Train: [1/10][1638/7400] Data 0.003 (0.004) Batch 0.616 (0.618) Remain 12:24:51 loss: 8.1014 mask_loss: 7.8480 roll_mask_loss: 8.1185 density_loss: 8.8966 unmask_loss: 8.0416 Lr: 0.00188
[2025-12-10 17:14:37,738 INFO misc.py line 117 4140988] Train: [1/10][1639/7400] Data 0.004 (0.004) Batch 0.509 (0.618) Remain 12:24:46 loss: 7.6799 mask_loss: 7.1563 roll_mask_loss: 7.3869 density_loss: 8.7604 unmask_loss: 7.9129 Lr: 0.00188
[2025-12-10 17:14:38,363 INFO misc.py line 117 4140988] Train: [1/10][1640/7400] Data 0.004 (0.004) Batch 0.626 (0.618) Remain 12:24:46 loss: 8.5092 mask_loss: 8.4076 roll_mask_loss: 8.4335 density_loss: 8.4337 unmask_loss: 8.4292 Lr: 0.00188
[2025-12-10 17:14:38,962 INFO misc.py line 117 4140988] Train: [1/10][1641/7400] Data 0.004 (0.004) Batch 0.599 (0.618) Remain 12:24:44 loss: 7.4912 mask_loss: 6.9694 roll_mask_loss: 7.4220 density_loss: 9.7526 unmask_loss: 7.5917 Lr: 0.00188
[2025-12-10 17:14:39,536 INFO misc.py line 117 4140988] Train: [1/10][1642/7400] Data 0.004 (0.004) Batch 0.573 (0.618) Remain 12:24:42 loss: 7.3841 mask_loss: 6.9104 roll_mask_loss: 7.3298 density_loss: 8.8838 unmask_loss: 7.4705 Lr: 0.00188
[2025-12-10 17:14:40,078 INFO misc.py line 117 4140988] Train: [1/10][1643/7400] Data 0.005 (0.004) Batch 0.543 (0.617) Remain 12:24:38 loss: 8.0461 mask_loss: 7.8016 roll_mask_loss: 7.9820 density_loss: 8.5033 unmask_loss: 8.0304 Lr: 0.00188
[2025-12-10 17:14:40,801 INFO misc.py line 117 4140988] Train: [1/10][1644/7400] Data 0.004 (0.004) Batch 0.723 (0.618) Remain 12:24:42 loss: 7.0482 mask_loss: 6.2969 roll_mask_loss: 6.8318 density_loss: 8.8549 unmask_loss: 7.3550 Lr: 0.00188
[2025-12-10 17:14:41,340 INFO misc.py line 117 4140988] Train: [1/10][1645/7400] Data 0.004 (0.004) Batch 0.539 (0.617) Remain 12:24:38 loss: 8.4260 mask_loss: 8.3379 roll_mask_loss: 8.3623 density_loss: 8.3499 unmask_loss: 8.3349 Lr: 0.00189
[2025-12-10 17:14:42,214 INFO misc.py line 117 4140988] Train: [1/10][1646/7400] Data 0.004 (0.004) Batch 0.874 (0.618) Remain 12:24:49 loss: 7.2301 mask_loss: 6.6103 roll_mask_loss: 7.1421 density_loss: 8.1683 unmask_loss: 7.4206 Lr: 0.00189
[2025-12-10 17:14:42,837 INFO misc.py line 117 4140988] Train: [1/10][1647/7400] Data 0.004 (0.004) Batch 0.623 (0.618) Remain 12:24:48 loss: 7.4957 mask_loss: 7.0908 roll_mask_loss: 7.4229 density_loss: 8.5893 unmask_loss: 7.5628 Lr: 0.00189
[2025-12-10 17:14:43,559 INFO misc.py line 117 4140988] Train: [1/10][1648/7400] Data 0.003 (0.004) Batch 0.722 (0.618) Remain 12:24:52 loss: 7.1863 mask_loss: 6.0978 roll_mask_loss: 6.9589 density_loss: 9.1016 unmask_loss: 7.6622 Lr: 0.00189
[2025-12-10 17:14:44,144 INFO misc.py line 117 4140988] Train: [1/10][1649/7400] Data 0.003 (0.004) Batch 0.584 (0.618) Remain 12:24:50 loss: 6.8698 mask_loss: 6.1078 roll_mask_loss: 6.7508 density_loss: 9.3074 unmask_loss: 7.1241 Lr: 0.00189
[2025-12-10 17:14:45,116 INFO misc.py line 117 4140988] Train: [1/10][1650/7400] Data 0.004 (0.004) Batch 0.972 (0.618) Remain 12:25:05 loss: 7.4316 mask_loss: 6.2178 roll_mask_loss: 8.0902 density_loss: 9.2044 unmask_loss: 7.5251 Lr: 0.00189
[2025-12-10 17:14:45,639 INFO misc.py line 117 4140988] Train: [1/10][1651/7400] Data 0.003 (0.004) Batch 0.523 (0.618) Remain 12:25:00 loss: 7.7435 mask_loss: 7.0063 roll_mask_loss: 8.0316 density_loss: 8.0808 unmask_loss: 7.8065 Lr: 0.00189
[2025-12-10 17:14:46,087 INFO misc.py line 117 4140988] Train: [1/10][1652/7400] Data 0.003 (0.004) Batch 0.447 (0.618) Remain 12:24:52 loss: 7.0919 mask_loss: 6.2502 roll_mask_loss: 6.7044 density_loss: 9.3439 unmask_loss: 7.5197 Lr: 0.00190
[2025-12-10 17:14:46,739 INFO misc.py line 117 4140988] Train: [1/10][1653/7400] Data 0.004 (0.004) Batch 0.652 (0.618) Remain 12:24:53 loss: 7.1472 mask_loss: 6.5158 roll_mask_loss: 7.1214 density_loss: 8.5585 unmask_loss: 7.3047 Lr: 0.00190
[2025-12-10 17:14:47,449 INFO misc.py line 117 4140988] Train: [1/10][1654/7400] Data 0.004 (0.004) Batch 0.710 (0.618) Remain 12:24:56 loss: 7.2453 mask_loss: 6.5317 roll_mask_loss: 7.2092 density_loss: 9.4561 unmask_loss: 7.4311 Lr: 0.00190
[2025-12-10 17:14:48,147 INFO misc.py line 117 4140988] Train: [1/10][1655/7400] Data 0.004 (0.004) Batch 0.698 (0.618) Remain 12:24:59 loss: 7.0386 mask_loss: 6.3821 roll_mask_loss: 6.9324 density_loss: 9.3380 unmask_loss: 7.2331 Lr: 0.00190
[2025-12-10 17:14:48,432 INFO misc.py line 117 4140988] Train: [1/10][1656/7400] Data 0.004 (0.004) Batch 0.285 (0.618) Remain 12:24:44 loss: 8.4562 mask_loss: 8.3984 roll_mask_loss: 8.4035 density_loss: 8.4027 unmask_loss: 8.3435 Lr: 0.00190
[2025-12-10 17:14:49,031 INFO misc.py line 117 4140988] Train: [1/10][1657/7400] Data 0.004 (0.004) Batch 0.599 (0.618) Remain 12:24:43 loss: 7.8414 mask_loss: 7.2591 roll_mask_loss: 7.7589 density_loss: 8.5698 unmask_loss: 8.0023 Lr: 0.00190
[2025-12-10 17:14:49,380 INFO misc.py line 117 4140988] Train: [1/10][1658/7400] Data 0.003 (0.004) Batch 0.350 (0.617) Remain 12:24:30 loss: 7.0417 mask_loss: 6.1047 roll_mask_loss: 6.8263 density_loss: 9.8637 unmask_loss: 7.4207 Lr: 0.00191
[2025-12-10 17:14:50,015 INFO misc.py line 117 4140988] Train: [1/10][1659/7400] Data 0.003 (0.004) Batch 0.634 (0.618) Remain 12:24:30 loss: 7.0146 mask_loss: 6.1261 roll_mask_loss: 6.9068 density_loss: 9.2024 unmask_loss: 7.3287 Lr: 0.00191
[2025-12-10 17:14:50,808 INFO misc.py line 117 4140988] Train: [1/10][1660/7400] Data 0.004 (0.004) Batch 0.792 (0.618) Remain 12:24:38 loss: 6.8157 mask_loss: 6.0371 roll_mask_loss: 6.6166 density_loss: 9.4500 unmask_loss: 7.1156 Lr: 0.00191
[2025-12-10 17:14:51,403 INFO misc.py line 117 4140988] Train: [1/10][1661/7400] Data 0.004 (0.004) Batch 0.595 (0.618) Remain 12:24:36 loss: 7.2846 mask_loss: 6.6263 roll_mask_loss: 7.0416 density_loss: 8.7076 unmask_loss: 7.5611 Lr: 0.00191
[2025-12-10 17:14:52,140 INFO misc.py line 117 4140988] Train: [1/10][1662/7400] Data 0.004 (0.004) Batch 0.736 (0.618) Remain 12:24:40 loss: 7.1099 mask_loss: 6.0543 roll_mask_loss: 7.0032 density_loss: 9.1561 unmask_loss: 7.5080 Lr: 0.00191
[2025-12-10 17:14:52,780 INFO misc.py line 117 4140988] Train: [1/10][1663/7400] Data 0.004 (0.004) Batch 0.641 (0.618) Remain 12:24:41 loss: 7.1457 mask_loss: 6.4862 roll_mask_loss: 7.1370 density_loss: 9.5087 unmask_loss: 7.2896 Lr: 0.00191
[2025-12-10 17:14:53,351 INFO misc.py line 117 4140988] Train: [1/10][1664/7400] Data 0.004 (0.004) Batch 0.571 (0.618) Remain 12:24:38 loss: 7.6393 mask_loss: 7.0097 roll_mask_loss: 7.5285 density_loss: 8.6639 unmask_loss: 7.8361 Lr: 0.00191
[2025-12-10 17:14:53,918 INFO misc.py line 117 4140988] Train: [1/10][1665/7400] Data 0.004 (0.004) Batch 0.567 (0.618) Remain 12:24:35 loss: 7.1062 mask_loss: 6.4508 roll_mask_loss: 6.9192 density_loss: 9.0954 unmask_loss: 7.3454 Lr: 0.00192
[2025-12-10 17:14:54,526 INFO misc.py line 117 4140988] Train: [1/10][1666/7400] Data 0.004 (0.004) Batch 0.609 (0.618) Remain 12:24:34 loss: 6.9833 mask_loss: 6.1342 roll_mask_loss: 6.8958 density_loss: 8.8442 unmask_loss: 7.2747 Lr: 0.00192
[2025-12-10 17:14:55,207 INFO misc.py line 117 4140988] Train: [1/10][1667/7400] Data 0.003 (0.004) Batch 0.682 (0.618) Remain 12:24:37 loss: 6.8786 mask_loss: 6.1539 roll_mask_loss: 6.7604 density_loss: 9.0772 unmask_loss: 7.1184 Lr: 0.00192
[2025-12-10 17:14:55,764 INFO misc.py line 117 4140988] Train: [1/10][1668/7400] Data 0.003 (0.004) Batch 0.557 (0.618) Remain 12:24:33 loss: 7.5062 mask_loss: 6.9669 roll_mask_loss: 7.5035 density_loss: 8.5903 unmask_loss: 7.6053 Lr: 0.00192
[2025-12-10 17:14:56,047 INFO misc.py line 117 4140988] Train: [1/10][1669/7400] Data 0.003 (0.004) Batch 0.282 (0.617) Remain 12:24:18 loss: 8.3524 mask_loss: 7.9383 roll_mask_loss: 8.5410 density_loss: 8.3930 unmask_loss: 8.2973 Lr: 0.00192
[2025-12-10 17:14:56,521 INFO misc.py line 117 4140988] Train: [1/10][1670/7400] Data 0.004 (0.004) Batch 0.474 (0.617) Remain 12:24:11 loss: 7.9180 mask_loss: 7.6334 roll_mask_loss: 7.8862 density_loss: 8.4676 unmask_loss: 7.9067 Lr: 0.00192
[2025-12-10 17:14:57,123 INFO misc.py line 117 4140988] Train: [1/10][1671/7400] Data 0.004 (0.004) Batch 0.602 (0.617) Remain 12:24:10 loss: 8.3968 mask_loss: 8.2410 roll_mask_loss: 8.3279 density_loss: 8.3429 unmask_loss: 8.3424 Lr: 0.00193
[2025-12-10 17:14:58,019 INFO misc.py line 117 4140988] Train: [1/10][1672/7400] Data 0.004 (0.004) Batch 0.896 (0.617) Remain 12:24:21 loss: 7.0863 mask_loss: 6.0614 roll_mask_loss: 6.9214 density_loss: 9.6097 unmask_loss: 7.4890 Lr: 0.00193
[2025-12-10 17:14:58,592 INFO misc.py line 117 4140988] Train: [1/10][1673/7400] Data 0.004 (0.004) Batch 0.573 (0.617) Remain 12:24:19 loss: 8.3151 mask_loss: 8.0801 roll_mask_loss: 8.3623 density_loss: 8.3153 unmask_loss: 8.2427 Lr: 0.00193
[2025-12-10 17:14:58,888 INFO misc.py line 117 4140988] Train: [1/10][1674/7400] Data 0.004 (0.004) Batch 0.297 (0.617) Remain 12:24:04 loss: 7.9529 mask_loss: 7.6076 roll_mask_loss: 7.8474 density_loss: 8.2976 unmask_loss: 8.0124 Lr: 0.00193
[2025-12-10 17:14:59,430 INFO misc.py line 117 4140988] Train: [1/10][1675/7400] Data 0.004 (0.004) Batch 0.542 (0.617) Remain 12:24:00 loss: 7.9668 mask_loss: 7.4787 roll_mask_loss: 8.0682 density_loss: 8.3316 unmask_loss: 7.9935 Lr: 0.00193
[2025-12-10 17:15:00,205 INFO misc.py line 117 4140988] Train: [1/10][1676/7400] Data 0.004 (0.004) Batch 0.775 (0.617) Remain 12:24:07 loss: 7.1241 mask_loss: 6.2173 roll_mask_loss: 7.2489 density_loss: 9.2231 unmask_loss: 7.3306 Lr: 0.00193
[2025-12-10 17:15:00,539 INFO misc.py line 117 4140988] Train: [1/10][1677/7400] Data 0.003 (0.004) Batch 0.334 (0.617) Remain 12:23:54 loss: 7.4282 mask_loss: 6.7898 roll_mask_loss: 7.2103 density_loss: 8.3812 unmask_loss: 7.6888 Lr: 0.00193
[2025-12-10 17:15:01,425 INFO misc.py line 117 4140988] Train: [1/10][1678/7400] Data 0.004 (0.004) Batch 0.886 (0.617) Remain 12:24:05 loss: 7.0527 mask_loss: 6.1813 roll_mask_loss: 7.0114 density_loss: 9.1078 unmask_loss: 7.3270 Lr: 0.00194
[2025-12-10 17:15:02,014 INFO misc.py line 117 4140988] Train: [1/10][1679/7400] Data 0.004 (0.004) Batch 0.589 (0.617) Remain 12:24:03 loss: 7.1548 mask_loss: 6.4094 roll_mask_loss: 6.9678 density_loss: 8.7403 unmask_loss: 7.4463 Lr: 0.00194
[2025-12-10 17:15:02,619 INFO misc.py line 117 4140988] Train: [1/10][1680/7400] Data 0.004 (0.004) Batch 0.605 (0.617) Remain 12:24:02 loss: 8.4292 mask_loss: 8.3349 roll_mask_loss: 8.3494 density_loss: 8.3468 unmask_loss: 8.3494 Lr: 0.00194
[2025-12-10 17:15:03,537 INFO misc.py line 117 4140988] Train: [1/10][1681/7400] Data 0.003 (0.004) Batch 0.917 (0.617) Remain 12:24:14 loss: 7.2079 mask_loss: 5.9871 roll_mask_loss: 7.0806 density_loss: 9.6466 unmask_loss: 7.6890 Lr: 0.00194
[2025-12-10 17:15:03,843 INFO misc.py line 117 4140988] Train: [1/10][1682/7400] Data 0.004 (0.004) Batch 0.307 (0.617) Remain 12:24:00 loss: 7.8592 mask_loss: 7.4455 roll_mask_loss: 7.8614 density_loss: 8.7358 unmask_loss: 7.8902 Lr: 0.00194
[2025-12-10 17:15:04,431 INFO misc.py line 117 4140988] Train: [1/10][1683/7400] Data 0.004 (0.004) Batch 0.587 (0.617) Remain 12:23:58 loss: 8.4622 mask_loss: 8.0200 roll_mask_loss: 8.5177 density_loss: 8.2239 unmask_loss: 8.4911 Lr: 0.00194
[2025-12-10 17:15:04,956 INFO misc.py line 117 4140988] Train: [1/10][1684/7400] Data 0.004 (0.004) Batch 0.525 (0.617) Remain 12:23:54 loss: 7.2998 mask_loss: 6.6926 roll_mask_loss: 7.2042 density_loss: 9.4529 unmask_loss: 7.4621 Lr: 0.00194
[2025-12-10 17:15:05,826 INFO misc.py line 117 4140988] Train: [1/10][1685/7400] Data 0.003 (0.004) Batch 0.870 (0.617) Remain 12:24:04 loss: 6.9902 mask_loss: 6.1885 roll_mask_loss: 6.8879 density_loss: 9.7651 unmask_loss: 7.2469 Lr: 0.00195
[2025-12-10 17:15:06,408 INFO misc.py line 117 4140988] Train: [1/10][1686/7400] Data 0.004 (0.004) Batch 0.582 (0.617) Remain 12:24:02 loss: 6.8611 mask_loss: 5.8411 roll_mask_loss: 6.8003 density_loss: 8.9709 unmask_loss: 7.2221 Lr: 0.00195
[2025-12-10 17:15:07,194 INFO misc.py line 117 4140988] Train: [1/10][1687/7400] Data 0.004 (0.004) Batch 0.787 (0.617) Remain 12:24:08 loss: 7.0209 mask_loss: 6.2340 roll_mask_loss: 7.0095 density_loss: 8.9884 unmask_loss: 7.2402 Lr: 0.00195
[2025-12-10 17:15:07,724 INFO misc.py line 117 4140988] Train: [1/10][1688/7400] Data 0.003 (0.004) Batch 0.530 (0.617) Remain 12:24:04 loss: 7.9457 mask_loss: 6.9531 roll_mask_loss: 8.2848 density_loss: 9.2339 unmask_loss: 8.0878 Lr: 0.00195
[2025-12-10 17:15:07,991 INFO misc.py line 117 4140988] Train: [1/10][1689/7400] Data 0.003 (0.004) Batch 0.266 (0.617) Remain 12:23:48 loss: 8.4307 mask_loss: 8.1744 roll_mask_loss: 8.4188 density_loss: 8.7174 unmask_loss: 8.3905 Lr: 0.00195
[2025-12-10 17:15:08,519 INFO misc.py line 117 4140988] Train: [1/10][1690/7400] Data 0.003 (0.004) Batch 0.528 (0.617) Remain 12:23:44 loss: 8.0132 mask_loss: 7.7426 roll_mask_loss: 7.9253 density_loss: 8.3922 unmask_loss: 8.0246 Lr: 0.00195
[2025-12-10 17:15:09,254 INFO misc.py line 117 4140988] Train: [1/10][1691/7400] Data 0.003 (0.004) Batch 0.734 (0.617) Remain 12:23:48 loss: 6.9169 mask_loss: 6.0053 roll_mask_loss: 6.7482 density_loss: 9.6349 unmask_loss: 7.2644 Lr: 0.00196
[2025-12-10 17:15:09,949 INFO misc.py line 117 4140988] Train: [1/10][1692/7400] Data 0.004 (0.004) Batch 0.696 (0.617) Remain 12:23:51 loss: 7.0548 mask_loss: 5.8735 roll_mask_loss: 6.8894 density_loss: 9.7268 unmask_loss: 7.5336 Lr: 0.00196
[2025-12-10 17:15:10,531 INFO misc.py line 117 4140988] Train: [1/10][1693/7400] Data 0.003 (0.004) Batch 0.581 (0.617) Remain 12:23:49 loss: 8.3848 mask_loss: 8.2122 roll_mask_loss: 8.3366 density_loss: 8.4070 unmask_loss: 8.3271 Lr: 0.00196
[2025-12-10 17:15:11,209 INFO misc.py line 117 4140988] Train: [1/10][1694/7400] Data 0.004 (0.004) Batch 0.678 (0.617) Remain 12:23:51 loss: 6.9977 mask_loss: 6.2219 roll_mask_loss: 6.9067 density_loss: 9.0874 unmask_loss: 7.2493 Lr: 0.00196
[2025-12-10 17:15:11,859 INFO misc.py line 117 4140988] Train: [1/10][1695/7400] Data 0.003 (0.004) Batch 0.651 (0.617) Remain 12:23:52 loss: 7.6951 mask_loss: 7.3368 roll_mask_loss: 7.6844 density_loss: 8.3265 unmask_loss: 7.7130 Lr: 0.00196
[2025-12-10 17:15:12,398 INFO misc.py line 117 4140988] Train: [1/10][1696/7400] Data 0.003 (0.004) Batch 0.539 (0.617) Remain 12:23:48 loss: 7.4401 mask_loss: 6.8766 roll_mask_loss: 7.4771 density_loss: 8.6482 unmask_loss: 7.5303 Lr: 0.00196
[2025-12-10 17:15:13,006 INFO misc.py line 117 4140988] Train: [1/10][1697/7400] Data 0.003 (0.004) Batch 0.608 (0.617) Remain 12:23:47 loss: 6.8730 mask_loss: 6.1574 roll_mask_loss: 6.6771 density_loss: 9.2795 unmask_loss: 7.1432 Lr: 0.00196
[2025-12-10 17:15:13,292 INFO misc.py line 117 4140988] Train: [1/10][1698/7400] Data 0.003 (0.004) Batch 0.286 (0.617) Remain 12:23:32 loss: 7.7402 mask_loss: 7.2086 roll_mask_loss: 7.6855 density_loss: 9.2488 unmask_loss: 7.8483 Lr: 0.00197
[2025-12-10 17:15:13,770 INFO misc.py line 117 4140988] Train: [1/10][1699/7400] Data 0.003 (0.004) Batch 0.477 (0.617) Remain 12:23:25 loss: 8.2351 mask_loss: 7.8645 roll_mask_loss: 8.2203 density_loss: 8.5655 unmask_loss: 8.2565 Lr: 0.00197
[2025-12-10 17:15:14,335 INFO misc.py line 117 4140988] Train: [1/10][1700/7400] Data 0.004 (0.004) Batch 0.565 (0.617) Remain 12:23:23 loss: 8.1861 mask_loss: 7.7795 roll_mask_loss: 8.0879 density_loss: 8.7057 unmask_loss: 8.2644 Lr: 0.00197
[2025-12-10 17:15:15,009 INFO misc.py line 117 4140988] Train: [1/10][1701/7400] Data 0.004 (0.004) Batch 0.675 (0.617) Remain 12:23:24 loss: 7.5496 mask_loss: 6.8848 roll_mask_loss: 7.7623 density_loss: 8.8258 unmask_loss: 7.5992 Lr: 0.00197
[2025-12-10 17:15:15,536 INFO misc.py line 117 4140988] Train: [1/10][1702/7400] Data 0.003 (0.004) Batch 0.527 (0.617) Remain 12:23:20 loss: 7.7911 mask_loss: 7.3783 roll_mask_loss: 7.7271 density_loss: 8.4735 unmask_loss: 7.8600 Lr: 0.00197
[2025-12-10 17:15:16,332 INFO misc.py line 117 4140988] Train: [1/10][1703/7400] Data 0.004 (0.004) Batch 0.796 (0.617) Remain 12:23:27 loss: 7.0410 mask_loss: 6.1336 roll_mask_loss: 6.8930 density_loss: 9.2827 unmask_loss: 7.3830 Lr: 0.00197
[2025-12-10 17:15:16,950 INFO misc.py line 117 4140988] Train: [1/10][1704/7400] Data 0.004 (0.004) Batch 0.618 (0.617) Remain 12:23:26 loss: 6.9521 mask_loss: 6.1282 roll_mask_loss: 6.7840 density_loss: 9.1822 unmask_loss: 7.2644 Lr: 0.00198
[2025-12-10 17:15:17,659 INFO misc.py line 117 4140988] Train: [1/10][1705/7400] Data 0.004 (0.004) Batch 0.709 (0.617) Remain 12:23:30 loss: 6.8901 mask_loss: 5.9558 roll_mask_loss: 6.8295 density_loss: 9.0195 unmask_loss: 7.2072 Lr: 0.00198
[2025-12-10 17:15:18,384 INFO misc.py line 117 4140988] Train: [1/10][1706/7400] Data 0.004 (0.004) Batch 0.725 (0.617) Remain 12:23:34 loss: 7.3029 mask_loss: 6.8411 roll_mask_loss: 7.1712 density_loss: 8.2559 unmask_loss: 7.4346 Lr: 0.00198
[2025-12-10 17:15:18,868 INFO misc.py line 117 4140988] Train: [1/10][1707/7400] Data 0.004 (0.004) Batch 0.484 (0.617) Remain 12:23:27 loss: 8.4164 mask_loss: 8.2412 roll_mask_loss: 8.3784 density_loss: 8.4493 unmask_loss: 8.3540 Lr: 0.00198
[2025-12-10 17:15:19,375 INFO misc.py line 117 4140988] Train: [1/10][1708/7400] Data 0.003 (0.004) Batch 0.507 (0.617) Remain 12:23:22 loss: 7.2383 mask_loss: 6.6325 roll_mask_loss: 7.1430 density_loss: 9.0052 unmask_loss: 7.4087 Lr: 0.00198
[2025-12-10 17:15:20,068 INFO misc.py line 117 4140988] Train: [1/10][1709/7400] Data 0.003 (0.004) Batch 0.693 (0.617) Remain 12:23:25 loss: 6.9477 mask_loss: 5.9756 roll_mask_loss: 6.9407 density_loss: 9.4151 unmask_loss: 7.2490 Lr: 0.00198
[2025-12-10 17:15:20,686 INFO misc.py line 117 4140988] Train: [1/10][1710/7400] Data 0.004 (0.004) Batch 0.618 (0.617) Remain 12:23:24 loss: 6.9524 mask_loss: 6.2017 roll_mask_loss: 6.7147 density_loss: 8.8818 unmask_loss: 7.2689 Lr: 0.00198
[2025-12-10 17:15:20,973 INFO misc.py line 117 4140988] Train: [1/10][1711/7400] Data 0.004 (0.004) Batch 0.287 (0.617) Remain 12:23:10 loss: 8.2188 mask_loss: 7.9573 roll_mask_loss: 8.1605 density_loss: 8.2240 unmask_loss: 8.2143 Lr: 0.00199
[2025-12-10 17:15:21,627 INFO misc.py line 117 4140988] Train: [1/10][1712/7400] Data 0.004 (0.004) Batch 0.654 (0.617) Remain 12:23:11 loss: 7.3960 mask_loss: 6.8534 roll_mask_loss: 7.4308 density_loss: 9.1288 unmask_loss: 7.4675 Lr: 0.00199
[2025-12-10 17:15:22,269 INFO misc.py line 117 4140988] Train: [1/10][1713/7400] Data 0.004 (0.004) Batch 0.642 (0.617) Remain 12:23:11 loss: 7.3724 mask_loss: 6.7829 roll_mask_loss: 7.4359 density_loss: 8.6010 unmask_loss: 7.4634 Lr: 0.00199
[2025-12-10 17:15:22,746 INFO misc.py line 117 4140988] Train: [1/10][1714/7400] Data 0.004 (0.004) Batch 0.477 (0.617) Remain 12:23:04 loss: 7.3374 mask_loss: 6.6801 roll_mask_loss: 7.3088 density_loss: 9.9522 unmask_loss: 7.4813 Lr: 0.00199
[2025-12-10 17:15:23,304 INFO misc.py line 117 4140988] Train: [1/10][1715/7400] Data 0.003 (0.004) Batch 0.559 (0.617) Remain 12:23:01 loss: 6.9340 mask_loss: 6.2351 roll_mask_loss: 6.7736 density_loss: 9.1421 unmask_loss: 7.1808 Lr: 0.00199
[2025-12-10 17:15:23,898 INFO misc.py line 117 4140988] Train: [1/10][1716/7400] Data 0.003 (0.004) Batch 0.593 (0.617) Remain 12:23:00 loss: 6.9208 mask_loss: 6.0626 roll_mask_loss: 6.8857 density_loss: 8.4166 unmask_loss: 7.1992 Lr: 0.00199
[2025-12-10 17:15:24,464 INFO misc.py line 117 4140988] Train: [1/10][1717/7400] Data 0.004 (0.004) Batch 0.566 (0.617) Remain 12:22:57 loss: 6.8442 mask_loss: 5.9240 roll_mask_loss: 6.6787 density_loss: 9.6741 unmask_loss: 7.1936 Lr: 0.00199
[2025-12-10 17:15:25,069 INFO misc.py line 117 4140988] Train: [1/10][1718/7400] Data 0.004 (0.004) Batch 0.605 (0.617) Remain 12:22:56 loss: 8.0716 mask_loss: 7.5314 roll_mask_loss: 7.8149 density_loss: 8.1606 unmask_loss: 8.3069 Lr: 0.00200
[2025-12-10 17:15:25,648 INFO misc.py line 117 4140988] Train: [1/10][1719/7400] Data 0.004 (0.004) Batch 0.580 (0.617) Remain 12:22:54 loss: 7.2736 mask_loss: 6.7772 roll_mask_loss: 7.1220 density_loss: 8.6172 unmask_loss: 7.4253 Lr: 0.00200
[2025-12-10 17:15:26,477 INFO misc.py line 117 4140988] Train: [1/10][1720/7400] Data 0.004 (0.004) Batch 0.829 (0.617) Remain 12:23:02 loss: 7.0321 mask_loss: 6.3152 roll_mask_loss: 6.8478 density_loss: 9.9093 unmask_loss: 7.2845 Lr: 0.00200
[2025-12-10 17:15:26,828 INFO misc.py line 117 4140988] Train: [1/10][1721/7400] Data 0.003 (0.004) Batch 0.350 (0.617) Remain 12:22:50 loss: 7.0304 mask_loss: 6.2165 roll_mask_loss: 6.7625 density_loss: 9.5191 unmask_loss: 7.3809 Lr: 0.00200
[2025-12-10 17:15:27,464 INFO misc.py line 117 4140988] Train: [1/10][1722/7400] Data 0.004 (0.004) Batch 0.636 (0.617) Remain 12:22:50 loss: 7.0957 mask_loss: 6.2292 roll_mask_loss: 7.0878 density_loss: 8.9351 unmask_loss: 7.3541 Lr: 0.00200
[2025-12-10 17:15:27,998 INFO misc.py line 117 4140988] Train: [1/10][1723/7400] Data 0.003 (0.004) Batch 0.534 (0.617) Remain 12:22:46 loss: 8.3613 mask_loss: 8.2066 roll_mask_loss: 8.2559 density_loss: 8.3997 unmask_loss: 8.3234 Lr: 0.00200
[2025-12-10 17:15:28,480 INFO misc.py line 117 4140988] Train: [1/10][1724/7400] Data 0.004 (0.004) Batch 0.482 (0.617) Remain 12:22:40 loss: 7.5608 mask_loss: 7.0527 roll_mask_loss: 7.1381 density_loss: 8.4430 unmask_loss: 7.8573 Lr: 0.00201
[2025-12-10 17:15:29,199 INFO misc.py line 117 4140988] Train: [1/10][1725/7400] Data 0.004 (0.004) Batch 0.719 (0.617) Remain 12:22:44 loss: 6.8352 mask_loss: 5.8529 roll_mask_loss: 6.7662 density_loss: 8.4886 unmask_loss: 7.1911 Lr: 0.00201
[2025-12-10 17:15:29,744 INFO misc.py line 117 4140988] Train: [1/10][1726/7400] Data 0.004 (0.004) Batch 0.545 (0.617) Remain 12:22:40 loss: 7.2128 mask_loss: 6.5417 roll_mask_loss: 7.3188 density_loss: 9.7195 unmask_loss: 7.3010 Lr: 0.00201
[2025-12-10 17:15:30,295 INFO misc.py line 117 4140988] Train: [1/10][1727/7400] Data 0.003 (0.004) Batch 0.552 (0.617) Remain 12:22:37 loss: 8.4234 mask_loss: 8.3341 roll_mask_loss: 8.3440 density_loss: 8.3422 unmask_loss: 8.3408 Lr: 0.00201
[2025-12-10 17:15:30,925 INFO misc.py line 117 4140988] Train: [1/10][1728/7400] Data 0.003 (0.004) Batch 0.629 (0.617) Remain 12:22:37 loss: 7.4813 mask_loss: 6.9566 roll_mask_loss: 7.5185 density_loss: 8.8057 unmask_loss: 7.5489 Lr: 0.00201
[2025-12-10 17:15:31,630 INFO misc.py line 117 4140988] Train: [1/10][1729/7400] Data 0.003 (0.004) Batch 0.704 (0.617) Remain 12:22:40 loss: 6.8907 mask_loss: 6.0262 roll_mask_loss: 6.8809 density_loss: 9.3276 unmask_loss: 7.1414 Lr: 0.00201
[2025-12-10 17:15:32,197 INFO misc.py line 117 4140988] Train: [1/10][1730/7400] Data 0.004 (0.004) Batch 0.567 (0.617) Remain 12:22:37 loss: 7.9796 mask_loss: 7.3957 roll_mask_loss: 8.1794 density_loss: 8.5400 unmask_loss: 8.0008 Lr: 0.00201
[2025-12-10 17:15:32,826 INFO misc.py line 117 4140988] Train: [1/10][1731/7400] Data 0.004 (0.004) Batch 0.630 (0.617) Remain 12:22:37 loss: 6.9807 mask_loss: 6.1443 roll_mask_loss: 6.7755 density_loss: 9.3088 unmask_loss: 7.3154 Lr: 0.00202
[2025-12-10 17:15:33,501 INFO misc.py line 117 4140988] Train: [1/10][1732/7400] Data 0.003 (0.004) Batch 0.674 (0.617) Remain 12:22:39 loss: 7.0301 mask_loss: 6.1204 roll_mask_loss: 6.7462 density_loss: 8.8877 unmask_loss: 7.4491 Lr: 0.00202
[2025-12-10 17:15:34,265 INFO misc.py line 117 4140988] Train: [1/10][1733/7400] Data 0.004 (0.004) Batch 0.764 (0.617) Remain 12:22:44 loss: 6.9715 mask_loss: 6.2253 roll_mask_loss: 6.7581 density_loss: 8.9503 unmask_loss: 7.2724 Lr: 0.00202
[2025-12-10 17:15:34,948 INFO misc.py line 117 4140988] Train: [1/10][1734/7400] Data 0.004 (0.004) Batch 0.683 (0.617) Remain 12:22:47 loss: 7.3302 mask_loss: 6.6547 roll_mask_loss: 7.2230 density_loss: 8.5989 unmask_loss: 7.5496 Lr: 0.00202
[2025-12-10 17:15:35,709 INFO misc.py line 117 4140988] Train: [1/10][1735/7400] Data 0.004 (0.004) Batch 0.762 (0.617) Remain 12:22:52 loss: 6.8557 mask_loss: 5.9297 roll_mask_loss: 6.9375 density_loss: 8.9847 unmask_loss: 7.0981 Lr: 0.00202
[2025-12-10 17:15:36,341 INFO misc.py line 117 4140988] Train: [1/10][1736/7400] Data 0.003 (0.004) Batch 0.632 (0.617) Remain 12:22:52 loss: 7.3449 mask_loss: 6.7820 roll_mask_loss: 7.0970 density_loss: 8.9340 unmask_loss: 7.5717 Lr: 0.00202
[2025-12-10 17:15:36,961 INFO misc.py line 117 4140988] Train: [1/10][1737/7400] Data 0.003 (0.004) Batch 0.619 (0.617) Remain 12:22:51 loss: 7.7325 mask_loss: 6.8944 roll_mask_loss: 7.8960 density_loss: 8.6489 unmask_loss: 7.8968 Lr: 0.00203
[2025-12-10 17:15:37,302 INFO misc.py line 117 4140988] Train: [1/10][1738/7400] Data 0.004 (0.004) Batch 0.341 (0.617) Remain 12:22:39 loss: 7.2917 mask_loss: 6.6370 roll_mask_loss: 7.1914 density_loss: 8.7356 unmask_loss: 7.4945 Lr: 0.00203
[2025-12-10 17:15:37,708 INFO misc.py line 117 4140988] Train: [1/10][1739/7400] Data 0.004 (0.004) Batch 0.405 (0.617) Remain 12:22:30 loss: 7.3315 mask_loss: 6.8249 roll_mask_loss: 7.1736 density_loss: 9.1090 unmask_loss: 7.4815 Lr: 0.00203
[2025-12-10 17:15:38,326 INFO misc.py line 117 4140988] Train: [1/10][1740/7400] Data 0.004 (0.004) Batch 0.618 (0.617) Remain 12:22:29 loss: 7.3689 mask_loss: 6.7258 roll_mask_loss: 7.2532 density_loss: 9.2021 unmask_loss: 7.5643 Lr: 0.00203
[2025-12-10 17:15:39,170 INFO misc.py line 117 4140988] Train: [1/10][1741/7400] Data 0.004 (0.004) Batch 0.844 (0.617) Remain 12:22:38 loss: 6.9206 mask_loss: 6.0316 roll_mask_loss: 6.8322 density_loss: 9.1630 unmask_loss: 7.2260 Lr: 0.00203
[2025-12-10 17:15:39,931 INFO misc.py line 117 4140988] Train: [1/10][1742/7400] Data 0.004 (0.004) Batch 0.762 (0.617) Remain 12:22:44 loss: 6.8317 mask_loss: 6.0302 roll_mask_loss: 6.7522 density_loss: 9.0286 unmask_loss: 7.0916 Lr: 0.00203
[2025-12-10 17:15:40,743 INFO misc.py line 117 4140988] Train: [1/10][1743/7400] Data 0.004 (0.004) Batch 0.812 (0.617) Remain 12:22:51 loss: 6.8170 mask_loss: 5.9712 roll_mask_loss: 6.6169 density_loss: 9.3451 unmask_loss: 7.1531 Lr: 0.00203
[2025-12-10 17:15:41,275 INFO misc.py line 117 4140988] Train: [1/10][1744/7400] Data 0.003 (0.004) Batch 0.532 (0.617) Remain 12:22:47 loss: 7.0889 mask_loss: 6.3500 roll_mask_loss: 7.0050 density_loss: 7.0280 unmask_loss: 7.3597 Lr: 0.00204
[2025-12-10 17:15:41,965 INFO misc.py line 117 4140988] Train: [1/10][1745/7400] Data 0.003 (0.004) Batch 0.688 (0.617) Remain 12:22:49 loss: 7.4651 mask_loss: 6.7309 roll_mask_loss: 7.4001 density_loss: 9.4401 unmask_loss: 7.6758 Lr: 0.00204
[2025-12-10 17:15:42,687 INFO misc.py line 117 4140988] Train: [1/10][1746/7400] Data 0.004 (0.004) Batch 0.723 (0.617) Remain 12:22:53 loss: 7.1846 mask_loss: 6.6256 roll_mask_loss: 7.2037 density_loss: 8.8226 unmask_loss: 7.2781 Lr: 0.00204
[2025-12-10 17:15:43,299 INFO misc.py line 117 4140988] Train: [1/10][1747/7400] Data 0.003 (0.004) Batch 0.612 (0.617) Remain 12:22:52 loss: 7.0108 mask_loss: 6.2210 roll_mask_loss: 6.9002 density_loss: 8.3251 unmask_loss: 7.2945 Lr: 0.00204
[2025-12-10 17:15:43,854 INFO misc.py line 117 4140988] Train: [1/10][1748/7400] Data 0.003 (0.004) Batch 0.555 (0.617) Remain 12:22:49 loss: 7.1248 mask_loss: 6.4664 roll_mask_loss: 6.9308 density_loss: 9.0107 unmask_loss: 7.3709 Lr: 0.00204
[2025-12-10 17:15:44,376 INFO misc.py line 117 4140988] Train: [1/10][1749/7400] Data 0.004 (0.004) Batch 0.522 (0.617) Remain 12:22:45 loss: 6.9392 mask_loss: 6.1933 roll_mask_loss: 6.7933 density_loss: 9.3040 unmask_loss: 7.1990 Lr: 0.00204
[2025-12-10 17:15:44,858 INFO misc.py line 117 4140988] Train: [1/10][1750/7400] Data 0.004 (0.004) Batch 0.481 (0.617) Remain 12:22:38 loss: 7.7635 mask_loss: 7.3137 roll_mask_loss: 7.7364 density_loss: 8.9892 unmask_loss: 7.8221 Lr: 0.00205
[2025-12-10 17:15:45,374 INFO misc.py line 117 4140988] Train: [1/10][1751/7400] Data 0.004 (0.004) Batch 0.516 (0.617) Remain 12:22:34 loss: 8.1844 mask_loss: 7.8050 roll_mask_loss: 8.2009 density_loss: 8.7289 unmask_loss: 8.1914 Lr: 0.00205
[2025-12-10 17:15:46,065 INFO misc.py line 117 4140988] Train: [1/10][1752/7400] Data 0.004 (0.004) Batch 0.691 (0.617) Remain 12:22:36 loss: 7.0403 mask_loss: 6.2570 roll_mask_loss: 6.7954 density_loss: 8.9430 unmask_loss: 7.3755 Lr: 0.00205
[2025-12-10 17:15:46,886 INFO misc.py line 117 4140988] Train: [1/10][1753/7400] Data 0.004 (0.004) Batch 0.821 (0.617) Remain 12:22:44 loss: 7.1222 mask_loss: 6.1427 roll_mask_loss: 7.3037 density_loss: 9.9794 unmask_loss: 7.3217 Lr: 0.00205
[2025-12-10 17:15:47,470 INFO misc.py line 117 4140988] Train: [1/10][1754/7400] Data 0.004 (0.004) Batch 0.584 (0.617) Remain 12:22:42 loss: 7.3617 mask_loss: 6.9450 roll_mask_loss: 7.1267 density_loss: 8.7251 unmask_loss: 7.5131 Lr: 0.00205
[2025-12-10 17:15:48,004 INFO misc.py line 117 4140988] Train: [1/10][1755/7400] Data 0.004 (0.004) Batch 0.534 (0.617) Remain 12:22:38 loss: 8.3183 mask_loss: 7.9156 roll_mask_loss: 8.4080 density_loss: 8.3673 unmask_loss: 8.3074 Lr: 0.00205
[2025-12-10 17:15:48,594 INFO misc.py line 117 4140988] Train: [1/10][1756/7400] Data 0.004 (0.004) Batch 0.590 (0.617) Remain 12:22:36 loss: 7.0496 mask_loss: 6.2904 roll_mask_loss: 7.1612 density_loss: 8.7310 unmask_loss: 7.1989 Lr: 0.00205
[2025-12-10 17:15:49,274 INFO misc.py line 117 4140988] Train: [1/10][1757/7400] Data 0.004 (0.004) Batch 0.680 (0.617) Remain 12:22:38 loss: 7.6535 mask_loss: 7.2907 roll_mask_loss: 7.5622 density_loss: 8.5784 unmask_loss: 7.7090 Lr: 0.00206
[2025-12-10 17:15:49,907 INFO misc.py line 117 4140988] Train: [1/10][1758/7400] Data 0.004 (0.004) Batch 0.633 (0.617) Remain 12:22:38 loss: 7.5917 mask_loss: 6.9805 roll_mask_loss: 7.4766 density_loss: 8.5645 unmask_loss: 7.7836 Lr: 0.00206
[2025-12-10 17:15:50,589 INFO misc.py line 117 4140988] Train: [1/10][1759/7400] Data 0.004 (0.004) Batch 0.682 (0.617) Remain 12:22:40 loss: 6.8508 mask_loss: 5.9717 roll_mask_loss: 6.6862 density_loss: 9.5905 unmask_loss: 7.1809 Lr: 0.00206
[2025-12-10 17:15:51,303 INFO misc.py line 117 4140988] Train: [1/10][1760/7400] Data 0.004 (0.004) Batch 0.714 (0.617) Remain 12:22:44 loss: 7.7908 mask_loss: 7.3399 roll_mask_loss: 7.7178 density_loss: 8.4498 unmask_loss: 7.8839 Lr: 0.00206
[2025-12-10 17:15:52,015 INFO misc.py line 117 4140988] Train: [1/10][1761/7400] Data 0.003 (0.004) Batch 0.712 (0.617) Remain 12:22:47 loss: 6.8959 mask_loss: 6.1120 roll_mask_loss: 6.5637 density_loss: 9.2024 unmask_loss: 7.2700 Lr: 0.00206
[2025-12-10 17:15:52,925 INFO misc.py line 117 4140988] Train: [1/10][1762/7400] Data 0.003 (0.004) Batch 0.911 (0.617) Remain 12:22:58 loss: 7.0981 mask_loss: 6.0526 roll_mask_loss: 7.0535 density_loss: 9.4383 unmask_loss: 7.4544 Lr: 0.00206
[2025-12-10 17:15:53,748 INFO misc.py line 117 4140988] Train: [1/10][1763/7400] Data 0.003 (0.004) Batch 0.822 (0.617) Remain 12:23:06 loss: 6.7556 mask_loss: 5.9913 roll_mask_loss: 6.5420 density_loss: 8.5629 unmask_loss: 7.0732 Lr: 0.00206
[2025-12-10 17:15:54,387 INFO misc.py line 117 4140988] Train: [1/10][1764/7400] Data 0.003 (0.004) Batch 0.640 (0.617) Remain 12:23:07 loss: 6.7856 mask_loss: 5.7556 roll_mask_loss: 6.6720 density_loss: 9.5794 unmask_loss: 7.1658 Lr: 0.00207
[2025-12-10 17:15:54,937 INFO misc.py line 117 4140988] Train: [1/10][1765/7400] Data 0.003 (0.004) Batch 0.549 (0.617) Remain 12:23:03 loss: 7.7103 mask_loss: 7.0672 roll_mask_loss: 7.9916 density_loss: 9.0653 unmask_loss: 7.7099 Lr: 0.00207
[2025-12-10 17:15:55,678 INFO misc.py line 117 4140988] Train: [1/10][1766/7400] Data 0.004 (0.004) Batch 0.740 (0.617) Remain 12:23:08 loss: 7.1004 mask_loss: 6.2387 roll_mask_loss: 7.4511 density_loss: 8.6353 unmask_loss: 7.1832 Lr: 0.00207
[2025-12-10 17:15:56,289 INFO misc.py line 117 4140988] Train: [1/10][1767/7400] Data 0.005 (0.004) Batch 0.612 (0.617) Remain 12:23:07 loss: 7.9406 mask_loss: 7.4660 roll_mask_loss: 8.0058 density_loss: 8.2954 unmask_loss: 7.9794 Lr: 0.00207
[2025-12-10 17:15:56,921 INFO misc.py line 117 4140988] Train: [1/10][1768/7400] Data 0.004 (0.004) Batch 0.632 (0.617) Remain 12:23:07 loss: 8.4240 mask_loss: 7.9744 roll_mask_loss: 8.4703 density_loss: 8.6444 unmask_loss: 8.4528 Lr: 0.00207
[2025-12-10 17:15:57,423 INFO misc.py line 117 4140988] Train: [1/10][1769/7400] Data 0.004 (0.004) Batch 0.502 (0.617) Remain 12:23:01 loss: 8.4406 mask_loss: 8.3370 roll_mask_loss: 8.3586 density_loss: 8.3607 unmask_loss: 8.3661 Lr: 0.00207
[2025-12-10 17:15:57,909 INFO misc.py line 117 4140988] Train: [1/10][1770/7400] Data 0.004 (0.004) Batch 0.486 (0.617) Remain 12:22:55 loss: 8.4249 mask_loss: 8.3257 roll_mask_loss: 8.3443 density_loss: 8.3453 unmask_loss: 8.3479 Lr: 0.00208
[2025-12-10 17:15:58,628 INFO misc.py line 117 4140988] Train: [1/10][1771/7400] Data 0.004 (0.004) Batch 0.719 (0.617) Remain 12:22:59 loss: 7.1996 mask_loss: 6.5050 roll_mask_loss: 7.0792 density_loss: 9.2746 unmask_loss: 7.4216 Lr: 0.00208
[2025-12-10 17:15:58,916 INFO misc.py line 117 4140988] Train: [1/10][1772/7400] Data 0.004 (0.004) Batch 0.289 (0.617) Remain 12:22:45 loss: 7.8975 mask_loss: 6.3393 roll_mask_loss: 8.2194 density_loss: 8.6340 unmask_loss: 8.3429 Lr: 0.00208
[2025-12-10 17:15:59,454 INFO misc.py line 117 4140988] Train: [1/10][1773/7400] Data 0.004 (0.004) Batch 0.538 (0.617) Remain 12:22:41 loss: 6.9849 mask_loss: 6.3133 roll_mask_loss: 6.7622 density_loss: 9.5128 unmask_loss: 7.2418 Lr: 0.00208
[2025-12-10 17:15:59,975 INFO misc.py line 117 4140988] Train: [1/10][1774/7400] Data 0.003 (0.004) Batch 0.522 (0.617) Remain 12:22:37 loss: 8.0324 mask_loss: 7.4722 roll_mask_loss: 8.0064 density_loss: 8.3853 unmask_loss: 8.1578 Lr: 0.00208
[2025-12-10 17:16:00,552 INFO misc.py line 117 4140988] Train: [1/10][1775/7400] Data 0.003 (0.004) Batch 0.577 (0.617) Remain 12:22:34 loss: 6.9334 mask_loss: 6.0942 roll_mask_loss: 6.8470 density_loss: 8.7486 unmask_loss: 7.2212 Lr: 0.00208
[2025-12-10 17:16:01,037 INFO misc.py line 117 4140988] Train: [1/10][1776/7400] Data 0.003 (0.004) Batch 0.485 (0.617) Remain 12:22:28 loss: 8.0666 mask_loss: 7.6600 roll_mask_loss: 7.9635 density_loss: 8.6752 unmask_loss: 8.1478 Lr: 0.00208
[2025-12-10 17:16:01,693 INFO misc.py line 117 4140988] Train: [1/10][1777/7400] Data 0.003 (0.004) Batch 0.655 (0.617) Remain 12:22:29 loss: 7.0314 mask_loss: 6.1658 roll_mask_loss: 7.0026 density_loss: 8.8978 unmask_loss: 7.3006 Lr: 0.00209
[2025-12-10 17:16:02,173 INFO misc.py line 117 4140988] Train: [1/10][1778/7400] Data 0.004 (0.004) Batch 0.480 (0.617) Remain 12:22:23 loss: 7.8633 mask_loss: 7.3131 roll_mask_loss: 7.7978 density_loss: 8.6177 unmask_loss: 7.9988 Lr: 0.00209
[2025-12-10 17:16:02,722 INFO misc.py line 117 4140988] Train: [1/10][1779/7400] Data 0.004 (0.004) Batch 0.549 (0.617) Remain 12:22:20 loss: 7.1208 mask_loss: 6.4344 roll_mask_loss: 6.9308 density_loss: 8.1741 unmask_loss: 7.3956 Lr: 0.00209
[2025-12-10 17:16:03,399 INFO misc.py line 117 4140988] Train: [1/10][1780/7400] Data 0.004 (0.004) Batch 0.678 (0.617) Remain 12:22:22 loss: 7.0675 mask_loss: 6.4504 roll_mask_loss: 6.9915 density_loss: 9.3214 unmask_loss: 7.2276 Lr: 0.00209
[2025-12-10 17:16:04,153 INFO misc.py line 117 4140988] Train: [1/10][1781/7400] Data 0.004 (0.004) Batch 0.754 (0.617) Remain 12:22:26 loss: 6.8160 mask_loss: 6.1235 roll_mask_loss: 6.5209 density_loss: 9.4227 unmask_loss: 7.1214 Lr: 0.00209
[2025-12-10 17:16:04,811 INFO misc.py line 117 4140988] Train: [1/10][1782/7400] Data 0.003 (0.004) Batch 0.658 (0.617) Remain 12:22:28 loss: 7.0908 mask_loss: 6.2424 roll_mask_loss: 7.0158 density_loss: 9.5995 unmask_loss: 7.3604 Lr: 0.00209
[2025-12-10 17:16:05,357 INFO misc.py line 117 4140988] Train: [1/10][1783/7400] Data 0.004 (0.004) Batch 0.546 (0.617) Remain 12:22:24 loss: 8.3858 mask_loss: 8.1713 roll_mask_loss: 8.4351 density_loss: 8.6956 unmask_loss: 8.2945 Lr: 0.00210
[2025-12-10 17:16:06,189 INFO misc.py line 117 4140988] Train: [1/10][1784/7400] Data 0.004 (0.004) Batch 0.833 (0.617) Remain 12:22:32 loss: 6.8334 mask_loss: 5.8392 roll_mask_loss: 6.8157 density_loss: 9.5223 unmask_loss: 7.1489 Lr: 0.00210
[2025-12-10 17:16:06,840 INFO misc.py line 117 4140988] Train: [1/10][1785/7400] Data 0.004 (0.004) Batch 0.651 (0.617) Remain 12:22:33 loss: 7.8496 mask_loss: 7.4982 roll_mask_loss: 8.0054 density_loss: 8.4495 unmask_loss: 7.7783 Lr: 0.00210
[2025-12-10 17:16:07,512 INFO misc.py line 117 4140988] Train: [1/10][1786/7400] Data 0.004 (0.004) Batch 0.672 (0.617) Remain 12:22:35 loss: 7.5700 mask_loss: 7.0144 roll_mask_loss: 7.7220 density_loss: 8.6237 unmask_loss: 7.5993 Lr: 0.00210
[2025-12-10 17:16:08,286 INFO misc.py line 117 4140988] Train: [1/10][1787/7400] Data 0.003 (0.004) Batch 0.773 (0.617) Remain 12:22:40 loss: 6.8800 mask_loss: 5.8227 roll_mask_loss: 6.7851 density_loss: 8.5743 unmask_loss: 7.2847 Lr: 0.00210
[2025-12-10 17:16:08,895 INFO misc.py line 117 4140988] Train: [1/10][1788/7400] Data 0.004 (0.004) Batch 0.609 (0.617) Remain 12:22:39 loss: 7.1746 mask_loss: 6.4169 roll_mask_loss: 7.0577 density_loss: 8.4026 unmask_loss: 7.4439 Lr: 0.00210
[2025-12-10 17:16:09,517 INFO misc.py line 117 4140988] Train: [1/10][1789/7400] Data 0.004 (0.004) Batch 0.622 (0.617) Remain 12:22:39 loss: 7.0070 mask_loss: 6.3501 roll_mask_loss: 6.8804 density_loss: 8.6714 unmask_loss: 7.2253 Lr: 0.00210
[2025-12-10 17:16:10,091 INFO misc.py line 117 4140988] Train: [1/10][1790/7400] Data 0.004 (0.004) Batch 0.575 (0.617) Remain 12:22:37 loss: 7.9685 mask_loss: 7.5790 roll_mask_loss: 7.9377 density_loss: 8.8085 unmask_loss: 8.0024 Lr: 0.00211
[2025-12-10 17:16:10,606 INFO misc.py line 117 4140988] Train: [1/10][1791/7400] Data 0.003 (0.004) Batch 0.515 (0.617) Remain 12:22:32 loss: 7.9214 mask_loss: 7.2783 roll_mask_loss: 7.8532 density_loss: 8.6203 unmask_loss: 8.1047 Lr: 0.00211
[2025-12-10 17:16:11,195 INFO misc.py line 117 4140988] Train: [1/10][1792/7400] Data 0.003 (0.004) Batch 0.590 (0.617) Remain 12:22:30 loss: 8.4312 mask_loss: 8.3492 roll_mask_loss: 8.3651 density_loss: 8.3602 unmask_loss: 8.3380 Lr: 0.00211
[2025-12-10 17:16:11,799 INFO misc.py line 117 4140988] Train: [1/10][1793/7400] Data 0.003 (0.004) Batch 0.604 (0.617) Remain 12:22:29 loss: 8.1760 mask_loss: 7.7372 roll_mask_loss: 8.6009 density_loss: 8.5431 unmask_loss: 8.0121 Lr: 0.00211
[2025-12-10 17:16:12,421 INFO misc.py line 117 4140988] Train: [1/10][1794/7400] Data 0.004 (0.004) Batch 0.621 (0.617) Remain 12:22:28 loss: 7.4827 mask_loss: 6.8448 roll_mask_loss: 7.4167 density_loss: 9.5255 unmask_loss: 7.6441 Lr: 0.00211
[2025-12-10 17:16:12,951 INFO misc.py line 117 4140988] Train: [1/10][1795/7400] Data 0.004 (0.004) Batch 0.531 (0.617) Remain 12:22:24 loss: 8.0049 mask_loss: 7.6561 roll_mask_loss: 8.0857 density_loss: 8.5394 unmask_loss: 7.9681 Lr: 0.00211
[2025-12-10 17:16:13,599 INFO misc.py line 117 4140988] Train: [1/10][1796/7400] Data 0.004 (0.004) Batch 0.648 (0.617) Remain 12:22:25 loss: 7.3085 mask_loss: 6.8662 roll_mask_loss: 7.2502 density_loss: 9.0646 unmask_loss: 7.3776 Lr: 0.00212
[2025-12-10 17:16:14,260 INFO misc.py line 117 4140988] Train: [1/10][1797/7400] Data 0.003 (0.004) Batch 0.660 (0.617) Remain 12:22:26 loss: 7.7177 mask_loss: 7.3539 roll_mask_loss: 7.6912 density_loss: 8.3699 unmask_loss: 7.7453 Lr: 0.00212
[2025-12-10 17:16:14,879 INFO misc.py line 117 4140988] Train: [1/10][1798/7400] Data 0.004 (0.004) Batch 0.619 (0.617) Remain 12:22:26 loss: 7.0413 mask_loss: 6.5226 roll_mask_loss: 6.9136 density_loss: 9.4405 unmask_loss: 7.1757 Lr: 0.00212
[2025-12-10 17:16:15,576 INFO misc.py line 117 4140988] Train: [1/10][1799/7400] Data 0.004 (0.004) Batch 0.697 (0.617) Remain 12:22:28 loss: 7.8982 mask_loss: 7.3746 roll_mask_loss: 7.8969 density_loss: 8.5057 unmask_loss: 7.9906 Lr: 0.00212
[2025-12-10 17:16:16,324 INFO misc.py line 117 4140988] Train: [1/10][1800/7400] Data 0.004 (0.004) Batch 0.749 (0.617) Remain 12:22:33 loss: 6.9420 mask_loss: 5.9681 roll_mask_loss: 6.8387 density_loss: 9.4261 unmask_loss: 7.2920 Lr: 0.00212
[2025-12-10 17:16:17,072 INFO misc.py line 117 4140988] Train: [1/10][1801/7400] Data 0.003 (0.004) Batch 0.748 (0.617) Remain 12:22:38 loss: 6.8922 mask_loss: 5.7674 roll_mask_loss: 6.9892 density_loss: 10.1396 unmask_loss: 7.2033 Lr: 0.00212
[2025-12-10 17:16:17,817 INFO misc.py line 117 4140988] Train: [1/10][1802/7400] Data 0.004 (0.004) Batch 0.745 (0.617) Remain 12:22:42 loss: 6.9132 mask_loss: 5.8780 roll_mask_loss: 6.7848 density_loss: 9.9035 unmask_loss: 7.2969 Lr: 0.00212
[2025-12-10 17:16:18,462 INFO misc.py line 117 4140988] Train: [1/10][1803/7400] Data 0.004 (0.004) Batch 0.646 (0.617) Remain 12:22:43 loss: 6.9309 mask_loss: 6.1877 roll_mask_loss: 6.7438 density_loss: 8.7192 unmask_loss: 7.2217 Lr: 0.00213
[2025-12-10 17:16:19,021 INFO misc.py line 117 4140988] Train: [1/10][1804/7400] Data 0.004 (0.004) Batch 0.559 (0.617) Remain 12:22:40 loss: 8.1970 mask_loss: 8.0718 roll_mask_loss: 8.3899 density_loss: 8.3398 unmask_loss: 7.9964 Lr: 0.00213
[2025-12-10 17:16:19,324 INFO misc.py line 117 4140988] Train: [1/10][1805/7400] Data 0.003 (0.004) Batch 0.303 (0.617) Remain 12:22:26 loss: 8.4408 mask_loss: 8.3509 roll_mask_loss: 8.3591 density_loss: 8.3603 unmask_loss: 8.3594 Lr: 0.00213
[2025-12-10 17:16:19,957 INFO misc.py line 117 4140988] Train: [1/10][1806/7400] Data 0.003 (0.004) Batch 0.632 (0.617) Remain 12:22:26 loss: 7.6651 mask_loss: 7.2581 roll_mask_loss: 7.3662 density_loss: 8.8022 unmask_loss: 7.8421 Lr: 0.00213
[2025-12-10 17:16:20,898 INFO misc.py line 117 4140988] Train: [1/10][1807/7400] Data 0.003 (0.004) Batch 0.941 (0.617) Remain 12:22:39 loss: 7.0800 mask_loss: 5.9020 roll_mask_loss: 6.8903 density_loss: 9.9009 unmask_loss: 7.5657 Lr: 0.00213
[2025-12-10 17:16:21,578 INFO misc.py line 117 4140988] Train: [1/10][1808/7400] Data 0.003 (0.004) Batch 0.680 (0.617) Remain 12:22:41 loss: 7.0271 mask_loss: 6.2125 roll_mask_loss: 6.9904 density_loss: 8.8576 unmask_loss: 7.2756 Lr: 0.00213
[2025-12-10 17:16:22,241 INFO misc.py line 117 4140988] Train: [1/10][1809/7400] Data 0.003 (0.004) Batch 0.662 (0.617) Remain 12:22:42 loss: 7.4030 mask_loss: 6.4629 roll_mask_loss: 7.7196 density_loss: 8.6186 unmask_loss: 7.5423 Lr: 0.00214
[2025-12-10 17:16:23,098 INFO misc.py line 117 4140988] Train: [1/10][1810/7400] Data 0.003 (0.004) Batch 0.857 (0.617) Remain 12:22:51 loss: 6.8737 mask_loss: 5.9001 roll_mask_loss: 6.6442 density_loss: 8.8967 unmask_loss: 7.2973 Lr: 0.00214
[2025-12-10 17:16:23,777 INFO misc.py line 117 4140988] Train: [1/10][1811/7400] Data 0.003 (0.004) Batch 0.679 (0.617) Remain 12:22:53 loss: 7.0587 mask_loss: 6.1336 roll_mask_loss: 7.0790 density_loss: 9.1962 unmask_loss: 7.3271 Lr: 0.00214
[2025-12-10 17:16:24,422 INFO misc.py line 117 4140988] Train: [1/10][1812/7400] Data 0.004 (0.004) Batch 0.646 (0.617) Remain 12:22:53 loss: 7.1486 mask_loss: 6.5183 roll_mask_loss: 7.2468 density_loss: 9.0316 unmask_loss: 7.2340 Lr: 0.00214
[2025-12-10 17:16:24,913 INFO misc.py line 117 4140988] Train: [1/10][1813/7400] Data 0.003 (0.004) Batch 0.491 (0.617) Remain 12:22:48 loss: 6.8712 mask_loss: 5.9523 roll_mask_loss: 6.7777 density_loss: 9.5297 unmask_loss: 7.1868 Lr: 0.00214
[2025-12-10 17:16:25,515 INFO misc.py line 117 4140988] Train: [1/10][1814/7400] Data 0.003 (0.004) Batch 0.601 (0.617) Remain 12:22:46 loss: 7.1298 mask_loss: 6.3252 roll_mask_loss: 6.9376 density_loss: 9.5658 unmask_loss: 7.4370 Lr: 0.00214
[2025-12-10 17:16:26,079 INFO misc.py line 117 4140988] Train: [1/10][1815/7400] Data 0.004 (0.004) Batch 0.564 (0.617) Remain 12:22:44 loss: 7.7097 mask_loss: 6.7208 roll_mask_loss: 7.8549 density_loss: 8.6229 unmask_loss: 7.9590 Lr: 0.00214
[2025-12-10 17:16:26,675 INFO misc.py line 117 4140988] Train: [1/10][1816/7400] Data 0.004 (0.004) Batch 0.596 (0.617) Remain 12:22:42 loss: 7.5158 mask_loss: 6.8732 roll_mask_loss: 7.3214 density_loss: 9.0766 unmask_loss: 7.7528 Lr: 0.00215
[2025-12-10 17:16:27,274 INFO misc.py line 117 4140988] Train: [1/10][1817/7400] Data 0.004 (0.004) Batch 0.599 (0.617) Remain 12:22:41 loss: 7.5498 mask_loss: 6.9656 roll_mask_loss: 7.5409 density_loss: 8.9467 unmask_loss: 7.6674 Lr: 0.00215
[2025-12-10 17:16:27,965 INFO misc.py line 117 4140988] Train: [1/10][1818/7400] Data 0.004 (0.004) Batch 0.690 (0.617) Remain 12:22:43 loss: 7.1639 mask_loss: 6.1283 roll_mask_loss: 7.3850 density_loss: 9.4448 unmask_loss: 7.3822 Lr: 0.00215
[2025-12-10 17:16:28,585 INFO misc.py line 117 4140988] Train: [1/10][1819/7400] Data 0.004 (0.004) Batch 0.620 (0.617) Remain 12:22:42 loss: 7.5385 mask_loss: 6.8260 roll_mask_loss: 7.7414 density_loss: 8.3210 unmask_loss: 7.6270 Lr: 0.00215
[2025-12-10 17:16:29,131 INFO misc.py line 117 4140988] Train: [1/10][1820/7400] Data 0.004 (0.004) Batch 0.547 (0.617) Remain 12:22:39 loss: 8.4524 mask_loss: 7.7955 roll_mask_loss: 8.7736 density_loss: 8.4889 unmask_loss: 8.4505 Lr: 0.00215
[2025-12-10 17:16:29,728 INFO misc.py line 117 4140988] Train: [1/10][1821/7400] Data 0.004 (0.004) Batch 0.597 (0.617) Remain 12:22:38 loss: 7.5723 mask_loss: 7.0297 roll_mask_loss: 7.7812 density_loss: 8.6447 unmask_loss: 7.5662 Lr: 0.00215
[2025-12-10 17:16:30,254 INFO misc.py line 117 4140988] Train: [1/10][1822/7400] Data 0.004 (0.004) Batch 0.526 (0.617) Remain 12:22:33 loss: 8.2288 mask_loss: 7.9173 roll_mask_loss: 8.1816 density_loss: 8.1169 unmask_loss: 8.2457 Lr: 0.00215
[2025-12-10 17:16:30,757 INFO misc.py line 117 4140988] Train: [1/10][1823/7400] Data 0.004 (0.004) Batch 0.503 (0.617) Remain 12:22:28 loss: 8.4130 mask_loss: 8.3228 roll_mask_loss: 8.3332 density_loss: 8.3317 unmask_loss: 8.3314 Lr: 0.00216
[2025-12-10 17:16:31,289 INFO misc.py line 117 4140988] Train: [1/10][1824/7400] Data 0.004 (0.004) Batch 0.533 (0.617) Remain 12:22:24 loss: 7.1808 mask_loss: 6.3444 roll_mask_loss: 7.1122 density_loss: 9.8124 unmask_loss: 7.4371 Lr: 0.00216
[2025-12-10 17:16:31,895 INFO misc.py line 117 4140988] Train: [1/10][1825/7400] Data 0.004 (0.004) Batch 0.606 (0.617) Remain 12:22:23 loss: 7.2252 mask_loss: 6.4943 roll_mask_loss: 7.0981 density_loss: 8.0620 unmask_loss: 7.4930 Lr: 0.00216
[2025-12-10 17:16:32,480 INFO misc.py line 117 4140988] Train: [1/10][1826/7400] Data 0.004 (0.004) Batch 0.585 (0.617) Remain 12:22:21 loss: 7.3682 mask_loss: 6.4552 roll_mask_loss: 7.1119 density_loss: 8.9006 unmask_loss: 7.7747 Lr: 0.00216
[2025-12-10 17:16:33,204 INFO misc.py line 117 4140988] Train: [1/10][1827/7400] Data 0.004 (0.004) Batch 0.724 (0.617) Remain 12:22:25 loss: 7.6873 mask_loss: 7.3746 roll_mask_loss: 7.7381 density_loss: 8.5730 unmask_loss: 7.6467 Lr: 0.00216
[2025-12-10 17:16:33,751 INFO misc.py line 117 4140988] Train: [1/10][1828/7400] Data 0.004 (0.004) Batch 0.548 (0.617) Remain 12:22:22 loss: 8.4359 mask_loss: 8.3486 roll_mask_loss: 8.3616 density_loss: 8.3680 unmask_loss: 8.3493 Lr: 0.00216
[2025-12-10 17:16:34,652 INFO misc.py line 117 4140988] Train: [1/10][1829/7400] Data 0.003 (0.004) Batch 0.900 (0.617) Remain 12:22:32 loss: 7.1326 mask_loss: 5.9845 roll_mask_loss: 7.1242 density_loss: 10.3349 unmask_loss: 7.5042 Lr: 0.00217
[2025-12-10 17:16:35,224 INFO misc.py line 117 4140988] Train: [1/10][1830/7400] Data 0.004 (0.004) Batch 0.573 (0.617) Remain 12:22:30 loss: 7.4300 mask_loss: 6.6053 roll_mask_loss: 7.5486 density_loss: 8.9250 unmask_loss: 7.6046 Lr: 0.00217
[2025-12-10 17:16:35,843 INFO misc.py line 117 4140988] Train: [1/10][1831/7400] Data 0.003 (0.004) Batch 0.619 (0.617) Remain 12:22:29 loss: 8.0649 mask_loss: 7.5527 roll_mask_loss: 7.8334 density_loss: 8.6896 unmask_loss: 8.2630 Lr: 0.00217
[2025-12-10 17:16:36,464 INFO misc.py line 117 4140988] Train: [1/10][1832/7400] Data 0.003 (0.004) Batch 0.621 (0.617) Remain 12:22:29 loss: 7.4270 mask_loss: 6.8197 roll_mask_loss: 7.2040 density_loss: 8.3787 unmask_loss: 7.6745 Lr: 0.00217
[2025-12-10 17:16:37,051 INFO misc.py line 117 4140988] Train: [1/10][1833/7400] Data 0.003 (0.004) Batch 0.586 (0.617) Remain 12:22:27 loss: 7.1428 mask_loss: 6.3872 roll_mask_loss: 7.0755 density_loss: 9.0304 unmask_loss: 7.3736 Lr: 0.00217
[2025-12-10 17:16:37,561 INFO misc.py line 117 4140988] Train: [1/10][1834/7400] Data 0.004 (0.004) Batch 0.510 (0.617) Remain 12:22:22 loss: 7.4140 mask_loss: 6.8485 roll_mask_loss: 7.4886 density_loss: 8.0843 unmask_loss: 7.4977 Lr: 0.00217
[2025-12-10 17:16:37,875 INFO misc.py line 117 4140988] Train: [1/10][1835/7400] Data 0.004 (0.004) Batch 0.314 (0.617) Remain 12:22:09 loss: 7.6954 mask_loss: 7.1189 roll_mask_loss: 7.4303 density_loss: 8.5512 unmask_loss: 7.9452 Lr: 0.00217
[2025-12-10 17:16:38,594 INFO misc.py line 117 4140988] Train: [1/10][1836/7400] Data 0.004 (0.004) Batch 0.719 (0.617) Remain 12:22:13 loss: 7.1566 mask_loss: 6.5003 roll_mask_loss: 7.2293 density_loss: 8.5729 unmask_loss: 7.2769 Lr: 0.00218
[2025-12-10 17:16:38,919 INFO misc.py line 117 4140988] Train: [1/10][1837/7400] Data 0.004 (0.004) Batch 0.325 (0.617) Remain 12:22:01 loss: 7.1512 mask_loss: 6.1265 roll_mask_loss: 6.9189 density_loss: 9.0957 unmask_loss: 7.5978 Lr: 0.00218
[2025-12-10 17:16:39,548 INFO misc.py line 117 4140988] Train: [1/10][1838/7400] Data 0.004 (0.004) Batch 0.630 (0.617) Remain 12:22:01 loss: 7.8799 mask_loss: 7.1217 roll_mask_loss: 8.2887 density_loss: 8.5547 unmask_loss: 7.8835 Lr: 0.00218
[2025-12-10 17:16:40,107 INFO misc.py line 117 4140988] Train: [1/10][1839/7400] Data 0.003 (0.004) Batch 0.559 (0.617) Remain 12:21:58 loss: 7.1216 mask_loss: 5.9138 roll_mask_loss: 7.5108 density_loss: 9.4409 unmask_loss: 7.3420 Lr: 0.00218
[2025-12-10 17:16:40,730 INFO misc.py line 117 4140988] Train: [1/10][1840/7400] Data 0.003 (0.004) Batch 0.623 (0.617) Remain 12:21:57 loss: 7.2267 mask_loss: 6.4950 roll_mask_loss: 7.1144 density_loss: 9.2570 unmask_loss: 7.4636 Lr: 0.00218
[2025-12-10 17:16:41,494 INFO misc.py line 117 4140988] Train: [1/10][1841/7400] Data 0.003 (0.004) Batch 0.764 (0.617) Remain 12:22:02 loss: 7.0053 mask_loss: 6.3192 roll_mask_loss: 6.9076 density_loss: 8.5168 unmask_loss: 7.2268 Lr: 0.00218
[2025-12-10 17:16:42,134 INFO misc.py line 117 4140988] Train: [1/10][1842/7400] Data 0.004 (0.004) Batch 0.640 (0.617) Remain 12:22:03 loss: 7.1403 mask_loss: 6.2495 roll_mask_loss: 6.8865 density_loss: 9.0409 unmask_loss: 7.5318 Lr: 0.00219
[2025-12-10 17:16:42,710 INFO misc.py line 117 4140988] Train: [1/10][1843/7400] Data 0.003 (0.004) Batch 0.576 (0.617) Remain 12:22:01 loss: 6.9725 mask_loss: 6.1790 roll_mask_loss: 6.8082 density_loss: 9.1591 unmask_loss: 7.2682 Lr: 0.00219
[2025-12-10 17:16:43,233 INFO misc.py line 117 4140988] Train: [1/10][1844/7400] Data 0.003 (0.004) Batch 0.523 (0.617) Remain 12:21:56 loss: 7.1662 mask_loss: 6.5226 roll_mask_loss: 7.0236 density_loss: 9.2148 unmask_loss: 7.3750 Lr: 0.00219
[2025-12-10 17:16:43,546 INFO misc.py line 117 4140988] Train: [1/10][1845/7400] Data 0.003 (0.004) Batch 0.313 (0.617) Remain 12:21:44 loss: 8.2801 mask_loss: 7.8191 roll_mask_loss: 8.5960 density_loss: 8.0331 unmask_loss: 8.1920 Lr: 0.00219
[2025-12-10 17:16:44,223 INFO misc.py line 117 4140988] Train: [1/10][1846/7400] Data 0.004 (0.004) Batch 0.677 (0.617) Remain 12:21:45 loss: 7.0085 mask_loss: 6.1696 roll_mask_loss: 6.9811 density_loss: 9.6302 unmask_loss: 7.2490 Lr: 0.00219
[2025-12-10 17:16:44,839 INFO misc.py line 117 4140988] Train: [1/10][1847/7400] Data 0.004 (0.004) Batch 0.616 (0.617) Remain 12:21:45 loss: 7.0982 mask_loss: 6.2252 roll_mask_loss: 7.2096 density_loss: 9.0567 unmask_loss: 7.2979 Lr: 0.00219
[2025-12-10 17:16:45,516 INFO misc.py line 117 4140988] Train: [1/10][1848/7400] Data 0.004 (0.004) Batch 0.677 (0.617) Remain 12:21:47 loss: 7.5180 mask_loss: 7.1964 roll_mask_loss: 7.6268 density_loss: 8.6362 unmask_loss: 7.4518 Lr: 0.00219
[2025-12-10 17:16:46,222 INFO misc.py line 117 4140988] Train: [1/10][1849/7400] Data 0.004 (0.004) Batch 0.705 (0.617) Remain 12:21:49 loss: 7.0169 mask_loss: 6.1147 roll_mask_loss: 7.1321 density_loss: 9.2821 unmask_loss: 7.2247 Lr: 0.00220
[2025-12-10 17:16:46,702 INFO misc.py line 117 4140988] Train: [1/10][1850/7400] Data 0.004 (0.004) Batch 0.480 (0.617) Remain 12:21:43 loss: 7.7500 mask_loss: 7.2602 roll_mask_loss: 8.1489 density_loss: 8.4759 unmask_loss: 7.6260 Lr: 0.00220
[2025-12-10 17:16:47,533 INFO misc.py line 117 4140988] Train: [1/10][1851/7400] Data 0.004 (0.004) Batch 0.831 (0.617) Remain 12:21:51 loss: 7.0185 mask_loss: 6.1149 roll_mask_loss: 6.8748 density_loss: 8.7408 unmask_loss: 7.3673 Lr: 0.00220
[2025-12-10 17:16:48,169 INFO misc.py line 117 4140988] Train: [1/10][1852/7400] Data 0.004 (0.004) Batch 0.635 (0.617) Remain 12:21:51 loss: 7.1121 mask_loss: 6.1887 roll_mask_loss: 7.0394 density_loss: 8.9068 unmask_loss: 7.4319 Lr: 0.00220
[2025-12-10 17:16:48,872 INFO misc.py line 117 4140988] Train: [1/10][1853/7400] Data 0.004 (0.004) Batch 0.704 (0.617) Remain 12:21:54 loss: 6.8365 mask_loss: 5.6797 roll_mask_loss: 6.5273 density_loss: 9.5078 unmask_loss: 7.3793 Lr: 0.00220
[2025-12-10 17:16:49,600 INFO misc.py line 117 4140988] Train: [1/10][1854/7400] Data 0.003 (0.004) Batch 0.728 (0.617) Remain 12:21:58 loss: 6.8728 mask_loss: 5.6132 roll_mask_loss: 6.3936 density_loss: 9.9919 unmask_loss: 7.5424 Lr: 0.00220
[2025-12-10 17:16:50,269 INFO misc.py line 117 4140988] Train: [1/10][1855/7400] Data 0.003 (0.004) Batch 0.670 (0.617) Remain 12:21:59 loss: 6.9468 mask_loss: 6.0860 roll_mask_loss: 6.8848 density_loss: 9.5928 unmask_loss: 7.2163 Lr: 0.00221
[2025-12-10 17:16:50,905 INFO misc.py line 117 4140988] Train: [1/10][1856/7400] Data 0.003 (0.004) Batch 0.636 (0.617) Remain 12:21:59 loss: 8.0583 mask_loss: 7.2644 roll_mask_loss: 8.5026 density_loss: 8.5705 unmask_loss: 8.0616 Lr: 0.00221
[2025-12-10 17:16:51,687 INFO misc.py line 117 4140988] Train: [1/10][1857/7400] Data 0.003 (0.004) Batch 0.781 (0.617) Remain 12:22:05 loss: 7.0087 mask_loss: 6.1857 roll_mask_loss: 6.9184 density_loss: 8.9283 unmask_loss: 7.2868 Lr: 0.00221
[2025-12-10 17:16:52,197 INFO misc.py line 117 4140988] Train: [1/10][1858/7400] Data 0.004 (0.004) Batch 0.510 (0.617) Remain 12:22:00 loss: 8.3103 mask_loss: 7.9521 roll_mask_loss: 8.1441 density_loss: 8.4026 unmask_loss: 8.4045 Lr: 0.00221
[2025-12-10 17:16:52,787 INFO misc.py line 117 4140988] Train: [1/10][1859/7400] Data 0.004 (0.004) Batch 0.590 (0.617) Remain 12:21:59 loss: 8.1700 mask_loss: 7.8760 roll_mask_loss: 8.2143 density_loss: 8.6891 unmask_loss: 8.1211 Lr: 0.00221
[2025-12-10 17:16:53,504 INFO misc.py line 117 4140988] Train: [1/10][1860/7400] Data 0.004 (0.004) Batch 0.718 (0.617) Remain 12:22:02 loss: 6.7956 mask_loss: 5.9537 roll_mask_loss: 6.5738 density_loss: 9.4374 unmask_loss: 7.1388 Lr: 0.00221
[2025-12-10 17:16:54,034 INFO misc.py line 117 4140988] Train: [1/10][1861/7400] Data 0.004 (0.004) Batch 0.529 (0.617) Remain 12:21:58 loss: 8.1906 mask_loss: 7.8764 roll_mask_loss: 8.1450 density_loss: 8.3741 unmask_loss: 8.2031 Lr: 0.00221
[2025-12-10 17:16:54,487 INFO misc.py line 117 4140988] Train: [1/10][1862/7400] Data 0.004 (0.004) Batch 0.453 (0.617) Remain 12:21:51 loss: 6.9255 mask_loss: 5.9775 roll_mask_loss: 6.9502 density_loss: 8.1163 unmask_loss: 7.2248 Lr: 0.00222
[2025-12-10 17:16:55,041 INFO misc.py line 117 4140988] Train: [1/10][1863/7400] Data 0.004 (0.004) Batch 0.554 (0.617) Remain 12:21:48 loss: 7.7503 mask_loss: 7.3857 roll_mask_loss: 7.7369 density_loss: 8.7687 unmask_loss: 7.7640 Lr: 0.00222
[2025-12-10 17:16:55,590 INFO misc.py line 117 4140988] Train: [1/10][1864/7400] Data 0.004 (0.004) Batch 0.548 (0.617) Remain 12:21:45 loss: 7.6374 mask_loss: 7.0043 roll_mask_loss: 7.5088 density_loss: 9.0167 unmask_loss: 7.8380 Lr: 0.00222
[2025-12-10 17:16:56,209 INFO misc.py line 117 4140988] Train: [1/10][1865/7400] Data 0.005 (0.004) Batch 0.620 (0.617) Remain 12:21:44 loss: 7.3709 mask_loss: 6.7125 roll_mask_loss: 7.2122 density_loss: 9.0183 unmask_loss: 7.5992 Lr: 0.00222
[2025-12-10 17:16:56,901 INFO misc.py line 117 4140988] Train: [1/10][1866/7400] Data 0.004 (0.004) Batch 0.692 (0.617) Remain 12:21:46 loss: 7.0318 mask_loss: 6.3780 roll_mask_loss: 6.9436 density_loss: 8.2053 unmask_loss: 7.2386 Lr: 0.00222
[2025-12-10 17:16:57,443 INFO misc.py line 117 4140988] Train: [1/10][1867/7400] Data 0.004 (0.004) Batch 0.542 (0.617) Remain 12:21:43 loss: 8.3260 mask_loss: 8.1401 roll_mask_loss: 8.2449 density_loss: 8.3527 unmask_loss: 8.2924 Lr: 0.00222
[2025-12-10 17:16:57,962 INFO misc.py line 117 4140988] Train: [1/10][1868/7400] Data 0.004 (0.004) Batch 0.519 (0.617) Remain 12:21:38 loss: 7.6596 mask_loss: 7.1415 roll_mask_loss: 7.7449 density_loss: 8.7043 unmask_loss: 7.7019 Lr: 0.00223
[2025-12-10 17:16:58,606 INFO misc.py line 117 4140988] Train: [1/10][1869/7400] Data 0.003 (0.004) Batch 0.644 (0.617) Remain 12:21:39 loss: 7.1105 mask_loss: 6.3508 roll_mask_loss: 6.9454 density_loss: 9.3243 unmask_loss: 7.3865 Lr: 0.00223
[2025-12-10 17:16:59,310 INFO misc.py line 117 4140988] Train: [1/10][1870/7400] Data 0.003 (0.004) Batch 0.704 (0.617) Remain 12:21:42 loss: 6.8889 mask_loss: 6.0304 roll_mask_loss: 6.7816 density_loss: 9.7836 unmask_loss: 7.1762 Lr: 0.00223
[2025-12-10 17:17:00,005 INFO misc.py line 117 4140988] Train: [1/10][1871/7400] Data 0.003 (0.004) Batch 0.695 (0.617) Remain 12:21:44 loss: 6.9640 mask_loss: 6.0345 roll_mask_loss: 6.9318 density_loss: 9.4018 unmask_loss: 7.2569 Lr: 0.00223
[2025-12-10 17:17:00,494 INFO misc.py line 117 4140988] Train: [1/10][1872/7400] Data 0.003 (0.004) Batch 0.489 (0.617) Remain 12:21:38 loss: 8.0106 mask_loss: 7.8156 roll_mask_loss: 7.9227 density_loss: 8.4767 unmask_loss: 7.9825 Lr: 0.00223
[2025-12-10 17:17:00,951 INFO misc.py line 117 4140988] Train: [1/10][1873/7400] Data 0.003 (0.004) Batch 0.456 (0.617) Remain 12:21:32 loss: 8.3004 mask_loss: 8.1226 roll_mask_loss: 8.2357 density_loss: 8.4118 unmask_loss: 8.2534 Lr: 0.00223
[2025-12-10 17:17:01,573 INFO misc.py line 117 4140988] Train: [1/10][1874/7400] Data 0.004 (0.004) Batch 0.622 (0.617) Remain 12:21:31 loss: 7.9502 mask_loss: 7.2860 roll_mask_loss: 7.9979 density_loss: 8.6852 unmask_loss: 8.0848 Lr: 0.00223
[2025-12-10 17:17:02,370 INFO misc.py line 117 4140988] Train: [1/10][1875/7400] Data 0.004 (0.004) Batch 0.798 (0.617) Remain 12:21:38 loss: 7.0367 mask_loss: 5.8803 roll_mask_loss: 6.9860 density_loss: 9.9307 unmask_loss: 7.4417 Lr: 0.00224
[2025-12-10 17:17:03,145 INFO misc.py line 117 4140988] Train: [1/10][1876/7400] Data 0.003 (0.004) Batch 0.775 (0.617) Remain 12:21:43 loss: 7.1163 mask_loss: 6.3334 roll_mask_loss: 7.0800 density_loss: 8.9794 unmask_loss: 7.3464 Lr: 0.00224
[2025-12-10 17:17:04,036 INFO misc.py line 117 4140988] Train: [1/10][1877/7400] Data 0.003 (0.004) Batch 0.891 (0.617) Remain 12:21:53 loss: 6.8419 mask_loss: 5.9597 roll_mask_loss: 6.5577 density_loss: 8.5697 unmask_loss: 7.2537 Lr: 0.00224
[2025-12-10 17:17:04,536 INFO misc.py line 117 4140988] Train: [1/10][1878/7400] Data 0.004 (0.004) Batch 0.499 (0.617) Remain 12:21:48 loss: 7.0366 mask_loss: 6.3214 roll_mask_loss: 6.9547 density_loss: 8.3136 unmask_loss: 7.2690 Lr: 0.00224
[2025-12-10 17:17:05,170 INFO misc.py line 117 4140988] Train: [1/10][1879/7400] Data 0.004 (0.004) Batch 0.634 (0.617) Remain 12:21:48 loss: 7.1393 mask_loss: 6.3790 roll_mask_loss: 6.8834 density_loss: 8.9775 unmask_loss: 7.4678 Lr: 0.00224
[2025-12-10 17:17:05,738 INFO misc.py line 117 4140988] Train: [1/10][1880/7400] Data 0.004 (0.004) Batch 0.568 (0.617) Remain 12:21:45 loss: 7.0562 mask_loss: 6.2896 roll_mask_loss: 7.0513 density_loss: 9.5167 unmask_loss: 7.2515 Lr: 0.00224
[2025-12-10 17:17:06,333 INFO misc.py line 117 4140988] Train: [1/10][1881/7400] Data 0.004 (0.004) Batch 0.596 (0.617) Remain 12:21:44 loss: 7.0588 mask_loss: 6.3461 roll_mask_loss: 6.6500 density_loss: 8.9261 unmask_loss: 7.4410 Lr: 0.00225
[2025-12-10 17:17:06,888 INFO misc.py line 117 4140988] Train: [1/10][1882/7400] Data 0.004 (0.004) Batch 0.554 (0.617) Remain 12:21:41 loss: 6.9420 mask_loss: 6.1562 roll_mask_loss: 6.9164 density_loss: 8.7769 unmask_loss: 7.1723 Lr: 0.00225
[2025-12-10 17:17:07,611 INFO misc.py line 117 4140988] Train: [1/10][1883/7400] Data 0.004 (0.004) Batch 0.724 (0.617) Remain 12:21:44 loss: 6.8448 mask_loss: 5.9285 roll_mask_loss: 6.7725 density_loss: 9.8193 unmask_loss: 7.1428 Lr: 0.00225
[2025-12-10 17:17:08,517 INFO misc.py line 117 4140988] Train: [1/10][1884/7400] Data 0.004 (0.004) Batch 0.906 (0.617) Remain 12:21:55 loss: 7.0063 mask_loss: 6.3569 roll_mask_loss: 6.8729 density_loss: 9.2069 unmask_loss: 7.2137 Lr: 0.00225
[2025-12-10 17:17:09,168 INFO misc.py line 117 4140988] Train: [1/10][1885/7400] Data 0.004 (0.004) Batch 0.651 (0.617) Remain 12:21:55 loss: 7.7165 mask_loss: 7.4273 roll_mask_loss: 7.8322 density_loss: 9.4157 unmask_loss: 7.6150 Lr: 0.00225
[2025-12-10 17:17:09,483 INFO misc.py line 117 4140988] Train: [1/10][1886/7400] Data 0.004 (0.004) Batch 0.315 (0.617) Remain 12:21:43 loss: 8.5024 mask_loss: 8.3695 roll_mask_loss: 8.3720 density_loss: 8.3728 unmask_loss: 8.4666 Lr: 0.00225
[2025-12-10 17:17:10,024 INFO misc.py line 117 4140988] Train: [1/10][1887/7400] Data 0.004 (0.004) Batch 0.541 (0.617) Remain 12:21:40 loss: 8.2964 mask_loss: 7.7514 roll_mask_loss: 8.3963 density_loss: 8.6464 unmask_loss: 8.3460 Lr: 0.00225
[2025-12-10 17:17:10,645 INFO misc.py line 117 4140988] Train: [1/10][1888/7400] Data 0.004 (0.004) Batch 0.620 (0.617) Remain 12:21:39 loss: 7.5661 mask_loss: 6.8976 roll_mask_loss: 7.7112 density_loss: 8.6824 unmask_loss: 7.6541 Lr: 0.00226
[2025-12-10 17:17:11,258 INFO misc.py line 117 4140988] Train: [1/10][1889/7400] Data 0.004 (0.004) Batch 0.614 (0.617) Remain 12:21:38 loss: 7.0229 mask_loss: 6.3482 roll_mask_loss: 6.8382 density_loss: 9.4765 unmask_loss: 7.2631 Lr: 0.00226
[2025-12-10 17:17:11,549 INFO misc.py line 117 4140988] Train: [1/10][1890/7400] Data 0.003 (0.004) Batch 0.292 (0.617) Remain 12:21:25 loss: 7.8072 mask_loss: 7.3990 roll_mask_loss: 7.6512 density_loss: 8.6356 unmask_loss: 7.9166 Lr: 0.00226
[2025-12-10 17:17:12,139 INFO misc.py line 117 4140988] Train: [1/10][1891/7400] Data 0.003 (0.004) Batch 0.590 (0.617) Remain 12:21:24 loss: 7.5106 mask_loss: 6.9199 roll_mask_loss: 7.1640 density_loss: 8.4286 unmask_loss: 7.8107 Lr: 0.00226
[2025-12-10 17:17:12,781 INFO misc.py line 117 4140988] Train: [1/10][1892/7400] Data 0.003 (0.004) Batch 0.642 (0.617) Remain 12:21:24 loss: 7.0427 mask_loss: 5.9985 roll_mask_loss: 6.9764 density_loss: 9.7405 unmask_loss: 7.4032 Lr: 0.00226
[2025-12-10 17:17:13,300 INFO misc.py line 117 4140988] Train: [1/10][1893/7400] Data 0.003 (0.004) Batch 0.518 (0.617) Remain 12:21:20 loss: 7.8376 mask_loss: 7.3217 roll_mask_loss: 7.6553 density_loss: 8.4660 unmask_loss: 8.0173 Lr: 0.00226
[2025-12-10 17:17:13,967 INFO misc.py line 117 4140988] Train: [1/10][1894/7400] Data 0.004 (0.004) Batch 0.667 (0.617) Remain 12:21:21 loss: 7.1955 mask_loss: 6.4397 roll_mask_loss: 7.2426 density_loss: 8.8002 unmask_loss: 7.3738 Lr: 0.00226
[2025-12-10 17:17:14,758 INFO misc.py line 117 4140988] Train: [1/10][1895/7400] Data 0.004 (0.004) Batch 0.791 (0.617) Remain 12:21:27 loss: 6.8722 mask_loss: 5.9834 roll_mask_loss: 6.6325 density_loss: 9.3322 unmask_loss: 7.2499 Lr: 0.00227
[2025-12-10 17:17:15,410 INFO misc.py line 117 4140988] Train: [1/10][1896/7400] Data 0.004 (0.004) Batch 0.652 (0.617) Remain 12:21:28 loss: 7.8362 mask_loss: 7.3875 roll_mask_loss: 7.6468 density_loss: 9.0272 unmask_loss: 7.9748 Lr: 0.00227
[2025-12-10 17:17:16,172 INFO misc.py line 117 4140988] Train: [1/10][1897/7400] Data 0.003 (0.004) Batch 0.762 (0.617) Remain 12:21:33 loss: 6.9504 mask_loss: 5.9817 roll_mask_loss: 6.9328 density_loss: 8.4814 unmask_loss: 7.2738 Lr: 0.00227
[2025-12-10 17:17:16,530 INFO misc.py line 117 4140988] Train: [1/10][1898/7400] Data 0.003 (0.004) Batch 0.358 (0.617) Remain 12:21:22 loss: 8.4565 mask_loss: 8.3515 roll_mask_loss: 8.3656 density_loss: 8.3675 unmask_loss: 8.3872 Lr: 0.00227
[2025-12-10 17:17:17,111 INFO misc.py line 117 4140988] Train: [1/10][1899/7400] Data 0.003 (0.004) Batch 0.581 (0.617) Remain 12:21:20 loss: 6.9571 mask_loss: 6.1967 roll_mask_loss: 6.8178 density_loss: 9.7872 unmask_loss: 7.2112 Lr: 0.00227
[2025-12-10 17:17:17,677 INFO misc.py line 117 4140988] Train: [1/10][1900/7400] Data 0.004 (0.004) Batch 0.566 (0.617) Remain 12:21:18 loss: 7.9176 mask_loss: 7.4822 roll_mask_loss: 7.8320 density_loss: 8.7761 unmask_loss: 8.0027 Lr: 0.00227
[2025-12-10 17:17:18,185 INFO misc.py line 117 4140988] Train: [1/10][1901/7400] Data 0.004 (0.004) Batch 0.508 (0.617) Remain 12:21:13 loss: 7.2069 mask_loss: 6.5391 roll_mask_loss: 7.0848 density_loss: 9.0986 unmask_loss: 7.4200 Lr: 0.00228
[2025-12-10 17:17:18,866 INFO misc.py line 117 4140988] Train: [1/10][1902/7400] Data 0.004 (0.004) Batch 0.681 (0.617) Remain 12:21:15 loss: 6.9626 mask_loss: 6.1849 roll_mask_loss: 6.7611 density_loss: 9.3798 unmask_loss: 7.2647 Lr: 0.00228
[2025-12-10 17:17:19,542 INFO misc.py line 117 4140988] Train: [1/10][1903/7400] Data 0.004 (0.004) Batch 0.676 (0.617) Remain 12:21:16 loss: 7.0599 mask_loss: 6.4100 roll_mask_loss: 6.9836 density_loss: 7.4975 unmask_loss: 7.2730 Lr: 0.00228
[2025-12-10 17:17:20,106 INFO misc.py line 117 4140988] Train: [1/10][1904/7400] Data 0.003 (0.004) Batch 0.564 (0.617) Remain 12:21:14 loss: 7.4820 mask_loss: 6.8402 roll_mask_loss: 8.1447 density_loss: 9.1718 unmask_loss: 7.2881 Lr: 0.00228
[2025-12-10 17:17:20,806 INFO misc.py line 117 4140988] Train: [1/10][1905/7400] Data 0.003 (0.004) Batch 0.700 (0.617) Remain 12:21:16 loss: 7.2026 mask_loss: 6.3923 roll_mask_loss: 7.3498 density_loss: 8.3227 unmask_loss: 7.3677 Lr: 0.00228
[2025-12-10 17:17:21,392 INFO misc.py line 117 4140988] Train: [1/10][1906/7400] Data 0.004 (0.004) Batch 0.586 (0.617) Remain 12:21:14 loss: 6.8754 mask_loss: 6.1852 roll_mask_loss: 6.7291 density_loss: 8.4704 unmask_loss: 7.1241 Lr: 0.00228
[2025-12-10 17:17:22,024 INFO misc.py line 117 4140988] Train: [1/10][1907/7400] Data 0.004 (0.004) Batch 0.631 (0.617) Remain 12:21:14 loss: 7.1883 mask_loss: 6.1803 roll_mask_loss: 6.4999 density_loss: 9.5297 unmask_loss: 7.8458 Lr: 0.00228
[2025-12-10 17:17:22,805 INFO misc.py line 117 4140988] Train: [1/10][1908/7400] Data 0.004 (0.004) Batch 0.782 (0.617) Remain 12:21:20 loss: 6.9261 mask_loss: 5.9553 roll_mask_loss: 7.0794 density_loss: 9.4444 unmask_loss: 7.1459 Lr: 0.00229
[2025-12-10 17:17:23,431 INFO misc.py line 117 4140988] Train: [1/10][1909/7400] Data 0.003 (0.004) Batch 0.626 (0.617) Remain 12:21:20 loss: 7.0697 mask_loss: 6.3912 roll_mask_loss: 6.8824 density_loss: 8.3228 unmask_loss: 7.3361 Lr: 0.00229
[2025-12-10 17:17:24,096 INFO misc.py line 117 4140988] Train: [1/10][1910/7400] Data 0.004 (0.004) Batch 0.664 (0.617) Remain 12:21:21 loss: 8.1138 mask_loss: 7.7244 roll_mask_loss: 7.9577 density_loss: 8.7058 unmask_loss: 8.2125 Lr: 0.00229
[2025-12-10 17:17:24,868 INFO misc.py line 117 4140988] Train: [1/10][1911/7400] Data 0.004 (0.004) Batch 0.772 (0.617) Remain 12:21:26 loss: 6.7279 mask_loss: 5.8700 roll_mask_loss: 6.4816 density_loss: 9.3286 unmask_loss: 7.0934 Lr: 0.00229
[2025-12-10 17:17:25,481 INFO misc.py line 117 4140988] Train: [1/10][1912/7400] Data 0.003 (0.004) Batch 0.613 (0.617) Remain 12:21:25 loss: 7.1296 mask_loss: 6.4328 roll_mask_loss: 7.2071 density_loss: 8.9387 unmask_loss: 7.2604 Lr: 0.00229
[2025-12-10 17:17:26,028 INFO misc.py line 117 4140988] Train: [1/10][1913/7400] Data 0.003 (0.004) Batch 0.546 (0.617) Remain 12:21:22 loss: 7.8984 mask_loss: 7.2648 roll_mask_loss: 7.4893 density_loss: 8.6730 unmask_loss: 8.2462 Lr: 0.00229
[2025-12-10 17:17:26,632 INFO misc.py line 117 4140988] Train: [1/10][1914/7400] Data 0.004 (0.004) Batch 0.604 (0.617) Remain 12:21:21 loss: 7.3447 mask_loss: 6.7662 roll_mask_loss: 7.0536 density_loss: 8.2713 unmask_loss: 7.6142 Lr: 0.00230
[2025-12-10 17:17:27,370 INFO misc.py line 117 4140988] Train: [1/10][1915/7400] Data 0.004 (0.004) Batch 0.739 (0.617) Remain 12:21:25 loss: 7.1078 mask_loss: 5.6595 roll_mask_loss: 7.1323 density_loss: 9.5577 unmask_loss: 7.6285 Lr: 0.00230
[2025-12-10 17:17:27,691 INFO misc.py line 117 4140988] Train: [1/10][1916/7400] Data 0.003 (0.004) Batch 0.321 (0.617) Remain 12:21:13 loss: 8.4169 mask_loss: 8.3298 roll_mask_loss: 8.3336 density_loss: 8.3443 unmask_loss: 8.3352 Lr: 0.00230
[2025-12-10 17:17:28,445 INFO misc.py line 117 4140988] Train: [1/10][1917/7400] Data 0.004 (0.004) Batch 0.753 (0.617) Remain 12:21:18 loss: 6.8089 mask_loss: 5.9625 roll_mask_loss: 6.5228 density_loss: 8.8232 unmask_loss: 7.1987 Lr: 0.00230
[2025-12-10 17:17:29,041 INFO misc.py line 117 4140988] Train: [1/10][1918/7400] Data 0.004 (0.004) Batch 0.597 (0.617) Remain 12:21:16 loss: 7.2658 mask_loss: 6.4767 roll_mask_loss: 7.0141 density_loss: 8.9484 unmask_loss: 7.6072 Lr: 0.00230
[2025-12-10 17:17:29,562 INFO misc.py line 117 4140988] Train: [1/10][1919/7400] Data 0.004 (0.004) Batch 0.522 (0.617) Remain 12:21:12 loss: 7.1563 mask_loss: 6.0911 roll_mask_loss: 7.0453 density_loss: 10.1563 unmask_loss: 7.5413 Lr: 0.00230
[2025-12-10 17:17:30,554 INFO misc.py line 117 4140988] Train: [1/10][1920/7400] Data 0.003 (0.004) Batch 0.992 (0.617) Remain 12:21:26 loss: 6.9299 mask_loss: 5.8684 roll_mask_loss: 6.8416 density_loss: 9.2736 unmask_loss: 7.3192 Lr: 0.00230
[2025-12-10 17:17:30,843 INFO misc.py line 117 4140988] Train: [1/10][1921/7400] Data 0.003 (0.004) Batch 0.288 (0.617) Remain 12:21:13 loss: 7.7258 mask_loss: 6.2524 roll_mask_loss: 8.4542 density_loss: 8.9900 unmask_loss: 7.9185 Lr: 0.00231
[2025-12-10 17:17:31,178 INFO misc.py line 117 4140988] Train: [1/10][1922/7400] Data 0.004 (0.004) Batch 0.336 (0.617) Remain 12:21:01 loss: 8.3160 mask_loss: 7.7741 roll_mask_loss: 8.9947 density_loss: 8.2792 unmask_loss: 8.0819 Lr: 0.00231
[2025-12-10 17:17:31,977 INFO misc.py line 117 4140988] Train: [1/10][1923/7400] Data 0.004 (0.004) Batch 0.799 (0.617) Remain 12:21:08 loss: 6.7871 mask_loss: 5.9415 roll_mask_loss: 6.6209 density_loss: 8.8725 unmask_loss: 7.1156 Lr: 0.00231
[2025-12-10 17:17:32,736 INFO misc.py line 117 4140988] Train: [1/10][1924/7400] Data 0.003 (0.004) Batch 0.760 (0.617) Remain 12:21:12 loss: 6.9185 mask_loss: 6.1977 roll_mask_loss: 6.6455 density_loss: 9.0353 unmask_loss: 7.2348 Lr: 0.00231
[2025-12-10 17:17:33,306 INFO misc.py line 117 4140988] Train: [1/10][1925/7400] Data 0.003 (0.004) Batch 0.570 (0.617) Remain 12:21:10 loss: 7.4862 mask_loss: 7.2286 roll_mask_loss: 7.4411 density_loss: 9.1143 unmask_loss: 7.4552 Lr: 0.00231
[2025-12-10 17:17:33,941 INFO misc.py line 117 4140988] Train: [1/10][1926/7400] Data 0.004 (0.004) Batch 0.635 (0.617) Remain 12:21:10 loss: 7.1178 mask_loss: 6.4686 roll_mask_loss: 6.9870 density_loss: 8.6272 unmask_loss: 7.3352 Lr: 0.00231
[2025-12-10 17:17:34,580 INFO misc.py line 117 4140988] Train: [1/10][1927/7400] Data 0.004 (0.004) Batch 0.640 (0.617) Remain 12:21:10 loss: 7.7916 mask_loss: 7.4281 roll_mask_loss: 7.6198 density_loss: 8.2731 unmask_loss: 7.8937 Lr: 0.00232
[2025-12-10 17:17:35,126 INFO misc.py line 117 4140988] Train: [1/10][1928/7400] Data 0.003 (0.004) Batch 0.547 (0.617) Remain 12:21:07 loss: 7.8637 mask_loss: 7.5100 roll_mask_loss: 7.7971 density_loss: 8.6349 unmask_loss: 7.9012 Lr: 0.00232
[2025-12-10 17:17:35,500 INFO misc.py line 117 4140988] Train: [1/10][1929/7400] Data 0.003 (0.004) Batch 0.372 (0.617) Remain 12:20:57 loss: 7.8575 mask_loss: 7.1576 roll_mask_loss: 7.9060 density_loss: 8.2109 unmask_loss: 8.0190 Lr: 0.00232
[2025-12-10 17:17:36,135 INFO misc.py line 117 4140988] Train: [1/10][1930/7400] Data 0.004 (0.004) Batch 0.635 (0.617) Remain 12:20:57 loss: 6.8175 mask_loss: 5.9138 roll_mask_loss: 6.6407 density_loss: 9.2710 unmask_loss: 7.1724 Lr: 0.00232
[2025-12-10 17:17:36,743 INFO misc.py line 117 4140988] Train: [1/10][1931/7400] Data 0.004 (0.004) Batch 0.608 (0.617) Remain 12:20:56 loss: 7.0918 mask_loss: 6.4235 roll_mask_loss: 6.8184 density_loss: 9.0199 unmask_loss: 7.3823 Lr: 0.00232
[2025-12-10 17:17:37,531 INFO misc.py line 117 4140988] Train: [1/10][1932/7400] Data 0.004 (0.004) Batch 0.788 (0.617) Remain 12:21:02 loss: 7.2321 mask_loss: 5.9825 roll_mask_loss: 7.0835 density_loss: 9.8318 unmask_loss: 7.7346 Lr: 0.00232
[2025-12-10 17:17:38,189 INFO misc.py line 117 4140988] Train: [1/10][1933/7400] Data 0.004 (0.004) Batch 0.658 (0.617) Remain 12:21:03 loss: 7.2785 mask_loss: 6.5494 roll_mask_loss: 7.2147 density_loss: 9.0792 unmask_loss: 7.4933 Lr: 0.00232
[2025-12-10 17:17:38,879 INFO misc.py line 117 4140988] Train: [1/10][1934/7400] Data 0.004 (0.004) Batch 0.691 (0.617) Remain 12:21:05 loss: 7.0385 mask_loss: 6.2337 roll_mask_loss: 6.9697 density_loss: 8.8040 unmask_loss: 7.2992 Lr: 0.00233
[2025-12-10 17:17:39,691 INFO misc.py line 117 4140988] Train: [1/10][1935/7400] Data 0.003 (0.004) Batch 0.812 (0.617) Remain 12:21:12 loss: 7.1180 mask_loss: 5.9544 roll_mask_loss: 7.1982 density_loss: 9.8676 unmask_loss: 7.4622 Lr: 0.00233
[2025-12-10 17:17:40,572 INFO misc.py line 117 4140988] Train: [1/10][1936/7400] Data 0.003 (0.004) Batch 0.881 (0.617) Remain 12:21:21 loss: 6.9250 mask_loss: 5.8561 roll_mask_loss: 6.8707 density_loss: 10.0722 unmask_loss: 7.2851 Lr: 0.00233
[2025-12-10 17:17:41,159 INFO misc.py line 117 4140988] Train: [1/10][1937/7400] Data 0.003 (0.004) Batch 0.586 (0.617) Remain 12:21:19 loss: 6.9544 mask_loss: 6.1669 roll_mask_loss: 6.8992 density_loss: 8.9762 unmask_loss: 7.1962 Lr: 0.00233
[2025-12-10 17:17:41,971 INFO misc.py line 117 4140988] Train: [1/10][1938/7400] Data 0.004 (0.004) Batch 0.812 (0.617) Remain 12:21:26 loss: 6.8611 mask_loss: 5.8191 roll_mask_loss: 6.7856 density_loss: 10.0950 unmask_loss: 7.2180 Lr: 0.00233
[2025-12-10 17:17:42,510 INFO misc.py line 117 4140988] Train: [1/10][1939/7400] Data 0.004 (0.004) Batch 0.540 (0.617) Remain 12:21:22 loss: 8.1553 mask_loss: 7.9252 roll_mask_loss: 8.1580 density_loss: 8.7488 unmask_loss: 8.0939 Lr: 0.00233
[2025-12-10 17:17:43,373 INFO misc.py line 117 4140988] Train: [1/10][1940/7400] Data 0.003 (0.004) Batch 0.864 (0.617) Remain 12:21:31 loss: 6.8415 mask_loss: 6.0517 roll_mask_loss: 6.7290 density_loss: 8.6025 unmask_loss: 7.1206 Lr: 0.00234
[2025-12-10 17:17:43,839 INFO misc.py line 117 4140988] Train: [1/10][1941/7400] Data 0.003 (0.004) Batch 0.465 (0.617) Remain 12:21:25 loss: 7.5330 mask_loss: 6.6824 roll_mask_loss: 7.3558 density_loss: 8.1835 unmask_loss: 7.8833 Lr: 0.00234
[2025-12-10 17:17:44,459 INFO misc.py line 117 4140988] Train: [1/10][1942/7400] Data 0.004 (0.004) Batch 0.619 (0.617) Remain 12:21:24 loss: 7.5197 mask_loss: 6.8120 roll_mask_loss: 7.8974 density_loss: 8.6593 unmask_loss: 7.5115 Lr: 0.00234
[2025-12-10 17:17:44,961 INFO misc.py line 117 4140988] Train: [1/10][1943/7400] Data 0.004 (0.004) Batch 0.502 (0.617) Remain 12:21:19 loss: 8.4556 mask_loss: 8.3296 roll_mask_loss: 8.3468 density_loss: 8.3511 unmask_loss: 8.4059 Lr: 0.00234
[2025-12-10 17:17:45,671 INFO misc.py line 117 4140988] Train: [1/10][1944/7400] Data 0.004 (0.004) Batch 0.710 (0.617) Remain 12:21:22 loss: 7.4577 mask_loss: 6.9683 roll_mask_loss: 7.4131 density_loss: 8.6481 unmask_loss: 7.5517 Lr: 0.00234
[2025-12-10 17:17:46,425 INFO misc.py line 117 4140988] Train: [1/10][1945/7400] Data 0.004 (0.004) Batch 0.755 (0.617) Remain 12:21:27 loss: 6.8785 mask_loss: 5.9163 roll_mask_loss: 6.6968 density_loss: 9.3828 unmask_loss: 7.2629 Lr: 0.00234
[2025-12-10 17:17:46,942 INFO misc.py line 117 4140988] Train: [1/10][1946/7400] Data 0.004 (0.004) Batch 0.517 (0.617) Remain 12:21:22 loss: 8.4656 mask_loss: 8.3189 roll_mask_loss: 8.3325 density_loss: 8.3305 unmask_loss: 8.4390 Lr: 0.00234
[2025-12-10 17:17:47,267 INFO misc.py line 117 4140988] Train: [1/10][1947/7400] Data 0.003 (0.004) Batch 0.325 (0.617) Remain 12:21:11 loss: 7.0825 mask_loss: 6.2966 roll_mask_loss: 6.8476 density_loss: 9.5178 unmask_loss: 7.4025 Lr: 0.00235
[2025-12-10 17:17:47,802 INFO misc.py line 117 4140988] Train: [1/10][1948/7400] Data 0.004 (0.004) Batch 0.535 (0.617) Remain 12:21:07 loss: 8.4093 mask_loss: 8.3180 roll_mask_loss: 8.3267 density_loss: 8.3310 unmask_loss: 8.3297 Lr: 0.00235
[2025-12-10 17:17:48,141 INFO misc.py line 117 4140988] Train: [1/10][1949/7400] Data 0.003 (0.004) Batch 0.339 (0.617) Remain 12:20:56 loss: 7.9470 mask_loss: 7.2276 roll_mask_loss: 7.8836 density_loss: 8.7157 unmask_loss: 8.1641 Lr: 0.00235
[2025-12-10 17:17:48,782 INFO misc.py line 117 4140988] Train: [1/10][1950/7400] Data 0.004 (0.004) Batch 0.641 (0.617) Remain 12:20:56 loss: 7.4413 mask_loss: 6.5709 roll_mask_loss: 7.3570 density_loss: 9.0437 unmask_loss: 7.7377 Lr: 0.00235
[2025-12-10 17:17:49,281 INFO misc.py line 117 4140988] Train: [1/10][1951/7400] Data 0.004 (0.004) Batch 0.499 (0.617) Remain 12:20:51 loss: 7.8994 mask_loss: 7.6521 roll_mask_loss: 7.9055 density_loss: 8.4832 unmask_loss: 7.8503 Lr: 0.00235
[2025-12-10 17:17:49,887 INFO misc.py line 117 4140988] Train: [1/10][1952/7400] Data 0.003 (0.004) Batch 0.606 (0.617) Remain 12:20:50 loss: 7.2128 mask_loss: 6.4224 roll_mask_loss: 7.3429 density_loss: 9.1673 unmask_loss: 7.3596 Lr: 0.00235
[2025-12-10 17:17:50,564 INFO misc.py line 117 4140988] Train: [1/10][1953/7400] Data 0.003 (0.004) Batch 0.677 (0.617) Remain 12:20:52 loss: 7.0508 mask_loss: 6.2562 roll_mask_loss: 6.7582 density_loss: 8.8819 unmask_loss: 7.4167 Lr: 0.00235
[2025-12-10 17:17:51,164 INFO misc.py line 117 4140988] Train: [1/10][1954/7400] Data 0.003 (0.004) Batch 0.601 (0.617) Remain 12:20:51 loss: 7.4193 mask_loss: 6.7487 roll_mask_loss: 7.3313 density_loss: 8.4173 unmask_loss: 7.6304 Lr: 0.00236
[2025-12-10 17:17:51,832 INFO misc.py line 117 4140988] Train: [1/10][1955/7400] Data 0.003 (0.004) Batch 0.667 (0.617) Remain 12:20:52 loss: 7.0072 mask_loss: 6.4493 roll_mask_loss: 6.8453 density_loss: 9.2263 unmask_loss: 7.1826 Lr: 0.00236
[2025-12-10 17:17:52,652 INFO misc.py line 117 4140988] Train: [1/10][1956/7400] Data 0.003 (0.004) Batch 0.819 (0.617) Remain 12:20:59 loss: 6.7844 mask_loss: 5.8478 roll_mask_loss: 6.5951 density_loss: 9.7524 unmask_loss: 7.1522 Lr: 0.00236
[2025-12-10 17:17:53,340 INFO misc.py line 117 4140988] Train: [1/10][1957/7400] Data 0.004 (0.004) Batch 0.688 (0.617) Remain 12:21:01 loss: 6.7823 mask_loss: 5.7271 roll_mask_loss: 6.6658 density_loss: 9.2366 unmask_loss: 7.1835 Lr: 0.00236
[2025-12-10 17:17:54,087 INFO misc.py line 117 4140988] Train: [1/10][1958/7400] Data 0.004 (0.004) Batch 0.747 (0.617) Remain 12:21:05 loss: 6.8896 mask_loss: 5.8640 roll_mask_loss: 6.8954 density_loss: 9.2510 unmask_loss: 7.2146 Lr: 0.00236
[2025-12-10 17:17:54,580 INFO misc.py line 117 4140988] Train: [1/10][1959/7400] Data 0.004 (0.004) Batch 0.493 (0.617) Remain 12:21:00 loss: 7.1133 mask_loss: 6.5397 roll_mask_loss: 7.1160 density_loss: 8.7915 unmask_loss: 7.2230 Lr: 0.00236
[2025-12-10 17:17:55,228 INFO misc.py line 117 4140988] Train: [1/10][1960/7400] Data 0.004 (0.004) Batch 0.648 (0.617) Remain 12:21:00 loss: 6.8010 mask_loss: 6.0262 roll_mask_loss: 6.5963 density_loss: 9.7346 unmask_loss: 7.0961 Lr: 0.00237
[2025-12-10 17:17:56,039 INFO misc.py line 117 4140988] Train: [1/10][1961/7400] Data 0.003 (0.004) Batch 0.811 (0.617) Remain 12:21:07 loss: 6.8083 mask_loss: 6.1152 roll_mask_loss: 6.7065 density_loss: 9.3295 unmask_loss: 7.0191 Lr: 0.00237
[2025-12-10 17:17:56,605 INFO misc.py line 117 4140988] Train: [1/10][1962/7400] Data 0.004 (0.004) Batch 0.567 (0.617) Remain 12:21:04 loss: 7.0031 mask_loss: 6.0979 roll_mask_loss: 6.9182 density_loss: 9.2887 unmask_loss: 7.3123 Lr: 0.00237
[2025-12-10 17:17:57,181 INFO misc.py line 117 4140988] Train: [1/10][1963/7400] Data 0.003 (0.004) Batch 0.575 (0.617) Remain 12:21:02 loss: 8.5297 mask_loss: 8.3661 roll_mask_loss: 8.4164 density_loss: 8.4160 unmask_loss: 8.4999 Lr: 0.00237
[2025-12-10 17:17:57,943 INFO misc.py line 117 4140988] Train: [1/10][1964/7400] Data 0.003 (0.004) Batch 0.762 (0.617) Remain 12:21:07 loss: 7.2554 mask_loss: 6.6369 roll_mask_loss: 7.2348 density_loss: 8.6708 unmask_loss: 7.4015 Lr: 0.00237
[2025-12-10 17:17:58,574 INFO misc.py line 117 4140988] Train: [1/10][1965/7400] Data 0.003 (0.004) Batch 0.630 (0.617) Remain 12:21:07 loss: 8.3519 mask_loss: 7.9665 roll_mask_loss: 8.3259 density_loss: 8.3313 unmask_loss: 8.3910 Lr: 0.00237
[2025-12-10 17:17:58,890 INFO misc.py line 117 4140988] Train: [1/10][1966/7400] Data 0.004 (0.004) Batch 0.316 (0.617) Remain 12:20:55 loss: 8.4472 mask_loss: 8.3450 roll_mask_loss: 8.3497 density_loss: 8.3544 unmask_loss: 8.3801 Lr: 0.00237
[2025-12-10 17:17:59,437 INFO misc.py line 117 4140988] Train: [1/10][1967/7400] Data 0.004 (0.004) Batch 0.547 (0.617) Remain 12:20:52 loss: 6.9837 mask_loss: 6.3003 roll_mask_loss: 6.8060 density_loss: 9.2345 unmask_loss: 7.2297 Lr: 0.00238
[2025-12-10 17:18:00,068 INFO misc.py line 117 4140988] Train: [1/10][1968/7400] Data 0.004 (0.004) Batch 0.632 (0.617) Remain 12:20:52 loss: 7.6744 mask_loss: 6.7915 roll_mask_loss: 7.3372 density_loss: 8.7663 unmask_loss: 8.1092 Lr: 0.00238
[2025-12-10 17:18:00,649 INFO misc.py line 117 4140988] Train: [1/10][1969/7400] Data 0.004 (0.004) Batch 0.580 (0.617) Remain 12:20:50 loss: 7.3122 mask_loss: 6.4634 roll_mask_loss: 7.3101 density_loss: 8.8043 unmask_loss: 7.5615 Lr: 0.00238
[2025-12-10 17:18:01,229 INFO misc.py line 117 4140988] Train: [1/10][1970/7400] Data 0.004 (0.004) Batch 0.580 (0.617) Remain 12:20:48 loss: 7.0562 mask_loss: 6.6046 roll_mask_loss: 7.0582 density_loss: 8.2971 unmask_loss: 7.1151 Lr: 0.00238
[2025-12-10 17:18:01,797 INFO misc.py line 117 4140988] Train: [1/10][1971/7400] Data 0.004 (0.004) Batch 0.569 (0.617) Remain 12:20:46 loss: 6.9641 mask_loss: 6.1706 roll_mask_loss: 6.9161 density_loss: 9.5234 unmask_loss: 7.1943 Lr: 0.00238
[2025-12-10 17:18:02,591 INFO misc.py line 117 4140988] Train: [1/10][1972/7400] Data 0.003 (0.004) Batch 0.794 (0.617) Remain 12:20:51 loss: 6.7342 mask_loss: 6.0125 roll_mask_loss: 6.5795 density_loss: 8.5273 unmask_loss: 7.0019 Lr: 0.00238
[2025-12-10 17:18:03,199 INFO misc.py line 117 4140988] Train: [1/10][1973/7400] Data 0.003 (0.004) Batch 0.607 (0.617) Remain 12:20:51 loss: 7.3244 mask_loss: 6.5641 roll_mask_loss: 7.9745 density_loss: 8.8462 unmask_loss: 7.2025 Lr: 0.00239
[2025-12-10 17:18:03,858 INFO misc.py line 117 4140988] Train: [1/10][1974/7400] Data 0.004 (0.004) Batch 0.659 (0.617) Remain 12:20:51 loss: 7.0845 mask_loss: 6.4449 roll_mask_loss: 6.8646 density_loss: 8.6332 unmask_loss: 7.3416 Lr: 0.00239
[2025-12-10 17:18:04,490 INFO misc.py line 117 4140988] Train: [1/10][1975/7400] Data 0.003 (0.004) Batch 0.632 (0.617) Remain 12:20:51 loss: 8.1235 mask_loss: 7.9583 roll_mask_loss: 8.0754 density_loss: 8.4085 unmask_loss: 8.0620 Lr: 0.00239
[2025-12-10 17:18:05,023 INFO misc.py line 117 4140988] Train: [1/10][1976/7400] Data 0.004 (0.004) Batch 0.533 (0.617) Remain 12:20:48 loss: 7.2242 mask_loss: 6.4159 roll_mask_loss: 7.1119 density_loss: 8.9637 unmask_loss: 7.5051 Lr: 0.00239
[2025-12-10 17:18:05,345 INFO misc.py line 117 4140988] Train: [1/10][1977/7400] Data 0.003 (0.004) Batch 0.322 (0.617) Remain 12:20:36 loss: 7.7264 mask_loss: 7.3195 roll_mask_loss: 7.8229 density_loss: 9.3843 unmask_loss: 7.6939 Lr: 0.00239
[2025-12-10 17:18:05,711 INFO misc.py line 117 4140988] Train: [1/10][1978/7400] Data 0.004 (0.004) Batch 0.366 (0.617) Remain 12:20:27 loss: 6.7716 mask_loss: 5.7286 roll_mask_loss: 6.3590 density_loss: 9.6555 unmask_loss: 7.3063 Lr: 0.00239
[2025-12-10 17:18:06,196 INFO misc.py line 117 4140988] Train: [1/10][1979/7400] Data 0.004 (0.004) Batch 0.484 (0.617) Remain 12:20:21 loss: 8.4509 mask_loss: 8.3569 roll_mask_loss: 8.3638 density_loss: 8.3591 unmask_loss: 8.3742 Lr: 0.00239
[2025-12-10 17:18:06,826 INFO misc.py line 117 4140988] Train: [1/10][1980/7400] Data 0.004 (0.004) Batch 0.630 (0.617) Remain 12:20:21 loss: 6.9746 mask_loss: 6.2674 roll_mask_loss: 6.8022 density_loss: 9.3707 unmask_loss: 7.2270 Lr: 0.00240
[2025-12-10 17:18:07,529 INFO misc.py line 117 4140988] Train: [1/10][1981/7400] Data 0.004 (0.004) Batch 0.703 (0.617) Remain 12:20:23 loss: 6.9620 mask_loss: 5.8988 roll_mask_loss: 6.7711 density_loss: 9.6283 unmask_loss: 7.3964 Lr: 0.00240
[2025-12-10 17:18:08,202 INFO misc.py line 117 4140988] Train: [1/10][1982/7400] Data 0.004 (0.004) Batch 0.673 (0.617) Remain 12:20:25 loss: 7.1434 mask_loss: 6.4356 roll_mask_loss: 7.2769 density_loss: 8.6430 unmask_loss: 7.2577 Lr: 0.00240
[2025-12-10 17:18:08,864 INFO misc.py line 117 4140988] Train: [1/10][1983/7400] Data 0.004 (0.004) Batch 0.662 (0.617) Remain 12:20:26 loss: 6.9674 mask_loss: 6.1029 roll_mask_loss: 6.9571 density_loss: 9.2039 unmask_loss: 7.2207 Lr: 0.00240
[2025-12-10 17:18:09,200 INFO misc.py line 117 4140988] Train: [1/10][1984/7400] Data 0.004 (0.004) Batch 0.337 (0.617) Remain 12:20:15 loss: 7.8253 mask_loss: 7.0915 roll_mask_loss: 7.7751 density_loss: 8.0940 unmask_loss: 8.0555 Lr: 0.00240
[2025-12-10 17:18:10,071 INFO misc.py line 117 4140988] Train: [1/10][1985/7400] Data 0.004 (0.004) Batch 0.871 (0.617) Remain 12:20:24 loss: 6.9806 mask_loss: 5.7525 roll_mask_loss: 6.7184 density_loss: 9.4167 unmask_loss: 7.5374 Lr: 0.00240
[2025-12-10 17:18:10,768 INFO misc.py line 117 4140988] Train: [1/10][1986/7400] Data 0.004 (0.004) Batch 0.697 (0.617) Remain 12:20:26 loss: 6.8500 mask_loss: 5.9324 roll_mask_loss: 6.5449 density_loss: 9.0716 unmask_loss: 7.2798 Lr: 0.00241
[2025-12-10 17:18:11,438 INFO misc.py line 117 4140988] Train: [1/10][1987/7400] Data 0.004 (0.004) Batch 0.669 (0.617) Remain 12:20:27 loss: 6.8702 mask_loss: 6.0723 roll_mask_loss: 6.8291 density_loss: 9.0118 unmask_loss: 7.1094 Lr: 0.00241
[2025-12-10 17:18:12,022 INFO misc.py line 117 4140988] Train: [1/10][1988/7400] Data 0.004 (0.004) Batch 0.585 (0.617) Remain 12:20:26 loss: 7.8016 mask_loss: 7.0882 roll_mask_loss: 8.0846 density_loss: 8.4259 unmask_loss: 7.8483 Lr: 0.00241
[2025-12-10 17:18:12,513 INFO misc.py line 117 4140988] Train: [1/10][1989/7400] Data 0.003 (0.004) Batch 0.490 (0.617) Remain 12:20:20 loss: 8.4405 mask_loss: 8.3406 roll_mask_loss: 8.3539 density_loss: 8.3621 unmask_loss: 8.3666 Lr: 0.00241
[2025-12-10 17:18:13,114 INFO misc.py line 117 4140988] Train: [1/10][1990/7400] Data 0.004 (0.004) Batch 0.601 (0.617) Remain 12:20:19 loss: 7.4789 mask_loss: 7.0002 roll_mask_loss: 7.8380 density_loss: 8.8528 unmask_loss: 7.3616 Lr: 0.00241
[2025-12-10 17:18:13,727 INFO misc.py line 117 4140988] Train: [1/10][1991/7400] Data 0.004 (0.004) Batch 0.613 (0.617) Remain 12:20:18 loss: 7.6454 mask_loss: 7.1714 roll_mask_loss: 7.5193 density_loss: 8.8201 unmask_loss: 7.7692 Lr: 0.00241
[2025-12-10 17:18:14,350 INFO misc.py line 117 4140988] Train: [1/10][1992/7400] Data 0.004 (0.004) Batch 0.624 (0.617) Remain 12:20:18 loss: 6.9108 mask_loss: 6.0517 roll_mask_loss: 6.9492 density_loss: 8.8913 unmask_loss: 7.1434 Lr: 0.00241
[2025-12-10 17:18:15,109 INFO misc.py line 117 4140988] Train: [1/10][1993/7400] Data 0.004 (0.004) Batch 0.759 (0.617) Remain 12:20:23 loss: 6.7392 mask_loss: 5.9295 roll_mask_loss: 6.4296 density_loss: 9.1945 unmask_loss: 7.1149 Lr: 0.00242
[2025-12-10 17:18:15,757 INFO misc.py line 117 4140988] Train: [1/10][1994/7400] Data 0.004 (0.004) Batch 0.648 (0.617) Remain 12:20:23 loss: 6.7472 mask_loss: 5.8785 roll_mask_loss: 6.6087 density_loss: 9.3877 unmask_loss: 7.0630 Lr: 0.00242
[2025-12-10 17:18:16,377 INFO misc.py line 117 4140988] Train: [1/10][1995/7400] Data 0.003 (0.004) Batch 0.619 (0.617) Remain 12:20:22 loss: 7.2119 mask_loss: 6.4035 roll_mask_loss: 6.7233 density_loss: 8.0753 unmask_loss: 7.6988 Lr: 0.00242
[2025-12-10 17:18:17,093 INFO misc.py line 117 4140988] Train: [1/10][1996/7400] Data 0.004 (0.004) Batch 0.716 (0.617) Remain 12:20:25 loss: 6.9621 mask_loss: 6.1669 roll_mask_loss: 6.9189 density_loss: 9.1416 unmask_loss: 7.1984 Lr: 0.00242
[2025-12-10 17:18:17,835 INFO misc.py line 117 4140988] Train: [1/10][1997/7400] Data 0.004 (0.004) Batch 0.741 (0.617) Remain 12:20:29 loss: 6.9434 mask_loss: 6.0480 roll_mask_loss: 7.1192 density_loss: 8.7757 unmask_loss: 7.1277 Lr: 0.00242
[2025-12-10 17:18:18,289 INFO misc.py line 117 4140988] Train: [1/10][1998/7400] Data 0.004 (0.004) Batch 0.455 (0.617) Remain 12:20:23 loss: 7.0408 mask_loss: 6.3061 roll_mask_loss: 7.0394 density_loss: 8.8525 unmask_loss: 7.2319 Lr: 0.00242
[2025-12-10 17:18:18,719 INFO misc.py line 117 4140988] Train: [1/10][1999/7400] Data 0.004 (0.004) Batch 0.430 (0.617) Remain 12:20:15 loss: 7.7401 mask_loss: 6.9706 roll_mask_loss: 7.7791 density_loss: 8.4864 unmask_loss: 7.9357 Lr: 0.00242
[2025-12-10 17:18:19,355 INFO misc.py line 117 4140988] Train: [1/10][2000/7400] Data 0.004 (0.004) Batch 0.637 (0.617) Remain 12:20:16 loss: 7.2718 mask_loss: 6.5108 roll_mask_loss: 7.3688 density_loss: 8.7383 unmask_loss: 7.4290 Lr: 0.00243
[2025-12-10 17:18:20,018 INFO misc.py line 117 4140988] Train: [1/10][2001/7400] Data 0.003 (0.004) Batch 0.662 (0.617) Remain 12:20:17 loss: 7.2969 mask_loss: 6.6212 roll_mask_loss: 7.0769 density_loss: 7.7762 unmask_loss: 7.5891 Lr: 0.00243
[2025-12-10 17:18:20,570 INFO misc.py line 117 4140988] Train: [1/10][2002/7400] Data 0.004 (0.004) Batch 0.551 (0.617) Remain 12:20:14 loss: 7.0319 mask_loss: 6.2434 roll_mask_loss: 6.8905 density_loss: 9.0416 unmask_loss: 7.3160 Lr: 0.00243
[2025-12-10 17:18:21,120 INFO misc.py line 117 4140988] Train: [1/10][2003/7400] Data 0.004 (0.004) Batch 0.551 (0.617) Remain 12:20:11 loss: 8.1985 mask_loss: 7.9466 roll_mask_loss: 8.4154 density_loss: 8.5472 unmask_loss: 8.0451 Lr: 0.00243
[2025-12-10 17:18:22,084 INFO misc.py line 117 4140988] Train: [1/10][2004/7400] Data 0.004 (0.004) Batch 0.965 (0.617) Remain 12:20:23 loss: 6.8914 mask_loss: 5.7854 roll_mask_loss: 7.0027 density_loss: 9.0536 unmask_loss: 7.2076 Lr: 0.00243
[2025-12-10 17:18:22,863 INFO misc.py line 117 4140988] Train: [1/10][2005/7400] Data 0.003 (0.004) Batch 0.777 (0.617) Remain 12:20:28 loss: 7.0183 mask_loss: 6.2103 roll_mask_loss: 6.8773 density_loss: 9.3032 unmask_loss: 7.3068 Lr: 0.00243
[2025-12-10 17:18:23,506 INFO misc.py line 117 4140988] Train: [1/10][2006/7400] Data 0.004 (0.004) Batch 0.643 (0.617) Remain 12:20:28 loss: 6.6636 mask_loss: 5.7018 roll_mask_loss: 6.3654 density_loss: 9.7226 unmask_loss: 7.0991 Lr: 0.00244
[2025-12-10 17:18:23,991 INFO misc.py line 117 4140988] Train: [1/10][2007/7400] Data 0.004 (0.004) Batch 0.485 (0.617) Remain 12:20:23 loss: 7.8541 mask_loss: 7.4675 roll_mask_loss: 7.9309 density_loss: 8.4671 unmask_loss: 7.8397 Lr: 0.00244
[2025-12-10 17:18:24,543 INFO misc.py line 117 4140988] Train: [1/10][2008/7400] Data 0.004 (0.004) Batch 0.552 (0.617) Remain 12:20:20 loss: 8.4323 mask_loss: 8.3286 roll_mask_loss: 8.3394 density_loss: 8.3391 unmask_loss: 8.3637 Lr: 0.00244
[2025-12-10 17:18:25,068 INFO misc.py line 117 4140988] Train: [1/10][2009/7400] Data 0.004 (0.004) Batch 0.525 (0.617) Remain 12:20:16 loss: 8.3860 mask_loss: 8.1001 roll_mask_loss: 8.3407 density_loss: 8.3680 unmask_loss: 8.3842 Lr: 0.00244
[2025-12-10 17:18:25,583 INFO misc.py line 117 4140988] Train: [1/10][2010/7400] Data 0.004 (0.004) Batch 0.516 (0.617) Remain 12:20:12 loss: 6.9794 mask_loss: 6.1850 roll_mask_loss: 6.8037 density_loss: 8.5472 unmask_loss: 7.2935 Lr: 0.00244
[2025-12-10 17:18:26,149 INFO misc.py line 117 4140988] Train: [1/10][2011/7400] Data 0.003 (0.004) Batch 0.566 (0.617) Remain 12:20:09 loss: 7.1948 mask_loss: 6.3441 roll_mask_loss: 7.2417 density_loss: 8.9407 unmask_loss: 7.4179 Lr: 0.00244
[2025-12-10 17:18:26,912 INFO misc.py line 117 4140988] Train: [1/10][2012/7400] Data 0.004 (0.004) Batch 0.763 (0.617) Remain 12:20:14 loss: 6.8724 mask_loss: 6.0323 roll_mask_loss: 6.8154 density_loss: 9.0111 unmask_loss: 7.1407 Lr: 0.00244
[2025-12-10 17:18:27,403 INFO misc.py line 117 4140988] Train: [1/10][2013/7400] Data 0.005 (0.004) Batch 0.491 (0.617) Remain 12:20:09 loss: 8.4116 mask_loss: 8.3201 roll_mask_loss: 8.3328 density_loss: 8.3370 unmask_loss: 8.3300 Lr: 0.00245
[2025-12-10 17:18:27,994 INFO misc.py line 117 4140988] Train: [1/10][2014/7400] Data 0.004 (0.004) Batch 0.590 (0.617) Remain 12:20:07 loss: 7.3024 mask_loss: 6.5167 roll_mask_loss: 7.1882 density_loss: 9.6065 unmask_loss: 7.5604 Lr: 0.00245
[2025-12-10 17:18:28,799 INFO misc.py line 117 4140988] Train: [1/10][2015/7400] Data 0.004 (0.004) Batch 0.806 (0.617) Remain 12:20:13 loss: 6.8542 mask_loss: 6.0396 roll_mask_loss: 6.7706 density_loss: 8.9216 unmask_loss: 7.1248 Lr: 0.00245
[2025-12-10 17:18:29,521 INFO misc.py line 117 4140988] Train: [1/10][2016/7400] Data 0.004 (0.004) Batch 0.723 (0.617) Remain 12:20:16 loss: 7.0552 mask_loss: 6.1694 roll_mask_loss: 6.8378 density_loss: 8.6479 unmask_loss: 7.4339 Lr: 0.00245
[2025-12-10 17:18:30,033 INFO misc.py line 117 4140988] Train: [1/10][2017/7400] Data 0.003 (0.004) Batch 0.512 (0.617) Remain 12:20:12 loss: 8.4082 mask_loss: 8.3220 roll_mask_loss: 8.3311 density_loss: 8.3297 unmask_loss: 8.3233 Lr: 0.00245
[2025-12-10 17:18:30,694 INFO misc.py line 117 4140988] Train: [1/10][2018/7400] Data 0.003 (0.004) Batch 0.661 (0.617) Remain 12:20:13 loss: 7.0124 mask_loss: 6.5152 roll_mask_loss: 6.6599 density_loss: 8.2359 unmask_loss: 7.2725 Lr: 0.00245
[2025-12-10 17:18:31,308 INFO misc.py line 117 4140988] Train: [1/10][2019/7400] Data 0.003 (0.004) Batch 0.613 (0.617) Remain 12:20:12 loss: 6.6078 mask_loss: 5.8052 roll_mask_loss: 6.2271 density_loss: 8.5559 unmask_loss: 7.0283 Lr: 0.00246
[2025-12-10 17:18:31,943 INFO misc.py line 117 4140988] Train: [1/10][2020/7400] Data 0.003 (0.004) Batch 0.635 (0.617) Remain 12:20:12 loss: 7.4100 mask_loss: 6.9289 roll_mask_loss: 7.5390 density_loss: 9.2718 unmask_loss: 7.4005 Lr: 0.00246
[2025-12-10 17:18:32,628 INFO misc.py line 117 4140988] Train: [1/10][2021/7400] Data 0.003 (0.004) Batch 0.684 (0.617) Remain 12:20:14 loss: 7.2088 mask_loss: 5.8665 roll_mask_loss: 6.9940 density_loss: 10.1270 unmask_loss: 7.7849 Lr: 0.00246
[2025-12-10 17:18:33,286 INFO misc.py line 117 4140988] Train: [1/10][2022/7400] Data 0.004 (0.004) Batch 0.658 (0.617) Remain 12:20:15 loss: 6.8954 mask_loss: 5.8491 roll_mask_loss: 6.9414 density_loss: 9.7032 unmask_loss: 7.2015 Lr: 0.00246
[2025-12-10 17:18:34,049 INFO misc.py line 117 4140988] Train: [1/10][2023/7400] Data 0.004 (0.004) Batch 0.763 (0.617) Remain 12:20:19 loss: 7.0621 mask_loss: 6.1642 roll_mask_loss: 6.9996 density_loss: 9.4418 unmask_loss: 7.3535 Lr: 0.00246
[2025-12-10 17:18:34,845 INFO misc.py line 117 4140988] Train: [1/10][2024/7400] Data 0.004 (0.004) Batch 0.796 (0.617) Remain 12:20:25 loss: 7.5800 mask_loss: 7.0486 roll_mask_loss: 7.2871 density_loss: 8.8861 unmask_loss: 7.8145 Lr: 0.00246
[2025-12-10 17:18:35,447 INFO misc.py line 117 4140988] Train: [1/10][2025/7400] Data 0.004 (0.004) Batch 0.602 (0.617) Remain 12:20:24 loss: 6.7626 mask_loss: 5.6889 roll_mask_loss: 6.7299 density_loss: 9.4377 unmask_loss: 7.1271 Lr: 0.00246
[2025-12-10 17:18:35,995 INFO misc.py line 117 4140988] Train: [1/10][2026/7400] Data 0.003 (0.004) Batch 0.549 (0.617) Remain 12:20:21 loss: 8.0414 mask_loss: 7.3886 roll_mask_loss: 8.2632 density_loss: 8.5031 unmask_loss: 8.0869 Lr: 0.00247
[2025-12-10 17:18:36,731 INFO misc.py line 117 4140988] Train: [1/10][2027/7400] Data 0.003 (0.004) Batch 0.735 (0.617) Remain 12:20:25 loss: 7.4682 mask_loss: 6.6027 roll_mask_loss: 7.4771 density_loss: 8.5451 unmask_loss: 7.7257 Lr: 0.00247
[2025-12-10 17:18:37,589 INFO misc.py line 117 4140988] Train: [1/10][2028/7400] Data 0.004 (0.004) Batch 0.858 (0.617) Remain 12:20:32 loss: 6.7328 mask_loss: 5.7567 roll_mask_loss: 6.4201 density_loss: 9.9556 unmask_loss: 7.1781 Lr: 0.00247
[2025-12-10 17:18:38,221 INFO misc.py line 117 4140988] Train: [1/10][2029/7400] Data 0.004 (0.004) Batch 0.631 (0.617) Remain 12:20:32 loss: 7.1476 mask_loss: 6.4829 roll_mask_loss: 7.1419 density_loss: 9.3289 unmask_loss: 7.2962 Lr: 0.00247
[2025-12-10 17:18:38,912 INFO misc.py line 117 4140988] Train: [1/10][2030/7400] Data 0.004 (0.004) Batch 0.691 (0.617) Remain 12:20:34 loss: 6.9065 mask_loss: 5.9294 roll_mask_loss: 6.7744 density_loss: 9.4381 unmask_loss: 7.2724 Lr: 0.00247
[2025-12-10 17:18:39,540 INFO misc.py line 117 4140988] Train: [1/10][2031/7400] Data 0.005 (0.004) Batch 0.628 (0.617) Remain 12:20:34 loss: 6.9369 mask_loss: 6.0472 roll_mask_loss: 6.9926 density_loss: 9.0957 unmask_loss: 7.1720 Lr: 0.00247
[2025-12-10 17:18:40,193 INFO misc.py line 117 4140988] Train: [1/10][2032/7400] Data 0.004 (0.004) Batch 0.654 (0.617) Remain 12:20:35 loss: 6.9698 mask_loss: 6.1141 roll_mask_loss: 6.9016 density_loss: 8.8404 unmask_loss: 7.2549 Lr: 0.00247
[2025-12-10 17:18:40,808 INFO misc.py line 117 4140988] Train: [1/10][2033/7400] Data 0.003 (0.004) Batch 0.614 (0.617) Remain 12:20:34 loss: 7.6845 mask_loss: 6.9585 roll_mask_loss: 7.8151 density_loss: 8.0804 unmask_loss: 7.8206 Lr: 0.00248
[2025-12-10 17:18:41,395 INFO misc.py line 117 4140988] Train: [1/10][2034/7400] Data 0.004 (0.004) Batch 0.588 (0.617) Remain 12:20:32 loss: 6.9504 mask_loss: 6.0878 roll_mask_loss: 6.9308 density_loss: 9.4201 unmask_loss: 7.2031 Lr: 0.00248
[2025-12-10 17:18:41,924 INFO misc.py line 117 4140988] Train: [1/10][2035/7400] Data 0.004 (0.004) Batch 0.529 (0.617) Remain 12:20:29 loss: 8.1548 mask_loss: 7.8054 roll_mask_loss: 8.1447 density_loss: 8.5307 unmask_loss: 8.1639 Lr: 0.00248
[2025-12-10 17:18:42,507 INFO misc.py line 117 4140988] Train: [1/10][2036/7400] Data 0.003 (0.004) Batch 0.584 (0.617) Remain 12:20:27 loss: 7.8063 mask_loss: 6.9956 roll_mask_loss: 7.9315 density_loss: 8.5445 unmask_loss: 7.9782 Lr: 0.00248
[2025-12-10 17:18:42,967 INFO misc.py line 117 4140988] Train: [1/10][2037/7400] Data 0.003 (0.004) Batch 0.459 (0.617) Remain 12:20:21 loss: 8.4156 mask_loss: 8.3268 roll_mask_loss: 8.3358 density_loss: 8.3362 unmask_loss: 8.3332 Lr: 0.00248
[2025-12-10 17:18:43,516 INFO misc.py line 117 4140988] Train: [1/10][2038/7400] Data 0.004 (0.004) Batch 0.549 (0.617) Remain 12:20:18 loss: 7.6922 mask_loss: 7.2238 roll_mask_loss: 7.6436 density_loss: 8.3719 unmask_loss: 7.7832 Lr: 0.00248
[2025-12-10 17:18:43,847 INFO misc.py line 117 4140988] Train: [1/10][2039/7400] Data 0.004 (0.004) Batch 0.331 (0.617) Remain 12:20:07 loss: 7.1427 mask_loss: 6.4306 roll_mask_loss: 6.9346 density_loss: 9.1905 unmask_loss: 7.4189 Lr: 0.00249
[2025-12-10 17:18:44,587 INFO misc.py line 117 4140988] Train: [1/10][2040/7400] Data 0.004 (0.004) Batch 0.740 (0.617) Remain 12:20:11 loss: 7.1107 mask_loss: 6.4674 roll_mask_loss: 6.9913 density_loss: 8.9696 unmask_loss: 7.3127 Lr: 0.00249
[2025-12-10 17:18:44,958 INFO misc.py line 117 4140988] Train: [1/10][2041/7400] Data 0.004 (0.004) Batch 0.371 (0.617) Remain 12:20:01 loss: 7.2890 mask_loss: 6.6186 roll_mask_loss: 7.1026 density_loss: 9.6301 unmask_loss: 7.5249 Lr: 0.00249
[2025-12-10 17:18:45,308 INFO misc.py line 117 4140988] Train: [1/10][2042/7400] Data 0.004 (0.004) Batch 0.350 (0.617) Remain 12:19:51 loss: 6.9872 mask_loss: 6.2209 roll_mask_loss: 6.9007 density_loss: 9.0945 unmask_loss: 7.2317 Lr: 0.00249
[2025-12-10 17:18:45,878 INFO misc.py line 117 4140988] Train: [1/10][2043/7400] Data 0.004 (0.004) Batch 0.569 (0.617) Remain 12:19:49 loss: 8.2600 mask_loss: 8.1169 roll_mask_loss: 8.2511 density_loss: 8.3960 unmask_loss: 8.1681 Lr: 0.00249
[2025-12-10 17:18:46,437 INFO misc.py line 117 4140988] Train: [1/10][2044/7400] Data 0.006 (0.004) Batch 0.560 (0.617) Remain 12:19:46 loss: 7.9757 mask_loss: 7.5830 roll_mask_loss: 8.0046 density_loss: 8.3562 unmask_loss: 7.9905 Lr: 0.00249
[2025-12-10 17:18:47,038 INFO misc.py line 117 4140988] Train: [1/10][2045/7400] Data 0.004 (0.004) Batch 0.602 (0.617) Remain 12:19:45 loss: 7.1136 mask_loss: 6.3502 roll_mask_loss: 6.9243 density_loss: 9.4745 unmask_loss: 7.4005 Lr: 0.00249
[2025-12-10 17:18:48,093 INFO misc.py line 117 4140988] Train: [1/10][2046/7400] Data 0.004 (0.004) Batch 1.055 (0.617) Remain 12:20:00 loss: 7.3641 mask_loss: 5.9773 roll_mask_loss: 7.2270 density_loss: 10.2060 unmask_loss: 7.9220 Lr: 0.00250
[2025-12-10 17:18:48,839 INFO misc.py line 117 4140988] Train: [1/10][2047/7400] Data 0.004 (0.004) Batch 0.747 (0.617) Remain 12:20:04 loss: 7.3488 mask_loss: 6.5195 roll_mask_loss: 7.4139 density_loss: 8.8489 unmask_loss: 7.5539 Lr: 0.00250
[2025-12-10 17:18:49,480 INFO misc.py line 117 4140988] Train: [1/10][2048/7400] Data 0.003 (0.004) Batch 0.641 (0.617) Remain 12:20:04 loss: 7.0157 mask_loss: 6.3590 roll_mask_loss: 6.8974 density_loss: 9.2407 unmask_loss: 7.2184 Lr: 0.00250
[2025-12-10 17:18:49,885 INFO misc.py line 117 4140988] Train: [1/10][2049/7400] Data 0.003 (0.004) Batch 0.405 (0.617) Remain 12:19:56 loss: 7.7622 mask_loss: 7.2440 roll_mask_loss: 7.5187 density_loss: 8.9265 unmask_loss: 7.9644 Lr: 0.00250
[2025-12-10 17:18:50,524 INFO misc.py line 117 4140988] Train: [1/10][2050/7400] Data 0.004 (0.004) Batch 0.639 (0.617) Remain 12:19:56 loss: 7.2368 mask_loss: 6.5952 roll_mask_loss: 7.3532 density_loss: 8.3911 unmask_loss: 7.3316 Lr: 0.00250
[2025-12-10 17:18:51,090 INFO misc.py line 117 4140988] Train: [1/10][2051/7400] Data 0.003 (0.004) Batch 0.566 (0.617) Remain 12:19:54 loss: 7.7525 mask_loss: 7.3391 roll_mask_loss: 7.6100 density_loss: 9.0340 unmask_loss: 7.8497 Lr: 0.00250
[2025-12-10 17:18:51,639 INFO misc.py line 117 4140988] Train: [1/10][2052/7400] Data 0.003 (0.004) Batch 0.549 (0.617) Remain 12:19:51 loss: 7.3889 mask_loss: 6.8191 roll_mask_loss: 7.2274 density_loss: 9.2600 unmask_loss: 7.5694 Lr: 0.00251
[2025-12-10 17:18:52,389 INFO misc.py line 117 4140988] Train: [1/10][2053/7400] Data 0.003 (0.004) Batch 0.749 (0.617) Remain 12:19:55 loss: 6.9997 mask_loss: 5.9668 roll_mask_loss: 6.7683 density_loss: 9.6479 unmask_loss: 7.4388 Lr: 0.00251
[2025-12-10 17:18:53,016 INFO misc.py line 117 4140988] Train: [1/10][2054/7400] Data 0.004 (0.004) Batch 0.626 (0.617) Remain 12:19:54 loss: 7.1134 mask_loss: 6.6137 roll_mask_loss: 7.0399 density_loss: 8.7671 unmask_loss: 7.2246 Lr: 0.00251
[2025-12-10 17:18:53,602 INFO misc.py line 117 4140988] Train: [1/10][2055/7400] Data 0.004 (0.004) Batch 0.586 (0.617) Remain 12:19:53 loss: 7.2377 mask_loss: 6.5500 roll_mask_loss: 7.1653 density_loss: 9.0243 unmask_loss: 7.4373 Lr: 0.00251
[2025-12-10 17:18:54,230 INFO misc.py line 117 4140988] Train: [1/10][2056/7400] Data 0.004 (0.004) Batch 0.628 (0.617) Remain 12:19:53 loss: 7.5723 mask_loss: 6.9645 roll_mask_loss: 7.3627 density_loss: 8.6296 unmask_loss: 7.8085 Lr: 0.00251
[2025-12-10 17:18:54,543 INFO misc.py line 117 4140988] Train: [1/10][2057/7400] Data 0.005 (0.004) Batch 0.314 (0.617) Remain 12:19:41 loss: 8.0144 mask_loss: 7.5007 roll_mask_loss: 7.8082 density_loss: 8.8691 unmask_loss: 8.1969 Lr: 0.00251
[2025-12-10 17:18:55,132 INFO misc.py line 117 4140988] Train: [1/10][2058/7400] Data 0.004 (0.004) Batch 0.589 (0.617) Remain 12:19:40 loss: 7.8339 mask_loss: 7.1409 roll_mask_loss: 7.6488 density_loss: 8.4385 unmask_loss: 8.1043 Lr: 0.00251
[2025-12-10 17:18:55,786 INFO misc.py line 117 4140988] Train: [1/10][2059/7400] Data 0.004 (0.004) Batch 0.654 (0.617) Remain 12:19:40 loss: 6.9802 mask_loss: 5.9020 roll_mask_loss: 6.8003 density_loss: 10.2153 unmask_loss: 7.4048 Lr: 0.00252
[2025-12-10 17:18:56,333 INFO misc.py line 117 4140988] Train: [1/10][2060/7400] Data 0.004 (0.004) Batch 0.547 (0.617) Remain 12:19:37 loss: 7.4889 mask_loss: 6.6768 roll_mask_loss: 8.2693 density_loss: 9.2586 unmask_loss: 7.3196 Lr: 0.00252
[2025-12-10 17:18:56,880 INFO misc.py line 117 4140988] Train: [1/10][2061/7400] Data 0.004 (0.004) Batch 0.547 (0.617) Remain 12:19:34 loss: 6.9209 mask_loss: 5.7901 roll_mask_loss: 6.7549 density_loss: 9.9679 unmask_loss: 7.3699 Lr: 0.00252
[2025-12-10 17:18:57,707 INFO misc.py line 117 4140988] Train: [1/10][2062/7400] Data 0.004 (0.004) Batch 0.827 (0.617) Remain 12:19:41 loss: 6.9985 mask_loss: 5.7805 roll_mask_loss: 6.7893 density_loss: 10.2595 unmask_loss: 7.5069 Lr: 0.00252
[2025-12-10 17:18:58,369 INFO misc.py line 117 4140988] Train: [1/10][2063/7400] Data 0.004 (0.004) Batch 0.663 (0.617) Remain 12:19:42 loss: 6.8742 mask_loss: 5.9898 roll_mask_loss: 6.5823 density_loss: 8.6185 unmask_loss: 7.2901 Lr: 0.00252
[2025-12-10 17:18:58,918 INFO misc.py line 117 4140988] Train: [1/10][2064/7400] Data 0.004 (0.004) Batch 0.549 (0.617) Remain 12:19:39 loss: 6.8746 mask_loss: 6.0336 roll_mask_loss: 6.8710 density_loss: 8.6788 unmask_loss: 7.1234 Lr: 0.00252
[2025-12-10 17:18:59,502 INFO misc.py line 117 4140988] Train: [1/10][2065/7400] Data 0.003 (0.004) Batch 0.585 (0.617) Remain 12:19:37 loss: 8.0546 mask_loss: 7.8423 roll_mask_loss: 8.1798 density_loss: 8.3878 unmask_loss: 7.9303 Lr: 0.00252
[2025-12-10 17:19:00,153 INFO misc.py line 117 4140988] Train: [1/10][2066/7400] Data 0.003 (0.004) Batch 0.651 (0.617) Remain 12:19:38 loss: 7.0460 mask_loss: 5.9721 roll_mask_loss: 7.1525 density_loss: 8.9166 unmask_loss: 7.3513 Lr: 0.00253
[2025-12-10 17:19:00,786 INFO misc.py line 117 4140988] Train: [1/10][2067/7400] Data 0.003 (0.004) Batch 0.633 (0.617) Remain 12:19:38 loss: 7.2069 mask_loss: 6.4577 roll_mask_loss: 7.0900 density_loss: 9.1688 unmask_loss: 7.4565 Lr: 0.00253
[2025-12-10 17:19:01,488 INFO misc.py line 117 4140988] Train: [1/10][2068/7400] Data 0.003 (0.004) Batch 0.702 (0.617) Remain 12:19:40 loss: 7.0475 mask_loss: 6.4582 roll_mask_loss: 6.8196 density_loss: 8.7889 unmask_loss: 7.2804 Lr: 0.00253
[2025-12-10 17:19:02,053 INFO misc.py line 117 4140988] Train: [1/10][2069/7400] Data 0.003 (0.004) Batch 0.564 (0.617) Remain 12:19:38 loss: 7.0384 mask_loss: 6.2251 roll_mask_loss: 7.0218 density_loss: 9.5755 unmask_loss: 7.2617 Lr: 0.00253
[2025-12-10 17:19:02,999 INFO misc.py line 117 4140988] Train: [1/10][2070/7400] Data 0.004 (0.004) Batch 0.946 (0.617) Remain 12:19:48 loss: 6.7287 mask_loss: 5.6835 roll_mask_loss: 6.5277 density_loss: 9.7922 unmask_loss: 7.1560 Lr: 0.00253
[2025-12-10 17:19:03,347 INFO misc.py line 117 4140988] Train: [1/10][2071/7400] Data 0.004 (0.004) Batch 0.348 (0.617) Remain 12:19:38 loss: 7.1572 mask_loss: 6.5340 roll_mask_loss: 6.9033 density_loss: 8.3325 unmask_loss: 7.4290 Lr: 0.00253
[2025-12-10 17:19:04,019 INFO misc.py line 117 4140988] Train: [1/10][2072/7400] Data 0.004 (0.004) Batch 0.673 (0.617) Remain 12:19:40 loss: 6.7604 mask_loss: 5.6328 roll_mask_loss: 6.7424 density_loss: 9.1822 unmask_loss: 7.1496 Lr: 0.00254
[2025-12-10 17:19:04,490 INFO misc.py line 117 4140988] Train: [1/10][2073/7400] Data 0.003 (0.004) Batch 0.471 (0.617) Remain 12:19:34 loss: 7.9998 mask_loss: 7.4129 roll_mask_loss: 8.1828 density_loss: 8.7029 unmask_loss: 8.0276 Lr: 0.00254
[2025-12-10 17:19:05,166 INFO misc.py line 117 4140988] Train: [1/10][2074/7400] Data 0.003 (0.004) Batch 0.676 (0.617) Remain 12:19:36 loss: 6.9246 mask_loss: 5.9582 roll_mask_loss: 6.8481 density_loss: 9.4056 unmask_loss: 7.2579 Lr: 0.00254
[2025-12-10 17:19:06,000 INFO misc.py line 117 4140988] Train: [1/10][2075/7400] Data 0.004 (0.004) Batch 0.834 (0.617) Remain 12:19:42 loss: 6.9722 mask_loss: 5.7535 roll_mask_loss: 6.8418 density_loss: 9.9637 unmask_loss: 7.4474 Lr: 0.00254
[2025-12-10 17:19:06,565 INFO misc.py line 117 4140988] Train: [1/10][2076/7400] Data 0.004 (0.004) Batch 0.565 (0.617) Remain 12:19:40 loss: 7.5809 mask_loss: 7.0149 roll_mask_loss: 7.4942 density_loss: 8.8491 unmask_loss: 7.7302 Lr: 0.00254
[2025-12-10 17:19:07,041 INFO misc.py line 117 4140988] Train: [1/10][2077/7400] Data 0.004 (0.004) Batch 0.476 (0.617) Remain 12:19:34 loss: 7.5507 mask_loss: 6.8698 roll_mask_loss: 7.5628 density_loss: 8.5662 unmask_loss: 7.7138 Lr: 0.00254
[2025-12-10 17:19:07,628 INFO misc.py line 117 4140988] Train: [1/10][2078/7400] Data 0.004 (0.004) Batch 0.587 (0.617) Remain 12:19:33 loss: 6.9323 mask_loss: 6.2509 roll_mask_loss: 6.6320 density_loss: 8.9115 unmask_loss: 7.2450 Lr: 0.00254
[2025-12-10 17:19:08,200 INFO misc.py line 117 4140988] Train: [1/10][2079/7400] Data 0.004 (0.004) Batch 0.573 (0.617) Remain 12:19:31 loss: 8.3123 mask_loss: 8.1708 roll_mask_loss: 8.1762 density_loss: 8.4558 unmask_loss: 8.2821 Lr: 0.00255
[2025-12-10 17:19:09,012 INFO misc.py line 117 4140988] Train: [1/10][2080/7400] Data 0.003 (0.004) Batch 0.812 (0.617) Remain 12:19:37 loss: 7.0635 mask_loss: 6.3449 roll_mask_loss: 6.8249 density_loss: 8.4010 unmask_loss: 7.3740 Lr: 0.00255
[2025-12-10 17:19:09,652 INFO misc.py line 117 4140988] Train: [1/10][2081/7400] Data 0.003 (0.004) Batch 0.640 (0.617) Remain 12:19:37 loss: 6.8408 mask_loss: 5.9335 roll_mask_loss: 6.6665 density_loss: 8.8251 unmask_loss: 7.2051 Lr: 0.00255
[2025-12-10 17:19:10,431 INFO misc.py line 117 4140988] Train: [1/10][2082/7400] Data 0.004 (0.004) Batch 0.779 (0.617) Remain 12:19:42 loss: 7.0327 mask_loss: 6.1565 roll_mask_loss: 6.9906 density_loss: 8.0269 unmask_loss: 7.3313 Lr: 0.00255
[2025-12-10 17:19:10,983 INFO misc.py line 117 4140988] Train: [1/10][2083/7400] Data 0.004 (0.004) Batch 0.552 (0.617) Remain 12:19:39 loss: 6.8157 mask_loss: 6.0267 roll_mask_loss: 6.6824 density_loss: 9.7537 unmask_loss: 7.0819 Lr: 0.00255
[2025-12-10 17:19:11,695 INFO misc.py line 117 4140988] Train: [1/10][2084/7400] Data 0.003 (0.004) Batch 0.712 (0.617) Remain 12:19:42 loss: 6.8198 mask_loss: 6.1061 roll_mask_loss: 6.6679 density_loss: 9.3722 unmask_loss: 7.0651 Lr: 0.00255
[2025-12-10 17:19:12,354 INFO misc.py line 117 4140988] Train: [1/10][2085/7400] Data 0.003 (0.004) Batch 0.659 (0.617) Remain 12:19:43 loss: 6.9219 mask_loss: 6.0535 roll_mask_loss: 6.7792 density_loss: 8.4255 unmask_loss: 7.2589 Lr: 0.00255
[2025-12-10 17:19:12,932 INFO misc.py line 117 4140988] Train: [1/10][2086/7400] Data 0.004 (0.004) Batch 0.578 (0.617) Remain 12:19:41 loss: 6.8418 mask_loss: 5.8282 roll_mask_loss: 6.6384 density_loss: 9.9998 unmask_loss: 7.2503 Lr: 0.00256
[2025-12-10 17:19:13,633 INFO misc.py line 117 4140988] Train: [1/10][2087/7400] Data 0.003 (0.004) Batch 0.702 (0.617) Remain 12:19:43 loss: 6.7441 mask_loss: 5.8330 roll_mask_loss: 6.6257 density_loss: 9.8461 unmask_loss: 7.0620 Lr: 0.00256
[2025-12-10 17:19:14,169 INFO misc.py line 117 4140988] Train: [1/10][2088/7400] Data 0.003 (0.004) Batch 0.536 (0.617) Remain 12:19:39 loss: 6.8631 mask_loss: 5.9848 roll_mask_loss: 6.6368 density_loss: 9.3219 unmask_loss: 7.2291 Lr: 0.00256
[2025-12-10 17:19:14,991 INFO misc.py line 117 4140988] Train: [1/10][2089/7400] Data 0.003 (0.004) Batch 0.822 (0.617) Remain 12:19:46 loss: 7.0711 mask_loss: 6.0440 roll_mask_loss: 7.1656 density_loss: 10.2882 unmask_loss: 7.3316 Lr: 0.00256
[2025-12-10 17:19:15,604 INFO misc.py line 117 4140988] Train: [1/10][2090/7400] Data 0.004 (0.004) Batch 0.613 (0.617) Remain 12:19:45 loss: 7.1702 mask_loss: 6.2419 roll_mask_loss: 6.8987 density_loss: 8.8448 unmask_loss: 7.5933 Lr: 0.00256
[2025-12-10 17:19:16,255 INFO misc.py line 117 4140988] Train: [1/10][2091/7400] Data 0.004 (0.004) Batch 0.651 (0.617) Remain 12:19:46 loss: 6.8613 mask_loss: 6.0889 roll_mask_loss: 6.5602 density_loss: 9.8728 unmask_loss: 7.2006 Lr: 0.00256
[2025-12-10 17:19:16,818 INFO misc.py line 117 4140988] Train: [1/10][2092/7400] Data 0.004 (0.004) Batch 0.563 (0.617) Remain 12:19:43 loss: 8.2170 mask_loss: 7.8933 roll_mask_loss: 8.1091 density_loss: 8.5117 unmask_loss: 8.2626 Lr: 0.00257
[2025-12-10 17:19:17,320 INFO misc.py line 117 4140988] Train: [1/10][2093/7400] Data 0.003 (0.004) Batch 0.502 (0.617) Remain 12:19:39 loss: 6.9110 mask_loss: 5.8672 roll_mask_loss: 6.5829 density_loss: 10.2343 unmask_loss: 7.3922 Lr: 0.00257
[2025-12-10 17:19:17,888 INFO misc.py line 117 4140988] Train: [1/10][2094/7400] Data 0.004 (0.004) Batch 0.568 (0.617) Remain 12:19:36 loss: 7.2632 mask_loss: 6.5837 roll_mask_loss: 6.9974 density_loss: 8.6955 unmask_loss: 7.5620 Lr: 0.00257
[2025-12-10 17:19:18,335 INFO misc.py line 117 4140988] Train: [1/10][2095/7400] Data 0.004 (0.004) Batch 0.447 (0.617) Remain 12:19:30 loss: 6.9624 mask_loss: 5.9870 roll_mask_loss: 6.7389 density_loss: 9.7066 unmask_loss: 7.3678 Lr: 0.00257
[2025-12-10 17:19:18,839 INFO misc.py line 117 4140988] Train: [1/10][2096/7400] Data 0.004 (0.004) Batch 0.504 (0.617) Remain 12:19:25 loss: 6.8809 mask_loss: 6.0221 roll_mask_loss: 6.8137 density_loss: 9.1609 unmask_loss: 7.1606 Lr: 0.00257
[2025-12-10 17:19:19,498 INFO misc.py line 117 4140988] Train: [1/10][2097/7400] Data 0.004 (0.004) Batch 0.659 (0.617) Remain 12:19:26 loss: 7.8542 mask_loss: 7.4211 roll_mask_loss: 7.6050 density_loss: 8.6467 unmask_loss: 8.0225 Lr: 0.00257
[2025-12-10 17:19:20,122 INFO misc.py line 117 4140988] Train: [1/10][2098/7400] Data 0.004 (0.004) Batch 0.625 (0.617) Remain 12:19:26 loss: 6.6865 mask_loss: 5.9553 roll_mask_loss: 6.4582 density_loss: 8.3580 unmask_loss: 6.9991 Lr: 0.00257
[2025-12-10 17:19:20,401 INFO misc.py line 117 4140988] Train: [1/10][2099/7400] Data 0.003 (0.004) Batch 0.279 (0.617) Remain 12:19:14 loss: 8.3209 mask_loss: 7.7484 roll_mask_loss: 9.0252 density_loss: 8.5538 unmask_loss: 8.0839 Lr: 0.00258
[2025-12-10 17:19:21,026 INFO misc.py line 117 4140988] Train: [1/10][2100/7400] Data 0.003 (0.004) Batch 0.625 (0.617) Remain 12:19:13 loss: 7.8718 mask_loss: 7.3454 roll_mask_loss: 8.2984 density_loss: 8.8452 unmask_loss: 7.7449 Lr: 0.00258
[2025-12-10 17:19:21,740 INFO misc.py line 117 4140988] Train: [1/10][2101/7400] Data 0.003 (0.004) Batch 0.713 (0.617) Remain 12:19:16 loss: 6.8844 mask_loss: 5.9250 roll_mask_loss: 6.9670 density_loss: 9.2786 unmask_loss: 7.1373 Lr: 0.00258
[2025-12-10 17:19:22,293 INFO misc.py line 117 4140988] Train: [1/10][2102/7400] Data 0.003 (0.004) Batch 0.553 (0.617) Remain 12:19:13 loss: 7.1507 mask_loss: 6.4695 roll_mask_loss: 7.4563 density_loss: 8.7833 unmask_loss: 7.1628 Lr: 0.00258
[2025-12-10 17:19:22,886 INFO misc.py line 117 4140988] Train: [1/10][2103/7400] Data 0.004 (0.004) Batch 0.594 (0.617) Remain 12:19:12 loss: 7.2083 mask_loss: 6.5462 roll_mask_loss: 7.1651 density_loss: 9.3736 unmask_loss: 7.3734 Lr: 0.00258
[2025-12-10 17:19:23,563 INFO misc.py line 117 4140988] Train: [1/10][2104/7400] Data 0.003 (0.004) Batch 0.677 (0.617) Remain 12:19:13 loss: 6.9277 mask_loss: 6.1726 roll_mask_loss: 6.7484 density_loss: 8.7010 unmask_loss: 7.2209 Lr: 0.00258
[2025-12-10 17:19:24,199 INFO misc.py line 117 4140988] Train: [1/10][2105/7400] Data 0.003 (0.004) Batch 0.635 (0.617) Remain 12:19:13 loss: 6.7214 mask_loss: 5.6870 roll_mask_loss: 6.5034 density_loss: 9.5530 unmask_loss: 7.1565 Lr: 0.00258
[2025-12-10 17:19:24,889 INFO misc.py line 117 4140988] Train: [1/10][2106/7400] Data 0.004 (0.004) Batch 0.690 (0.617) Remain 12:19:15 loss: 7.0371 mask_loss: 6.2374 roll_mask_loss: 6.9781 density_loss: 9.1135 unmask_loss: 7.2842 Lr: 0.00259
[2025-12-10 17:19:25,441 INFO misc.py line 117 4140988] Train: [1/10][2107/7400] Data 0.004 (0.004) Batch 0.552 (0.617) Remain 12:19:12 loss: 8.4373 mask_loss: 8.2599 roll_mask_loss: 8.3521 density_loss: 8.4146 unmask_loss: 8.4002 Lr: 0.00259
[2025-12-10 17:19:25,973 INFO misc.py line 117 4140988] Train: [1/10][2108/7400] Data 0.004 (0.004) Batch 0.532 (0.617) Remain 12:19:09 loss: 7.7833 mask_loss: 7.1771 roll_mask_loss: 7.7359 density_loss: 8.5167 unmask_loss: 7.9398 Lr: 0.00259
[2025-12-10 17:19:26,455 INFO misc.py line 117 4140988] Train: [1/10][2109/7400] Data 0.004 (0.004) Batch 0.481 (0.617) Remain 12:19:03 loss: 6.8872 mask_loss: 6.0211 roll_mask_loss: 6.5816 density_loss: 9.7416 unmask_loss: 7.2782 Lr: 0.00259
[2025-12-10 17:19:26,879 INFO misc.py line 117 4140988] Train: [1/10][2110/7400] Data 0.004 (0.004) Batch 0.425 (0.617) Remain 12:18:56 loss: 7.4225 mask_loss: 6.8294 roll_mask_loss: 7.2584 density_loss: 8.5363 unmask_loss: 7.6304 Lr: 0.00259
[2025-12-10 17:19:27,560 INFO misc.py line 117 4140988] Train: [1/10][2111/7400] Data 0.004 (0.004) Batch 0.681 (0.617) Remain 12:18:58 loss: 6.8591 mask_loss: 5.5763 roll_mask_loss: 6.9339 density_loss: 9.8278 unmask_loss: 7.2665 Lr: 0.00259
[2025-12-10 17:19:28,067 INFO misc.py line 117 4140988] Train: [1/10][2112/7400] Data 0.004 (0.004) Batch 0.507 (0.617) Remain 12:18:54 loss: 7.5362 mask_loss: 7.2726 roll_mask_loss: 7.1441 density_loss: 8.8332 unmask_loss: 7.6873 Lr: 0.00259
[2025-12-10 17:19:28,629 INFO misc.py line 117 4140988] Train: [1/10][2113/7400] Data 0.003 (0.004) Batch 0.561 (0.617) Remain 12:18:51 loss: 7.7915 mask_loss: 7.5155 roll_mask_loss: 7.7264 density_loss: 8.6885 unmask_loss: 7.7883 Lr: 0.00260
[2025-12-10 17:19:29,018 INFO misc.py line 117 4140988] Train: [1/10][2114/7400] Data 0.004 (0.004) Batch 0.390 (0.617) Remain 12:18:43 loss: 7.4679 mask_loss: 6.8071 roll_mask_loss: 7.4110 density_loss: 8.6982 unmask_loss: 7.6528 Lr: 0.00260
[2025-12-10 17:19:29,313 INFO misc.py line 117 4140988] Train: [1/10][2115/7400] Data 0.004 (0.004) Batch 0.294 (0.616) Remain 12:18:31 loss: 8.3069 mask_loss: 7.7626 roll_mask_loss: 8.4293 density_loss: 8.2492 unmask_loss: 8.3528 Lr: 0.00260
[2025-12-10 17:19:30,132 INFO misc.py line 117 4140988] Train: [1/10][2116/7400] Data 0.004 (0.004) Batch 0.819 (0.617) Remain 12:18:37 loss: 6.8946 mask_loss: 5.9608 roll_mask_loss: 6.9227 density_loss: 9.4685 unmask_loss: 7.1581 Lr: 0.00260
[2025-12-10 17:19:30,668 INFO misc.py line 117 4140988] Train: [1/10][2117/7400] Data 0.004 (0.004) Batch 0.536 (0.616) Remain 12:18:34 loss: 7.7946 mask_loss: 7.2355 roll_mask_loss: 7.7585 density_loss: 8.9420 unmask_loss: 7.9134 Lr: 0.00260
[2025-12-10 17:19:31,309 INFO misc.py line 117 4140988] Train: [1/10][2118/7400] Data 0.004 (0.004) Batch 0.641 (0.616) Remain 12:18:34 loss: 7.1924 mask_loss: 6.2169 roll_mask_loss: 6.8329 density_loss: 9.5361 unmask_loss: 7.6691 Lr: 0.00260
[2025-12-10 17:19:31,888 INFO misc.py line 117 4140988] Train: [1/10][2119/7400] Data 0.004 (0.004) Batch 0.579 (0.616) Remain 12:18:32 loss: 8.2149 mask_loss: 7.9488 roll_mask_loss: 8.1089 density_loss: 8.5238 unmask_loss: 8.2304 Lr: 0.00261
[2025-12-10 17:19:32,448 INFO misc.py line 117 4140988] Train: [1/10][2120/7400] Data 0.004 (0.004) Batch 0.560 (0.616) Remain 12:18:30 loss: 7.1447 mask_loss: 6.3489 roll_mask_loss: 6.8303 density_loss: 9.3234 unmask_loss: 7.5134 Lr: 0.00261
[2025-12-10 17:19:32,960 INFO misc.py line 117 4140988] Train: [1/10][2121/7400] Data 0.003 (0.004) Batch 0.512 (0.616) Remain 12:18:26 loss: 8.2047 mask_loss: 8.0358 roll_mask_loss: 8.5470 density_loss: 8.3874 unmask_loss: 7.9503 Lr: 0.00261
[2025-12-10 17:19:33,510 INFO misc.py line 117 4140988] Train: [1/10][2122/7400] Data 0.004 (0.004) Batch 0.550 (0.616) Remain 12:18:23 loss: 7.1273 mask_loss: 6.3528 roll_mask_loss: 7.0101 density_loss: 9.0454 unmask_loss: 7.3923 Lr: 0.00261
[2025-12-10 17:19:33,848 INFO misc.py line 117 4140988] Train: [1/10][2123/7400] Data 0.004 (0.004) Batch 0.338 (0.616) Remain 12:18:13 loss: 7.1143 mask_loss: 6.1591 roll_mask_loss: 6.9975 density_loss: 9.3919 unmask_loss: 7.4624 Lr: 0.00261
[2025-12-10 17:19:34,613 INFO misc.py line 117 4140988] Train: [1/10][2124/7400] Data 0.004 (0.004) Batch 0.765 (0.616) Remain 12:18:17 loss: 6.8681 mask_loss: 5.6291 roll_mask_loss: 6.6286 density_loss: 9.6658 unmask_loss: 7.4140 Lr: 0.00261
[2025-12-10 17:19:35,345 INFO misc.py line 117 4140988] Train: [1/10][2125/7400] Data 0.004 (0.004) Batch 0.731 (0.616) Remain 12:18:20 loss: 6.9263 mask_loss: 6.0350 roll_mask_loss: 6.8546 density_loss: 8.8613 unmask_loss: 7.2306 Lr: 0.00261
[2025-12-10 17:19:35,725 INFO misc.py line 117 4140988] Train: [1/10][2126/7400] Data 0.004 (0.004) Batch 0.380 (0.616) Remain 12:18:12 loss: 8.1018 mask_loss: 7.2118 roll_mask_loss: 8.1926 density_loss: 8.4759 unmask_loss: 8.3319 Lr: 0.00262
[2025-12-10 17:19:36,370 INFO misc.py line 117 4140988] Train: [1/10][2127/7400] Data 0.004 (0.004) Batch 0.645 (0.616) Remain 12:18:12 loss: 7.0600 mask_loss: 6.4005 roll_mask_loss: 6.7985 density_loss: 8.8488 unmask_loss: 7.3435 Lr: 0.00262
[2025-12-10 17:19:37,073 INFO misc.py line 117 4140988] Train: [1/10][2128/7400] Data 0.004 (0.004) Batch 0.703 (0.616) Remain 12:18:15 loss: 7.1334 mask_loss: 6.3004 roll_mask_loss: 7.1308 density_loss: 9.3611 unmask_loss: 7.3640 Lr: 0.00262
[2025-12-10 17:19:37,633 INFO misc.py line 117 4140988] Train: [1/10][2129/7400] Data 0.004 (0.004) Batch 0.560 (0.616) Remain 12:18:12 loss: 7.8405 mask_loss: 7.4703 roll_mask_loss: 7.7891 density_loss: 8.7916 unmask_loss: 7.8754 Lr: 0.00262
[2025-12-10 17:19:38,168 INFO misc.py line 117 4140988] Train: [1/10][2130/7400] Data 0.004 (0.004) Batch 0.536 (0.616) Remain 12:18:09 loss: 8.1044 mask_loss: 7.6946 roll_mask_loss: 8.3561 density_loss: 8.6893 unmask_loss: 8.0097 Lr: 0.00262
[2025-12-10 17:19:38,873 INFO misc.py line 117 4140988] Train: [1/10][2131/7400] Data 0.004 (0.004) Batch 0.705 (0.616) Remain 12:18:11 loss: 6.9203 mask_loss: 6.2063 roll_mask_loss: 6.8515 density_loss: 9.3076 unmask_loss: 7.1256 Lr: 0.00262
[2025-12-10 17:19:39,414 INFO misc.py line 117 4140988] Train: [1/10][2132/7400] Data 0.003 (0.004) Batch 0.541 (0.616) Remain 12:18:08 loss: 8.0296 mask_loss: 7.5880 roll_mask_loss: 7.8967 density_loss: 8.8397 unmask_loss: 8.1399 Lr: 0.00262
[2025-12-10 17:19:39,950 INFO misc.py line 117 4140988] Train: [1/10][2133/7400] Data 0.003 (0.004) Batch 0.536 (0.616) Remain 12:18:05 loss: 7.3403 mask_loss: 6.4772 roll_mask_loss: 7.1985 density_loss: 9.5304 unmask_loss: 7.6523 Lr: 0.00263
[2025-12-10 17:19:40,256 INFO misc.py line 117 4140988] Train: [1/10][2134/7400] Data 0.003 (0.004) Batch 0.306 (0.616) Remain 12:17:53 loss: 7.3518 mask_loss: 6.7335 roll_mask_loss: 7.1379 density_loss: 9.5188 unmask_loss: 7.5776 Lr: 0.00263
[2025-12-10 17:19:40,835 INFO misc.py line 117 4140988] Train: [1/10][2135/7400] Data 0.003 (0.004) Batch 0.579 (0.616) Remain 12:17:52 loss: 7.6736 mask_loss: 7.1632 roll_mask_loss: 7.4529 density_loss: 8.2226 unmask_loss: 7.8747 Lr: 0.00263
[2025-12-10 17:19:41,172 INFO misc.py line 117 4140988] Train: [1/10][2136/7400] Data 0.003 (0.004) Batch 0.338 (0.616) Remain 12:17:42 loss: 7.6365 mask_loss: 7.2447 roll_mask_loss: 7.7334 density_loss: 8.5171 unmask_loss: 7.6136 Lr: 0.00263
[2025-12-10 17:19:41,748 INFO misc.py line 117 4140988] Train: [1/10][2137/7400] Data 0.003 (0.004) Batch 0.575 (0.616) Remain 12:17:40 loss: 7.1885 mask_loss: 6.5003 roll_mask_loss: 7.0767 density_loss: 7.9103 unmask_loss: 7.4303 Lr: 0.00263
[2025-12-10 17:19:42,020 INFO misc.py line 117 4140988] Train: [1/10][2138/7400] Data 0.003 (0.004) Batch 0.272 (0.616) Remain 12:17:27 loss: 7.7699 mask_loss: 6.3114 roll_mask_loss: 7.5473 density_loss: 8.9462 unmask_loss: 8.4315 Lr: 0.00263
[2025-12-10 17:19:42,551 INFO misc.py line 117 4140988] Train: [1/10][2139/7400] Data 0.003 (0.004) Batch 0.531 (0.616) Remain 12:17:24 loss: 8.3692 mask_loss: 8.0029 roll_mask_loss: 8.3554 density_loss: 8.4492 unmask_loss: 8.3903 Lr: 0.00264
[2025-12-10 17:19:43,210 INFO misc.py line 117 4140988] Train: [1/10][2140/7400] Data 0.004 (0.004) Batch 0.659 (0.616) Remain 12:17:25 loss: 7.4947 mask_loss: 7.1251 roll_mask_loss: 7.3472 density_loss: 8.2688 unmask_loss: 7.5878 Lr: 0.00264
[2025-12-10 17:19:43,874 INFO misc.py line 117 4140988] Train: [1/10][2141/7400] Data 0.003 (0.004) Batch 0.665 (0.616) Remain 12:17:26 loss: 7.3828 mask_loss: 6.8987 roll_mask_loss: 7.5863 density_loss: 8.6654 unmask_loss: 7.3498 Lr: 0.00264
[2025-12-10 17:19:44,675 INFO misc.py line 117 4140988] Train: [1/10][2142/7400] Data 0.003 (0.004) Batch 0.800 (0.616) Remain 12:17:31 loss: 6.8020 mask_loss: 5.8692 roll_mask_loss: 6.5117 density_loss: 8.8012 unmask_loss: 7.2374 Lr: 0.00264
[2025-12-10 17:19:45,203 INFO misc.py line 117 4140988] Train: [1/10][2143/7400] Data 0.003 (0.004) Batch 0.529 (0.616) Remain 12:17:28 loss: 8.1293 mask_loss: 7.8237 roll_mask_loss: 7.9441 density_loss: 8.6676 unmask_loss: 8.2015 Lr: 0.00264
[2025-12-10 17:19:45,665 INFO misc.py line 117 4140988] Train: [1/10][2144/7400] Data 0.003 (0.004) Batch 0.462 (0.616) Remain 12:17:22 loss: 8.2403 mask_loss: 8.0804 roll_mask_loss: 8.1471 density_loss: 8.5102 unmask_loss: 8.1968 Lr: 0.00264
[2025-12-10 17:19:46,170 INFO misc.py line 117 4140988] Train: [1/10][2145/7400] Data 0.003 (0.004) Batch 0.504 (0.616) Remain 12:17:18 loss: 8.1444 mask_loss: 7.9096 roll_mask_loss: 8.0346 density_loss: 8.6466 unmask_loss: 8.1438 Lr: 0.00264
[2025-12-10 17:19:46,737 INFO misc.py line 117 4140988] Train: [1/10][2146/7400] Data 0.003 (0.004) Batch 0.567 (0.616) Remain 12:17:16 loss: 7.1635 mask_loss: 6.4063 roll_mask_loss: 7.1875 density_loss: 8.9558 unmask_loss: 7.3509 Lr: 0.00265
[2025-12-10 17:19:47,371 INFO misc.py line 117 4140988] Train: [1/10][2147/7400] Data 0.003 (0.004) Batch 0.634 (0.616) Remain 12:17:15 loss: 6.8266 mask_loss: 5.8847 roll_mask_loss: 6.7072 density_loss: 9.8156 unmask_loss: 7.1609 Lr: 0.00265
[2025-12-10 17:19:48,047 INFO misc.py line 117 4140988] Train: [1/10][2148/7400] Data 0.004 (0.004) Batch 0.675 (0.616) Remain 12:17:17 loss: 7.6096 mask_loss: 7.1306 roll_mask_loss: 7.3973 density_loss: 8.9749 unmask_loss: 7.7758 Lr: 0.00265
[2025-12-10 17:19:48,777 INFO misc.py line 117 4140988] Train: [1/10][2149/7400] Data 0.004 (0.004) Batch 0.731 (0.616) Remain 12:17:20 loss: 6.9213 mask_loss: 5.8339 roll_mask_loss: 6.8029 density_loss: 8.8301 unmask_loss: 7.3476 Lr: 0.00265
[2025-12-10 17:19:49,433 INFO misc.py line 117 4140988] Train: [1/10][2150/7400] Data 0.004 (0.004) Batch 0.656 (0.616) Remain 12:17:21 loss: 7.5280 mask_loss: 7.0237 roll_mask_loss: 7.3179 density_loss: 8.4616 unmask_loss: 7.7159 Lr: 0.00265
[2025-12-10 17:19:50,097 INFO misc.py line 117 4140988] Train: [1/10][2151/7400] Data 0.004 (0.004) Batch 0.664 (0.616) Remain 12:17:22 loss: 6.8272 mask_loss: 5.8546 roll_mask_loss: 6.4763 density_loss: 9.5379 unmask_loss: 7.2982 Lr: 0.00265
[2025-12-10 17:19:50,971 INFO misc.py line 117 4140988] Train: [1/10][2152/7400] Data 0.004 (0.004) Batch 0.873 (0.616) Remain 12:17:30 loss: 6.8403 mask_loss: 5.9091 roll_mask_loss: 6.6760 density_loss: 9.6061 unmask_loss: 7.1958 Lr: 0.00265
[2025-12-10 17:19:51,495 INFO misc.py line 117 4140988] Train: [1/10][2153/7400] Data 0.004 (0.004) Batch 0.525 (0.616) Remain 12:17:26 loss: 8.4729 mask_loss: 8.3872 roll_mask_loss: 8.3983 density_loss: 8.3927 unmask_loss: 8.3853 Lr: 0.00266
[2025-12-10 17:19:52,088 INFO misc.py line 117 4140988] Train: [1/10][2154/7400] Data 0.004 (0.004) Batch 0.593 (0.616) Remain 12:17:25 loss: 6.9697 mask_loss: 5.9759 roll_mask_loss: 6.8315 density_loss: 9.5041 unmask_loss: 7.3456 Lr: 0.00266
[2025-12-10 17:19:52,801 INFO misc.py line 117 4140988] Train: [1/10][2155/7400] Data 0.004 (0.004) Batch 0.713 (0.616) Remain 12:17:27 loss: 6.7471 mask_loss: 5.6638 roll_mask_loss: 6.4543 density_loss: 9.5590 unmask_loss: 7.2441 Lr: 0.00266
[2025-12-10 17:19:53,345 INFO misc.py line 117 4140988] Train: [1/10][2156/7400] Data 0.004 (0.004) Batch 0.544 (0.616) Remain 12:17:24 loss: 7.3188 mask_loss: 6.3036 roll_mask_loss: 7.8058 density_loss: 9.2367 unmask_loss: 7.3981 Lr: 0.00266
[2025-12-10 17:19:53,923 INFO misc.py line 117 4140988] Train: [1/10][2157/7400] Data 0.004 (0.004) Batch 0.578 (0.616) Remain 12:17:23 loss: 7.2747 mask_loss: 6.5371 roll_mask_loss: 7.0962 density_loss: 8.9458 unmask_loss: 7.5538 Lr: 0.00266
[2025-12-10 17:19:54,561 INFO misc.py line 117 4140988] Train: [1/10][2158/7400] Data 0.004 (0.004) Batch 0.639 (0.616) Remain 12:17:23 loss: 7.5825 mask_loss: 6.5642 roll_mask_loss: 7.8566 density_loss: 8.7389 unmask_loss: 7.7798 Lr: 0.00266
[2025-12-10 17:19:55,234 INFO misc.py line 117 4140988] Train: [1/10][2159/7400] Data 0.004 (0.004) Batch 0.674 (0.616) Remain 12:17:24 loss: 7.2319 mask_loss: 6.4327 roll_mask_loss: 7.1492 density_loss: 8.6181 unmask_loss: 7.5005 Lr: 0.00266
[2025-12-10 17:19:55,826 INFO misc.py line 117 4140988] Train: [1/10][2160/7400] Data 0.003 (0.004) Batch 0.592 (0.616) Remain 12:17:23 loss: 6.8539 mask_loss: 5.9938 roll_mask_loss: 6.5700 density_loss: 7.9346 unmask_loss: 7.2672 Lr: 0.00267
[2025-12-10 17:19:56,413 INFO misc.py line 117 4140988] Train: [1/10][2161/7400] Data 0.003 (0.004) Batch 0.587 (0.616) Remain 12:17:21 loss: 6.9251 mask_loss: 5.9494 roll_mask_loss: 6.8859 density_loss: 9.5476 unmask_loss: 7.2416 Lr: 0.00267
[2025-12-10 17:19:57,111 INFO misc.py line 117 4140988] Train: [1/10][2162/7400] Data 0.003 (0.004) Batch 0.698 (0.616) Remain 12:17:23 loss: 7.1053 mask_loss: 6.3018 roll_mask_loss: 7.2135 density_loss: 8.7187 unmask_loss: 7.2785 Lr: 0.00267
[2025-12-10 17:19:57,757 INFO misc.py line 117 4140988] Train: [1/10][2163/7400] Data 0.003 (0.004) Batch 0.646 (0.616) Remain 12:17:23 loss: 6.9465 mask_loss: 6.3058 roll_mask_loss: 6.7050 density_loss: 9.1752 unmask_loss: 7.2041 Lr: 0.00267
[2025-12-10 17:19:58,402 INFO misc.py line 117 4140988] Train: [1/10][2164/7400] Data 0.003 (0.004) Batch 0.645 (0.616) Remain 12:17:24 loss: 7.4323 mask_loss: 6.8214 roll_mask_loss: 7.4399 density_loss: 8.5311 unmask_loss: 7.5634 Lr: 0.00267
[2025-12-10 17:19:59,010 INFO misc.py line 117 4140988] Train: [1/10][2165/7400] Data 0.003 (0.004) Batch 0.608 (0.616) Remain 12:17:23 loss: 8.3187 mask_loss: 8.1171 roll_mask_loss: 8.2334 density_loss: 8.4378 unmask_loss: 8.2934 Lr: 0.00267
[2025-12-10 17:19:59,382 INFO misc.py line 117 4140988] Train: [1/10][2166/7400] Data 0.004 (0.004) Batch 0.372 (0.616) Remain 12:17:14 loss: 7.0966 mask_loss: 6.3436 roll_mask_loss: 6.8782 density_loss: 9.3687 unmask_loss: 7.3949 Lr: 0.00268
[2025-12-10 17:19:59,849 INFO misc.py line 117 4140988] Train: [1/10][2167/7400] Data 0.004 (0.004) Batch 0.466 (0.616) Remain 12:17:09 loss: 8.4133 mask_loss: 8.3270 roll_mask_loss: 8.3346 density_loss: 8.3355 unmask_loss: 8.3290 Lr: 0.00268
[2025-12-10 17:20:00,610 INFO misc.py line 117 4140988] Train: [1/10][2168/7400] Data 0.004 (0.004) Batch 0.761 (0.616) Remain 12:17:13 loss: 6.8587 mask_loss: 6.1277 roll_mask_loss: 6.6016 density_loss: 8.7104 unmask_loss: 7.1786 Lr: 0.00268
[2025-12-10 17:20:01,317 INFO misc.py line 117 4140988] Train: [1/10][2169/7400] Data 0.004 (0.004) Batch 0.707 (0.616) Remain 12:17:15 loss: 6.8730 mask_loss: 6.0629 roll_mask_loss: 6.7836 density_loss: 9.9200 unmask_loss: 7.1244 Lr: 0.00268
[2025-12-10 17:20:01,899 INFO misc.py line 117 4140988] Train: [1/10][2170/7400] Data 0.004 (0.004) Batch 0.583 (0.616) Remain 12:17:14 loss: 7.4749 mask_loss: 7.0727 roll_mask_loss: 7.4959 density_loss: 8.5282 unmask_loss: 7.4949 Lr: 0.00268
[2025-12-10 17:20:02,555 INFO misc.py line 117 4140988] Train: [1/10][2171/7400] Data 0.003 (0.004) Batch 0.655 (0.616) Remain 12:17:14 loss: 6.8553 mask_loss: 5.8243 roll_mask_loss: 6.7527 density_loss: 9.8788 unmask_loss: 7.2246 Lr: 0.00268
[2025-12-10 17:20:03,059 INFO misc.py line 117 4140988] Train: [1/10][2172/7400] Data 0.004 (0.004) Batch 0.505 (0.616) Remain 12:17:10 loss: 8.4362 mask_loss: 8.2502 roll_mask_loss: 8.3674 density_loss: 8.3711 unmask_loss: 8.3961 Lr: 0.00268
[2025-12-10 17:20:03,644 INFO misc.py line 117 4140988] Train: [1/10][2173/7400] Data 0.004 (0.004) Batch 0.585 (0.616) Remain 12:17:08 loss: 6.9250 mask_loss: 6.0082 roll_mask_loss: 6.9553 density_loss: 8.8795 unmask_loss: 7.1907 Lr: 0.00269
[2025-12-10 17:20:04,344 INFO misc.py line 117 4140988] Train: [1/10][2174/7400] Data 0.003 (0.004) Batch 0.699 (0.616) Remain 12:17:10 loss: 7.5175 mask_loss: 6.7352 roll_mask_loss: 7.3725 density_loss: 8.7831 unmask_loss: 7.8056 Lr: 0.00269
[2025-12-10 17:20:05,037 INFO misc.py line 117 4140988] Train: [1/10][2175/7400] Data 0.004 (0.004) Batch 0.694 (0.616) Remain 12:17:12 loss: 6.8816 mask_loss: 5.9500 roll_mask_loss: 6.7577 density_loss: 9.0620 unmask_loss: 7.2281 Lr: 0.00269
[2025-12-10 17:20:05,652 INFO misc.py line 117 4140988] Train: [1/10][2176/7400] Data 0.003 (0.004) Batch 0.616 (0.616) Remain 12:17:12 loss: 7.0851 mask_loss: 6.3066 roll_mask_loss: 7.1021 density_loss: 8.9679 unmask_loss: 7.2865 Lr: 0.00269
[2025-12-10 17:20:06,372 INFO misc.py line 117 4140988] Train: [1/10][2177/7400] Data 0.003 (0.004) Batch 0.719 (0.616) Remain 12:17:15 loss: 7.3850 mask_loss: 6.7471 roll_mask_loss: 7.3330 density_loss: 8.0689 unmask_loss: 7.5686 Lr: 0.00269
[2025-12-10 17:20:06,982 INFO misc.py line 117 4140988] Train: [1/10][2178/7400] Data 0.004 (0.004) Batch 0.610 (0.616) Remain 12:17:14 loss: 6.9128 mask_loss: 5.9295 roll_mask_loss: 6.6289 density_loss: 9.3131 unmask_loss: 7.3601 Lr: 0.00269
[2025-12-10 17:20:07,470 INFO misc.py line 117 4140988] Train: [1/10][2179/7400] Data 0.003 (0.004) Batch 0.488 (0.616) Remain 12:17:09 loss: 8.1493 mask_loss: 7.8063 roll_mask_loss: 8.0779 density_loss: 8.2956 unmask_loss: 8.1905 Lr: 0.00269
[2025-12-10 17:20:07,990 INFO misc.py line 117 4140988] Train: [1/10][2180/7400] Data 0.003 (0.004) Batch 0.520 (0.616) Remain 12:17:05 loss: 7.6132 mask_loss: 6.8566 roll_mask_loss: 7.3566 density_loss: 9.2225 unmask_loss: 7.9354 Lr: 0.00270
[2025-12-10 17:20:08,604 INFO misc.py line 117 4140988] Train: [1/10][2181/7400] Data 0.003 (0.004) Batch 0.613 (0.616) Remain 12:17:04 loss: 6.8157 mask_loss: 6.0861 roll_mask_loss: 6.6812 density_loss: 8.6666 unmask_loss: 7.0745 Lr: 0.00270
[2025-12-10 17:20:09,178 INFO misc.py line 117 4140988] Train: [1/10][2182/7400] Data 0.004 (0.004) Batch 0.574 (0.616) Remain 12:17:03 loss: 7.0289 mask_loss: 6.2527 roll_mask_loss: 7.1525 density_loss: 8.9483 unmask_loss: 7.1762 Lr: 0.00270
[2025-12-10 17:20:09,638 INFO misc.py line 117 4140988] Train: [1/10][2183/7400] Data 0.003 (0.004) Batch 0.461 (0.616) Remain 12:16:57 loss: 8.4060 mask_loss: 8.3169 roll_mask_loss: 8.3148 density_loss: 8.3424 unmask_loss: 8.3294 Lr: 0.00270
[2025-12-10 17:20:10,317 INFO misc.py line 117 4140988] Train: [1/10][2184/7400] Data 0.003 (0.004) Batch 0.679 (0.616) Remain 12:16:58 loss: 6.9093 mask_loss: 6.1906 roll_mask_loss: 6.6028 density_loss: 8.3019 unmask_loss: 7.2559 Lr: 0.00270
[2025-12-10 17:20:10,889 INFO misc.py line 117 4140988] Train: [1/10][2185/7400] Data 0.003 (0.004) Batch 0.571 (0.616) Remain 12:16:56 loss: 7.4094 mask_loss: 6.8001 roll_mask_loss: 7.3109 density_loss: 8.8097 unmask_loss: 7.5871 Lr: 0.00270
[2025-12-10 17:20:11,501 INFO misc.py line 117 4140988] Train: [1/10][2186/7400] Data 0.004 (0.004) Batch 0.612 (0.616) Remain 12:16:55 loss: 8.3878 mask_loss: 7.9083 roll_mask_loss: 8.5124 density_loss: 8.3647 unmask_loss: 8.3980 Lr: 0.00270
[2025-12-10 17:20:12,253 INFO misc.py line 117 4140988] Train: [1/10][2187/7400] Data 0.004 (0.004) Batch 0.752 (0.616) Remain 12:16:59 loss: 6.8668 mask_loss: 6.0885 roll_mask_loss: 6.7327 density_loss: 9.2876 unmask_loss: 7.1373 Lr: 0.00271
[2025-12-10 17:20:12,558 INFO misc.py line 117 4140988] Train: [1/10][2188/7400] Data 0.004 (0.004) Batch 0.305 (0.616) Remain 12:16:48 loss: 7.8461 mask_loss: 7.3446 roll_mask_loss: 7.5880 density_loss: 7.9423 unmask_loss: 8.0671 Lr: 0.00271
[2025-12-10 17:20:13,287 INFO misc.py line 117 4140988] Train: [1/10][2189/7400] Data 0.004 (0.004) Batch 0.729 (0.616) Remain 12:16:52 loss: 7.1536 mask_loss: 6.1856 roll_mask_loss: 7.3117 density_loss: 8.7701 unmask_loss: 7.3832 Lr: 0.00271
[2025-12-10 17:20:13,833 INFO misc.py line 117 4140988] Train: [1/10][2190/7400] Data 0.004 (0.004) Batch 0.546 (0.616) Remain 12:16:49 loss: 7.9410 mask_loss: 7.6111 roll_mask_loss: 7.7751 density_loss: 8.4242 unmask_loss: 8.0205 Lr: 0.00271
[2025-12-10 17:20:14,342 INFO misc.py line 117 4140988] Train: [1/10][2191/7400] Data 0.004 (0.004) Batch 0.510 (0.616) Remain 12:16:45 loss: 8.4089 mask_loss: 8.2968 roll_mask_loss: 8.3199 density_loss: 8.3416 unmask_loss: 8.3427 Lr: 0.00271
[2025-12-10 17:20:14,977 INFO misc.py line 117 4140988] Train: [1/10][2192/7400] Data 0.003 (0.004) Batch 0.635 (0.616) Remain 12:16:45 loss: 7.2570 mask_loss: 6.5577 roll_mask_loss: 7.0743 density_loss: 9.2444 unmask_loss: 7.5131 Lr: 0.00271
[2025-12-10 17:20:15,277 INFO misc.py line 117 4140988] Train: [1/10][2193/7400] Data 0.003 (0.004) Batch 0.300 (0.615) Remain 12:16:34 loss: 7.7635 mask_loss: 7.3151 roll_mask_loss: 7.5532 density_loss: 8.3439 unmask_loss: 7.9261 Lr: 0.00271
[2025-12-10 17:20:15,813 INFO misc.py line 117 4140988] Train: [1/10][2194/7400] Data 0.004 (0.004) Batch 0.536 (0.615) Remain 12:16:30 loss: 6.9840 mask_loss: 6.1816 roll_mask_loss: 6.9558 density_loss: 8.7423 unmask_loss: 7.2244 Lr: 0.00272
[2025-12-10 17:20:16,563 INFO misc.py line 117 4140988] Train: [1/10][2195/7400] Data 0.004 (0.004) Batch 0.749 (0.615) Remain 12:16:34 loss: 6.9804 mask_loss: 6.0633 roll_mask_loss: 6.8594 density_loss: 8.6704 unmask_loss: 7.3261 Lr: 0.00272
[2025-12-10 17:20:17,320 INFO misc.py line 117 4140988] Train: [1/10][2196/7400] Data 0.004 (0.004) Batch 0.757 (0.616) Remain 12:16:38 loss: 7.4552 mask_loss: 6.7006 roll_mask_loss: 7.1870 density_loss: 8.7724 unmask_loss: 7.7911 Lr: 0.00272
[2025-12-10 17:20:18,040 INFO misc.py line 117 4140988] Train: [1/10][2197/7400] Data 0.004 (0.004) Batch 0.720 (0.616) Remain 12:16:41 loss: 7.0200 mask_loss: 6.2702 roll_mask_loss: 6.7147 density_loss: 8.6578 unmask_loss: 7.3744 Lr: 0.00272
[2025-12-10 17:20:18,674 INFO misc.py line 117 4140988] Train: [1/10][2198/7400] Data 0.004 (0.004) Batch 0.634 (0.616) Remain 12:16:41 loss: 7.8611 mask_loss: 7.3510 roll_mask_loss: 8.1018 density_loss: 8.4253 unmask_loss: 7.8273 Lr: 0.00272
[2025-12-10 17:20:19,147 INFO misc.py line 117 4140988] Train: [1/10][2199/7400] Data 0.004 (0.004) Batch 0.474 (0.616) Remain 12:16:36 loss: 7.1205 mask_loss: 6.5046 roll_mask_loss: 7.0300 density_loss: 9.0989 unmask_loss: 7.2917 Lr: 0.00272
[2025-12-10 17:20:19,717 INFO misc.py line 117 4140988] Train: [1/10][2200/7400] Data 0.003 (0.004) Batch 0.570 (0.616) Remain 12:16:34 loss: 7.4159 mask_loss: 6.7523 roll_mask_loss: 7.1939 density_loss: 8.8542 unmask_loss: 7.6817 Lr: 0.00273
[2025-12-10 17:20:20,399 INFO misc.py line 117 4140988] Train: [1/10][2201/7400] Data 0.003 (0.004) Batch 0.681 (0.616) Remain 12:16:35 loss: 6.8924 mask_loss: 5.9902 roll_mask_loss: 6.8143 density_loss: 8.9537 unmask_loss: 7.2034 Lr: 0.00273
[2025-12-10 17:20:21,155 INFO misc.py line 117 4140988] Train: [1/10][2202/7400] Data 0.004 (0.004) Batch 0.757 (0.616) Remain 12:16:39 loss: 7.1507 mask_loss: 6.4066 roll_mask_loss: 7.0324 density_loss: 8.9990 unmask_loss: 7.4020 Lr: 0.00273
[2025-12-10 17:20:21,968 INFO misc.py line 117 4140988] Train: [1/10][2203/7400] Data 0.004 (0.004) Batch 0.813 (0.616) Remain 12:16:45 loss: 7.0300 mask_loss: 6.0322 roll_mask_loss: 6.7061 density_loss: 9.1280 unmask_loss: 7.5084 Lr: 0.00273
[2025-12-10 17:20:22,726 INFO misc.py line 117 4140988] Train: [1/10][2204/7400] Data 0.004 (0.004) Batch 0.758 (0.616) Remain 12:16:49 loss: 6.9255 mask_loss: 6.0615 roll_mask_loss: 6.8521 density_loss: 8.7647 unmask_loss: 7.2188 Lr: 0.00273
[2025-12-10 17:20:23,353 INFO misc.py line 117 4140988] Train: [1/10][2205/7400] Data 0.004 (0.004) Batch 0.628 (0.616) Remain 12:16:49 loss: 7.9106 mask_loss: 7.6009 roll_mask_loss: 7.8013 density_loss: 8.3835 unmask_loss: 7.9524 Lr: 0.00273
[2025-12-10 17:20:24,090 INFO misc.py line 117 4140988] Train: [1/10][2206/7400] Data 0.003 (0.004) Batch 0.737 (0.616) Remain 12:16:52 loss: 7.0785 mask_loss: 6.3022 roll_mask_loss: 6.9501 density_loss: 8.8451 unmask_loss: 7.3539 Lr: 0.00273
[2025-12-10 17:20:24,816 INFO misc.py line 117 4140988] Train: [1/10][2207/7400] Data 0.003 (0.004) Batch 0.727 (0.616) Remain 12:16:55 loss: 7.0520 mask_loss: 6.5239 roll_mask_loss: 6.8859 density_loss: 8.7864 unmask_loss: 7.2233 Lr: 0.00274
[2025-12-10 17:20:25,369 INFO misc.py line 117 4140988] Train: [1/10][2208/7400] Data 0.003 (0.004) Batch 0.553 (0.616) Remain 12:16:52 loss: 8.1614 mask_loss: 7.2208 roll_mask_loss: 8.3249 density_loss: 8.7103 unmask_loss: 8.3757 Lr: 0.00274
[2025-12-10 17:20:26,009 INFO misc.py line 117 4140988] Train: [1/10][2209/7400] Data 0.003 (0.004) Batch 0.640 (0.616) Remain 12:16:53 loss: 6.9185 mask_loss: 6.0792 roll_mask_loss: 6.8581 density_loss: 8.4903 unmask_loss: 7.1986 Lr: 0.00274
[2025-12-10 17:20:26,281 INFO misc.py line 117 4140988] Train: [1/10][2210/7400] Data 0.004 (0.004) Batch 0.272 (0.616) Remain 12:16:41 loss: 8.3632 mask_loss: 8.1446 roll_mask_loss: 8.2394 density_loss: 8.3589 unmask_loss: 8.3672 Lr: 0.00274
[2025-12-10 17:20:27,038 INFO misc.py line 117 4140988] Train: [1/10][2211/7400] Data 0.003 (0.004) Batch 0.758 (0.616) Remain 12:16:45 loss: 6.7120 mask_loss: 5.6584 roll_mask_loss: 6.3446 density_loss: 9.2061 unmask_loss: 7.2383 Lr: 0.00274
slurmstepd: error: *** JOB 1015908 ON compute-3-16 CANCELLED AT 2025-12-10T17:20:27 ***
